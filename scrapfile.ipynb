{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook is an initial scrap file to play around with Gymnasium's Car Racing environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import environments.cartpole_dualpendulum\n",
    "\n",
    "from stable_baselines3 import PPO, DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n",
      "Using cpu device\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Episode reward: 26.8724\n",
      "Episode reward: 31.90878\n",
      "Episode reward: 67.417238\n",
      "Episode reward: 16.943892\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36       |\n",
      "|    ep_rew_mean      | 35.8     |\n",
      "|    exploration_rate | 0.999    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 5725     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 144      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.499    |\n",
      "|    n_updates        | 10       |\n",
      "----------------------------------\n",
      "Episode reward: 21.947922\n",
      "Episode reward: 34.930441\n",
      "Episode reward: 48.907272\n",
      "Episode reward: 20.960212\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.9     |\n",
      "|    ep_rew_mean      | 33.7     |\n",
      "|    exploration_rate | 0.997    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 5082     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 271      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.445    |\n",
      "|    n_updates        | 42       |\n",
      "----------------------------------\n",
      "Episode reward: 37.870958\n",
      "Episode reward: 43.201721\n",
      "Episode reward: 27.953143\n",
      "Episode reward: 49.894809\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | 35.7     |\n",
      "|    exploration_rate | 0.996    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 4788     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 431      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.387    |\n",
      "|    n_updates        | 82       |\n",
      "----------------------------------\n",
      "Episode reward: 33.831791\n",
      "Episode reward: 20.965723\n",
      "Episode reward: 36.941792\n",
      "Episode reward: 45.900939\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.6     |\n",
      "|    ep_rew_mean      | 35.4     |\n",
      "|    exploration_rate | 0.995    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 4464     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 569      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.324    |\n",
      "|    n_updates        | 117      |\n",
      "----------------------------------\n",
      "Episode reward: 42.93894\n",
      "Episode reward: 38.884602\n",
      "Episode reward: 26.947812\n",
      "Episode reward: 54.532082\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | 36.5     |\n",
      "|    exploration_rate | 0.993    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 4594     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 733      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.233    |\n",
      "|    n_updates        | 158      |\n",
      "----------------------------------\n",
      "Episode reward: 28.803952\n",
      "Episode reward: 28.895089\n",
      "Episode reward: 35.925592\n",
      "Episode reward: 38.770598\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.1     |\n",
      "|    ep_rew_mean      | 35.9     |\n",
      "|    exploration_rate | 0.992    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 4166     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 866      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.153    |\n",
      "|    n_updates        | 191      |\n",
      "----------------------------------\n",
      "Episode reward: 35.936172\n",
      "Episode reward: 40.943478\n",
      "Episode reward: 35.937975\n",
      "Episode reward: 46.923928\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | 36.5     |\n",
      "|    exploration_rate | 0.99     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 4253     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1026     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0919   |\n",
      "|    n_updates        | 231      |\n",
      "----------------------------------\n",
      "Episode reward: 39.942371\n",
      "Episode reward: 44.920855\n",
      "Episode reward: 27.949942\n",
      "Episode reward: 24.714505\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.4     |\n",
      "|    ep_rew_mean      | 36.2     |\n",
      "|    exploration_rate | 0.989    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 4329     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1164     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0572   |\n",
      "|    n_updates        | 265      |\n",
      "----------------------------------\n",
      "Episode reward: 24.848293\n",
      "Episode reward: 50.895665\n",
      "Episode reward: 29.910088\n",
      "Episode reward: 40.741719\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.4     |\n",
      "|    ep_rew_mean      | 36.3     |\n",
      "|    exploration_rate | 0.988    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 4398     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1311     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0285   |\n",
      "|    n_updates        | 302      |\n",
      "----------------------------------\n",
      "Episode reward: 45.658612\n",
      "Episode reward: 27.90845\n",
      "Episode reward: 28.688687\n",
      "Episode reward: 35.842347\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | 36.1     |\n",
      "|    exploration_rate | 0.986    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 4436     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1450     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 337      |\n",
      "----------------------------------\n",
      "Episode reward: 19.936299\n",
      "Episode reward: 41.949735\n",
      "Episode reward: 34.598134\n",
      "Episode reward: 27.944477\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | 35.6     |\n",
      "|    exploration_rate | 0.985    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 4460     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1575     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00662  |\n",
      "|    n_updates        | 368      |\n",
      "----------------------------------\n",
      "Episode reward: 28.863063\n",
      "Episode reward: 41.934281\n",
      "Episode reward: 24.959062\n",
      "Episode reward: 23.818939\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | 35.2     |\n",
      "|    exploration_rate | 0.984    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 4457     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1695     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00571  |\n",
      "|    n_updates        | 398      |\n",
      "----------------------------------\n",
      "Episode reward: 42.946122\n",
      "Episode reward: 19.899156\n",
      "Episode reward: 27.93956\n",
      "Episode reward: 49.85853\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | 35.2     |\n",
      "|    exploration_rate | 0.983    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 4382     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1836     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0019   |\n",
      "|    n_updates        | 433      |\n",
      "----------------------------------\n",
      "Episode reward: 55.88108\n",
      "Episode reward: 70.824279\n",
      "Episode reward: 56.815823\n",
      "Episode reward: 41.93442\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.8     |\n",
      "|    ep_rew_mean      | 36.7     |\n",
      "|    exploration_rate | 0.98     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 4256     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2062     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000478 |\n",
      "|    n_updates        | 490      |\n",
      "----------------------------------\n",
      "Episode reward: 46.648747\n",
      "Episode reward: 33.914988\n",
      "Episode reward: 25.951093\n",
      "Episode reward: 39.928982\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.8     |\n",
      "|    ep_rew_mean      | 36.7     |\n",
      "|    exploration_rate | 0.979    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 4223     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2209     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00207  |\n",
      "|    n_updates        | 527      |\n",
      "----------------------------------\n",
      "Episode reward: 22.959545\n",
      "Episode reward: 22.962405\n",
      "Episode reward: 28.915949\n",
      "Episode reward: 25.95578\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.1     |\n",
      "|    ep_rew_mean      | 36       |\n",
      "|    exploration_rate | 0.978    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 4176     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2310     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00106  |\n",
      "|    n_updates        | 552      |\n",
      "----------------------------------\n",
      "Episode reward: 44.827383\n",
      "Episode reward: 22.961923\n",
      "Episode reward: 28.931797\n",
      "Episode reward: 29.927614\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | 35.7     |\n",
      "|    exploration_rate | 0.977    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 4148     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2437     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0007   |\n",
      "|    n_updates        | 584      |\n",
      "----------------------------------\n",
      "Episode reward: 27.959896\n",
      "Episode reward: 29.938431\n",
      "Episode reward: 39.803139\n",
      "Episode reward: 46.941333\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | 35.7     |\n",
      "|    exploration_rate | 0.975    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 4163     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2582     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000956 |\n",
      "|    n_updates        | 620      |\n",
      "----------------------------------\n",
      "Episode reward: 27.918266\n",
      "Episode reward: 30.858232\n",
      "Episode reward: 37.939076\n",
      "Episode reward: 21.87806\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.5     |\n",
      "|    ep_rew_mean      | 35.4     |\n",
      "|    exploration_rate | 0.974    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 4185     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2701     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00145  |\n",
      "|    n_updates        | 650      |\n",
      "----------------------------------\n",
      "Episode reward: 16.945416\n",
      "Episode reward: 27.808142\n",
      "Episode reward: 33.917758\n",
      "Episode reward: 46.863415\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | 35.2     |\n",
      "|    exploration_rate | 0.973    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 4168     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2827     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000172 |\n",
      "|    n_updates        | 681      |\n",
      "----------------------------------\n",
      "Episode reward: 31.715572\n",
      "Episode reward: 31.881367\n",
      "Episode reward: 42.791753\n",
      "Episode reward: 26.885136\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.2     |\n",
      "|    ep_rew_mean      | 35.1     |\n",
      "|    exploration_rate | 0.972    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 4133     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2961     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00022  |\n",
      "|    n_updates        | 715      |\n",
      "----------------------------------\n",
      "Episode reward: 52.854404\n",
      "Episode reward: 29.796348\n",
      "Episode reward: 62.966114\n",
      "Episode reward: 24.946575\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.6     |\n",
      "|    ep_rew_mean      | 35.5     |\n",
      "|    exploration_rate | 0.97     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 4121     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3133     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000188 |\n",
      "|    n_updates        | 758      |\n",
      "----------------------------------\n",
      "Episode reward: 43.733424\n",
      "Episode reward: 41.947913\n",
      "Episode reward: 38.388509\n",
      "Episode reward: 42.874985\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | 35.7     |\n",
      "|    exploration_rate | 0.969    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 4144     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3301     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000128 |\n",
      "|    n_updates        | 800      |\n",
      "----------------------------------\n",
      "Episode reward: 24.946543\n",
      "Episode reward: 23.952659\n",
      "Episode reward: 23.863453\n",
      "Episode reward: 20.954664\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | 35.2     |\n",
      "|    exploration_rate | 0.968    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 4163     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3395     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00084  |\n",
      "|    n_updates        | 823      |\n",
      "----------------------------------\n",
      "Episode reward: 36.93784\n",
      "Episode reward: 31.905789\n",
      "Episode reward: 20.954953\n",
      "Episode reward: 33.913786\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.2     |\n",
      "|    ep_rew_mean      | 35       |\n",
      "|    exploration_rate | 0.967    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 4165     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3519     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000714 |\n",
      "|    n_updates        | 854      |\n",
      "----------------------------------\n",
      "Episode reward: 37.941217\n",
      "Episode reward: 47.701865\n",
      "Episode reward: 53.927097\n",
      "Episode reward: 23.963415\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | 35.3     |\n",
      "|    exploration_rate | 0.965    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 4176     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3683     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000398 |\n",
      "|    n_updates        | 895      |\n",
      "----------------------------------\n",
      "Episode reward: 31.897787\n",
      "Episode reward: 35.89662\n",
      "Episode reward: 33.926867\n",
      "Episode reward: 27.958809\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | 35.3     |\n",
      "|    exploration_rate | 0.964    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 4183     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3813     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00018  |\n",
      "|    n_updates        | 928      |\n",
      "----------------------------------\n",
      "Episode reward: 40.851556\n",
      "Episode reward: 22.923849\n",
      "Episode reward: 28.887566\n",
      "Episode reward: 34.96291\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.1     |\n",
      "|    ep_rew_mean      | 35       |\n",
      "|    exploration_rate | 0.963    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 4169     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3941     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00149  |\n",
      "|    n_updates        | 960      |\n",
      "----------------------------------\n",
      "Episode reward: 26.929484\n",
      "Episode reward: 37.893518\n",
      "Episode reward: 33.956546\n",
      "Episode reward: 31.910797\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35       |\n",
      "|    ep_rew_mean      | 34.9     |\n",
      "|    exploration_rate | 0.961    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 4165     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4072     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000465 |\n",
      "|    n_updates        | 992      |\n",
      "----------------------------------\n",
      "Episode reward: 34.872464\n",
      "Episode reward: 34.757166\n",
      "Episode reward: 22.954628\n",
      "Episode reward: 40.93012\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.7     |\n",
      "|    ep_rew_mean      | 34.6     |\n",
      "|    exploration_rate | 0.96     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 4183     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 4206     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000384 |\n",
      "|    n_updates        | 1026     |\n",
      "----------------------------------\n",
      "Episode reward: 25.948142\n",
      "Episode reward: 23.93206\n",
      "Episode reward: 44.740391\n",
      "Episode reward: 22.773647\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.6     |\n",
      "|    ep_rew_mean      | 34.5     |\n",
      "|    exploration_rate | 0.959    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 4180     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 4324     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000103 |\n",
      "|    n_updates        | 1055     |\n",
      "----------------------------------\n",
      "Episode reward: 43.45528\n",
      "Episode reward: 21.87816\n",
      "Episode reward: 25.902241\n",
      "Episode reward: 35.931819\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.3     |\n",
      "|    ep_rew_mean      | 34.1     |\n",
      "|    exploration_rate | 0.958    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 4187     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 4452     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000409 |\n",
      "|    n_updates        | 1087     |\n",
      "----------------------------------\n",
      "Episode reward: 27.94063\n",
      "Episode reward: 62.452087\n",
      "Episode reward: 40.713695\n",
      "Episode reward: 40.944179\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.6     |\n",
      "|    ep_rew_mean      | 34.5     |\n",
      "|    exploration_rate | 0.956    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 4168     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 4625     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000725 |\n",
      "|    n_updates        | 1131     |\n",
      "----------------------------------\n",
      "Episode reward: 39.885701\n",
      "Episode reward: 42.70299\n",
      "Episode reward: 27.875654\n",
      "Episode reward: 52.909098\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.8     |\n",
      "|    ep_rew_mean      | 34.6     |\n",
      "|    exploration_rate | 0.955    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 4182     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 4789     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000214 |\n",
      "|    n_updates        | 1172     |\n",
      "----------------------------------\n",
      "Episode reward: 39.956125\n",
      "Episode reward: 28.935924\n",
      "Episode reward: 32.830943\n",
      "Episode reward: 49.9076\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.9     |\n",
      "|    ep_rew_mean      | 34.8     |\n",
      "|    exploration_rate | 0.953    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 4195     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 4941     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000288 |\n",
      "|    n_updates        | 1210     |\n",
      "----------------------------------\n",
      "Episode reward: 25.923898\n",
      "Episode reward: 37.91793\n",
      "Episode reward: 36.861572\n",
      "Episode reward: 42.945088\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.1     |\n",
      "|    ep_rew_mean      | 35       |\n",
      "|    exploration_rate | 0.952    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 4189     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 5085     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00026  |\n",
      "|    n_updates        | 1246     |\n",
      "----------------------------------\n",
      "Episode reward: 34.956429\n",
      "Episode reward: 22.92584\n",
      "Episode reward: 34.887362\n",
      "Episode reward: 28.831507\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.1     |\n",
      "|    ep_rew_mean      | 35       |\n",
      "|    exploration_rate | 0.951    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 4197     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 5207     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00025  |\n",
      "|    n_updates        | 1276     |\n",
      "----------------------------------\n",
      "Episode reward: 35.908871\n",
      "Episode reward: 29.860578\n",
      "Episode reward: 45.819377\n",
      "Episode reward: 23.903327\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.1     |\n",
      "|    ep_rew_mean      | 34.9     |\n",
      "|    exploration_rate | 0.949    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 4173     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 5343     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000738 |\n",
      "|    n_updates        | 1310     |\n",
      "----------------------------------\n",
      "Episode reward: 28.956644\n",
      "Episode reward: 22.955087\n",
      "Episode reward: 47.740007\n",
      "Episode reward: 38.934898\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.2     |\n",
      "|    ep_rew_mean      | 34.1     |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 4172     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 5482     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000586 |\n",
      "|    n_updates        | 1345     |\n",
      "----------------------------------\n",
      "Episode reward: 41.735519\n",
      "Episode reward: 40.927402\n",
      "Episode reward: 45.228557\n",
      "Episode reward: 40.952703\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.4     |\n",
      "|    ep_rew_mean      | 34.3     |\n",
      "|    exploration_rate | 0.946    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 4184     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 5652     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00105  |\n",
      "|    n_updates        | 1387     |\n",
      "----------------------------------\n",
      "Episode reward: 27.89063\n",
      "Episode reward: 59.801248\n",
      "Episode reward: 33.863204\n",
      "Episode reward: 30.949804\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35       |\n",
      "|    ep_rew_mean      | 34.8     |\n",
      "|    exploration_rate | 0.945    |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 4194     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 5805     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.14e-05 |\n",
      "|    n_updates        | 1426     |\n",
      "----------------------------------\n",
      "Episode reward: 25.952026\n",
      "Episode reward: 41.973099\n",
      "Episode reward: 36.785132\n",
      "Episode reward: 24.923849\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35       |\n",
      "|    ep_rew_mean      | 34.8     |\n",
      "|    exploration_rate | 0.944    |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 4200     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 5936     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000315 |\n",
      "|    n_updates        | 1458     |\n",
      "----------------------------------\n",
      "Episode reward: 26.82363\n",
      "Episode reward: 42.768077\n",
      "Episode reward: 62.532619\n",
      "Episode reward: 39.905714\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | 35.1     |\n",
      "|    exploration_rate | 0.942    |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 4191     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 6109     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000146 |\n",
      "|    n_updates        | 1502     |\n",
      "----------------------------------\n",
      "Episode reward: 67.771675\n",
      "Episode reward: 25.909972\n",
      "Episode reward: 26.895452\n",
      "Episode reward: 46.796315\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | 35.6     |\n",
      "|    exploration_rate | 0.94     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 4190     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 6278     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.85e-05 |\n",
      "|    n_updates        | 1544     |\n",
      "----------------------------------\n",
      "Episode reward: 30.706875\n",
      "Episode reward: 29.925366\n",
      "Episode reward: 35.690098\n",
      "Episode reward: 40.859967\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | 35.7     |\n",
      "|    exploration_rate | 0.939    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 4192     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 6416     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000535 |\n",
      "|    n_updates        | 1578     |\n",
      "----------------------------------\n",
      "Episode reward: 32.897419\n",
      "Episode reward: 37.871033\n",
      "Episode reward: 27.880553\n",
      "Episode reward: 24.832343\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | 35.6     |\n",
      "|    exploration_rate | 0.938    |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 4170     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 6540     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.25e-05 |\n",
      "|    n_updates        | 1609     |\n",
      "----------------------------------\n",
      "Episode reward: 34.677885\n",
      "Episode reward: 42.948468\n",
      "Episode reward: 38.899903\n",
      "Episode reward: 24.954178\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.5     |\n",
      "|    ep_rew_mean      | 35.3     |\n",
      "|    exploration_rate | 0.937    |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 4174     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 6682     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000588 |\n",
      "|    n_updates        | 1645     |\n",
      "----------------------------------\n",
      "Episode reward: 23.944653\n",
      "Episode reward: 18.957352\n",
      "Episode reward: 29.5743\n",
      "Episode reward: 24.873\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.8     |\n",
      "|    ep_rew_mean      | 34.6     |\n",
      "|    exploration_rate | 0.936    |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 4169     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 6780     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000114 |\n",
      "|    n_updates        | 1669     |\n",
      "----------------------------------\n",
      "Episode reward: 28.857393\n",
      "Episode reward: 50.813411\n",
      "Episode reward: 42.884283\n",
      "Episode reward: 33.933109\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | 35.3     |\n",
      "|    exploration_rate | 0.934    |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 4179     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 6937     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.63e-05 |\n",
      "|    n_updates        | 1709     |\n",
      "----------------------------------\n",
      "Episode reward: 22.916878\n",
      "Episode reward: 33.577924\n",
      "Episode reward: 42.873874\n",
      "Episode reward: 19.909682\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | 35.2     |\n",
      "|    exploration_rate | 0.933    |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 4184     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 7057     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000606 |\n",
      "|    n_updates        | 1739     |\n",
      "----------------------------------\n",
      "Episode reward: 39.944183\n",
      "Episode reward: 37.879904\n",
      "Episode reward: 49.903407\n",
      "Episode reward: 48.929411\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.5     |\n",
      "|    ep_rew_mean      | 35.3     |\n",
      "|    exploration_rate | 0.931    |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 4192     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 7234     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.42e-05 |\n",
      "|    n_updates        | 1783     |\n",
      "----------------------------------\n",
      "Episode reward: 28.902684\n",
      "Episode reward: 44.810197\n",
      "Episode reward: 48.556836\n",
      "Episode reward: 24.840003\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.7     |\n",
      "|    ep_rew_mean      | 35.5     |\n",
      "|    exploration_rate | 0.93     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 4186     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 7382     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.36e-05 |\n",
      "|    n_updates        | 1820     |\n",
      "----------------------------------\n",
      "Episode reward: 26.952909\n",
      "Episode reward: 24.893232\n",
      "Episode reward: 34.938191\n",
      "Episode reward: 47.929253\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | 35.6     |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 4166     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 7517     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.1e-05  |\n",
      "|    n_updates        | 1854     |\n",
      "----------------------------------\n",
      "Episode reward: 28.947986\n",
      "Episode reward: 30.905854\n",
      "Episode reward: 35.910521\n",
      "Episode reward: 35.894591\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | 35.6     |\n",
      "|    exploration_rate | 0.927    |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 4176     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 7649     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000369 |\n",
      "|    n_updates        | 1887     |\n",
      "----------------------------------\n",
      "Episode reward: 26.936285\n",
      "Episode reward: 24.93616\n",
      "Episode reward: 32.940788\n",
      "Episode reward: 39.264242\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.7     |\n",
      "|    ep_rew_mean      | 35.5     |\n",
      "|    exploration_rate | 0.926    |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 4182     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 7774     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000405 |\n",
      "|    n_updates        | 1918     |\n",
      "----------------------------------\n",
      "Episode reward: 26.961326\n",
      "Episode reward: 35.948742\n",
      "Episode reward: 50.862276\n",
      "Episode reward: 41.90949\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.1     |\n",
      "|    ep_rew_mean      | 35.9     |\n",
      "|    exploration_rate | 0.925    |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 4171     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 7930     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000476 |\n",
      "|    n_updates        | 1957     |\n",
      "----------------------------------\n",
      "Episode reward: 26.951474\n",
      "Episode reward: 39.831312\n",
      "Episode reward: 51.776929\n",
      "Episode reward: 39.870301\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.4     |\n",
      "|    ep_rew_mean      | 36.2     |\n",
      "|    exploration_rate | 0.923    |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 4164     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 8089     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000239 |\n",
      "|    n_updates        | 1997     |\n",
      "----------------------------------\n",
      "Episode reward: 59.898573\n",
      "Episode reward: 31.90802\n",
      "Episode reward: 37.941034\n",
      "Episode reward: 36.945779\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.3     |\n",
      "|    ep_rew_mean      | 36.2     |\n",
      "|    exploration_rate | 0.922    |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 4168     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 8256     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000145 |\n",
      "|    n_updates        | 2038     |\n",
      "----------------------------------\n",
      "Episode reward: 56.82055\n",
      "Episode reward: 47.875917\n",
      "Episode reward: 39.906277\n",
      "Episode reward: 41.514791\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.5     |\n",
      "|    ep_rew_mean      | 36.4     |\n",
      "|    exploration_rate | 0.92     |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 4176     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 8443     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000482 |\n",
      "|    n_updates        | 2085     |\n",
      "----------------------------------\n",
      "Episode reward: 37.909304\n",
      "Episode reward: 48.541718\n",
      "Episode reward: 35.940436\n",
      "Episode reward: 41.703198\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.7     |\n",
      "|    ep_rew_mean      | 36.5     |\n",
      "|    exploration_rate | 0.918    |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 4190     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 8608     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 9.48e-05 |\n",
      "|    n_updates        | 2126     |\n",
      "----------------------------------\n",
      "Episode reward: 41.874647\n",
      "Episode reward: 34.904476\n",
      "Episode reward: 23.967777\n",
      "Episode reward: 32.958475\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | 36.4     |\n",
      "|    exploration_rate | 0.917    |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 4185     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 8742     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 7.05e-05 |\n",
      "|    n_updates        | 2160     |\n",
      "----------------------------------\n",
      "Episode reward: 34.954067\n",
      "Episode reward: 56.738272\n",
      "Episode reward: 39.830827\n",
      "Episode reward: 31.948109\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37       |\n",
      "|    ep_rew_mean      | 36.8     |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 4189     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 8906     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 2201     |\n",
      "----------------------------------\n",
      "Episode reward: 17.969478\n",
      "Episode reward: 43.393227\n",
      "Episode reward: 48.33454\n",
      "Episode reward: 37.945984\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.1     |\n",
      "|    ep_rew_mean      | 36.9     |\n",
      "|    exploration_rate | 0.914    |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 4198     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 9055     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000128 |\n",
      "|    n_updates        | 2238     |\n",
      "----------------------------------\n",
      "Episode reward: 58.887353\n",
      "Episode reward: 18.88013\n",
      "Episode reward: 21.849085\n",
      "Episode reward: 24.907979\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37       |\n",
      "|    ep_rew_mean      | 36.8     |\n",
      "|    exploration_rate | 0.913    |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 4193     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 9180     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000709 |\n",
      "|    n_updates        | 2269     |\n",
      "----------------------------------\n",
      "Episode reward: 28.953274\n",
      "Episode reward: 42.944336\n",
      "Episode reward: 25.898499\n",
      "Episode reward: 32.92093\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | 36.4     |\n",
      "|    exploration_rate | 0.912    |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 4198     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 9311     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0004   |\n",
      "|    n_updates        | 2302     |\n",
      "----------------------------------\n",
      "Episode reward: 25.969444\n",
      "Episode reward: 28.84824\n",
      "Episode reward: 31.825896\n",
      "Episode reward: 29.775946\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | 36.1     |\n",
      "|    exploration_rate | 0.91     |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 4198     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 9428     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000151 |\n",
      "|    n_updates        | 2331     |\n",
      "----------------------------------\n",
      "Episode reward: 36.868735\n",
      "Episode reward: 29.926507\n",
      "Episode reward: 21.966068\n",
      "Episode reward: 26.929427\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.1     |\n",
      "|    ep_rew_mean      | 35.9     |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 4200     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 9544     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000132 |\n",
      "|    n_updates        | 2360     |\n",
      "----------------------------------\n",
      "Episode reward: 25.93465\n",
      "Episode reward: 19.844388\n",
      "Episode reward: 42.8811\n",
      "Episode reward: 53.921137\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | 35.6     |\n",
      "|    exploration_rate | 0.908    |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 4197     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 9687     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000124 |\n",
      "|    n_updates        | 2396     |\n",
      "----------------------------------\n",
      "Episode reward: 43.896033\n",
      "Episode reward: 28.887881\n",
      "Episode reward: 29.956323\n",
      "Episode reward: 39.929462\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.5     |\n",
      "|    ep_rew_mean      | 35.4     |\n",
      "|    exploration_rate | 0.907    |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 4196     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 9830     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000219 |\n",
      "|    n_updates        | 2432     |\n",
      "----------------------------------\n",
      "Episode reward: 48.908009\n",
      "Episode reward: 27.87857\n",
      "Episode reward: 33.830899\n",
      "Episode reward: 23.941419\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.5     |\n",
      "|    ep_rew_mean      | 35.4     |\n",
      "|    exploration_rate | 0.905    |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 4189     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 9965     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.34e-05 |\n",
      "|    n_updates        | 2466     |\n",
      "----------------------------------\n",
      "Episode reward: 30.906073\n",
      "Episode reward: 28.928572\n",
      "Episode reward: 36.959471\n",
      "Episode reward: 38.93056\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.6     |\n",
      "|    ep_rew_mean      | 35.5     |\n",
      "|    exploration_rate | 0.904    |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 4188     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 10101    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0836   |\n",
      "|    n_updates        | 2500     |\n",
      "----------------------------------\n",
      "Episode reward: 27.881832\n",
      "Episode reward: 46.900229\n",
      "Episode reward: 23.871538\n",
      "Episode reward: 48.939426\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.7     |\n",
      "|    ep_rew_mean      | 35.5     |\n",
      "|    exploration_rate | 0.903    |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 4187     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 10249    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000755 |\n",
      "|    n_updates        | 2537     |\n",
      "----------------------------------\n",
      "Episode reward: 33.903375\n",
      "Episode reward: 23.965579\n",
      "Episode reward: 27.91924\n",
      "Episode reward: 30.955784\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | 35.7     |\n",
      "|    exploration_rate | 0.902    |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 4186     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 10366    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000591 |\n",
      "|    n_updates        | 2566     |\n",
      "----------------------------------\n",
      "Episode reward: 49.45198\n",
      "Episode reward: 32.949223\n",
      "Episode reward: 26.934327\n",
      "Episode reward: 29.938554\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.7     |\n",
      "|    ep_rew_mean      | 35.6     |\n",
      "|    exploration_rate | 0.9      |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 4189     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 10506    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0366   |\n",
      "|    n_updates        | 2601     |\n",
      "----------------------------------\n",
      "Episode reward: 38.821568\n",
      "Episode reward: 25.777177\n",
      "Episode reward: 47.704575\n",
      "Episode reward: 51.897963\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.1     |\n",
      "|    ep_rew_mean      | 36       |\n",
      "|    exploration_rate | 0.899    |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 4152     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 10671    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000881 |\n",
      "|    n_updates        | 2642     |\n",
      "----------------------------------\n",
      "Episode reward: 34.910874\n",
      "Episode reward: 26.958983\n",
      "Episode reward: 34.732562\n",
      "Episode reward: 25.9201\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.6     |\n",
      "|    ep_rew_mean      | 35.5     |\n",
      "|    exploration_rate | 0.897    |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 4152     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 10794    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 2673     |\n",
      "----------------------------------\n",
      "Episode reward: 22.931266\n",
      "Episode reward: 32.658138\n",
      "Episode reward: 24.949901\n",
      "Episode reward: 34.923777\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | 35.1     |\n",
      "|    exploration_rate | 0.896    |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 4149     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 10910    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 2702     |\n",
      "----------------------------------\n",
      "Episode reward: 46.574281\n",
      "Episode reward: 32.908491\n",
      "Episode reward: 38.918177\n",
      "Episode reward: 26.853931\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | 35.3     |\n",
      "|    exploration_rate | 0.895    |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 4156     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 11056    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 2738     |\n",
      "----------------------------------\n",
      "Episode reward: 38.832624\n",
      "Episode reward: 52.730535\n",
      "Episode reward: 46.74359\n",
      "Episode reward: 57.847989\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36       |\n",
      "|    ep_rew_mean      | 35.9     |\n",
      "|    exploration_rate | 0.893    |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 4153     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 11253    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0491   |\n",
      "|    n_updates        | 2788     |\n",
      "----------------------------------\n",
      "Episode reward: 47.638622\n",
      "Episode reward: 25.951519\n",
      "Episode reward: 57.90256\n",
      "Episode reward: 50.682194\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | 36.5     |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 4159     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 11436    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 2833     |\n",
      "----------------------------------\n",
      "Episode reward: 46.908571\n",
      "Episode reward: 49.275237\n",
      "Episode reward: 23.896652\n",
      "Episode reward: 29.968877\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | 36.4     |\n",
      "|    exploration_rate | 0.89     |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 4160     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 11587    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 2871     |\n",
      "----------------------------------\n",
      "Episode reward: 29.962403\n",
      "Episode reward: 40.733237\n",
      "Episode reward: 35.78571\n",
      "Episode reward: 34.933846\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.4     |\n",
      "|    ep_rew_mean      | 36.3     |\n",
      "|    exploration_rate | 0.889    |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 4157     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 11729    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0253   |\n",
      "|    n_updates        | 2907     |\n",
      "----------------------------------\n",
      "Episode reward: 61.72735\n",
      "Episode reward: 44.870917\n",
      "Episode reward: 40.86405\n",
      "Episode reward: 29.862724\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.5     |\n",
      "|    ep_rew_mean      | 36.4     |\n",
      "|    exploration_rate | 0.887    |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 4153     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 11908    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0448   |\n",
      "|    n_updates        | 2951     |\n",
      "----------------------------------\n",
      "Episode reward: 45.860062\n",
      "Episode reward: 40.95621\n",
      "Episode reward: 56.743562\n",
      "Episode reward: 31.846845\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.4     |\n",
      "|    ep_rew_mean      | 36.3     |\n",
      "|    exploration_rate | 0.885    |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 4153     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 12084    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0342   |\n",
      "|    n_updates        | 2995     |\n",
      "----------------------------------\n",
      "Episode reward: 40.949903\n",
      "Episode reward: 30.925297\n",
      "Episode reward: 20.933135\n",
      "Episode reward: 20.90815\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | 35.8     |\n",
      "|    exploration_rate | 0.884    |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 4153     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 12198    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 3024     |\n",
      "----------------------------------\n",
      "Episode reward: 49.869473\n",
      "Episode reward: 25.954687\n",
      "Episode reward: 29.930537\n",
      "Episode reward: 43.185587\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.1     |\n",
      "|    ep_rew_mean      | 35.9     |\n",
      "|    exploration_rate | 0.883    |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 4154     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 12348    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 3061     |\n",
      "----------------------------------\n",
      "Episode reward: 41.907227\n",
      "Episode reward: 28.937267\n",
      "Episode reward: 24.973835\n",
      "Episode reward: 28.690836\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.7     |\n",
      "|    ep_rew_mean      | 35.5     |\n",
      "|    exploration_rate | 0.882    |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 4125     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 12473    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 3093     |\n",
      "----------------------------------\n",
      "Episode reward: 38.211572\n",
      "Episode reward: 48.91497\n",
      "Episode reward: 43.924383\n",
      "Episode reward: 23.944873\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.7     |\n",
      "|    ep_rew_mean      | 35.6     |\n",
      "|    exploration_rate | 0.88     |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 4122     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 12629    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00121  |\n",
      "|    n_updates        | 3132     |\n",
      "----------------------------------\n",
      "Episode reward: 81.335245\n",
      "Episode reward: 22.846604\n",
      "Episode reward: 48.113866\n",
      "Episode reward: 40.948906\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.4     |\n",
      "|    ep_rew_mean      | 36.3     |\n",
      "|    exploration_rate | 0.878    |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 4132     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 12824    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0309   |\n",
      "|    n_updates        | 3180     |\n",
      "----------------------------------\n",
      "Episode reward: 29.926285\n",
      "Episode reward: 38.918374\n",
      "Episode reward: 45.916948\n",
      "Episode reward: 22.964612\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.5     |\n",
      "|    ep_rew_mean      | 36.3     |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 4134     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 12962    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000665 |\n",
      "|    n_updates        | 3215     |\n",
      "----------------------------------\n",
      "Episode reward: 35.959123\n",
      "Episode reward: 22.938548\n",
      "Episode reward: 50.939582\n",
      "Episode reward: 23.964645\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.7     |\n",
      "|    ep_rew_mean      | 36.5     |\n",
      "|    exploration_rate | 0.876    |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 4132     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 13097    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0324   |\n",
      "|    n_updates        | 3249     |\n",
      "----------------------------------\n",
      "Episode reward: 37.903209\n",
      "Episode reward: 47.771344\n",
      "Episode reward: 25.966051\n",
      "Episode reward: 36.751372\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37       |\n",
      "|    ep_rew_mean      | 36.8     |\n",
      "|    exploration_rate | 0.874    |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 4130     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 13246    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 3286     |\n",
      "----------------------------------\n",
      "Episode reward: 44.534327\n",
      "Episode reward: 25.901415\n",
      "Episode reward: 54.808986\n",
      "Episode reward: 42.904288\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.3     |\n",
      "|    ep_rew_mean      | 37.1     |\n",
      "|    exploration_rate | 0.873    |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 4128     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 13415    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000691 |\n",
      "|    n_updates        | 3328     |\n",
      "----------------------------------\n",
      "Episode reward: 43.824695\n",
      "Episode reward: 23.907329\n",
      "Episode reward: 37.926424\n",
      "Episode reward: 53.848038\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.5     |\n",
      "|    ep_rew_mean      | 37.3     |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 4125     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 13575    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00165  |\n",
      "|    n_updates        | 3368     |\n",
      "----------------------------------\n",
      "Episode reward: 51.722784\n",
      "Episode reward: 42.857234\n",
      "Episode reward: 39.943618\n",
      "Episode reward: 44.765241\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.9     |\n",
      "|    ep_rew_mean      | 37.7     |\n",
      "|    exploration_rate | 0.869    |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 4118     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 13755    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 3413     |\n",
      "----------------------------------\n",
      "Episode reward: 40.856397\n",
      "Episode reward: 34.740337\n",
      "Episode reward: 40.603961\n",
      "Episode reward: 32.945546\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | 37.8     |\n",
      "|    exploration_rate | 0.868    |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 4109     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 13905    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00081  |\n",
      "|    n_updates        | 3451     |\n",
      "----------------------------------\n",
      "Episode reward: 46.872626\n",
      "Episode reward: 41.90236\n",
      "Episode reward: 31.82568\n",
      "Episode reward: 26.566528\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | 37.8     |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 4100     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 14053    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00131  |\n",
      "|    n_updates        | 3488     |\n",
      "----------------------------------\n",
      "Episode reward: 27.919109\n",
      "Episode reward: 32.925536\n",
      "Episode reward: 24.889046\n",
      "Episode reward: 26.848769\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | 37.8     |\n",
      "|    exploration_rate | 0.865    |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 4096     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 14166    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 3516     |\n",
      "----------------------------------\n",
      "Episode reward: 33.94787\n",
      "Episode reward: 34.94142\n",
      "Episode reward: 44.743541\n",
      "Episode reward: 27.855442\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38       |\n",
      "|    ep_rew_mean      | 37.8     |\n",
      "|    exploration_rate | 0.864    |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 4096     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 14308    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 3551     |\n",
      "----------------------------------\n",
      "Episode reward: 36.866794\n",
      "Episode reward: 32.772341\n",
      "Episode reward: 41.81512\n",
      "Episode reward: 41.845494\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.9     |\n",
      "|    ep_rew_mean      | 37.7     |\n",
      "|    exploration_rate | 0.863    |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 4098     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 14462    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00148  |\n",
      "|    n_updates        | 3590     |\n",
      "----------------------------------\n",
      "Episode reward: 25.899986\n",
      "Episode reward: 22.973553\n",
      "Episode reward: 26.94673\n",
      "Episode reward: 43.927393\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.9     |\n",
      "|    ep_rew_mean      | 37.7     |\n",
      "|    exploration_rate | 0.861    |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 4094     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 14582    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 3620     |\n",
      "----------------------------------\n",
      "Episode reward: 33.854179\n",
      "Episode reward: 30.941693\n",
      "Episode reward: 24.746564\n",
      "Episode reward: 21.921499\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | 37.6     |\n",
      "|    exploration_rate | 0.86     |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 4094     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 14694    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0244   |\n",
      "|    n_updates        | 3648     |\n",
      "----------------------------------\n",
      "Episode reward: 19.901018\n",
      "Episode reward: 24.798581\n",
      "Episode reward: 38.937276\n",
      "Episode reward: 34.854297\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.6     |\n",
      "|    ep_rew_mean      | 37.4     |\n",
      "|    exploration_rate | 0.859    |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 4090     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 14813    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0243   |\n",
      "|    n_updates        | 3678     |\n",
      "----------------------------------\n",
      "Episode reward: 24.959432\n",
      "Episode reward: 43.942924\n",
      "Episode reward: 20.95773\n",
      "Episode reward: 37.811284\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.9     |\n",
      "|    ep_rew_mean      | 36.7     |\n",
      "|    exploration_rate | 0.858    |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 4091     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 14941    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000943 |\n",
      "|    n_updates        | 3710     |\n",
      "----------------------------------\n",
      "Episode reward: 22.914186\n",
      "Episode reward: 23.965484\n",
      "Episode reward: 33.918191\n",
      "Episode reward: 31.961323\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | 36       |\n",
      "|    exploration_rate | 0.857    |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 4091     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 15054    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 3738     |\n",
      "----------------------------------\n",
      "Episode reward: 39.925535\n",
      "Episode reward: 45.86041\n",
      "Episode reward: 33.952736\n",
      "Episode reward: 40.930167\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.3     |\n",
      "|    ep_rew_mean      | 36.1     |\n",
      "|    exploration_rate | 0.855    |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 4090     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 15215    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00142  |\n",
      "|    n_updates        | 3778     |\n",
      "----------------------------------\n",
      "Episode reward: 25.921608\n",
      "Episode reward: 41.746669\n",
      "Episode reward: 40.812498\n",
      "Episode reward: 31.947354\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.3     |\n",
      "|    ep_rew_mean      | 36.1     |\n",
      "|    exploration_rate | 0.854    |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 4087     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 15356    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0272   |\n",
      "|    n_updates        | 3813     |\n",
      "----------------------------------\n",
      "Episode reward: 57.821327\n",
      "Episode reward: 29.966038\n",
      "Episode reward: 48.914314\n",
      "Episode reward: 35.948476\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | 36.1     |\n",
      "|    exploration_rate | 0.852    |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 4073     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 15529    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 3857     |\n",
      "----------------------------------\n",
      "Episode reward: 21.871911\n",
      "Episode reward: 19.946133\n",
      "Episode reward: 34.947899\n",
      "Episode reward: 41.86711\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.6     |\n",
      "|    ep_rew_mean      | 35.5     |\n",
      "|    exploration_rate | 0.851    |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 4044     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 15648    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0435   |\n",
      "|    n_updates        | 3886     |\n",
      "----------------------------------\n",
      "Episode reward: 47.854641\n",
      "Episode reward: 25.945172\n",
      "Episode reward: 23.94085\n",
      "Episode reward: 28.490382\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | 35.6     |\n",
      "|    exploration_rate | 0.85     |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 4037     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 15775    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 3918     |\n",
      "----------------------------------\n",
      "Episode reward: 28.945659\n",
      "Episode reward: 28.834785\n",
      "Episode reward: 33.858553\n",
      "Episode reward: 36.93363\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.6     |\n",
      "|    ep_rew_mean      | 35.4     |\n",
      "|    exploration_rate | 0.849    |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 4029     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 15904    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0342   |\n",
      "|    n_updates        | 3950     |\n",
      "----------------------------------\n",
      "Episode reward: 31.711821\n",
      "Episode reward: 24.880213\n",
      "Episode reward: 24.917963\n",
      "Episode reward: 29.930036\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | 35.3     |\n",
      "|    exploration_rate | 0.848    |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 4026     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 16016    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 3978     |\n",
      "----------------------------------\n",
      "Episode reward: 34.944739\n",
      "Episode reward: 30.951081\n",
      "Episode reward: 26.804708\n",
      "Episode reward: 44.928329\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.2     |\n",
      "|    ep_rew_mean      | 35.1     |\n",
      "|    exploration_rate | 0.847    |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 4029     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 16154    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0249   |\n",
      "|    n_updates        | 4013     |\n",
      "----------------------------------\n",
      "Episode reward: 47.932659\n",
      "Episode reward: 26.920244\n",
      "Episode reward: 36.465472\n",
      "Episode reward: 25.938404\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.7     |\n",
      "|    ep_rew_mean      | 34.5     |\n",
      "|    exploration_rate | 0.845    |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 4030     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 16292    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 4047     |\n",
      "----------------------------------\n",
      "Episode reward: 43.886506\n",
      "Episode reward: 21.845523\n",
      "Episode reward: 26.882251\n",
      "Episode reward: 36.90792\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.6     |\n",
      "|    ep_rew_mean      | 34.5     |\n",
      "|    exploration_rate | 0.844    |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 4025     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 16422    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 4080     |\n",
      "----------------------------------\n",
      "Episode reward: 46.683065\n",
      "Episode reward: 24.972615\n",
      "Episode reward: 44.526683\n",
      "Episode reward: 25.965878\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.7     |\n",
      "|    ep_rew_mean      | 34.5     |\n",
      "|    exploration_rate | 0.843    |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 4016     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 16565    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 4116     |\n",
      "----------------------------------\n",
      "Episode reward: 34.88635\n",
      "Episode reward: 25.929335\n",
      "Episode reward: 29.720886\n",
      "Episode reward: 33.941421\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.4     |\n",
      "|    ep_rew_mean      | 34.3     |\n",
      "|    exploration_rate | 0.841    |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 4009     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 16690    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 4147     |\n",
      "----------------------------------\n",
      "Episode reward: 37.856769\n",
      "Episode reward: 35.765235\n",
      "Episode reward: 43.904287\n",
      "Episode reward: 38.864632\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.3     |\n",
      "|    ep_rew_mean      | 34.2     |\n",
      "|    exploration_rate | 0.84     |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 4007     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 16847    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0386   |\n",
      "|    n_updates        | 4186     |\n",
      "----------------------------------\n",
      "Episode reward: 43.449047\n",
      "Episode reward: 94.792308\n",
      "Episode reward: 29.908102\n",
      "Episode reward: 37.786754\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.8     |\n",
      "|    ep_rew_mean      | 34.7     |\n",
      "|    exploration_rate | 0.838    |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 4010     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 17054    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0019   |\n",
      "|    n_updates        | 4238     |\n",
      "----------------------------------\n",
      "Episode reward: 24.862529\n",
      "Episode reward: 25.949926\n",
      "Episode reward: 35.694136\n",
      "Episode reward: 24.965722\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.1     |\n",
      "|    ep_rew_mean      | 34       |\n",
      "|    exploration_rate | 0.837    |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 4008     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 17166    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00264  |\n",
      "|    n_updates        | 4266     |\n",
      "----------------------------------\n",
      "Episode reward: 35.858159\n",
      "Episode reward: 50.90725\n",
      "Episode reward: 27.898721\n",
      "Episode reward: 39.908671\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.2     |\n",
      "|    ep_rew_mean      | 34       |\n",
      "|    exploration_rate | 0.835    |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 4000     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 17321    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0231   |\n",
      "|    n_updates        | 4305     |\n",
      "----------------------------------\n",
      "Episode reward: 38.957488\n",
      "Episode reward: 31.958353\n",
      "Episode reward: 20.964053\n",
      "Episode reward: 32.850484\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.9     |\n",
      "|    ep_rew_mean      | 33.8     |\n",
      "|    exploration_rate | 0.834    |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 4000     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 17446    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 4336     |\n",
      "----------------------------------\n",
      "Episode reward: 28.842342\n",
      "Episode reward: 41.678179\n",
      "Episode reward: 42.602131\n",
      "Episode reward: 22.888453\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.2     |\n",
      "|    ep_rew_mean      | 34       |\n",
      "|    exploration_rate | 0.833    |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 3994     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 17583    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0308   |\n",
      "|    n_updates        | 4370     |\n",
      "----------------------------------\n",
      "Episode reward: 54.869286\n",
      "Episode reward: 45.216877\n",
      "Episode reward: 20.933178\n",
      "Episode reward: 28.910218\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.3     |\n",
      "|    ep_rew_mean      | 34.1     |\n",
      "|    exploration_rate | 0.832    |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 3993     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 17734    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.03     |\n",
      "|    n_updates        | 4408     |\n",
      "----------------------------------\n",
      "Episode reward: 40.881952\n",
      "Episode reward: 22.95504\n",
      "Episode reward: 36.553472\n",
      "Episode reward: 31.848139\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34       |\n",
      "|    ep_rew_mean      | 33.9     |\n",
      "|    exploration_rate | 0.83     |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 3993     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 17867    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00198  |\n",
      "|    n_updates        | 4441     |\n",
      "----------------------------------\n",
      "Episode reward: 28.960291\n",
      "Episode reward: 20.850471\n",
      "Episode reward: 24.952224\n",
      "Episode reward: 29.941007\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.9     |\n",
      "|    ep_rew_mean      | 33.8     |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 3973     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 17972    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00235  |\n",
      "|    n_updates        | 4467     |\n",
      "----------------------------------\n",
      "Episode reward: 20.961268\n",
      "Episode reward: 23.900987\n",
      "Episode reward: 24.874263\n",
      "Episode reward: 21.698965\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.7     |\n",
      "|    ep_rew_mean      | 33.6     |\n",
      "|    exploration_rate | 0.828    |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 3970     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 18064    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0238   |\n",
      "|    n_updates        | 4490     |\n",
      "----------------------------------\n",
      "Episode reward: 24.841718\n",
      "Episode reward: 44.864619\n",
      "Episode reward: 29.761314\n",
      "Episode reward: 23.920873\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.8     |\n",
      "|    ep_rew_mean      | 33.6     |\n",
      "|    exploration_rate | 0.827    |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 3965     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 18188    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 4521     |\n",
      "----------------------------------\n",
      "Episode reward: 38.937303\n",
      "Episode reward: 37.917031\n",
      "Episode reward: 29.950776\n",
      "Episode reward: 26.970827\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.8     |\n",
      "|    ep_rew_mean      | 33.7     |\n",
      "|    exploration_rate | 0.826    |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 3959     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 18322    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 4555     |\n",
      "----------------------------------\n",
      "Episode reward: 26.924906\n",
      "Episode reward: 33.82381\n",
      "Episode reward: 31.936676\n",
      "Episode reward: 67.533728\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.3     |\n",
      "|    ep_rew_mean      | 34.1     |\n",
      "|    exploration_rate | 0.824    |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 3942     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 18484    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 4595     |\n",
      "----------------------------------\n",
      "Episode reward: 32.907643\n",
      "Episode reward: 30.905542\n",
      "Episode reward: 26.904672\n",
      "Episode reward: 27.429449\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.9     |\n",
      "|    ep_rew_mean      | 33.7     |\n",
      "|    exploration_rate | 0.823    |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 3937     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 18603    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00238  |\n",
      "|    n_updates        | 4625     |\n",
      "----------------------------------\n",
      "Episode reward: 30.856304\n",
      "Episode reward: 29.922511\n",
      "Episode reward: 23.903406\n",
      "Episode reward: 18.963484\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.5     |\n",
      "|    ep_rew_mean      | 33.4     |\n",
      "|    exploration_rate | 0.822    |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 3932     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 18707    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0418   |\n",
      "|    n_updates        | 4651     |\n",
      "----------------------------------\n",
      "Episode reward: 22.852754\n",
      "Episode reward: 25.967844\n",
      "Episode reward: 29.823879\n",
      "Episode reward: 30.931314\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 32.9     |\n",
      "|    ep_rew_mean      | 32.7     |\n",
      "|    exploration_rate | 0.821    |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 3929     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 18817    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00185  |\n",
      "|    n_updates        | 4679     |\n",
      "----------------------------------\n",
      "Episode reward: 24.946257\n",
      "Episode reward: 23.946912\n",
      "Episode reward: 27.947607\n",
      "Episode reward: 31.89851\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 32.8     |\n",
      "|    ep_rew_mean      | 32.6     |\n",
      "|    exploration_rate | 0.82     |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 3923     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 18926    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 4706     |\n",
      "----------------------------------\n",
      "Episode reward: 25.858538\n",
      "Episode reward: 31.905792\n",
      "Episode reward: 30.672366\n",
      "Episode reward: 39.867842\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 32.8     |\n",
      "|    ep_rew_mean      | 32.6     |\n",
      "|    exploration_rate | 0.819    |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 3923     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 19055    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0209   |\n",
      "|    n_updates        | 4738     |\n",
      "----------------------------------\n",
      "Episode reward: 37.903133\n",
      "Episode reward: 52.606871\n",
      "Episode reward: 36.927781\n",
      "Episode reward: 24.879941\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33       |\n",
      "|    ep_rew_mean      | 32.9     |\n",
      "|    exploration_rate | 0.818    |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 3907     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 19208    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0193   |\n",
      "|    n_updates        | 4776     |\n",
      "----------------------------------\n",
      "Episode reward: 16.956718\n",
      "Episode reward: 29.939\n",
      "Episode reward: 52.835213\n",
      "Episode reward: 32.769486\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.3     |\n",
      "|    ep_rew_mean      | 33.1     |\n",
      "|    exploration_rate | 0.816    |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 3907     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 19342    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000518 |\n",
      "|    n_updates        | 4810     |\n",
      "----------------------------------\n",
      "Episode reward: 30.710904\n",
      "Episode reward: 25.922214\n",
      "Episode reward: 49.861989\n",
      "Episode reward: 25.867749\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.2     |\n",
      "|    ep_rew_mean      | 33       |\n",
      "|    exploration_rate | 0.815    |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 3899     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 19475    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 4843     |\n",
      "----------------------------------\n",
      "Episode reward: 20.961013\n",
      "Episode reward: 32.965711\n",
      "Episode reward: 26.882245\n",
      "Episode reward: 27.963877\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 32.9     |\n",
      "|    ep_rew_mean      | 32.8     |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 3896     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 19584    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 4870     |\n",
      "----------------------------------\n",
      "Episode reward: 47.673894\n",
      "Episode reward: 20.837954\n",
      "Episode reward: 38.831423\n",
      "Episode reward: 38.903048\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.1     |\n",
      "|    ep_rew_mean      | 32.9     |\n",
      "|    exploration_rate | 0.813    |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 3896     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 19731    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 4907     |\n",
      "----------------------------------\n",
      "Episode reward: 20.92692\n",
      "Episode reward: 21.868422\n",
      "Episode reward: 27.946464\n",
      "Episode reward: 59.794289\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33       |\n",
      "|    ep_rew_mean      | 32.8     |\n",
      "|    exploration_rate | 0.811    |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 3874     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 19863    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00294  |\n",
      "|    n_updates        | 4940     |\n",
      "----------------------------------\n",
      "Episode reward: 40.841792\n",
      "Episode reward: 61.767887\n",
      "Episode reward: 29.530886\n",
      "Episode reward: 24.970732\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.3     |\n",
      "|    ep_rew_mean      | 33.1     |\n",
      "|    exploration_rate | 0.81     |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 3872     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 20021    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.376    |\n",
      "|    n_updates        | 4980     |\n",
      "----------------------------------\n",
      "Episode reward: 42.918541\n",
      "Episode reward: 28.70238\n",
      "Episode reward: 26.939347\n",
      "Episode reward: 44.681185\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.2     |\n",
      "|    ep_rew_mean      | 33       |\n",
      "|    exploration_rate | 0.808    |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 3875     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 20165    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.047    |\n",
      "|    n_updates        | 5016     |\n",
      "----------------------------------\n",
      "Episode reward: 35.913215\n",
      "Episode reward: 27.911037\n",
      "Episode reward: 30.831319\n",
      "Episode reward: 27.90927\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 32.3     |\n",
      "|    ep_rew_mean      | 32.2     |\n",
      "|    exploration_rate | 0.807    |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 3874     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 20288    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00054  |\n",
      "|    n_updates        | 5046     |\n",
      "----------------------------------\n",
      "Episode reward: 30.919105\n",
      "Episode reward: 38.918813\n",
      "Episode reward: 30.865497\n",
      "Episode reward: 33.921516\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 32.6     |\n",
      "|    ep_rew_mean      | 32.4     |\n",
      "|    exploration_rate | 0.806    |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 3865     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 20423    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0399   |\n",
      "|    n_updates        | 5080     |\n",
      "----------------------------------\n",
      "Episode reward: 22.965654\n",
      "Episode reward: 39.605178\n",
      "Episode reward: 42.921048\n",
      "Episode reward: 23.865914\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 32.3     |\n",
      "|    ep_rew_mean      | 32.1     |\n",
      "|    exploration_rate | 0.805    |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 3865     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 20553    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 5113     |\n",
      "----------------------------------\n",
      "Episode reward: 25.924355\n",
      "Episode reward: 24.963745\n",
      "Episode reward: 23.964809\n",
      "Episode reward: 23.876395\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 32.1     |\n",
      "|    ep_rew_mean      | 31.9     |\n",
      "|    exploration_rate | 0.804    |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 3862     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 20652    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0353   |\n",
      "|    n_updates        | 5137     |\n",
      "----------------------------------\n",
      "Episode reward: 42.849779\n",
      "Episode reward: 27.794806\n",
      "Episode reward: 38.854292\n",
      "Episode reward: 41.81324\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 32.2     |\n",
      "|    ep_rew_mean      | 32       |\n",
      "|    exploration_rate | 0.802    |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 3864     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 20804    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0403   |\n",
      "|    n_updates        | 5175     |\n",
      "----------------------------------\n",
      "Episode reward: 22.934914\n",
      "Episode reward: 40.888739\n",
      "Episode reward: 47.431337\n",
      "Episode reward: 36.838538\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 32.2     |\n",
      "|    ep_rew_mean      | 32       |\n",
      "|    exploration_rate | 0.801    |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 3867     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 20953    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0423   |\n",
      "|    n_updates        | 5213     |\n",
      "----------------------------------\n",
      "Episode reward: 46.914021\n",
      "Episode reward: 19.955073\n",
      "Episode reward: 27.904344\n",
      "Episode reward: 39.740715\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 32.2     |\n",
      "|    ep_rew_mean      | 32       |\n",
      "|    exploration_rate | 0.8      |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 3868     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 21088    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0719   |\n",
      "|    n_updates        | 5246     |\n",
      "----------------------------------\n",
      "Episode reward: 37.547527\n",
      "Episode reward: 41.826245\n",
      "Episode reward: 56.791039\n",
      "Episode reward: 19.819769\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 32.7     |\n",
      "|    ep_rew_mean      | 32.6     |\n",
      "|    exploration_rate | 0.798    |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 3853     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 21245    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0789   |\n",
      "|    n_updates        | 5286     |\n",
      "----------------------------------\n",
      "Episode reward: 32.896376\n",
      "Episode reward: 30.882384\n",
      "Episode reward: 34.93783\n",
      "Episode reward: 51.858974\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.3     |\n",
      "|    ep_rew_mean      | 33.1     |\n",
      "|    exploration_rate | 0.797    |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 3851     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 21396    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00119  |\n",
      "|    n_updates        | 5323     |\n",
      "----------------------------------\n",
      "Episode reward: 35.88523\n",
      "Episode reward: 26.936467\n",
      "Episode reward: 25.875335\n",
      "Episode reward: 39.914554\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.4     |\n",
      "|    ep_rew_mean      | 33.2     |\n",
      "|    exploration_rate | 0.796    |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 3849     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 21525    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00213  |\n",
      "|    n_updates        | 5356     |\n",
      "----------------------------------\n",
      "Episode reward: 21.9505\n",
      "Episode reward: 33.806981\n",
      "Episode reward: 49.873636\n",
      "Episode reward: 35.712213\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.5     |\n",
      "|    ep_rew_mean      | 33.3     |\n",
      "|    exploration_rate | 0.794    |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 3846     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 21668    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.115    |\n",
      "|    n_updates        | 5391     |\n",
      "----------------------------------\n",
      "Episode reward: 35.671194\n",
      "Episode reward: 52.90078\n",
      "Episode reward: 28.783092\n",
      "Episode reward: 25.964399\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.3     |\n",
      "|    ep_rew_mean      | 33.1     |\n",
      "|    exploration_rate | 0.793    |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 3847     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 21812    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00102  |\n",
      "|    n_updates        | 5427     |\n",
      "----------------------------------\n",
      "Episode reward: 39.842887\n",
      "Episode reward: 23.930903\n",
      "Episode reward: 62.747426\n",
      "Episode reward: 21.881798\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 33.6     |\n",
      "|    ep_rew_mean      | 33.4     |\n",
      "|    exploration_rate | 0.791    |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 3843     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 21961    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0409   |\n",
      "|    n_updates        | 5465     |\n",
      "----------------------------------\n",
      "Episode reward: 40.705724\n",
      "Episode reward: 36.957691\n",
      "Episode reward: 32.838836\n",
      "Episode reward: 36.925084\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34       |\n",
      "|    ep_rew_mean      | 33.8     |\n",
      "|    exploration_rate | 0.79     |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 3841     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 22109    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.036    |\n",
      "|    n_updates        | 5502     |\n",
      "----------------------------------\n",
      "Episode reward: 28.956559\n",
      "Episode reward: 38.892347\n",
      "Episode reward: 48.893609\n",
      "Episode reward: 41.859553\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.5     |\n",
      "|    ep_rew_mean      | 34.3     |\n",
      "|    exploration_rate | 0.788    |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 3843     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 22268    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.108    |\n",
      "|    n_updates        | 5541     |\n",
      "----------------------------------\n",
      "Episode reward: 45.902633\n",
      "Episode reward: 22.89321\n",
      "Episode reward: 28.857239\n",
      "Episode reward: 31.965422\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.7     |\n",
      "|    ep_rew_mean      | 34.5     |\n",
      "|    exploration_rate | 0.787    |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 3842     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 22398    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0387   |\n",
      "|    n_updates        | 5574     |\n",
      "----------------------------------\n",
      "Episode reward: 33.928012\n",
      "Episode reward: 40.945506\n",
      "Episode reward: 29.94204\n",
      "Episode reward: 33.959926\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.8     |\n",
      "|    ep_rew_mean      | 34.6     |\n",
      "|    exploration_rate | 0.786    |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 3834     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 22537    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0377   |\n",
      "|    n_updates        | 5609     |\n",
      "----------------------------------\n",
      "Episode reward: 49.638964\n",
      "Episode reward: 20.947956\n",
      "Episode reward: 40.862173\n",
      "Episode reward: 40.925921\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.8     |\n",
      "|    ep_rew_mean      | 34.7     |\n",
      "|    exploration_rate | 0.784    |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 3833     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 22690    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 5647     |\n",
      "----------------------------------\n",
      "Episode reward: 85.718028\n",
      "Episode reward: 27.931641\n",
      "Episode reward: 38.892189\n",
      "Episode reward: 20.866096\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | 35.1     |\n",
      "|    exploration_rate | 0.783    |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 3838     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 22869    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 5692     |\n",
      "----------------------------------\n",
      "Episode reward: 26.492855\n",
      "Episode reward: 27.92275\n",
      "Episode reward: 31.919553\n",
      "Episode reward: 28.840198\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.1     |\n",
      "|    ep_rew_mean      | 34.9     |\n",
      "|    exploration_rate | 0.782    |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 3841     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 22985    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00486  |\n",
      "|    n_updates        | 5721     |\n",
      "----------------------------------\n",
      "Episode reward: 40.622234\n",
      "Episode reward: 20.939875\n",
      "Episode reward: 49.840991\n",
      "Episode reward: 28.929686\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | 35.2     |\n",
      "|    exploration_rate | 0.78     |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 3842     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 23126    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0328   |\n",
      "|    n_updates        | 5756     |\n",
      "----------------------------------\n",
      "Episode reward: 39.669241\n",
      "Episode reward: 35.936068\n",
      "Episode reward: 19.93024\n",
      "Episode reward: 46.832499\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | 35.2     |\n",
      "|    exploration_rate | 0.779    |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 3843     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 23269    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.034    |\n",
      "|    n_updates        | 5792     |\n",
      "----------------------------------\n",
      "Episode reward: 28.930348\n",
      "Episode reward: 19.867413\n",
      "Episode reward: 24.932185\n",
      "Episode reward: 33.895596\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.1     |\n",
      "|    ep_rew_mean      | 34.9     |\n",
      "|    exploration_rate | 0.778    |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 3832     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 23377    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00163  |\n",
      "|    n_updates        | 5819     |\n",
      "----------------------------------\n",
      "Episode reward: 34.836921\n",
      "Episode reward: 35.521727\n",
      "Episode reward: 33.908814\n",
      "Episode reward: 42.903703\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35       |\n",
      "|    ep_rew_mean      | 34.8     |\n",
      "|    exploration_rate | 0.777    |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 3827     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 23525    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.035    |\n",
      "|    n_updates        | 5856     |\n",
      "----------------------------------\n",
      "Episode reward: 28.94513\n",
      "Episode reward: 20.971022\n",
      "Episode reward: 34.913032\n",
      "Episode reward: 34.817371\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.8     |\n",
      "|    ep_rew_mean      | 34.6     |\n",
      "|    exploration_rate | 0.775    |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 3826     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 23645    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0028   |\n",
      "|    n_updates        | 5886     |\n",
      "----------------------------------\n",
      "Episode reward: 35.952521\n",
      "Episode reward: 27.872844\n",
      "Episode reward: 39.458236\n",
      "Episode reward: 27.924781\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.9     |\n",
      "|    ep_rew_mean      | 34.7     |\n",
      "|    exploration_rate | 0.774    |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 3825     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 23777    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0405   |\n",
      "|    n_updates        | 5919     |\n",
      "----------------------------------\n",
      "Episode reward: 25.945732\n",
      "Episode reward: 39.754294\n",
      "Episode reward: 31.689683\n",
      "Episode reward: 43.745214\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35       |\n",
      "|    ep_rew_mean      | 34.8     |\n",
      "|    exploration_rate | 0.773    |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 3815     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 23919    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0321   |\n",
      "|    n_updates        | 5954     |\n",
      "----------------------------------\n",
      "Episode reward: 38.893589\n",
      "Episode reward: 52.809017\n",
      "Episode reward: 27.946049\n",
      "Episode reward: 34.917396\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.2     |\n",
      "|    ep_rew_mean      | 35       |\n",
      "|    exploration_rate | 0.771    |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 3806     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 24074    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0335   |\n",
      "|    n_updates        | 5993     |\n",
      "----------------------------------\n",
      "Episode reward: 33.842162\n",
      "Episode reward: 34.911619\n",
      "Episode reward: 35.941208\n",
      "Episode reward: 16.948521\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | 35.2     |\n",
      "|    exploration_rate | 0.77     |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 3806     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 24196    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00385  |\n",
      "|    n_updates        | 6023     |\n",
      "----------------------------------\n",
      "Episode reward: 37.911194\n",
      "Episode reward: 36.491647\n",
      "Episode reward: 52.837593\n",
      "Episode reward: 42.712932\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.6     |\n",
      "|    ep_rew_mean      | 35.4     |\n",
      "|    exploration_rate | 0.769    |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 3805     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 24367    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.049    |\n",
      "|    n_updates        | 6066     |\n",
      "----------------------------------\n",
      "Episode reward: 38.721302\n",
      "Episode reward: 26.794686\n",
      "Episode reward: 17.965939\n",
      "Episode reward: 21.880993\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.2     |\n",
      "|    ep_rew_mean      | 35       |\n",
      "|    exploration_rate | 0.768    |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 3800     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 24473    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0021   |\n",
      "|    n_updates        | 6093     |\n",
      "----------------------------------\n",
      "Episode reward: 25.85234\n",
      "Episode reward: 25.956393\n",
      "Episode reward: 23.942143\n",
      "Episode reward: 31.846929\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.9     |\n",
      "|    ep_rew_mean      | 34.7     |\n",
      "|    exploration_rate | 0.766    |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 3788     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 24581    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.109    |\n",
      "|    n_updates        | 6120     |\n",
      "----------------------------------\n",
      "Episode reward: 35.652578\n",
      "Episode reward: 44.791224\n",
      "Episode reward: 54.839167\n",
      "Episode reward: 55.546229\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | 35.1     |\n",
      "|    exploration_rate | 0.765    |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 3788     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 24773    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00386  |\n",
      "|    n_updates        | 6168     |\n",
      "----------------------------------\n",
      "Episode reward: 44.695812\n",
      "Episode reward: 48.743548\n",
      "Episode reward: 51.711117\n",
      "Episode reward: 53.722349\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | 35.6     |\n",
      "|    exploration_rate | 0.763    |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 3788     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 24973    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0684   |\n",
      "|    n_updates        | 6218     |\n",
      "----------------------------------\n",
      "Episode reward: 33.873571\n",
      "Episode reward: 34.560019\n",
      "Episode reward: 28.95543\n",
      "Episode reward: 28.880549\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | 35.5     |\n",
      "|    exploration_rate | 0.762    |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 3785     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 25100    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0367   |\n",
      "|    n_updates        | 6249     |\n",
      "----------------------------------\n",
      "Episode reward: 35.829127\n",
      "Episode reward: 30.913201\n",
      "Episode reward: 28.946381\n",
      "Episode reward: 41.917178\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.7     |\n",
      "|    ep_rew_mean      | 35.5     |\n",
      "|    exploration_rate | 0.76     |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 3773     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 25238    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0288   |\n",
      "|    n_updates        | 6284     |\n",
      "----------------------------------\n",
      "Episode reward: 19.966347\n",
      "Episode reward: 34.725294\n",
      "Episode reward: 28.741873\n",
      "Episode reward: 29.864101\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | 35.2     |\n",
      "|    exploration_rate | 0.759    |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 3772     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 25352    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0369   |\n",
      "|    n_updates        | 6312     |\n",
      "----------------------------------\n",
      "Episode reward: 26.836115\n",
      "Episode reward: 25.914562\n",
      "Episode reward: 36.866475\n",
      "Episode reward: 34.819686\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.2     |\n",
      "|    ep_rew_mean      | 35       |\n",
      "|    exploration_rate | 0.758    |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 3771     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 25477    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00286  |\n",
      "|    n_updates        | 6344     |\n",
      "----------------------------------\n",
      "Episode reward: 25.859342\n",
      "Episode reward: 48.817931\n",
      "Episode reward: 63.737866\n",
      "Episode reward: 45.906426\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.5     |\n",
      "|    ep_rew_mean      | 35.3     |\n",
      "|    exploration_rate | 0.756    |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 3767     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 25662    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0463   |\n",
      "|    n_updates        | 6390     |\n",
      "----------------------------------\n",
      "Episode reward: 31.962616\n",
      "Episode reward: 28.843132\n",
      "Episode reward: 33.949501\n",
      "Episode reward: 29.935704\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.2     |\n",
      "|    ep_rew_mean      | 35       |\n",
      "|    exploration_rate | 0.755    |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 3756     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 25787    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00156  |\n",
      "|    n_updates        | 6421     |\n",
      "----------------------------------\n",
      "Episode reward: 21.961452\n",
      "Episode reward: 65.914886\n",
      "Episode reward: 27.690222\n",
      "Episode reward: 22.808137\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | 35.1     |\n",
      "|    exploration_rate | 0.754    |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 3755     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 25929    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0369   |\n",
      "|    n_updates        | 6457     |\n",
      "----------------------------------\n",
      "Episode reward: 60.013105\n",
      "Episode reward: 23.880544\n",
      "Episode reward: 52.814967\n",
      "Episode reward: 42.835396\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | 35.5     |\n",
      "|    exploration_rate | 0.752    |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 3755     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 26113    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00219  |\n",
      "|    n_updates        | 6503     |\n",
      "----------------------------------\n",
      "Episode reward: 37.626495\n",
      "Episode reward: 23.953356\n",
      "Episode reward: 45.939025\n",
      "Episode reward: 38.731318\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.7     |\n",
      "|    ep_rew_mean      | 35.4     |\n",
      "|    exploration_rate | 0.751    |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 3756     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 26260    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0371   |\n",
      "|    n_updates        | 6539     |\n",
      "----------------------------------\n",
      "Episode reward: 34.822838\n",
      "Episode reward: 23.893951\n",
      "Episode reward: 42.782704\n",
      "Episode reward: 71.176406\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.7     |\n",
      "|    ep_rew_mean      | 35.4     |\n",
      "|    exploration_rate | 0.749    |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 3758     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 26435    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0752   |\n",
      "|    n_updates        | 6583     |\n",
      "----------------------------------\n",
      "Episode reward: 32.950643\n",
      "Episode reward: 32.89906\n",
      "Episode reward: 22.923555\n",
      "Episode reward: 37.919098\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | 35.5     |\n",
      "|    exploration_rate | 0.748    |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 3751     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 26562    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0378   |\n",
      "|    n_updates        | 6615     |\n",
      "----------------------------------\n",
      "Episode reward: 27.867461\n",
      "Episode reward: 30.930444\n",
      "Episode reward: 45.780101\n",
      "Episode reward: 35.901035\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | 35.5     |\n",
      "|    exploration_rate | 0.746    |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 3750     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 26703    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0489   |\n",
      "|    n_updates        | 6650     |\n",
      "----------------------------------\n",
      "Episode reward: 20.952563\n",
      "Episode reward: 30.94371\n",
      "Episode reward: 47.912624\n",
      "Episode reward: 32.951562\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.7     |\n",
      "|    ep_rew_mean      | 35.4     |\n",
      "|    exploration_rate | 0.745    |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 3751     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 26836    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0047   |\n",
      "|    n_updates        | 6683     |\n",
      "----------------------------------\n",
      "Episode reward: 19.948355\n",
      "Episode reward: 48.641922\n",
      "Episode reward: 30.952998\n",
      "Episode reward: 32.919663\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.9     |\n",
      "|    ep_rew_mean      | 35.7     |\n",
      "|    exploration_rate | 0.744    |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 3748     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 26969    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0498   |\n",
      "|    n_updates        | 6717     |\n",
      "----------------------------------\n",
      "Episode reward: 36.865605\n",
      "Episode reward: 48.800002\n",
      "Episode reward: 38.95718\n",
      "Episode reward: 35.944246\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36       |\n",
      "|    ep_rew_mean      | 35.8     |\n",
      "|    exploration_rate | 0.742    |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 3750     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 27130    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0441   |\n",
      "|    n_updates        | 6757     |\n",
      "----------------------------------\n",
      "Episode reward: 41.855026\n",
      "Episode reward: 24.870046\n",
      "Episode reward: 30.704114\n",
      "Episode reward: 47.870429\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.3     |\n",
      "|    ep_rew_mean      | 36.1     |\n",
      "|    exploration_rate | 0.741    |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 3751     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 27276    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00284  |\n",
      "|    n_updates        | 6793     |\n",
      "----------------------------------\n",
      "Episode reward: 34.91618\n",
      "Episode reward: 31.951947\n",
      "Episode reward: 42.935679\n",
      "Episode reward: 44.758666\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.5     |\n",
      "|    ep_rew_mean      | 36.3     |\n",
      "|    exploration_rate | 0.739    |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 3752     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 27431    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0361   |\n",
      "|    n_updates        | 6832     |\n",
      "----------------------------------\n",
      "Episode reward: 43.884139\n",
      "Episode reward: 30.916533\n",
      "Episode reward: 45.944446\n",
      "Episode reward: 31.838362\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.6     |\n",
      "|    ep_rew_mean      | 36.4     |\n",
      "|    exploration_rate | 0.738    |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 3753     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 27584    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00128  |\n",
      "|    n_updates        | 6870     |\n",
      "----------------------------------\n",
      "Episode reward: 18.959128\n",
      "Episode reward: 20.931089\n",
      "Episode reward: 31.942506\n",
      "Episode reward: 30.528411\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.1     |\n",
      "|    ep_rew_mean      | 35.9     |\n",
      "|    exploration_rate | 0.737    |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 3746     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 27687    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.031    |\n",
      "|    n_updates        | 6896     |\n",
      "----------------------------------\n",
      "Episode reward: 29.941326\n",
      "Episode reward: 22.960584\n",
      "Episode reward: 46.202963\n",
      "Episode reward: 30.598062\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | 36       |\n",
      "|    exploration_rate | 0.736    |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 3747     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 27818    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0356   |\n",
      "|    n_updates        | 6929     |\n",
      "----------------------------------\n",
      "Episode reward: 24.966296\n",
      "Episode reward: 22.953686\n",
      "Episode reward: 22.948735\n",
      "Episode reward: 34.640236\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.6     |\n",
      "|    ep_rew_mean      | 35.3     |\n",
      "|    exploration_rate | 0.735    |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 3746     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 27924    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.125    |\n",
      "|    n_updates        | 6955     |\n",
      "----------------------------------\n",
      "Episode reward: 27.895827\n",
      "Episode reward: 21.888123\n",
      "Episode reward: 25.961165\n",
      "Episode reward: 26.930982\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.5     |\n",
      "|    ep_rew_mean      | 35.3     |\n",
      "|    exploration_rate | 0.734    |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 3747     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 28027    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00257  |\n",
      "|    n_updates        | 6981     |\n",
      "----------------------------------\n",
      "Episode reward: 31.966589\n",
      "Episode reward: 36.899788\n",
      "Episode reward: 42.911233\n",
      "Episode reward: 25.967242\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | 35.6     |\n",
      "|    exploration_rate | 0.732    |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 3741     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 28165    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00177  |\n",
      "|    n_updates        | 7016     |\n",
      "----------------------------------\n",
      "Episode reward: 27.896829\n",
      "Episode reward: 50.9158\n",
      "Episode reward: 26.932232\n",
      "Episode reward: 32.895545\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | 35.1     |\n",
      "|    exploration_rate | 0.731    |\n",
      "| time/               |          |\n",
      "|    episodes         | 804      |\n",
      "|    fps              | 3739     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 28304    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00298  |\n",
      "|    n_updates        | 7050     |\n",
      "----------------------------------\n",
      "Episode reward: 34.878903\n",
      "Episode reward: 35.937053\n",
      "Episode reward: 34.938637\n",
      "Episode reward: 25.918456\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.6     |\n",
      "|    ep_rew_mean      | 34.4     |\n",
      "|    exploration_rate | 0.73     |\n",
      "| time/               |          |\n",
      "|    episodes         | 808      |\n",
      "|    fps              | 3741     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 28436    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00306  |\n",
      "|    n_updates        | 7083     |\n",
      "----------------------------------\n",
      "Episode reward: 26.943167\n",
      "Episode reward: 44.929955\n",
      "Episode reward: 48.240482\n",
      "Episode reward: 26.878683\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.8     |\n",
      "|    ep_rew_mean      | 34.6     |\n",
      "|    exploration_rate | 0.728    |\n",
      "| time/               |          |\n",
      "|    episodes         | 812      |\n",
      "|    fps              | 3742     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 28584    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00428  |\n",
      "|    n_updates        | 7120     |\n",
      "----------------------------------\n",
      "Episode reward: 57.897914\n",
      "Episode reward: 45.476741\n",
      "Episode reward: 49.815484\n",
      "Episode reward: 33.877088\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | 35.1     |\n",
      "|    exploration_rate | 0.727    |\n",
      "| time/               |          |\n",
      "|    episodes         | 816      |\n",
      "|    fps              | 3744     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 28772    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0703   |\n",
      "|    n_updates        | 7167     |\n",
      "----------------------------------\n",
      "Episode reward: 27.961461\n",
      "Episode reward: 40.815806\n",
      "Episode reward: 23.969681\n",
      "Episode reward: 28.968876\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | 35.2     |\n",
      "|    exploration_rate | 0.726    |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 3730     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 28894    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00262  |\n",
      "|    n_updates        | 7198     |\n",
      "----------------------------------\n",
      "Episode reward: 30.768394\n",
      "Episode reward: 20.893631\n",
      "Episode reward: 39.831334\n",
      "Episode reward: 38.943299\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.5     |\n",
      "|    ep_rew_mean      | 35.3     |\n",
      "|    exploration_rate | 0.724    |\n",
      "| time/               |          |\n",
      "|    episodes         | 824      |\n",
      "|    fps              | 3731     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 29025    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0292   |\n",
      "|    n_updates        | 7231     |\n",
      "----------------------------------\n",
      "Episode reward: 35.946141\n",
      "Episode reward: 49.924079\n",
      "Episode reward: 40.832869\n",
      "Episode reward: 26.961442\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.2     |\n",
      "|    ep_rew_mean      | 35       |\n",
      "|    exploration_rate | 0.723    |\n",
      "| time/               |          |\n",
      "|    episodes         | 828      |\n",
      "|    fps              | 3734     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 29179    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00306  |\n",
      "|    n_updates        | 7269     |\n",
      "----------------------------------\n",
      "Episode reward: 37.818956\n",
      "Episode reward: 82.794811\n",
      "Episode reward: 35.859612\n",
      "Episode reward: 29.890125\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | 35.6     |\n",
      "|    exploration_rate | 0.721    |\n",
      "| time/               |          |\n",
      "|    episodes         | 832      |\n",
      "|    fps              | 3736     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 29366    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00117  |\n",
      "|    n_updates        | 7316     |\n",
      "----------------------------------\n",
      "Episode reward: 46.642767\n",
      "Episode reward: 36.829255\n",
      "Episode reward: 38.907955\n",
      "Episode reward: 47.818983\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.1     |\n",
      "|    ep_rew_mean      | 35.9     |\n",
      "|    exploration_rate | 0.719    |\n",
      "| time/               |          |\n",
      "|    episodes         | 836      |\n",
      "|    fps              | 3725     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 29537    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0385   |\n",
      "|    n_updates        | 7359     |\n",
      "----------------------------------\n",
      "Episode reward: 28.927787\n",
      "Episode reward: 35.897122\n",
      "Episode reward: 34.779854\n",
      "Episode reward: 52.959405\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.8     |\n",
      "|    ep_rew_mean      | 35.6     |\n",
      "|    exploration_rate | 0.718    |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 3726     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 29691    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0488   |\n",
      "|    n_updates        | 7397     |\n",
      "----------------------------------\n",
      "Episode reward: 42.848563\n",
      "Episode reward: 25.949626\n",
      "Episode reward: 27.92409\n",
      "Episode reward: 33.919452\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.6     |\n",
      "|    ep_rew_mean      | 35.5     |\n",
      "|    exploration_rate | 0.717    |\n",
      "| time/               |          |\n",
      "|    episodes         | 844      |\n",
      "|    fps              | 3726     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 29822    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 7430     |\n",
      "----------------------------------\n",
      "Episode reward: 34.863515\n",
      "Episode reward: 34.950728\n",
      "Episode reward: 47.83403\n",
      "Episode reward: 29.643556\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | 35.2     |\n",
      "|    exploration_rate | 0.715    |\n",
      "| time/               |          |\n",
      "|    episodes         | 848      |\n",
      "|    fps              | 3726     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 29970    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0428   |\n",
      "|    n_updates        | 7467     |\n",
      "----------------------------------\n",
      "Episode reward: 22.969236\n",
      "Episode reward: 28.928462\n",
      "Episode reward: 38.815468\n",
      "Episode reward: 31.920717\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | 35.2     |\n",
      "|    exploration_rate | 0.714    |\n",
      "| time/               |          |\n",
      "|    episodes         | 852      |\n",
      "|    fps              | 3721     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 30093    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.124    |\n",
      "|    n_updates        | 7498     |\n",
      "----------------------------------\n",
      "Episode reward: 25.948578\n",
      "Episode reward: 25.936865\n",
      "Episode reward: 27.962015\n",
      "Episode reward: 27.888381\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35       |\n",
      "|    ep_rew_mean      | 34.8     |\n",
      "|    exploration_rate | 0.713    |\n",
      "| time/               |          |\n",
      "|    episodes         | 856      |\n",
      "|    fps              | 3719     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 30201    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 7525     |\n",
      "----------------------------------\n",
      "Episode reward: 29.873859\n",
      "Episode reward: 19.898363\n",
      "Episode reward: 37.723976\n",
      "Episode reward: 32.963966\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.9     |\n",
      "|    ep_rew_mean      | 34.7     |\n",
      "|    exploration_rate | 0.712    |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 3717     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 30322    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00112  |\n",
      "|    n_updates        | 7555     |\n",
      "----------------------------------\n",
      "Episode reward: 32.961663\n",
      "Episode reward: 36.884022\n",
      "Episode reward: 31.664373\n",
      "Episode reward: 60.800058\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.2     |\n",
      "|    ep_rew_mean      | 35       |\n",
      "|    exploration_rate | 0.71     |\n",
      "| time/               |          |\n",
      "|    episodes         | 864      |\n",
      "|    fps              | 3714     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 30485    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0537   |\n",
      "|    n_updates        | 7596     |\n",
      "----------------------------------\n",
      "Episode reward: 32.96175\n",
      "Episode reward: 30.786087\n",
      "Episode reward: 35.867788\n",
      "Episode reward: 27.906629\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.8     |\n",
      "|    ep_rew_mean      | 34.7     |\n",
      "|    exploration_rate | 0.709    |\n",
      "| time/               |          |\n",
      "|    episodes         | 868      |\n",
      "|    fps              | 3703     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 30613    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000809 |\n",
      "|    n_updates        | 7628     |\n",
      "----------------------------------\n",
      "Episode reward: 35.705142\n",
      "Episode reward: 20.949278\n",
      "Episode reward: 41.869237\n",
      "Episode reward: 59.89459\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35       |\n",
      "|    ep_rew_mean      | 34.8     |\n",
      "|    exploration_rate | 0.708    |\n",
      "| time/               |          |\n",
      "|    episodes         | 872      |\n",
      "|    fps              | 3703     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 30772    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0569   |\n",
      "|    n_updates        | 7667     |\n",
      "----------------------------------\n",
      "Episode reward: 30.961086\n",
      "Episode reward: 20.88506\n",
      "Episode reward: 31.961885\n",
      "Episode reward: 35.57649\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.6     |\n",
      "|    ep_rew_mean      | 34.5     |\n",
      "|    exploration_rate | 0.707    |\n",
      "| time/               |          |\n",
      "|    episodes         | 876      |\n",
      "|    fps              | 3704     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 30892    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0952   |\n",
      "|    n_updates        | 7697     |\n",
      "----------------------------------\n",
      "Episode reward: 36.926427\n",
      "Episode reward: 40.709541\n",
      "Episode reward: 56.514032\n",
      "Episode reward: 45.934985\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 34.9     |\n",
      "|    ep_rew_mean      | 34.7     |\n",
      "|    exploration_rate | 0.705    |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 3703     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 31073    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.131    |\n",
      "|    n_updates        | 7743     |\n",
      "----------------------------------\n",
      "Episode reward: 34.836009\n",
      "Episode reward: 41.732277\n",
      "Episode reward: 25.8798\n",
      "Episode reward: 43.943441\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | 35.2     |\n",
      "|    exploration_rate | 0.703    |\n",
      "| time/               |          |\n",
      "|    episodes         | 884      |\n",
      "|    fps              | 3697     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 31220    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 7779     |\n",
      "----------------------------------\n",
      "Episode reward: 29.949589\n",
      "Episode reward: 36.899658\n",
      "Episode reward: 28.762791\n",
      "Episode reward: 35.948824\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.3     |\n",
      "|    ep_rew_mean      | 35.2     |\n",
      "|    exploration_rate | 0.702    |\n",
      "| time/               |          |\n",
      "|    episodes         | 888      |\n",
      "|    fps              | 3696     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 31352    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0555   |\n",
      "|    n_updates        | 7812     |\n",
      "----------------------------------\n",
      "Episode reward: 25.955866\n",
      "Episode reward: 36.895658\n",
      "Episode reward: 23.961771\n",
      "Episode reward: 24.950347\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 35.4     |\n",
      "|    ep_rew_mean      | 35.3     |\n",
      "|    exploration_rate | 0.701    |\n",
      "| time/               |          |\n",
      "|    episodes         | 892      |\n",
      "|    fps              | 3692     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 31464    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0536   |\n",
      "|    n_updates        | 7840     |\n",
      "----------------------------------\n",
      "Episode reward: 35.950485\n",
      "Episode reward: 40.951018\n",
      "Episode reward: 46.602739\n",
      "Episode reward: 42.777398\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36       |\n",
      "|    ep_rew_mean      | 35.9     |\n",
      "|    exploration_rate | 0.7      |\n",
      "| time/               |          |\n",
      "|    episodes         | 896      |\n",
      "|    fps              | 3686     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 31631    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0511   |\n",
      "|    n_updates        | 7882     |\n",
      "----------------------------------\n",
      "Episode reward: 31.878475\n",
      "Episode reward: 33.941387\n",
      "Episode reward: 41.801955\n",
      "Episode reward: 33.943014\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.1     |\n",
      "|    ep_rew_mean      | 35.9     |\n",
      "|    exploration_rate | 0.698    |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 3685     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 31773    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0661   |\n",
      "|    n_updates        | 7918     |\n",
      "----------------------------------\n",
      "Episode reward: 33.866918\n",
      "Episode reward: 40.799899\n",
      "Episode reward: 43.793391\n",
      "Episode reward: 33.860132\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.2     |\n",
      "|    ep_rew_mean      | 36.1     |\n",
      "|    exploration_rate | 0.697    |\n",
      "| time/               |          |\n",
      "|    episodes         | 904      |\n",
      "|    fps              | 3683     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 31926    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00218  |\n",
      "|    n_updates        | 7956     |\n",
      "----------------------------------\n",
      "Episode reward: 47.672409\n",
      "Episode reward: 37.94452\n",
      "Episode reward: 25.958667\n",
      "Episode reward: 31.959204\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.3     |\n",
      "|    ep_rew_mean      | 36.2     |\n",
      "|    exploration_rate | 0.695    |\n",
      "| time/               |          |\n",
      "|    episodes         | 908      |\n",
      "|    fps              | 3683     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 32070    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00168  |\n",
      "|    n_updates        | 7992     |\n",
      "----------------------------------\n",
      "Episode reward: 41.212368\n",
      "Episode reward: 50.77108\n",
      "Episode reward: 45.902185\n",
      "Episode reward: 43.609634\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.7     |\n",
      "|    ep_rew_mean      | 36.5     |\n",
      "|    exploration_rate | 0.694    |\n",
      "| time/               |          |\n",
      "|    episodes         | 912      |\n",
      "|    fps              | 3672     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 32253    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.143    |\n",
      "|    n_updates        | 8038     |\n",
      "----------------------------------\n",
      "Episode reward: 49.821456\n",
      "Episode reward: 42.916008\n",
      "Episode reward: 49.673638\n",
      "Episode reward: 54.925278\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.8     |\n",
      "|    ep_rew_mean      | 36.6     |\n",
      "|    exploration_rate | 0.692    |\n",
      "| time/               |          |\n",
      "|    episodes         | 916      |\n",
      "|    fps              | 3672     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 32451    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00384  |\n",
      "|    n_updates        | 8087     |\n",
      "----------------------------------\n",
      "Episode reward: 77.224713\n",
      "Episode reward: 38.953326\n",
      "Episode reward: 54.886921\n",
      "Episode reward: 47.749076\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | 37.6     |\n",
      "|    exploration_rate | 0.69     |\n",
      "| time/               |          |\n",
      "|    episodes         | 920      |\n",
      "|    fps              | 3665     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 32671    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00211  |\n",
      "|    n_updates        | 8142     |\n",
      "----------------------------------\n",
      "Episode reward: 30.937369\n",
      "Episode reward: 34.734025\n",
      "Episode reward: 38.813845\n",
      "Episode reward: 32.92589\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | 37.7     |\n",
      "|    exploration_rate | 0.688    |\n",
      "| time/               |          |\n",
      "|    episodes         | 924      |\n",
      "|    fps              | 3666     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 32809    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.132    |\n",
      "|    n_updates        | 8177     |\n",
      "----------------------------------\n",
      "Episode reward: 31.959762\n",
      "Episode reward: 32.854329\n",
      "Episode reward: 33.917669\n",
      "Episode reward: 35.886423\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.6     |\n",
      "|    ep_rew_mean      | 37.5     |\n",
      "|    exploration_rate | 0.687    |\n",
      "| time/               |          |\n",
      "|    episodes         | 928      |\n",
      "|    fps              | 3667     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 32944    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0534   |\n",
      "|    n_updates        | 8210     |\n",
      "----------------------------------\n",
      "Episode reward: 73.729687\n",
      "Episode reward: 41.941428\n",
      "Episode reward: 30.941599\n",
      "Episode reward: 33.954249\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.6     |\n",
      "|    ep_rew_mean      | 37.4     |\n",
      "|    exploration_rate | 0.685    |\n",
      "| time/               |          |\n",
      "|    episodes         | 932      |\n",
      "|    fps              | 3664     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 33125    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.134    |\n",
      "|    n_updates        | 8256     |\n",
      "----------------------------------\n",
      "Episode reward: 23.970493\n",
      "Episode reward: 34.957497\n",
      "Episode reward: 27.945889\n",
      "Episode reward: 24.957664\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37       |\n",
      "|    ep_rew_mean      | 36.8     |\n",
      "|    exploration_rate | 0.684    |\n",
      "| time/               |          |\n",
      "|    episodes         | 936      |\n",
      "|    fps              | 3661     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 33237    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 8284     |\n",
      "----------------------------------\n",
      "Episode reward: 21.954153\n",
      "Episode reward: 37.751732\n",
      "Episode reward: 29.651116\n",
      "Episode reward: 31.953481\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 36.7     |\n",
      "|    ep_rew_mean      | 36.5     |\n",
      "|    exploration_rate | 0.683    |\n",
      "| time/               |          |\n",
      "|    episodes         | 940      |\n",
      "|    fps              | 3656     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 33359    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00232  |\n",
      "|    n_updates        | 8314     |\n",
      "----------------------------------\n",
      "Episode reward: 61.591722\n",
      "Episode reward: 35.955567\n",
      "Episode reward: 31.721035\n",
      "Episode reward: 34.852344\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37       |\n",
      "|    ep_rew_mean      | 36.9     |\n",
      "|    exploration_rate | 0.682    |\n",
      "| time/               |          |\n",
      "|    episodes         | 944      |\n",
      "|    fps              | 3658     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 33524    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0605   |\n",
      "|    n_updates        | 8355     |\n",
      "----------------------------------\n",
      "Episode reward: 62.877935\n",
      "Episode reward: 58.396273\n",
      "Episode reward: 66.683893\n",
      "Episode reward: 33.930215\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 37.8     |\n",
      "|    ep_rew_mean      | 37.6     |\n",
      "|    exploration_rate | 0.679    |\n",
      "| time/               |          |\n",
      "|    episodes         | 948      |\n",
      "|    fps              | 3660     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 33747    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0674   |\n",
      "|    n_updates        | 8411     |\n",
      "----------------------------------\n",
      "Episode reward: 32.890906\n",
      "Episode reward: 38.957233\n",
      "Episode reward: 41.91025\n",
      "Episode reward: 53.469373\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.2     |\n",
      "|    ep_rew_mean      | 38.1     |\n",
      "|    exploration_rate | 0.678    |\n",
      "| time/               |          |\n",
      "|    episodes         | 952      |\n",
      "|    fps              | 3663     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 33915    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00161  |\n",
      "|    n_updates        | 8453     |\n",
      "----------------------------------\n",
      "Episode reward: 39.915117\n",
      "Episode reward: 46.842013\n",
      "Episode reward: 28.836735\n",
      "Episode reward: 45.571004\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 38.8     |\n",
      "|    ep_rew_mean      | 38.6     |\n",
      "|    exploration_rate | 0.676    |\n",
      "| time/               |          |\n",
      "|    episodes         | 956      |\n",
      "|    fps              | 3663     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 34077    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 8494     |\n",
      "----------------------------------\n",
      "Episode reward: 52.750059\n",
      "Episode reward: 31.940809\n",
      "Episode reward: 59.995243\n",
      "Episode reward: 27.936127\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.3     |\n",
      "|    ep_rew_mean      | 39.1     |\n",
      "|    exploration_rate | 0.675    |\n",
      "| time/               |          |\n",
      "|    episodes         | 960      |\n",
      "|    fps              | 3661     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 34251    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0988   |\n",
      "|    n_updates        | 8537     |\n",
      "----------------------------------\n",
      "Episode reward: 35.781907\n",
      "Episode reward: 36.921603\n",
      "Episode reward: 30.903901\n",
      "Episode reward: 37.899967\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.1     |\n",
      "|    ep_rew_mean      | 38.9     |\n",
      "|    exploration_rate | 0.673    |\n",
      "| time/               |          |\n",
      "|    episodes         | 964      |\n",
      "|    fps              | 3662     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 34393    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0607   |\n",
      "|    n_updates        | 8573     |\n",
      "----------------------------------\n",
      "Episode reward: 26.919575\n",
      "Episode reward: 41.866149\n",
      "Episode reward: 40.911214\n",
      "Episode reward: 31.921282\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | 39       |\n",
      "|    exploration_rate | 0.672    |\n",
      "| time/               |          |\n",
      "|    episodes         | 968      |\n",
      "|    fps              | 3664     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 34535    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 8608     |\n",
      "----------------------------------\n",
      "Episode reward: 57.801909\n",
      "Episode reward: 37.863307\n",
      "Episode reward: 42.787329\n",
      "Episode reward: 22.823383\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | 39.1     |\n",
      "|    exploration_rate | 0.67     |\n",
      "| time/               |          |\n",
      "|    episodes         | 972      |\n",
      "|    fps              | 3666     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 34697    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00095  |\n",
      "|    n_updates        | 8649     |\n",
      "----------------------------------\n",
      "Episode reward: 29.908459\n",
      "Episode reward: 46.814066\n",
      "Episode reward: 40.892763\n",
      "Episode reward: 33.912926\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | 39.4     |\n",
      "|    exploration_rate | 0.669    |\n",
      "| time/               |          |\n",
      "|    episodes         | 976      |\n",
      "|    fps              | 3663     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 34849    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00243  |\n",
      "|    n_updates        | 8687     |\n",
      "----------------------------------\n",
      "Episode reward: 32.892083\n",
      "Episode reward: 28.962531\n",
      "Episode reward: 33.955916\n",
      "Episode reward: 31.812092\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39       |\n",
      "|    ep_rew_mean      | 38.9     |\n",
      "|    exploration_rate | 0.668    |\n",
      "| time/               |          |\n",
      "|    episodes         | 980      |\n",
      "|    fps              | 3664     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 34977    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 8719     |\n",
      "----------------------------------\n",
      "Episode reward: 26.950074\n",
      "Episode reward: 103.704828\n",
      "Episode reward: 30.878364\n",
      "Episode reward: 40.953543\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | 39.4     |\n",
      "|    exploration_rate | 0.666    |\n",
      "| time/               |          |\n",
      "|    episodes         | 984      |\n",
      "|    fps              | 3663     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 35180    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0556   |\n",
      "|    n_updates        | 8769     |\n",
      "----------------------------------\n",
      "Episode reward: 63.377023\n",
      "Episode reward: 35.849546\n",
      "Episode reward: 32.880983\n",
      "Episode reward: 40.646731\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | 39.8     |\n",
      "|    exploration_rate | 0.664    |\n",
      "| time/               |          |\n",
      "|    episodes         | 988      |\n",
      "|    fps              | 3664     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 35354    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00504  |\n",
      "|    n_updates        | 8813     |\n",
      "----------------------------------\n",
      "Episode reward: 37.86369\n",
      "Episode reward: 24.954199\n",
      "Episode reward: 52.848215\n",
      "Episode reward: 48.928658\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.5     |\n",
      "|    ep_rew_mean      | 40.4     |\n",
      "|    exploration_rate | 0.663    |\n",
      "| time/               |          |\n",
      "|    episodes         | 992      |\n",
      "|    fps              | 3663     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 35519    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.115    |\n",
      "|    n_updates        | 8854     |\n",
      "----------------------------------\n",
      "Episode reward: 41.891801\n",
      "Episode reward: 32.811818\n",
      "Episode reward: 46.919963\n",
      "Episode reward: 52.881177\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | 40.5     |\n",
      "|    exploration_rate | 0.661    |\n",
      "| time/               |          |\n",
      "|    episodes         | 996      |\n",
      "|    fps              | 3662     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 35694    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0606   |\n",
      "|    n_updates        | 8898     |\n",
      "----------------------------------\n",
      "Episode reward: 34.737318\n",
      "Episode reward: 54.697937\n",
      "Episode reward: 42.885953\n",
      "Episode reward: 51.869156\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | 40.9     |\n",
      "|    exploration_rate | 0.659    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1000     |\n",
      "|    fps              | 3658     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 35879    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00118  |\n",
      "|    n_updates        | 8944     |\n",
      "----------------------------------\n",
      "Episode reward: 39.915278\n",
      "Episode reward: 42.658237\n",
      "Episode reward: 47.70843\n",
      "Episode reward: 25.958951\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | 40.9     |\n",
      "|    exploration_rate | 0.658    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1004     |\n",
      "|    fps              | 3659     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 36036    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.148    |\n",
      "|    n_updates        | 8983     |\n",
      "----------------------------------\n",
      "Episode reward: 28.951647\n",
      "Episode reward: 32.956016\n",
      "Episode reward: 44.833244\n",
      "Episode reward: 38.91943\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.1     |\n",
      "|    ep_rew_mean      | 40.9     |\n",
      "|    exploration_rate | 0.656    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1008     |\n",
      "|    fps              | 3654     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 36182    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.112    |\n",
      "|    n_updates        | 9020     |\n",
      "----------------------------------\n",
      "Episode reward: 34.94163\n",
      "Episode reward: 46.534345\n",
      "Episode reward: 49.725563\n",
      "Episode reward: 67.962148\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | 41.1     |\n",
      "|    exploration_rate | 0.654    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1012     |\n",
      "|    fps              | 3656     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 36383    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00282  |\n",
      "|    n_updates        | 9070     |\n",
      "----------------------------------\n",
      "Episode reward: 34.927233\n",
      "Episode reward: 29.964042\n",
      "Episode reward: 84.043278\n",
      "Episode reward: 42.89395\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | 41.1     |\n",
      "|    exploration_rate | 0.652    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1016     |\n",
      "|    fps              | 3654     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 36579    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00465  |\n",
      "|    n_updates        | 9119     |\n",
      "----------------------------------\n",
      "Episode reward: 36.832396\n",
      "Episode reward: 47.803055\n",
      "Episode reward: 28.942479\n",
      "Episode reward: 63.914111\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.9     |\n",
      "|    ep_rew_mean      | 40.7     |\n",
      "|    exploration_rate | 0.651    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1020     |\n",
      "|    fps              | 3656     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 36757    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0569   |\n",
      "|    n_updates        | 9164     |\n",
      "----------------------------------\n",
      "Episode reward: 60.930219\n",
      "Episode reward: 47.746522\n",
      "Episode reward: 41.823005\n",
      "Episode reward: 35.958424\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | 41.1     |\n",
      "|    exploration_rate | 0.649    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1024     |\n",
      "|    fps              | 3657     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 36944    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0017   |\n",
      "|    n_updates        | 9210     |\n",
      "----------------------------------\n",
      "Episode reward: 51.74685\n",
      "Episode reward: 59.118206\n",
      "Episode reward: 49.772487\n",
      "Episode reward: 25.953356\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.9     |\n",
      "|    ep_rew_mean      | 41.7     |\n",
      "|    exploration_rate | 0.647    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1028     |\n",
      "|    fps              | 3656     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 37132    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00523  |\n",
      "|    n_updates        | 9257     |\n",
      "----------------------------------\n",
      "Episode reward: 29.849497\n",
      "Episode reward: 21.933401\n",
      "Episode reward: 36.956873\n",
      "Episode reward: 52.605646\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.5     |\n",
      "|    ep_rew_mean      | 41.3     |\n",
      "|    exploration_rate | 0.646    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1032     |\n",
      "|    fps              | 3658     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 37274    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.196    |\n",
      "|    n_updates        | 9293     |\n",
      "----------------------------------\n",
      "Episode reward: 71.368758\n",
      "Episode reward: 33.947533\n",
      "Episode reward: 57.756512\n",
      "Episode reward: 28.96518\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.3     |\n",
      "|    ep_rew_mean      | 42.1     |\n",
      "|    exploration_rate | 0.644    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1036     |\n",
      "|    fps              | 3660     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 37467    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 9341     |\n",
      "----------------------------------\n",
      "Episode reward: 36.938701\n",
      "Episode reward: 40.881632\n",
      "Episode reward: 36.923243\n",
      "Episode reward: 54.846962\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.8     |\n",
      "|    ep_rew_mean      | 42.6     |\n",
      "|    exploration_rate | 0.642    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1040     |\n",
      "|    fps              | 3652     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 37638    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0657   |\n",
      "|    n_updates        | 9384     |\n",
      "----------------------------------\n",
      "Episode reward: 39.870864\n",
      "Episode reward: 29.882231\n",
      "Episode reward: 25.786207\n",
      "Episode reward: 25.935827\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.4     |\n",
      "|    ep_rew_mean      | 42.1     |\n",
      "|    exploration_rate | 0.641    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1044     |\n",
      "|    fps              | 3654     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 37760    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0649   |\n",
      "|    n_updates        | 9414     |\n",
      "----------------------------------\n",
      "Episode reward: 34.859098\n",
      "Episode reward: 34.701296\n",
      "Episode reward: 36.948949\n",
      "Episode reward: 54.851774\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.8     |\n",
      "|    ep_rew_mean      | 41.5     |\n",
      "|    exploration_rate | 0.64     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1048     |\n",
      "|    fps              | 3656     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 37922    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0416   |\n",
      "|    n_updates        | 9455     |\n",
      "----------------------------------\n",
      "Episode reward: 30.90595\n",
      "Episode reward: 27.920962\n",
      "Episode reward: 46.697723\n",
      "Episode reward: 29.823657\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | 41.2     |\n",
      "|    exploration_rate | 0.638    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1052     |\n",
      "|    fps              | 3653     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 38058    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00137  |\n",
      "|    n_updates        | 9489     |\n",
      "----------------------------------\n",
      "Episode reward: 27.948323\n",
      "Episode reward: 30.941821\n",
      "Episode reward: 53.824737\n",
      "Episode reward: 43.925826\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.4     |\n",
      "|    ep_rew_mean      | 41.2     |\n",
      "|    exploration_rate | 0.637    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1056     |\n",
      "|    fps              | 3648     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 38215    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0679   |\n",
      "|    n_updates        | 9528     |\n",
      "----------------------------------\n",
      "Episode reward: 25.818467\n",
      "Episode reward: 22.810602\n",
      "Episode reward: 41.790186\n",
      "Episode reward: 36.881539\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.9     |\n",
      "|    ep_rew_mean      | 40.7     |\n",
      "|    exploration_rate | 0.636    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1060     |\n",
      "|    fps              | 3648     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 38343    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.198    |\n",
      "|    n_updates        | 9560     |\n",
      "----------------------------------\n",
      "Episode reward: 45.635037\n",
      "Episode reward: 22.969499\n",
      "Episode reward: 35.93114\n",
      "Episode reward: 38.754883\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.9     |\n",
      "|    ep_rew_mean      | 40.7     |\n",
      "|    exploration_rate | 0.634    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1064     |\n",
      "|    fps              | 3649     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 38487    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0547   |\n",
      "|    n_updates        | 9596     |\n",
      "----------------------------------\n",
      "Episode reward: 35.841238\n",
      "Episode reward: 55.49065\n",
      "Episode reward: 50.735144\n",
      "Episode reward: 34.924364\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | 41.1     |\n",
      "|    exploration_rate | 0.633    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1068     |\n",
      "|    fps              | 3643     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 38666    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0715   |\n",
      "|    n_updates        | 9641     |\n",
      "----------------------------------\n",
      "Episode reward: 28.926133\n",
      "Episode reward: 37.87043\n",
      "Episode reward: 62.814815\n",
      "Episode reward: 56.847194\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.6     |\n",
      "|    ep_rew_mean      | 41.3     |\n",
      "|    exploration_rate | 0.631    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1072     |\n",
      "|    fps              | 3639     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 38853    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0391   |\n",
      "|    n_updates        | 9688     |\n",
      "----------------------------------\n",
      "Episode reward: 58.643796\n",
      "Episode reward: 43.391013\n",
      "Episode reward: 36.943843\n",
      "Episode reward: 57.836544\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42       |\n",
      "|    ep_rew_mean      | 41.8     |\n",
      "|    exploration_rate | 0.629    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1076     |\n",
      "|    fps              | 3640     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 39051    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0432   |\n",
      "|    n_updates        | 9737     |\n",
      "----------------------------------\n",
      "Episode reward: 51.404168\n",
      "Episode reward: 73.864156\n",
      "Episode reward: 33.716289\n",
      "Episode reward: 34.711803\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.7     |\n",
      "|    ep_rew_mean      | 42.4     |\n",
      "|    exploration_rate | 0.627    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1080     |\n",
      "|    fps              | 3636     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 39246    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00384  |\n",
      "|    n_updates        | 9786     |\n",
      "----------------------------------\n",
      "Episode reward: 30.915391\n",
      "Episode reward: 32.952881\n",
      "Episode reward: 45.763957\n",
      "Episode reward: 36.912429\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.1     |\n",
      "|    ep_rew_mean      | 41.9     |\n",
      "|    exploration_rate | 0.626    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1084     |\n",
      "|    fps              | 3635     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 39393    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0761   |\n",
      "|    n_updates        | 9823     |\n",
      "----------------------------------\n",
      "Episode reward: 49.932663\n",
      "Episode reward: 24.910545\n",
      "Episode reward: 38.921029\n",
      "Episode reward: 25.906831\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.8     |\n",
      "|    ep_rew_mean      | 41.6     |\n",
      "|    exploration_rate | 0.624    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1088     |\n",
      "|    fps              | 3635     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 39533    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0546   |\n",
      "|    n_updates        | 9858     |\n",
      "----------------------------------\n",
      "Episode reward: 35.830417\n",
      "Episode reward: 45.517065\n",
      "Episode reward: 55.90794\n",
      "Episode reward: 74.753066\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.3     |\n",
      "|    ep_rew_mean      | 42       |\n",
      "|    exploration_rate | 0.622    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1092     |\n",
      "|    fps              | 3634     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 39746    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0572   |\n",
      "|    n_updates        | 9911     |\n",
      "----------------------------------\n",
      "Episode reward: 48.807161\n",
      "Episode reward: 57.699635\n",
      "Episode reward: 20.841474\n",
      "Episode reward: 97.698663\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.8     |\n",
      "|    ep_rew_mean      | 42.5     |\n",
      "|    exploration_rate | 0.62     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1096     |\n",
      "|    fps              | 3631     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 39974    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00378  |\n",
      "|    n_updates        | 9968     |\n",
      "----------------------------------\n",
      "Episode reward: 40.820373\n",
      "Episode reward: 53.891286\n",
      "Episode reward: 31.913791\n",
      "Episode reward: 32.859938\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.5     |\n",
      "|    ep_rew_mean      | 42.3     |\n",
      "|    exploration_rate | 0.619    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1100     |\n",
      "|    fps              | 3632     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 40134    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0083   |\n",
      "|    n_updates        | 10008    |\n",
      "----------------------------------\n",
      "Episode reward: 35.938256\n",
      "Episode reward: 53.637149\n",
      "Episode reward: 45.824046\n",
      "Episode reward: 70.38505\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43       |\n",
      "|    ep_rew_mean      | 42.8     |\n",
      "|    exploration_rate | 0.617    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1104     |\n",
      "|    fps              | 3635     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 40341    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.137    |\n",
      "|    n_updates        | 10060    |\n",
      "----------------------------------\n",
      "Episode reward: 29.931079\n",
      "Episode reward: 33.924919\n",
      "Episode reward: 44.931168\n",
      "Episode reward: 34.810971\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43       |\n",
      "|    ep_rew_mean      | 42.8     |\n",
      "|    exploration_rate | 0.615    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1108     |\n",
      "|    fps              | 3628     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 40485    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0661   |\n",
      "|    n_updates        | 10096    |\n",
      "----------------------------------\n",
      "Episode reward: 58.891793\n",
      "Episode reward: 41.762682\n",
      "Episode reward: 64.531107\n",
      "Episode reward: 26.954592\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43       |\n",
      "|    ep_rew_mean      | 42.7     |\n",
      "|    exploration_rate | 0.614    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1112     |\n",
      "|    fps              | 3624     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 40678    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.164    |\n",
      "|    n_updates        | 10144    |\n",
      "----------------------------------\n",
      "Episode reward: 90.793186\n",
      "Episode reward: 63.576416\n",
      "Episode reward: 58.887559\n",
      "Episode reward: 64.022811\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.8     |\n",
      "|    ep_rew_mean      | 43.5     |\n",
      "|    exploration_rate | 0.611    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1116     |\n",
      "|    fps              | 3628     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 40957    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0966   |\n",
      "|    n_updates        | 10214    |\n",
      "----------------------------------\n",
      "Episode reward: 38.934274\n",
      "Episode reward: 41.82888\n",
      "Episode reward: 50.876546\n",
      "Episode reward: 46.901948\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.8     |\n",
      "|    ep_rew_mean      | 43.6     |\n",
      "|    exploration_rate | 0.609    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1120     |\n",
      "|    fps              | 3625     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 41136    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0695   |\n",
      "|    n_updates        | 10258    |\n",
      "----------------------------------\n",
      "Episode reward: 35.852948\n",
      "Episode reward: 67.131255\n",
      "Episode reward: 32.914636\n",
      "Episode reward: 38.901174\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.7     |\n",
      "|    ep_rew_mean      | 43.4     |\n",
      "|    exploration_rate | 0.608    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1124     |\n",
      "|    fps              | 3627     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 41313    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00221  |\n",
      "|    n_updates        | 10303    |\n",
      "----------------------------------\n",
      "Episode reward: 52.824148\n",
      "Episode reward: 50.920043\n",
      "Episode reward: 65.581293\n",
      "Episode reward: 33.858801\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.9     |\n",
      "|    ep_rew_mean      | 43.6     |\n",
      "|    exploration_rate | 0.606    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1128     |\n",
      "|    fps              | 3627     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 41517    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.073    |\n",
      "|    n_updates        | 10354    |\n",
      "----------------------------------\n",
      "Episode reward: 30.958888\n",
      "Episode reward: 41.886062\n",
      "Episode reward: 34.827466\n",
      "Episode reward: 51.850988\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44       |\n",
      "|    ep_rew_mean      | 43.8     |\n",
      "|    exploration_rate | 0.604    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1132     |\n",
      "|    fps              | 3625     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 41677    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00521  |\n",
      "|    n_updates        | 10394    |\n",
      "----------------------------------\n",
      "Episode reward: 37.897057\n",
      "Episode reward: 31.775724\n",
      "Episode reward: 43.92296\n",
      "Episode reward: 23.968382\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.5     |\n",
      "|    ep_rew_mean      | 43.2     |\n",
      "|    exploration_rate | 0.603    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1136     |\n",
      "|    fps              | 3620     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 41815    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00158  |\n",
      "|    n_updates        | 10428    |\n",
      "----------------------------------\n",
      "Episode reward: 61.699013\n",
      "Episode reward: 45.838852\n",
      "Episode reward: 32.873037\n",
      "Episode reward: 38.90566\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.6     |\n",
      "|    ep_rew_mean      | 43.3     |\n",
      "|    exploration_rate | 0.601    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1140     |\n",
      "|    fps              | 3620     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 41995    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.131    |\n",
      "|    n_updates        | 10473    |\n",
      "----------------------------------\n",
      "Episode reward: 63.466206\n",
      "Episode reward: 43.76554\n",
      "Episode reward: 54.820653\n",
      "Episode reward: 37.877921\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.4     |\n",
      "|    ep_rew_mean      | 44.1     |\n",
      "|    exploration_rate | 0.599    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1144     |\n",
      "|    fps              | 3618     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 42200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000728 |\n",
      "|    n_updates        | 10524    |\n",
      "----------------------------------\n",
      "Episode reward: 37.903549\n",
      "Episode reward: 49.820939\n",
      "Episode reward: 37.940668\n",
      "Episode reward: 28.843486\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.3     |\n",
      "|    ep_rew_mean      | 44.1     |\n",
      "|    exploration_rate | 0.598    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1148     |\n",
      "|    fps              | 3620     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 42355    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00191  |\n",
      "|    n_updates        | 10563    |\n",
      "----------------------------------\n",
      "Episode reward: 46.91001\n",
      "Episode reward: 37.915338\n",
      "Episode reward: 97.707448\n",
      "Episode reward: 43.944398\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 45.3     |\n",
      "|    ep_rew_mean      | 45       |\n",
      "|    exploration_rate | 0.595    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1152     |\n",
      "|    fps              | 3607     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 42584    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00357  |\n",
      "|    n_updates        | 10620    |\n",
      "----------------------------------\n",
      "Episode reward: 49.117525\n",
      "Episode reward: 54.561267\n",
      "Episode reward: 35.927099\n",
      "Episode reward: 52.785781\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 45.6     |\n",
      "|    ep_rew_mean      | 45.3     |\n",
      "|    exploration_rate | 0.594    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1156     |\n",
      "|    fps              | 3607     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 42778    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00243  |\n",
      "|    n_updates        | 10669    |\n",
      "----------------------------------\n",
      "Episode reward: 39.762199\n",
      "Episode reward: 47.702191\n",
      "Episode reward: 56.686739\n",
      "Episode reward: 86.551337\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 46.7     |\n",
      "|    ep_rew_mean      | 46.4     |\n",
      "|    exploration_rate | 0.591    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1160     |\n",
      "|    fps              | 3604     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 43012    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.128    |\n",
      "|    n_updates        | 10727    |\n",
      "----------------------------------\n",
      "Episode reward: 48.844754\n",
      "Episode reward: 52.572884\n",
      "Episode reward: 39.879888\n",
      "Episode reward: 39.655226\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.1     |\n",
      "|    ep_rew_mean      | 46.7     |\n",
      "|    exploration_rate | 0.59     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1164     |\n",
      "|    fps              | 3607     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 43194    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00383  |\n",
      "|    n_updates        | 10773    |\n",
      "----------------------------------\n",
      "Episode reward: 27.945261\n",
      "Episode reward: 33.95537\n",
      "Episode reward: 48.758727\n",
      "Episode reward: 46.791813\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 46.9     |\n",
      "|    ep_rew_mean      | 46.5     |\n",
      "|    exploration_rate | 0.588    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1168     |\n",
      "|    fps              | 3607     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 43352    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.182    |\n",
      "|    n_updates        | 10812    |\n",
      "----------------------------------\n",
      "Episode reward: 48.739693\n",
      "Episode reward: 59.386753\n",
      "Episode reward: 33.933869\n",
      "Episode reward: 70.271167\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.1     |\n",
      "|    ep_rew_mean      | 46.8     |\n",
      "|    exploration_rate | 0.586    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1172     |\n",
      "|    fps              | 3606     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 43568    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0825   |\n",
      "|    n_updates        | 10866    |\n",
      "----------------------------------\n",
      "Episode reward: 55.617104\n",
      "Episode reward: 60.686902\n",
      "Episode reward: 75.842434\n",
      "Episode reward: 46.924955\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.6     |\n",
      "|    ep_rew_mean      | 47.2     |\n",
      "|    exploration_rate | 0.584    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1176     |\n",
      "|    fps              | 3604     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 43808    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00229  |\n",
      "|    n_updates        | 10926    |\n",
      "----------------------------------\n",
      "Episode reward: 29.902165\n",
      "Episode reward: 34.763401\n",
      "Episode reward: 73.716055\n",
      "Episode reward: 32.926462\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.3     |\n",
      "|    ep_rew_mean      | 47       |\n",
      "|    exploration_rate | 0.582    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1180     |\n",
      "|    fps              | 3606     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 43980    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00103  |\n",
      "|    n_updates        | 10969    |\n",
      "----------------------------------\n",
      "Episode reward: 64.615359\n",
      "Episode reward: 44.793455\n",
      "Episode reward: 46.753188\n",
      "Episode reward: 48.818072\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.9     |\n",
      "|    ep_rew_mean      | 47.6     |\n",
      "|    exploration_rate | 0.58     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1184     |\n",
      "|    fps              | 3607     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 44186    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0671   |\n",
      "|    n_updates        | 11021    |\n",
      "----------------------------------\n",
      "Episode reward: 57.425645\n",
      "Episode reward: 33.877996\n",
      "Episode reward: 48.804261\n",
      "Episode reward: 83.359325\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.8     |\n",
      "|    ep_rew_mean      | 48.4     |\n",
      "|    exploration_rate | 0.578    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1188     |\n",
      "|    fps              | 3601     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 44411    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00333  |\n",
      "|    n_updates        | 11077    |\n",
      "----------------------------------\n",
      "Episode reward: 38.701432\n",
      "Episode reward: 74.85366\n",
      "Episode reward: 56.881837\n",
      "Episode reward: 43.899755\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.8     |\n",
      "|    ep_rew_mean      | 48.4     |\n",
      "|    exploration_rate | 0.576    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1192     |\n",
      "|    fps              | 3601     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 44626    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0977   |\n",
      "|    n_updates        | 11131    |\n",
      "----------------------------------\n",
      "Episode reward: 55.215484\n",
      "Episode reward: 54.657883\n",
      "Episode reward: 41.666274\n",
      "Episode reward: 39.860583\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.5     |\n",
      "|    ep_rew_mean      | 48.1     |\n",
      "|    exploration_rate | 0.574    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1196     |\n",
      "|    fps              | 3604     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 44819    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00169  |\n",
      "|    n_updates        | 11179    |\n",
      "----------------------------------\n",
      "Episode reward: 60.803157\n",
      "Episode reward: 39.875392\n",
      "Episode reward: 33.811548\n",
      "Episode reward: 24.924434\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.5     |\n",
      "|    ep_rew_mean      | 48.1     |\n",
      "|    exploration_rate | 0.573    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1200     |\n",
      "|    fps              | 3606     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 44979    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00946  |\n",
      "|    n_updates        | 11219    |\n",
      "----------------------------------\n",
      "Episode reward: 38.94255\n",
      "Episode reward: 55.722737\n",
      "Episode reward: 36.884473\n",
      "Episode reward: 41.667728\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.1     |\n",
      "|    ep_rew_mean      | 47.8     |\n",
      "|    exploration_rate | 0.571    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1204     |\n",
      "|    fps              | 3600     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 45153    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00671  |\n",
      "|    n_updates        | 11263    |\n",
      "----------------------------------\n",
      "Episode reward: 44.87012\n",
      "Episode reward: 97.971911\n",
      "Episode reward: 39.723044\n",
      "Episode reward: 40.718606\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.9     |\n",
      "|    ep_rew_mean      | 48.6     |\n",
      "|    exploration_rate | 0.569    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1208     |\n",
      "|    fps              | 3602     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 45378    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00369  |\n",
      "|    n_updates        | 11319    |\n",
      "----------------------------------\n",
      "Episode reward: 39.816619\n",
      "Episode reward: 39.864331\n",
      "Episode reward: 61.720164\n",
      "Episode reward: 57.476267\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 49       |\n",
      "|    ep_rew_mean      | 48.6     |\n",
      "|    exploration_rate | 0.567    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1212     |\n",
      "|    fps              | 3604     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 45579    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.151    |\n",
      "|    n_updates        | 11369    |\n",
      "----------------------------------\n",
      "Episode reward: 55.895937\n",
      "Episode reward: 34.907232\n",
      "Episode reward: 48.887139\n",
      "Episode reward: 51.726161\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.1     |\n",
      "|    ep_rew_mean      | 47.8     |\n",
      "|    exploration_rate | 0.565    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1216     |\n",
      "|    fps              | 3603     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 45771    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.067    |\n",
      "|    n_updates        | 11417    |\n",
      "----------------------------------\n",
      "Episode reward: 29.947306\n",
      "Episode reward: 48.864412\n",
      "Episode reward: 33.962237\n",
      "Episode reward: 48.739375\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48       |\n",
      "|    ep_rew_mean      | 47.6     |\n",
      "|    exploration_rate | 0.564    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1220     |\n",
      "|    fps              | 3600     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 45933    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00224  |\n",
      "|    n_updates        | 11458    |\n",
      "----------------------------------\n",
      "Episode reward: 57.876637\n",
      "Episode reward: 34.929154\n",
      "Episode reward: 55.778036\n",
      "Episode reward: 59.899362\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.3     |\n",
      "|    ep_rew_mean      | 48       |\n",
      "|    exploration_rate | 0.562    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1224     |\n",
      "|    fps              | 3599     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 46143    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0885   |\n",
      "|    n_updates        | 11510    |\n",
      "----------------------------------\n",
      "Episode reward: 42.870297\n",
      "Episode reward: 34.834214\n",
      "Episode reward: 39.910126\n",
      "Episode reward: 29.961614\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.7     |\n",
      "|    ep_rew_mean      | 47.4     |\n",
      "|    exploration_rate | 0.56     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1228     |\n",
      "|    fps              | 3599     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 46291    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00546  |\n",
      "|    n_updates        | 11547    |\n",
      "----------------------------------\n",
      "Episode reward: 43.83862\n",
      "Episode reward: 54.513935\n",
      "Episode reward: 78.578166\n",
      "Episode reward: 37.921405\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.4     |\n",
      "|    ep_rew_mean      | 47.9     |\n",
      "|    exploration_rate | 0.558    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1232     |\n",
      "|    fps              | 3592     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 46512    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.176    |\n",
      "|    n_updates        | 11602    |\n",
      "----------------------------------\n",
      "Episode reward: 26.935992\n",
      "Episode reward: 46.856048\n",
      "Episode reward: 38.79077\n",
      "Episode reward: 54.459543\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.6     |\n",
      "|    ep_rew_mean      | 48.2     |\n",
      "|    exploration_rate | 0.557    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1236     |\n",
      "|    fps              | 3592     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 46680    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0955   |\n",
      "|    n_updates        | 11644    |\n",
      "----------------------------------\n",
      "Episode reward: 43.908486\n",
      "Episode reward: 44.90635\n",
      "Episode reward: 66.729139\n",
      "Episode reward: 47.830962\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.9     |\n",
      "|    ep_rew_mean      | 48.5     |\n",
      "|    exploration_rate | 0.555    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1240     |\n",
      "|    fps              | 3594     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 46885    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.195    |\n",
      "|    n_updates        | 11696    |\n",
      "----------------------------------\n",
      "Episode reward: 57.851205\n",
      "Episode reward: 43.91159\n",
      "Episode reward: 45.821724\n",
      "Episode reward: 25.952262\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.6     |\n",
      "|    ep_rew_mean      | 48.2     |\n",
      "|    exploration_rate | 0.553    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1244     |\n",
      "|    fps              | 3595     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 47059    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00493  |\n",
      "|    n_updates        | 11739    |\n",
      "----------------------------------\n",
      "Episode reward: 42.546393\n",
      "Episode reward: 61.843152\n",
      "Episode reward: 41.930855\n",
      "Episode reward: 48.919515\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 49       |\n",
      "|    ep_rew_mean      | 48.6     |\n",
      "|    exploration_rate | 0.551    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1248     |\n",
      "|    fps              | 3597     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 47256    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.267    |\n",
      "|    n_updates        | 11788    |\n",
      "----------------------------------\n",
      "Episode reward: 39.900029\n",
      "Episode reward: 36.938552\n",
      "Episode reward: 49.865033\n",
      "Episode reward: 31.764383\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.3     |\n",
      "|    ep_rew_mean      | 47.9     |\n",
      "|    exploration_rate | 0.55     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1252     |\n",
      "|    fps              | 3589     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 47415    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0971   |\n",
      "|    n_updates        | 11828    |\n",
      "----------------------------------\n",
      "Episode reward: 53.32233\n",
      "Episode reward: 50.731667\n",
      "Episode reward: 50.763779\n",
      "Episode reward: 50.721332\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.5     |\n",
      "|    ep_rew_mean      | 48.1     |\n",
      "|    exploration_rate | 0.548    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1256     |\n",
      "|    fps              | 3590     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 47623    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000945 |\n",
      "|    n_updates        | 11880    |\n",
      "----------------------------------\n",
      "Episode reward: 45.38841\n",
      "Episode reward: 32.826993\n",
      "Episode reward: 44.332801\n",
      "Episode reward: 27.875304\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.6     |\n",
      "|    ep_rew_mean      | 47.3     |\n",
      "|    exploration_rate | 0.546    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1260     |\n",
      "|    fps              | 3592     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 47775    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.15     |\n",
      "|    n_updates        | 11918    |\n",
      "----------------------------------\n",
      "Episode reward: 35.885233\n",
      "Episode reward: 25.96782\n",
      "Episode reward: 61.551467\n",
      "Episode reward: 41.887809\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.5     |\n",
      "|    ep_rew_mean      | 47.1     |\n",
      "|    exploration_rate | 0.545    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1264     |\n",
      "|    fps              | 3587     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 47941    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0582   |\n",
      "|    n_updates        | 11960    |\n",
      "----------------------------------\n",
      "Episode reward: 47.837144\n",
      "Episode reward: 35.932641\n",
      "Episode reward: 35.905373\n",
      "Episode reward: 37.912419\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.5     |\n",
      "|    ep_rew_mean      | 47.1     |\n",
      "|    exploration_rate | 0.543    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1268     |\n",
      "|    fps              | 3588     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 48099    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00303  |\n",
      "|    n_updates        | 11999    |\n",
      "----------------------------------\n",
      "Episode reward: 51.888473\n",
      "Episode reward: 38.671342\n",
      "Episode reward: 45.863163\n",
      "Episode reward: 43.792471\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.1     |\n",
      "|    ep_rew_mean      | 46.8     |\n",
      "|    exploration_rate | 0.541    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1272     |\n",
      "|    fps              | 3586     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 48280    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00249  |\n",
      "|    n_updates        | 12044    |\n",
      "----------------------------------\n",
      "Episode reward: 51.443339\n",
      "Episode reward: 48.412534\n",
      "Episode reward: 29.959126\n",
      "Episode reward: 56.228443\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 46.6     |\n",
      "|    ep_rew_mean      | 46.3     |\n",
      "|    exploration_rate | 0.54     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1276     |\n",
      "|    fps              | 3587     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 48468    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0704   |\n",
      "|    n_updates        | 12091    |\n",
      "----------------------------------\n",
      "Episode reward: 30.967578\n",
      "Episode reward: 52.714822\n",
      "Episode reward: 41.808427\n",
      "Episode reward: 39.665174\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 46.5     |\n",
      "|    ep_rew_mean      | 46.2     |\n",
      "|    exploration_rate | 0.538    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1280     |\n",
      "|    fps              | 3583     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 48634    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.148    |\n",
      "|    n_updates        | 12133    |\n",
      "----------------------------------\n",
      "Episode reward: 47.844022\n",
      "Episode reward: 80.586155\n",
      "Episode reward: 45.85409\n",
      "Episode reward: 79.604325\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47       |\n",
      "|    ep_rew_mean      | 46.7     |\n",
      "|    exploration_rate | 0.536    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1284     |\n",
      "|    fps              | 3584     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 48890    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00115  |\n",
      "|    n_updates        | 12197    |\n",
      "----------------------------------\n",
      "Episode reward: 41.781795\n",
      "Episode reward: 67.396067\n",
      "Episode reward: 31.905396\n",
      "Episode reward: 32.899717\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 46.5     |\n",
      "|    ep_rew_mean      | 46.2     |\n",
      "|    exploration_rate | 0.534    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1288     |\n",
      "|    fps              | 3585     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 49065    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00613  |\n",
      "|    n_updates        | 12241    |\n",
      "----------------------------------\n",
      "Episode reward: 56.107295\n",
      "Episode reward: 55.152156\n",
      "Episode reward: 51.702688\n",
      "Episode reward: 43.898013\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 46.5     |\n",
      "|    ep_rew_mean      | 46.1     |\n",
      "|    exploration_rate | 0.532    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1292     |\n",
      "|    fps              | 3579     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 49274    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0932   |\n",
      "|    n_updates        | 12293    |\n",
      "----------------------------------\n",
      "Episode reward: 73.34375\n",
      "Episode reward: 56.923437\n",
      "Episode reward: 39.912875\n",
      "Episode reward: 52.498327\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 46.8     |\n",
      "|    ep_rew_mean      | 46.4     |\n",
      "|    exploration_rate | 0.53     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1296     |\n",
      "|    fps              | 3577     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 49500    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.109    |\n",
      "|    n_updates        | 12349    |\n",
      "----------------------------------\n",
      "Episode reward: 41.79982\n",
      "Episode reward: 72.531342\n",
      "Episode reward: 78.096537\n",
      "Episode reward: 43.843053\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.7     |\n",
      "|    ep_rew_mean      | 47.2     |\n",
      "|    exploration_rate | 0.527    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1300     |\n",
      "|    fps              | 3577     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 49749    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00364  |\n",
      "|    n_updates        | 12412    |\n",
      "----------------------------------\n",
      "Episode reward: 34.949349\n",
      "Episode reward: 44.70234\n",
      "Episode reward: 51.385096\n",
      "Episode reward: 39.924836\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.7     |\n",
      "|    ep_rew_mean      | 47.2     |\n",
      "|    exploration_rate | 0.526    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1304     |\n",
      "|    fps              | 3576     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 49921    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.065    |\n",
      "|    n_updates        | 12455    |\n",
      "----------------------------------\n",
      "Episode reward: 39.899618\n",
      "Episode reward: 55.576967\n",
      "Episode reward: 49.688397\n",
      "Episode reward: 76.131634\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.7     |\n",
      "|    ep_rew_mean      | 47.2     |\n",
      "|    exploration_rate | 0.524    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1308     |\n",
      "|    fps              | 3572     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 50145    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00598  |\n",
      "|    n_updates        | 12511    |\n",
      "----------------------------------\n",
      "Episode reward: 53.147115\n",
      "Episode reward: 63.360416\n",
      "Episode reward: 38.832272\n",
      "Episode reward: 72.487917\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48       |\n",
      "|    ep_rew_mean      | 47.5     |\n",
      "|    exploration_rate | 0.521    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1312     |\n",
      "|    fps              | 3573     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 50377    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0928   |\n",
      "|    n_updates        | 12569    |\n",
      "----------------------------------\n",
      "Episode reward: 44.700404\n",
      "Episode reward: 36.817193\n",
      "Episode reward: 34.919031\n",
      "Episode reward: 61.838004\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.9     |\n",
      "|    ep_rew_mean      | 47.3     |\n",
      "|    exploration_rate | 0.52     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1316     |\n",
      "|    fps              | 3574     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 50557    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.31     |\n",
      "|    n_updates        | 12614    |\n",
      "----------------------------------\n",
      "Episode reward: 36.886196\n",
      "Episode reward: 36.961033\n",
      "Episode reward: 63.732229\n",
      "Episode reward: 55.941272\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.2     |\n",
      "|    ep_rew_mean      | 47.6     |\n",
      "|    exploration_rate | 0.518    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1320     |\n",
      "|    fps              | 3568     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 50751    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0842   |\n",
      "|    n_updates        | 12662    |\n",
      "----------------------------------\n",
      "Episode reward: 59.578681\n",
      "Episode reward: 37.927137\n",
      "Episode reward: 24.964033\n",
      "Episode reward: 39.603571\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.7     |\n",
      "|    ep_rew_mean      | 47.2     |\n",
      "|    exploration_rate | 0.516    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1324     |\n",
      "|    fps              | 3568     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 50914    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00297  |\n",
      "|    n_updates        | 12703    |\n",
      "----------------------------------\n",
      "Episode reward: 31.807304\n",
      "Episode reward: 48.566736\n",
      "Episode reward: 44.822718\n",
      "Episode reward: 47.625092\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48       |\n",
      "|    ep_rew_mean      | 47.4     |\n",
      "|    exploration_rate | 0.515    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1328     |\n",
      "|    fps              | 3569     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 51088    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.242    |\n",
      "|    n_updates        | 12746    |\n",
      "----------------------------------\n",
      "Episode reward: 56.63518\n",
      "Episode reward: 45.584864\n",
      "Episode reward: 33.936269\n",
      "Episode reward: 42.766742\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.6     |\n",
      "|    ep_rew_mean      | 47.1     |\n",
      "|    exploration_rate | 0.513    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1332     |\n",
      "|    fps              | 3564     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 51268    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 12791    |\n",
      "----------------------------------\n",
      "Episode reward: 82.699014\n",
      "Episode reward: 58.791809\n",
      "Episode reward: 55.773878\n",
      "Episode reward: 50.338807\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.4     |\n",
      "|    ep_rew_mean      | 47.9     |\n",
      "|    exploration_rate | 0.511    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1336     |\n",
      "|    fps              | 3566     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 51518    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.138    |\n",
      "|    n_updates        | 12854    |\n",
      "----------------------------------\n",
      "Episode reward: 30.952104\n",
      "Episode reward: 37.789265\n",
      "Episode reward: 60.863016\n",
      "Episode reward: 42.860842\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.1     |\n",
      "|    ep_rew_mean      | 47.6     |\n",
      "|    exploration_rate | 0.509    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1340     |\n",
      "|    fps              | 3566     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 51692    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0849   |\n",
      "|    n_updates        | 12897    |\n",
      "----------------------------------\n",
      "Episode reward: 37.782929\n",
      "Episode reward: 52.611892\n",
      "Episode reward: 41.713237\n",
      "Episode reward: 35.910715\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48       |\n",
      "|    ep_rew_mean      | 47.5     |\n",
      "|    exploration_rate | 0.507    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1344     |\n",
      "|    fps              | 3558     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 51861    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0017   |\n",
      "|    n_updates        | 12940    |\n",
      "----------------------------------\n",
      "Episode reward: 53.200159\n",
      "Episode reward: 69.819273\n",
      "Episode reward: 56.448538\n",
      "Episode reward: 32.950364\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.2     |\n",
      "|    ep_rew_mean      | 47.7     |\n",
      "|    exploration_rate | 0.505    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1348     |\n",
      "|    fps              | 3557     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 52075    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00268  |\n",
      "|    n_updates        | 12993    |\n",
      "----------------------------------\n",
      "Episode reward: 46.739386\n",
      "Episode reward: 83.745163\n",
      "Episode reward: 47.363096\n",
      "Episode reward: 43.630969\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.8     |\n",
      "|    ep_rew_mean      | 48.3     |\n",
      "|    exploration_rate | 0.503    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1352     |\n",
      "|    fps              | 3549     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 52299    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00392  |\n",
      "|    n_updates        | 13049    |\n",
      "----------------------------------\n",
      "Episode reward: 44.63047\n",
      "Episode reward: 55.740671\n",
      "Episode reward: 46.862178\n",
      "Episode reward: 28.963039\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.5     |\n",
      "|    ep_rew_mean      | 48       |\n",
      "|    exploration_rate | 0.501    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1356     |\n",
      "|    fps              | 3550     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 52477    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00187  |\n",
      "|    n_updates        | 13094    |\n",
      "----------------------------------\n",
      "Episode reward: 48.450326\n",
      "Episode reward: 72.661649\n",
      "Episode reward: 51.847876\n",
      "Episode reward: 53.894771\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 49.3     |\n",
      "|    ep_rew_mean      | 48.8     |\n",
      "|    exploration_rate | 0.499    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1360     |\n",
      "|    fps              | 3551     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 52709    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0713   |\n",
      "|    n_updates        | 13152    |\n",
      "----------------------------------\n",
      "Episode reward: 45.839813\n",
      "Episode reward: 36.941777\n",
      "Episode reward: 54.796888\n",
      "Episode reward: 63.331976\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 49.7     |\n",
      "|    ep_rew_mean      | 49.1     |\n",
      "|    exploration_rate | 0.497    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1364     |\n",
      "|    fps              | 3548     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 52912    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0936   |\n",
      "|    n_updates        | 13202    |\n",
      "----------------------------------\n",
      "Episode reward: 27.753039\n",
      "Episode reward: 62.366963\n",
      "Episode reward: 42.767077\n",
      "Episode reward: 55.652629\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50       |\n",
      "|    ep_rew_mean      | 49.5     |\n",
      "|    exploration_rate | 0.496    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1368     |\n",
      "|    fps              | 3548     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 53103    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.205    |\n",
      "|    n_updates        | 13250    |\n",
      "----------------------------------\n",
      "Episode reward: 63.834973\n",
      "Episode reward: 38.896056\n",
      "Episode reward: 47.70682\n",
      "Episode reward: 54.880385\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.3     |\n",
      "|    ep_rew_mean      | 49.7     |\n",
      "|    exploration_rate | 0.494    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1372     |\n",
      "|    fps              | 3549     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 53311    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0034   |\n",
      "|    n_updates        | 13302    |\n",
      "----------------------------------\n",
      "Episode reward: 82.63123\n",
      "Episode reward: 22.880307\n",
      "Episode reward: 48.921827\n",
      "Episode reward: 57.909038\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.6     |\n",
      "|    ep_rew_mean      | 50       |\n",
      "|    exploration_rate | 0.491    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1376     |\n",
      "|    fps              | 3546     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 53528    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 13356    |\n",
      "----------------------------------\n",
      "Episode reward: 50.591664\n",
      "Episode reward: 40.864748\n",
      "Episode reward: 51.251907\n",
      "Episode reward: 35.888828\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.8     |\n",
      "|    ep_rew_mean      | 50.1     |\n",
      "|    exploration_rate | 0.49     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1380     |\n",
      "|    fps              | 3545     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 53709    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.004    |\n",
      "|    n_updates        | 13402    |\n",
      "----------------------------------\n",
      "Episode reward: 44.78098\n",
      "Episode reward: 97.493416\n",
      "Episode reward: 56.526326\n",
      "Episode reward: 46.624053\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.7     |\n",
      "|    ep_rew_mean      | 50       |\n",
      "|    exploration_rate | 0.487    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1384     |\n",
      "|    fps              | 3545     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 53958    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00526  |\n",
      "|    n_updates        | 13464    |\n",
      "----------------------------------\n",
      "Episode reward: 62.356548\n",
      "Episode reward: 42.58834\n",
      "Episode reward: 34.866259\n",
      "Episode reward: 46.903872\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.8     |\n",
      "|    ep_rew_mean      | 50.1     |\n",
      "|    exploration_rate | 0.486    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1388     |\n",
      "|    fps              | 3546     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 54146    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0788   |\n",
      "|    n_updates        | 13511    |\n",
      "----------------------------------\n",
      "Episode reward: 33.816951\n",
      "Episode reward: 41.616937\n",
      "Episode reward: 43.877294\n",
      "Episode reward: 35.902747\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.3     |\n",
      "|    ep_rew_mean      | 49.6     |\n",
      "|    exploration_rate | 0.484    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1392     |\n",
      "|    fps              | 3543     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 54302    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0855   |\n",
      "|    n_updates        | 13550    |\n",
      "----------------------------------\n",
      "Episode reward: 46.557344\n",
      "Episode reward: 35.900431\n",
      "Episode reward: 32.918473\n",
      "Episode reward: 55.012077\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 49.7     |\n",
      "|    ep_rew_mean      | 49.1     |\n",
      "|    exploration_rate | 0.482    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1396     |\n",
      "|    fps              | 3543     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 54474    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00195  |\n",
      "|    n_updates        | 13593    |\n",
      "----------------------------------\n",
      "Episode reward: 55.770563\n",
      "Episode reward: 48.881475\n",
      "Episode reward: 39.945771\n",
      "Episode reward: 36.923856\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 49.1     |\n",
      "|    ep_rew_mean      | 48.6     |\n",
      "|    exploration_rate | 0.481    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1400     |\n",
      "|    fps              | 3544     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 54656    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.116    |\n",
      "|    n_updates        | 13638    |\n",
      "----------------------------------\n",
      "Episode reward: 38.944472\n",
      "Episode reward: 60.611243\n",
      "Episode reward: 65.610859\n",
      "Episode reward: 38.859991\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 49.4     |\n",
      "|    ep_rew_mean      | 48.9     |\n",
      "|    exploration_rate | 0.479    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1404     |\n",
      "|    fps              | 3535     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 54862    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.114    |\n",
      "|    n_updates        | 13690    |\n",
      "----------------------------------\n",
      "Episode reward: 44.598002\n",
      "Episode reward: 46.858888\n",
      "Episode reward: 34.871998\n",
      "Episode reward: 44.624235\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.9     |\n",
      "|    ep_rew_mean      | 48.4     |\n",
      "|    exploration_rate | 0.477    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1408     |\n",
      "|    fps              | 3534     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 55034    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00381  |\n",
      "|    n_updates        | 13733    |\n",
      "----------------------------------\n",
      "Episode reward: 47.4537\n",
      "Episode reward: 38.804317\n",
      "Episode reward: 45.875531\n",
      "Episode reward: 32.911632\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.2     |\n",
      "|    ep_rew_mean      | 47.8     |\n",
      "|    exploration_rate | 0.476    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1412     |\n",
      "|    fps              | 3535     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 55200    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00246  |\n",
      "|    n_updates        | 13774    |\n",
      "----------------------------------\n",
      "Episode reward: 50.601822\n",
      "Episode reward: 91.87938\n",
      "Episode reward: 57.456023\n",
      "Episode reward: 50.502259\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 49       |\n",
      "|    ep_rew_mean      | 48.5     |\n",
      "|    exploration_rate | 0.473    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1416     |\n",
      "|    fps              | 3535     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 55454    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00383  |\n",
      "|    n_updates        | 13838    |\n",
      "----------------------------------\n",
      "Episode reward: 56.247366\n",
      "Episode reward: 34.742127\n",
      "Episode reward: 48.856202\n",
      "Episode reward: 44.896291\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.9     |\n",
      "|    ep_rew_mean      | 48.4     |\n",
      "|    exploration_rate | 0.471    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1420     |\n",
      "|    fps              | 3530     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 55640    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0786   |\n",
      "|    n_updates        | 13884    |\n",
      "----------------------------------\n",
      "Episode reward: 39.944118\n",
      "Episode reward: 49.870834\n",
      "Episode reward: 72.863772\n",
      "Episode reward: 49.470207\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 49.4     |\n",
      "|    ep_rew_mean      | 48.9     |\n",
      "|    exploration_rate | 0.469    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1424     |\n",
      "|    fps              | 3529     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 55853    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00245  |\n",
      "|    n_updates        | 13938    |\n",
      "----------------------------------\n",
      "Episode reward: 38.895421\n",
      "Episode reward: 41.788713\n",
      "Episode reward: 117.002842\n",
      "Episode reward: 57.750021\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.3     |\n",
      "|    ep_rew_mean      | 49.7     |\n",
      "|    exploration_rate | 0.467    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1428     |\n",
      "|    fps              | 3527     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 56121    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 14005    |\n",
      "----------------------------------\n",
      "Episode reward: 36.871506\n",
      "Episode reward: 41.906015\n",
      "Episode reward: 46.815658\n",
      "Episode reward: 63.956811\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.4     |\n",
      "|    ep_rew_mean      | 49.8     |\n",
      "|    exploration_rate | 0.465    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1432     |\n",
      "|    fps              | 3529     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 56312    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 14052    |\n",
      "----------------------------------\n",
      "Episode reward: 66.665928\n",
      "Episode reward: 79.700989\n",
      "Episode reward: 42.906854\n",
      "Episode reward: 38.788797\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.2     |\n",
      "|    ep_rew_mean      | 49.6     |\n",
      "|    exploration_rate | 0.463    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1436     |\n",
      "|    fps              | 3529     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 56541    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.198    |\n",
      "|    n_updates        | 14110    |\n",
      "----------------------------------\n",
      "Episode reward: 59.851366\n",
      "Episode reward: 68.421629\n",
      "Episode reward: 31.890397\n",
      "Episode reward: 53.92022\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.6     |\n",
      "|    ep_rew_mean      | 50       |\n",
      "|    exploration_rate | 0.461    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1440     |\n",
      "|    fps              | 3526     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 56756    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.089    |\n",
      "|    n_updates        | 14163    |\n",
      "----------------------------------\n",
      "Episode reward: 30.876366\n",
      "Episode reward: 37.920602\n",
      "Episode reward: 49.804644\n",
      "Episode reward: 37.87493\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.5     |\n",
      "|    ep_rew_mean      | 49.9     |\n",
      "|    exploration_rate | 0.459    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1444     |\n",
      "|    fps              | 3527     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 56913    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.271    |\n",
      "|    n_updates        | 14203    |\n",
      "----------------------------------\n",
      "Episode reward: 55.902594\n",
      "Episode reward: 46.906802\n",
      "Episode reward: 94.612191\n",
      "Episode reward: 59.384422\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 51.3     |\n",
      "|    ep_rew_mean      | 50.4     |\n",
      "|    exploration_rate | 0.457    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1448     |\n",
      "|    fps              | 3521     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 57202    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.165    |\n",
      "|    n_updates        | 14275    |\n",
      "----------------------------------\n",
      "Episode reward: 50.49808\n",
      "Episode reward: 58.366604\n",
      "Episode reward: 77.209398\n",
      "Episode reward: 33.873005\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 51.3     |\n",
      "|    ep_rew_mean      | 50.4     |\n",
      "|    exploration_rate | 0.454    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1452     |\n",
      "|    fps              | 3517     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 57426    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00221  |\n",
      "|    n_updates        | 14331    |\n",
      "----------------------------------\n",
      "Episode reward: 30.935441\n",
      "Episode reward: 38.898712\n",
      "Episode reward: 56.408385\n",
      "Episode reward: 62.651988\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 51.4     |\n",
      "|    ep_rew_mean      | 50.5     |\n",
      "|    exploration_rate | 0.453    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1456     |\n",
      "|    fps              | 3513     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 57616    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0014   |\n",
      "|    n_updates        | 14378    |\n",
      "----------------------------------\n",
      "Episode reward: 42.804743\n",
      "Episode reward: 103.699071\n",
      "Episode reward: 41.915488\n",
      "Episode reward: 45.870021\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 51.4     |\n",
      "|    ep_rew_mean      | 50.6     |\n",
      "|    exploration_rate | 0.45     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1460     |\n",
      "|    fps              | 3512     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 57852    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00261  |\n",
      "|    n_updates        | 14437    |\n",
      "----------------------------------\n",
      "Episode reward: 47.506711\n",
      "Episode reward: 40.945396\n",
      "Episode reward: 30.884201\n",
      "Episode reward: 41.826962\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 51       |\n",
      "|    ep_rew_mean      | 50.2     |\n",
      "|    exploration_rate | 0.449    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1464     |\n",
      "|    fps              | 3509     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 58014    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00358  |\n",
      "|    n_updates        | 14478    |\n",
      "----------------------------------\n",
      "Episode reward: 57.454435\n",
      "Episode reward: 42.936756\n",
      "Episode reward: 48.480129\n",
      "Episode reward: 36.801059\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 51       |\n",
      "|    ep_rew_mean      | 50.1     |\n",
      "|    exploration_rate | 0.447    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1468     |\n",
      "|    fps              | 3505     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 58201    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00419  |\n",
      "|    n_updates        | 14525    |\n",
      "----------------------------------\n",
      "Episode reward: 35.808163\n",
      "Episode reward: 32.873716\n",
      "Episode reward: 54.074656\n",
      "Episode reward: 35.906241\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.5     |\n",
      "|    ep_rew_mean      | 49.7     |\n",
      "|    exploration_rate | 0.446    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1472     |\n",
      "|    fps              | 3505     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 58361    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00533  |\n",
      "|    n_updates        | 14565    |\n",
      "----------------------------------\n",
      "Episode reward: 44.785597\n",
      "Episode reward: 42.885875\n",
      "Episode reward: 79.16916\n",
      "Episode reward: 48.92927\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.5     |\n",
      "|    ep_rew_mean      | 49.7     |\n",
      "|    exploration_rate | 0.444    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1476     |\n",
      "|    fps              | 3504     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 58578    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.1      |\n",
      "|    n_updates        | 14619    |\n",
      "----------------------------------\n",
      "Episode reward: 40.93307\n",
      "Episode reward: 36.889772\n",
      "Episode reward: 65.869551\n",
      "Episode reward: 30.928281\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.4     |\n",
      "|    ep_rew_mean      | 49.7     |\n",
      "|    exploration_rate | 0.442    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1480     |\n",
      "|    fps              | 3496     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 58753    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.114    |\n",
      "|    n_updates        | 14663    |\n",
      "----------------------------------\n",
      "Episode reward: 68.403842\n",
      "Episode reward: 60.569077\n",
      "Episode reward: 32.863911\n",
      "Episode reward: 39.922576\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50       |\n",
      "|    ep_rew_mean      | 49.2     |\n",
      "|    exploration_rate | 0.44     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1484     |\n",
      "|    fps              | 3497     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 58956    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0027   |\n",
      "|    n_updates        | 14713    |\n",
      "----------------------------------\n",
      "Episode reward: 51.777403\n",
      "Episode reward: 33.947187\n",
      "Episode reward: 41.834339\n",
      "Episode reward: 55.909939\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 49.9     |\n",
      "|    ep_rew_mean      | 49.2     |\n",
      "|    exploration_rate | 0.438    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1488     |\n",
      "|    fps              | 3499     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 59140    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.112    |\n",
      "|    n_updates        | 14759    |\n",
      "----------------------------------\n",
      "Episode reward: 46.904039\n",
      "Episode reward: 50.911638\n",
      "Episode reward: 47.882241\n",
      "Episode reward: 40.893588\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.2     |\n",
      "|    ep_rew_mean      | 49.5     |\n",
      "|    exploration_rate | 0.436    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1492     |\n",
      "|    fps              | 3501     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 59327    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0667   |\n",
      "|    n_updates        | 14806    |\n",
      "----------------------------------\n",
      "Episode reward: 59.803133\n",
      "Episode reward: 35.914449\n",
      "Episode reward: 45.889643\n",
      "Episode reward: 34.945982\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.3     |\n",
      "|    ep_rew_mean      | 49.6     |\n",
      "|    exploration_rate | 0.435    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1496     |\n",
      "|    fps              | 3495     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 59504    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.114    |\n",
      "|    n_updates        | 14850    |\n",
      "----------------------------------\n",
      "Episode reward: 51.843917\n",
      "Episode reward: 55.635702\n",
      "Episode reward: 99.826209\n",
      "Episode reward: 51.582818\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 51.1     |\n",
      "|    ep_rew_mean      | 50.3     |\n",
      "|    exploration_rate | 0.432    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1500     |\n",
      "|    fps              | 3496     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 59769    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0034   |\n",
      "|    n_updates        | 14917    |\n",
      "----------------------------------\n",
      "Episode reward: 53.755084\n",
      "Episode reward: 48.895867\n",
      "Episode reward: 49.572598\n",
      "Episode reward: 39.783522\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 51       |\n",
      "|    ep_rew_mean      | 50.2     |\n",
      "|    exploration_rate | 0.43     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1504     |\n",
      "|    fps              | 3497     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 59962    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.128    |\n",
      "|    n_updates        | 14965    |\n",
      "----------------------------------\n",
      "Episode reward: 57.886479\n",
      "Episode reward: 49.496929\n",
      "Episode reward: 52.409248\n",
      "Episode reward: 28.910256\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 51.2     |\n",
      "|    ep_rew_mean      | 50.4     |\n",
      "|    exploration_rate | 0.429    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1508     |\n",
      "|    fps              | 3498     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 60152    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0943   |\n",
      "|    n_updates        | 15012    |\n",
      "----------------------------------\n",
      "Episode reward: 33.664517\n",
      "Episode reward: 52.027686\n",
      "Episode reward: 97.464195\n",
      "Episode reward: 43.624169\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 51.8     |\n",
      "|    ep_rew_mean      | 51       |\n",
      "|    exploration_rate | 0.426    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1512     |\n",
      "|    fps              | 3493     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 60383    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00146  |\n",
      "|    n_updates        | 15070    |\n",
      "----------------------------------\n",
      "Episode reward: 61.829761\n",
      "Episode reward: 43.834515\n",
      "Episode reward: 34.781252\n",
      "Episode reward: 79.102616\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 51.5     |\n",
      "|    ep_rew_mean      | 50.7     |\n",
      "|    exploration_rate | 0.424    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1516     |\n",
      "|    fps              | 3493     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 60604    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00273  |\n",
      "|    n_updates        | 15125    |\n",
      "----------------------------------\n",
      "Episode reward: 83.738415\n",
      "Episode reward: 34.945121\n",
      "Episode reward: 52.775919\n",
      "Episode reward: 63.955857\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52       |\n",
      "|    ep_rew_mean      | 51.2     |\n",
      "|    exploration_rate | 0.422    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1520     |\n",
      "|    fps              | 3488     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 60844    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.257    |\n",
      "|    n_updates        | 15185    |\n",
      "----------------------------------\n",
      "Episode reward: 56.870281\n",
      "Episode reward: 65.449181\n",
      "Episode reward: 69.713956\n",
      "Episode reward: 50.94255\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.4     |\n",
      "|    ep_rew_mean      | 51.5     |\n",
      "|    exploration_rate | 0.42     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1524     |\n",
      "|    fps              | 3487     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 61091    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.239    |\n",
      "|    n_updates        | 15247    |\n",
      "----------------------------------\n",
      "Episode reward: 41.908831\n",
      "Episode reward: 64.837537\n",
      "Episode reward: 38.93641\n",
      "Episode reward: 137.034147\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.6     |\n",
      "|    ep_rew_mean      | 51.8     |\n",
      "|    exploration_rate | 0.417    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1528     |\n",
      "|    fps              | 3489     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 61378    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.123    |\n",
      "|    n_updates        | 15319    |\n",
      "----------------------------------\n",
      "Episode reward: 48.844206\n",
      "Episode reward: 67.596261\n",
      "Episode reward: 57.455645\n",
      "Episode reward: 62.411631\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53       |\n",
      "|    ep_rew_mean      | 52.3     |\n",
      "|    exploration_rate | 0.415    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1532     |\n",
      "|    fps              | 3486     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 61617    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00277  |\n",
      "|    n_updates        | 15379    |\n",
      "----------------------------------\n",
      "Episode reward: 55.940807\n",
      "Episode reward: 85.156139\n",
      "Episode reward: 60.893787\n",
      "Episode reward: 57.67339\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.4     |\n",
      "|    ep_rew_mean      | 52.6     |\n",
      "|    exploration_rate | 0.412    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1536     |\n",
      "|    fps              | 3488     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 61883    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.179    |\n",
      "|    n_updates        | 15445    |\n",
      "----------------------------------\n",
      "Episode reward: 35.91033\n",
      "Episode reward: 51.301516\n",
      "Episode reward: 53.842023\n",
      "Episode reward: 49.899024\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.2     |\n",
      "|    ep_rew_mean      | 52.3     |\n",
      "|    exploration_rate | 0.41     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1540     |\n",
      "|    fps              | 3489     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 62075    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00187  |\n",
      "|    n_updates        | 15493    |\n",
      "----------------------------------\n",
      "Episode reward: 37.83765\n",
      "Episode reward: 69.348571\n",
      "Episode reward: 39.921151\n",
      "Episode reward: 44.860915\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.5     |\n",
      "|    ep_rew_mean      | 52.7     |\n",
      "|    exploration_rate | 0.408    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1544     |\n",
      "|    fps              | 3489     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 62268    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.188    |\n",
      "|    n_updates        | 15541    |\n",
      "----------------------------------\n",
      "Episode reward: 38.878774\n",
      "Episode reward: 48.804695\n",
      "Episode reward: 31.835259\n",
      "Episode reward: 45.812691\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.3     |\n",
      "|    ep_rew_mean      | 51.8     |\n",
      "|    exploration_rate | 0.407    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1548     |\n",
      "|    fps              | 3490     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 62434    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 15583    |\n",
      "----------------------------------\n",
      "Episode reward: 44.795954\n",
      "Episode reward: 33.930115\n",
      "Episode reward: 76.485271\n",
      "Episode reward: 55.778013\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.2     |\n",
      "|    ep_rew_mean      | 51.7     |\n",
      "|    exploration_rate | 0.405    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1552     |\n",
      "|    fps              | 3492     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 62647    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0878   |\n",
      "|    n_updates        | 15636    |\n",
      "----------------------------------\n",
      "Episode reward: 57.301285\n",
      "Episode reward: 75.612002\n",
      "Episode reward: 44.748062\n",
      "Episode reward: 33.934669\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.5     |\n",
      "|    ep_rew_mean      | 51.9     |\n",
      "|    exploration_rate | 0.403    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1556     |\n",
      "|    fps              | 3491     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 62861    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0032   |\n",
      "|    n_updates        | 15690    |\n",
      "----------------------------------\n",
      "Episode reward: 33.689744\n",
      "Episode reward: 93.314211\n",
      "Episode reward: 36.880362\n",
      "Episode reward: 36.879725\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.2     |\n",
      "|    ep_rew_mean      | 51.6     |\n",
      "|    exploration_rate | 0.401    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1560     |\n",
      "|    fps              | 3492     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 63068    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 15741    |\n",
      "----------------------------------\n",
      "Episode reward: 52.351039\n",
      "Episode reward: 44.895456\n",
      "Episode reward: 76.283363\n",
      "Episode reward: 45.949624\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.8     |\n",
      "|    ep_rew_mean      | 52.2     |\n",
      "|    exploration_rate | 0.399    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1564     |\n",
      "|    fps              | 3493     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 63291    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.123    |\n",
      "|    n_updates        | 15797    |\n",
      "----------------------------------\n",
      "Episode reward: 65.732178\n",
      "Episode reward: 58.886718\n",
      "Episode reward: 51.842264\n",
      "Episode reward: 48.758734\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.2     |\n",
      "|    ep_rew_mean      | 52.6     |\n",
      "|    exploration_rate | 0.397    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1568     |\n",
      "|    fps              | 3492     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 63517    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000568 |\n",
      "|    n_updates        | 15854    |\n",
      "----------------------------------\n",
      "Episode reward: 41.532221\n",
      "Episode reward: 36.541775\n",
      "Episode reward: 41.915697\n",
      "Episode reward: 45.853402\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.2     |\n",
      "|    ep_rew_mean      | 52.6     |\n",
      "|    exploration_rate | 0.395    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1572     |\n",
      "|    fps              | 3494     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 63684    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.145    |\n",
      "|    n_updates        | 15895    |\n",
      "----------------------------------\n",
      "Episode reward: 39.945895\n",
      "Episode reward: 38.929986\n",
      "Episode reward: 85.940008\n",
      "Episode reward: 62.623535\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.4     |\n",
      "|    ep_rew_mean      | 52.8     |\n",
      "|    exploration_rate | 0.393    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1576     |\n",
      "|    fps              | 3486     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 63914    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.374    |\n",
      "|    n_updates        | 15953    |\n",
      "----------------------------------\n",
      "Episode reward: 57.180386\n",
      "Episode reward: 45.791309\n",
      "Episode reward: 56.919526\n",
      "Episode reward: 41.440318\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.6     |\n",
      "|    ep_rew_mean      | 53       |\n",
      "|    exploration_rate | 0.391    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1580     |\n",
      "|    fps              | 3478     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 64118    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.29     |\n",
      "|    n_updates        | 16004    |\n",
      "----------------------------------\n",
      "Episode reward: 47.922126\n",
      "Episode reward: 38.930354\n",
      "Episode reward: 54.512526\n",
      "Episode reward: 50.87967\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.5     |\n",
      "|    ep_rew_mean      | 52.9     |\n",
      "|    exploration_rate | 0.389    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1584     |\n",
      "|    fps              | 3479     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 64311    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0038   |\n",
      "|    n_updates        | 16052    |\n",
      "----------------------------------\n",
      "Episode reward: 52.583027\n",
      "Episode reward: 56.520083\n",
      "Episode reward: 45.58812\n",
      "Episode reward: 46.350704\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.8     |\n",
      "|    ep_rew_mean      | 53.1     |\n",
      "|    exploration_rate | 0.387    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1588     |\n",
      "|    fps              | 3478     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 64516    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0956   |\n",
      "|    n_updates        | 16103    |\n",
      "----------------------------------\n",
      "Episode reward: 74.572178\n",
      "Episode reward: 64.836766\n",
      "Episode reward: 76.361495\n",
      "Episode reward: 62.160883\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.7     |\n",
      "|    ep_rew_mean      | 54       |\n",
      "|    exploration_rate | 0.384    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1592     |\n",
      "|    fps              | 3474     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 64800    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00436  |\n",
      "|    n_updates        | 16174    |\n",
      "----------------------------------\n",
      "Episode reward: 80.471873\n",
      "Episode reward: 38.630532\n",
      "Episode reward: 34.81407\n",
      "Episode reward: 53.087541\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55       |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.382    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1596     |\n",
      "|    fps              | 3473     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 65009    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000844 |\n",
      "|    n_updates        | 16227    |\n",
      "----------------------------------\n",
      "Episode reward: 34.913998\n",
      "Episode reward: 39.754166\n",
      "Episode reward: 81.324413\n",
      "Episode reward: 49.902472\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 53.8     |\n",
      "|    exploration_rate | 0.38     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1600     |\n",
      "|    fps              | 3474     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 65216    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.113    |\n",
      "|    n_updates        | 16278    |\n",
      "----------------------------------\n",
      "Episode reward: 44.924271\n",
      "Episode reward: 58.737305\n",
      "Episode reward: 46.920791\n",
      "Episode reward: 49.893511\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 53.9     |\n",
      "|    exploration_rate | 0.379    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1604     |\n",
      "|    fps              | 3473     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 65417    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00212  |\n",
      "|    n_updates        | 16329    |\n",
      "----------------------------------\n",
      "Episode reward: 35.904497\n",
      "Episode reward: 47.914292\n",
      "Episode reward: 49.876682\n",
      "Episode reward: 52.918194\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 53.9     |\n",
      "|    exploration_rate | 0.377    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1608     |\n",
      "|    fps              | 3473     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 65604    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00314  |\n",
      "|    n_updates        | 16375    |\n",
      "----------------------------------\n",
      "Episode reward: 38.686699\n",
      "Episode reward: 33.817679\n",
      "Episode reward: 55.71267\n",
      "Episode reward: 34.955757\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.9     |\n",
      "|    ep_rew_mean      | 53.2     |\n",
      "|    exploration_rate | 0.375    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1612     |\n",
      "|    fps              | 3473     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 65768    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0035   |\n",
      "|    n_updates        | 16416    |\n",
      "----------------------------------\n",
      "Episode reward: 55.889484\n",
      "Episode reward: 51.847825\n",
      "Episode reward: 91.409385\n",
      "Episode reward: 34.894766\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.1     |\n",
      "|    ep_rew_mean      | 53.4     |\n",
      "|    exploration_rate | 0.373    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1616     |\n",
      "|    fps              | 3473     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 66016    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.136    |\n",
      "|    n_updates        | 16478    |\n",
      "----------------------------------\n",
      "Episode reward: 40.895029\n",
      "Episode reward: 41.713348\n",
      "Episode reward: 54.200025\n",
      "Episode reward: 38.816002\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.5     |\n",
      "|    ep_rew_mean      | 52.8     |\n",
      "|    exploration_rate | 0.371    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1620     |\n",
      "|    fps              | 3470     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 66194    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.155    |\n",
      "|    n_updates        | 16523    |\n",
      "----------------------------------\n",
      "Episode reward: 51.148836\n",
      "Episode reward: 51.926262\n",
      "Episode reward: 41.904985\n",
      "Episode reward: 79.830121\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.3     |\n",
      "|    ep_rew_mean      | 52.6     |\n",
      "|    exploration_rate | 0.369    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1624     |\n",
      "|    fps              | 3471     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 66421    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 16580    |\n",
      "----------------------------------\n",
      "Episode reward: 42.173248\n",
      "Episode reward: 53.611353\n",
      "Episode reward: 75.786968\n",
      "Episode reward: 46.805641\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.6     |\n",
      "|    ep_rew_mean      | 51.9     |\n",
      "|    exploration_rate | 0.367    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1628     |\n",
      "|    fps              | 3471     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 66641    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.305    |\n",
      "|    n_updates        | 16635    |\n",
      "----------------------------------\n",
      "Episode reward: 68.57783\n",
      "Episode reward: 39.675699\n",
      "Episode reward: 61.829701\n",
      "Episode reward: 43.794033\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.4     |\n",
      "|    ep_rew_mean      | 51.7     |\n",
      "|    exploration_rate | 0.365    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1632     |\n",
      "|    fps              | 3469     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 66856    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00236  |\n",
      "|    n_updates        | 16688    |\n",
      "----------------------------------\n",
      "Episode reward: 55.854133\n",
      "Episode reward: 33.913571\n",
      "Episode reward: 31.809452\n",
      "Episode reward: 45.948215\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 51.4     |\n",
      "|    ep_rew_mean      | 50.8     |\n",
      "|    exploration_rate | 0.363    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1636     |\n",
      "|    fps              | 3469     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 67024    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00359  |\n",
      "|    n_updates        | 16730    |\n",
      "----------------------------------\n",
      "Episode reward: 37.888271\n",
      "Episode reward: 48.303221\n",
      "Episode reward: 59.832901\n",
      "Episode reward: 61.817009\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 51.6     |\n",
      "|    ep_rew_mean      | 51       |\n",
      "|    exploration_rate | 0.361    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1640     |\n",
      "|    fps              | 3466     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 67235    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00349  |\n",
      "|    n_updates        | 16783    |\n",
      "----------------------------------\n",
      "Episode reward: 45.33449\n",
      "Episode reward: 40.667376\n",
      "Episode reward: 39.729447\n",
      "Episode reward: 52.256859\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 51.5     |\n",
      "|    ep_rew_mean      | 50.8     |\n",
      "|    exploration_rate | 0.36     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1644     |\n",
      "|    fps              | 3465     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 67415    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 16828    |\n",
      "----------------------------------\n",
      "Episode reward: 45.892248\n",
      "Episode reward: 47.827215\n",
      "Episode reward: 44.707716\n",
      "Episode reward: 100.136601\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.3     |\n",
      "|    ep_rew_mean      | 51.6     |\n",
      "|    exploration_rate | 0.357    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1648     |\n",
      "|    fps              | 3467     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 67663    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00367  |\n",
      "|    n_updates        | 16890    |\n",
      "----------------------------------\n",
      "Episode reward: 71.267302\n",
      "Episode reward: 37.826244\n",
      "Episode reward: 66.60113\n",
      "Episode reward: 52.854393\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.5     |\n",
      "|    ep_rew_mean      | 51.7     |\n",
      "|    exploration_rate | 0.355    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1652     |\n",
      "|    fps              | 3465     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 67894    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00107  |\n",
      "|    n_updates        | 16948    |\n",
      "----------------------------------\n",
      "Episode reward: 55.444849\n",
      "Episode reward: 82.441512\n",
      "Episode reward: 52.726742\n",
      "Episode reward: 36.919054\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.7     |\n",
      "|    ep_rew_mean      | 51.9     |\n",
      "|    exploration_rate | 0.353    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1656     |\n",
      "|    fps              | 3465     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 68129    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.147    |\n",
      "|    n_updates        | 17007    |\n",
      "----------------------------------\n",
      "Episode reward: 79.217321\n",
      "Episode reward: 60.431083\n",
      "Episode reward: 54.805104\n",
      "Episode reward: 77.723803\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.4     |\n",
      "|    ep_rew_mean      | 52.6     |\n",
      "|    exploration_rate | 0.35     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1660     |\n",
      "|    fps              | 3467     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 68412    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0804   |\n",
      "|    n_updates        | 17077    |\n",
      "----------------------------------\n",
      "Episode reward: 89.131249\n",
      "Episode reward: 61.625251\n",
      "Episode reward: 88.238899\n",
      "Episode reward: 41.789041\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54       |\n",
      "|    ep_rew_mean      | 53.2     |\n",
      "|    exploration_rate | 0.347    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1664     |\n",
      "|    fps              | 3466     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 68695    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.143    |\n",
      "|    n_updates        | 17148    |\n",
      "----------------------------------\n",
      "Episode reward: 61.520461\n",
      "Episode reward: 63.794353\n",
      "Episode reward: 41.871054\n",
      "Episode reward: 50.42848\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54       |\n",
      "|    ep_rew_mean      | 53.1     |\n",
      "|    exploration_rate | 0.345    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1668     |\n",
      "|    fps              | 3464     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 68914    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.1      |\n",
      "|    n_updates        | 17203    |\n",
      "----------------------------------\n",
      "Episode reward: 40.909721\n",
      "Episode reward: 29.941686\n",
      "Episode reward: 37.8917\n",
      "Episode reward: 47.633321\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.9     |\n",
      "|    ep_rew_mean      | 53       |\n",
      "|    exploration_rate | 0.344    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1672     |\n",
      "|    fps              | 3465     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 69071    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.505    |\n",
      "|    n_updates        | 17242    |\n",
      "----------------------------------\n",
      "Episode reward: 38.924141\n",
      "Episode reward: 73.591291\n",
      "Episode reward: 33.843621\n",
      "Episode reward: 33.943177\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.5     |\n",
      "|    ep_rew_mean      | 52.6     |\n",
      "|    exploration_rate | 0.342    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1676     |\n",
      "|    fps              | 3467     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 69268    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.146    |\n",
      "|    n_updates        | 17291    |\n",
      "----------------------------------\n",
      "Episode reward: 45.811349\n",
      "Episode reward: 44.575849\n",
      "Episode reward: 44.86495\n",
      "Episode reward: 38.660044\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.2     |\n",
      "|    ep_rew_mean      | 52.3     |\n",
      "|    exploration_rate | 0.34     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1680     |\n",
      "|    fps              | 3466     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 69443    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 17335    |\n",
      "----------------------------------\n",
      "Episode reward: 68.915188\n",
      "Episode reward: 33.91467\n",
      "Episode reward: 96.938854\n",
      "Episode reward: 74.821429\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.1     |\n",
      "|    ep_rew_mean      | 53.1     |\n",
      "|    exploration_rate | 0.338    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1684     |\n",
      "|    fps              | 3466     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 69723    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00543  |\n",
      "|    n_updates        | 17405    |\n",
      "----------------------------------\n",
      "Episode reward: 47.549832\n",
      "Episode reward: 53.495677\n",
      "Episode reward: 38.907224\n",
      "Episode reward: 65.594109\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.1     |\n",
      "|    ep_rew_mean      | 53.2     |\n",
      "|    exploration_rate | 0.336    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1688     |\n",
      "|    fps              | 3467     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 69930    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00261  |\n",
      "|    n_updates        | 17457    |\n",
      "----------------------------------\n",
      "Episode reward: 35.881693\n",
      "Episode reward: 80.394443\n",
      "Episode reward: 40.713358\n",
      "Episode reward: 37.935015\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.3     |\n",
      "|    ep_rew_mean      | 52.3     |\n",
      "|    exploration_rate | 0.334    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1692     |\n",
      "|    fps              | 3464     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70132    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00432  |\n",
      "|    n_updates        | 17507    |\n",
      "----------------------------------\n",
      "Episode reward: 63.763963\n",
      "Episode reward: 60.761913\n",
      "Episode reward: 21.959063\n",
      "Episode reward: 35.926819\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.1     |\n",
      "|    ep_rew_mean      | 52.1     |\n",
      "|    exploration_rate | 0.332    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1696     |\n",
      "|    fps              | 3464     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70316    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000965 |\n",
      "|    n_updates        | 17553    |\n",
      "----------------------------------\n",
      "Episode reward: 63.443626\n",
      "Episode reward: 32.9395\n",
      "Episode reward: 43.782915\n",
      "Episode reward: 67.298415\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.1     |\n",
      "|    ep_rew_mean      | 52.1     |\n",
      "|    exploration_rate | 0.33     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1700     |\n",
      "|    fps              | 3461     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70525    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00183  |\n",
      "|    n_updates        | 17606    |\n",
      "----------------------------------\n",
      "Episode reward: 39.828483\n",
      "Episode reward: 41.652542\n",
      "Episode reward: 33.939306\n",
      "Episode reward: 95.111912\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.2     |\n",
      "|    ep_rew_mean      | 52.2     |\n",
      "|    exploration_rate | 0.328    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1704     |\n",
      "|    fps              | 3457     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70740    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00404  |\n",
      "|    n_updates        | 17659    |\n",
      "----------------------------------\n",
      "Episode reward: 83.036486\n",
      "Episode reward: 48.766468\n",
      "Episode reward: 43.766925\n",
      "Episode reward: 41.690882\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.5     |\n",
      "|    ep_rew_mean      | 52.5     |\n",
      "|    exploration_rate | 0.326    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1708     |\n",
      "|    fps              | 3457     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 70959    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.245    |\n",
      "|    n_updates        | 17714    |\n",
      "----------------------------------\n",
      "Episode reward: 86.463783\n",
      "Episode reward: 56.910112\n",
      "Episode reward: 85.520935\n",
      "Episode reward: 42.928549\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 53.6     |\n",
      "|    exploration_rate | 0.323    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1712     |\n",
      "|    fps              | 3453     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 71302    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.28     |\n",
      "|    n_updates        | 17800    |\n",
      "----------------------------------\n",
      "Episode reward: 35.902221\n",
      "Episode reward: 58.763669\n",
      "Episode reward: 41.749718\n",
      "Episode reward: 53.636682\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.8     |\n",
      "|    ep_rew_mean      | 53.2     |\n",
      "|    exploration_rate | 0.321    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1716     |\n",
      "|    fps              | 3451     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 71493    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.241    |\n",
      "|    n_updates        | 17848    |\n",
      "----------------------------------\n",
      "Episode reward: 33.892614\n",
      "Episode reward: 36.939505\n",
      "Episode reward: 32.891257\n",
      "Episode reward: 65.815493\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.7     |\n",
      "|    ep_rew_mean      | 53.1     |\n",
      "|    exploration_rate | 0.319    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1720     |\n",
      "|    fps              | 3449     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 71663    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.144    |\n",
      "|    n_updates        | 17890    |\n",
      "----------------------------------\n",
      "Episode reward: 94.217928\n",
      "Episode reward: 51.463222\n",
      "Episode reward: 63.49629\n",
      "Episode reward: 53.905397\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.317    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1724     |\n",
      "|    fps              | 3451     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 71933    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.135    |\n",
      "|    n_updates        | 17958    |\n",
      "----------------------------------\n",
      "Episode reward: 39.9197\n",
      "Episode reward: 31.915675\n",
      "Episode reward: 44.86724\n",
      "Episode reward: 49.513839\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.6     |\n",
      "|    ep_rew_mean      | 53       |\n",
      "|    exploration_rate | 0.315    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1728     |\n",
      "|    fps              | 3451     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 72100    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00387  |\n",
      "|    n_updates        | 17999    |\n",
      "----------------------------------\n",
      "Episode reward: 80.651585\n",
      "Episode reward: 34.946066\n",
      "Episode reward: 63.55442\n",
      "Episode reward: 45.754493\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.7     |\n",
      "|    ep_rew_mean      | 53.1     |\n",
      "|    exploration_rate | 0.313    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1732     |\n",
      "|    fps              | 3447     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 72326    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.233    |\n",
      "|    n_updates        | 18056    |\n",
      "----------------------------------\n",
      "Episode reward: 42.577648\n",
      "Episode reward: 55.357002\n",
      "Episode reward: 66.84313\n",
      "Episode reward: 51.874877\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 53.6     |\n",
      "|    exploration_rate | 0.311    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1736     |\n",
      "|    fps              | 3448     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 72545    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.131    |\n",
      "|    n_updates        | 18111    |\n",
      "----------------------------------\n",
      "Episode reward: 60.2043\n",
      "Episode reward: 89.763983\n",
      "Episode reward: 71.239799\n",
      "Episode reward: 81.665814\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.308    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1740     |\n",
      "|    fps              | 3450     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 72883    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00204  |\n",
      "|    n_updates        | 18195    |\n",
      "----------------------------------\n",
      "Episode reward: 60.44649\n",
      "Episode reward: 36.871391\n",
      "Episode reward: 34.910828\n",
      "Episode reward: 53.417732\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.306    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1744     |\n",
      "|    fps              | 3450     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 73071    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.156    |\n",
      "|    n_updates        | 18242    |\n",
      "----------------------------------\n",
      "Episode reward: 97.677456\n",
      "Episode reward: 80.280832\n",
      "Episode reward: 40.896411\n",
      "Episode reward: 101.68578\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.303    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1748     |\n",
      "|    fps              | 3447     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 73397    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.104    |\n",
      "|    n_updates        | 18324    |\n",
      "----------------------------------\n",
      "Episode reward: 42.89806\n",
      "Episode reward: 54.833956\n",
      "Episode reward: 74.723813\n",
      "Episode reward: 52.936332\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.301    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1752     |\n",
      "|    fps              | 3447     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 73624    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.135    |\n",
      "|    n_updates        | 18380    |\n",
      "----------------------------------\n",
      "Episode reward: 46.620513\n",
      "Episode reward: 61.796687\n",
      "Episode reward: 51.45804\n",
      "Episode reward: 46.799583\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.299    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1756     |\n",
      "|    fps              | 3443     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 73835    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0897   |\n",
      "|    n_updates        | 18433    |\n",
      "----------------------------------\n",
      "Episode reward: 68.742884\n",
      "Episode reward: 41.899538\n",
      "Episode reward: 37.813057\n",
      "Episode reward: 55.677189\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.296    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1760     |\n",
      "|    fps              | 3442     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 74095    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0021   |\n",
      "|    n_updates        | 18498    |\n",
      "----------------------------------\n",
      "Episode reward: 43.920903\n",
      "Episode reward: 52.480175\n",
      "Episode reward: 41.788926\n",
      "Episode reward: 39.742249\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.294    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1764     |\n",
      "|    fps              | 3442     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 74274    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00224  |\n",
      "|    n_updates        | 18543    |\n",
      "----------------------------------\n",
      "Episode reward: 97.423741\n",
      "Episode reward: 40.937462\n",
      "Episode reward: 45.883758\n",
      "Episode reward: 52.938985\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 53.7     |\n",
      "|    exploration_rate | 0.292    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1768     |\n",
      "|    fps              | 3440     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 74512    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.121    |\n",
      "|    n_updates        | 18602    |\n",
      "----------------------------------\n",
      "Episode reward: 41.935265\n",
      "Episode reward: 56.293353\n",
      "Episode reward: 36.933114\n",
      "Episode reward: 80.728104\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.29     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1772     |\n",
      "|    fps              | 3442     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 74733    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00244  |\n",
      "|    n_updates        | 18658    |\n",
      "----------------------------------\n",
      "Episode reward: 40.88931\n",
      "Episode reward: 66.275926\n",
      "Episode reward: 38.897424\n",
      "Episode reward: 72.4035\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.288    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1776     |\n",
      "|    fps              | 3441     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 74958    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.303    |\n",
      "|    n_updates        | 18714    |\n",
      "----------------------------------\n",
      "Episode reward: 39.925494\n",
      "Episode reward: 33.796403\n",
      "Episode reward: 39.903663\n",
      "Episode reward: 44.913379\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.286    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1780     |\n",
      "|    fps              | 3438     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 75117    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00446  |\n",
      "|    n_updates        | 18754    |\n",
      "----------------------------------\n",
      "Episode reward: 53.153761\n",
      "Episode reward: 63.760362\n",
      "Episode reward: 71.833842\n",
      "Episode reward: 58.097876\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.284    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1784     |\n",
      "|    fps              | 3437     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 75368    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.092    |\n",
      "|    n_updates        | 18816    |\n",
      "----------------------------------\n",
      "Episode reward: 35.860252\n",
      "Episode reward: 48.822315\n",
      "Episode reward: 36.853115\n",
      "Episode reward: 74.525523\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.282    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1788     |\n",
      "|    fps              | 3435     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 75566    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00232  |\n",
      "|    n_updates        | 18866    |\n",
      "----------------------------------\n",
      "Episode reward: 31.823389\n",
      "Episode reward: 50.84153\n",
      "Episode reward: 48.840935\n",
      "Episode reward: 63.762126\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.28     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1792     |\n",
      "|    fps              | 3433     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 75762    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.273    |\n",
      "|    n_updates        | 18915    |\n",
      "----------------------------------\n",
      "Episode reward: 45.873001\n",
      "Episode reward: 60.491642\n",
      "Episode reward: 52.813087\n",
      "Episode reward: 68.127326\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.278    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1796     |\n",
      "|    fps              | 3425     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 75992    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.164    |\n",
      "|    n_updates        | 18972    |\n",
      "----------------------------------\n",
      "Episode reward: 31.660905\n",
      "Episode reward: 53.889985\n",
      "Episode reward: 36.919449\n",
      "Episode reward: 48.212461\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.276    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1800     |\n",
      "|    fps              | 3426     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 76164    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.376    |\n",
      "|    n_updates        | 19015    |\n",
      "----------------------------------\n",
      "Episode reward: 42.940418\n",
      "Episode reward: 34.589171\n",
      "Episode reward: 63.894568\n",
      "Episode reward: 33.950219\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 53.8     |\n",
      "|    exploration_rate | 0.275    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1804     |\n",
      "|    fps              | 3424     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 76340    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00261  |\n",
      "|    n_updates        | 19059    |\n",
      "----------------------------------\n",
      "Episode reward: 40.947172\n",
      "Episode reward: 48.896223\n",
      "Episode reward: 37.688304\n",
      "Episode reward: 41.755493\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.5     |\n",
      "|    ep_rew_mean      | 53.4     |\n",
      "|    exploration_rate | 0.273    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1808     |\n",
      "|    fps              | 3423     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 76510    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00143  |\n",
      "|    n_updates        | 19102    |\n",
      "----------------------------------\n",
      "Episode reward: 93.274348\n",
      "Episode reward: 44.950387\n",
      "Episode reward: 57.784617\n",
      "Episode reward: 58.900229\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.7     |\n",
      "|    ep_rew_mean      | 53.2     |\n",
      "|    exploration_rate | 0.271    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1812     |\n",
      "|    fps              | 3425     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 76768    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.285    |\n",
      "|    n_updates        | 19166    |\n",
      "----------------------------------\n",
      "Episode reward: 99.075783\n",
      "Episode reward: 75.918536\n",
      "Episode reward: 33.942042\n",
      "Episode reward: 71.274678\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.268    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1816     |\n",
      "|    fps              | 3424     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 77051    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.137    |\n",
      "|    n_updates        | 19237    |\n",
      "----------------------------------\n",
      "Episode reward: 50.463807\n",
      "Episode reward: 58.314154\n",
      "Episode reward: 85.990495\n",
      "Episode reward: 44.784204\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.266    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1820     |\n",
      "|    fps              | 3423     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 77293    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.133    |\n",
      "|    n_updates        | 19298    |\n",
      "----------------------------------\n",
      "Episode reward: 29.878187\n",
      "Episode reward: 49.827979\n",
      "Episode reward: 65.145722\n",
      "Episode reward: 60.983029\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.264    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1824     |\n",
      "|    fps              | 3422     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 77501    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.154    |\n",
      "|    n_updates        | 19350    |\n",
      "----------------------------------\n",
      "Episode reward: 70.745225\n",
      "Episode reward: 63.794787\n",
      "Episode reward: 44.296377\n",
      "Episode reward: 65.089502\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.261    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1828     |\n",
      "|    fps              | 3419     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 77755    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.132    |\n",
      "|    n_updates        | 19413    |\n",
      "----------------------------------\n",
      "Episode reward: 40.826784\n",
      "Episode reward: 127.632564\n",
      "Episode reward: 41.619611\n",
      "Episode reward: 37.876899\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.259    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1832     |\n",
      "|    fps              | 3420     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 78009    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00398  |\n",
      "|    n_updates        | 19477    |\n",
      "----------------------------------\n",
      "Episode reward: 70.653294\n",
      "Episode reward: 38.783857\n",
      "Episode reward: 37.908575\n",
      "Episode reward: 75.361743\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.257    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1836     |\n",
      "|    fps              | 3420     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 78235    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.436    |\n",
      "|    n_updates        | 19533    |\n",
      "----------------------------------\n",
      "Episode reward: 34.867365\n",
      "Episode reward: 65.117246\n",
      "Episode reward: 43.892867\n",
      "Episode reward: 62.538119\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.255    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1840     |\n",
      "|    fps              | 3418     |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 78451    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0565   |\n",
      "|    n_updates        | 19587    |\n",
      "----------------------------------\n",
      "Episode reward: 48.682361\n",
      "Episode reward: 63.579472\n",
      "Episode reward: 41.801244\n",
      "Episode reward: 67.709416\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.253    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1844     |\n",
      "|    fps              | 3420     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 78674    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00421  |\n",
      "|    n_updates        | 19643    |\n",
      "----------------------------------\n",
      "Episode reward: 52.200063\n",
      "Episode reward: 46.622018\n",
      "Episode reward: 141.393288\n",
      "Episode reward: 62.847226\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.25     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1848     |\n",
      "|    fps              | 3421     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 78981    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.212    |\n",
      "|    n_updates        | 19720    |\n",
      "----------------------------------\n",
      "Episode reward: 45.938987\n",
      "Episode reward: 84.9312\n",
      "Episode reward: 40.814621\n",
      "Episode reward: 77.746975\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.247    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1852     |\n",
      "|    fps              | 3418     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 79236    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.193    |\n",
      "|    n_updates        | 19783    |\n",
      "----------------------------------\n",
      "Episode reward: 51.593098\n",
      "Episode reward: 39.921748\n",
      "Episode reward: 40.638214\n",
      "Episode reward: 34.69503\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.246    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1856     |\n",
      "|    fps              | 3416     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 79404    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00173  |\n",
      "|    n_updates        | 19825    |\n",
      "----------------------------------\n",
      "Episode reward: 72.587608\n",
      "Episode reward: 65.780997\n",
      "Episode reward: 39.933379\n",
      "Episode reward: 49.817423\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.243    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1860     |\n",
      "|    fps              | 3415     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 79637    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.144    |\n",
      "|    n_updates        | 19884    |\n",
      "----------------------------------\n",
      "Episode reward: 33.837869\n",
      "Episode reward: 35.942355\n",
      "Episode reward: 38.843438\n",
      "Episode reward: 80.898016\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.242    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1864     |\n",
      "|    fps              | 3415     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 79831    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.159    |\n",
      "|    n_updates        | 19932    |\n",
      "----------------------------------\n",
      "Episode reward: 56.991678\n",
      "Episode reward: 40.918625\n",
      "Episode reward: 45.39821\n",
      "Episode reward: 41.809659\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1868     |\n",
      "|    fps              | 3416     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 80018    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.534    |\n",
      "|    n_updates        | 19979    |\n",
      "----------------------------------\n",
      "Episode reward: 51.894119\n",
      "Episode reward: 54.7516\n",
      "Episode reward: 45.761789\n",
      "Episode reward: 58.279278\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55       |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.238    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1872     |\n",
      "|    fps              | 3411     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 80232    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.188    |\n",
      "|    n_updates        | 20032    |\n",
      "----------------------------------\n",
      "Episode reward: 56.913453\n",
      "Episode reward: 41.887934\n",
      "Episode reward: 35.933761\n",
      "Episode reward: 54.154173\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.6     |\n",
      "|    ep_rew_mean      | 53.8     |\n",
      "|    exploration_rate | 0.236    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1876     |\n",
      "|    fps              | 3410     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 80422    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00129  |\n",
      "|    n_updates        | 20080    |\n",
      "----------------------------------\n",
      "Episode reward: 34.787284\n",
      "Episode reward: 37.840678\n",
      "Episode reward: 78.428734\n",
      "Episode reward: 49.677255\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.234    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1880     |\n",
      "|    fps              | 3408     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 80628    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00346  |\n",
      "|    n_updates        | 20131    |\n",
      "----------------------------------\n",
      "Episode reward: 45.688674\n",
      "Episode reward: 59.906269\n",
      "Episode reward: 52.496585\n",
      "Episode reward: 67.328128\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.231    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1884     |\n",
      "|    fps              | 3407     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 80981    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00911  |\n",
      "|    n_updates        | 20220    |\n",
      "----------------------------------\n",
      "Episode reward: 69.498172\n",
      "Episode reward: 71.580307\n",
      "Episode reward: 64.476728\n",
      "Episode reward: 59.82215\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.228    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1888     |\n",
      "|    fps              | 3408     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 81248    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.196    |\n",
      "|    n_updates        | 20286    |\n",
      "----------------------------------\n",
      "Episode reward: 65.870128\n",
      "Episode reward: 38.898164\n",
      "Episode reward: 29.781432\n",
      "Episode reward: 78.84709\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.226    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1892     |\n",
      "|    fps              | 3407     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 81463    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.291    |\n",
      "|    n_updates        | 20340    |\n",
      "----------------------------------\n",
      "Episode reward: 49.77311\n",
      "Episode reward: 81.761786\n",
      "Episode reward: 46.284533\n",
      "Episode reward: 38.928817\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.224    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1896     |\n",
      "|    fps              | 3406     |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 81681    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.171    |\n",
      "|    n_updates        | 20395    |\n",
      "----------------------------------\n",
      "Episode reward: 63.532946\n",
      "Episode reward: 67.075746\n",
      "Episode reward: 78.94001\n",
      "Episode reward: 45.962149\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.222    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1900     |\n",
      "|    fps              | 3407     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 81943    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0239   |\n",
      "|    n_updates        | 20460    |\n",
      "----------------------------------\n",
      "Episode reward: 45.849705\n",
      "Episode reward: 47.727493\n",
      "Episode reward: 45.646792\n",
      "Episode reward: 41.882163\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.22     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1904     |\n",
      "|    fps              | 3407     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 82125    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00272  |\n",
      "|    n_updates        | 20506    |\n",
      "----------------------------------\n",
      "Episode reward: 48.893963\n",
      "Episode reward: 99.240572\n",
      "Episode reward: 86.53817\n",
      "Episode reward: 44.917361\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.217    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1908     |\n",
      "|    fps              | 3403     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 82409    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00198  |\n",
      "|    n_updates        | 20577    |\n",
      "----------------------------------\n",
      "Episode reward: 56.445544\n",
      "Episode reward: 71.799182\n",
      "Episode reward: 77.12592\n",
      "Episode reward: 33.911416\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.215    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1912     |\n",
      "|    fps              | 3404     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 82655    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00113  |\n",
      "|    n_updates        | 20638    |\n",
      "----------------------------------\n",
      "Episode reward: 41.821423\n",
      "Episode reward: 42.74325\n",
      "Episode reward: 41.520184\n",
      "Episode reward: 71.085885\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.213    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1916     |\n",
      "|    fps              | 3404     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 82855    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.169    |\n",
      "|    n_updates        | 20688    |\n",
      "----------------------------------\n",
      "Episode reward: 54.90971\n",
      "Episode reward: 50.935736\n",
      "Episode reward: 32.770729\n",
      "Episode reward: 40.562663\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.211    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1920     |\n",
      "|    fps              | 3401     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 83035    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.139    |\n",
      "|    n_updates        | 20733    |\n",
      "----------------------------------\n",
      "Episode reward: 49.767052\n",
      "Episode reward: 68.387074\n",
      "Episode reward: 47.927828\n",
      "Episode reward: 68.378407\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.209    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1924     |\n",
      "|    fps              | 3402     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 83276    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.323    |\n",
      "|    n_updates        | 20793    |\n",
      "----------------------------------\n",
      "Episode reward: 38.898342\n",
      "Episode reward: 45.712206\n",
      "Episode reward: 40.781159\n",
      "Episode reward: 63.506386\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.207    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1928     |\n",
      "|    fps              | 3401     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 83467    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00556  |\n",
      "|    n_updates        | 20841    |\n",
      "----------------------------------\n",
      "Episode reward: 59.91006\n",
      "Episode reward: 82.536782\n",
      "Episode reward: 33.843736\n",
      "Episode reward: 51.889148\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.205    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1932     |\n",
      "|    fps              | 3401     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 83698    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.163    |\n",
      "|    n_updates        | 20899    |\n",
      "----------------------------------\n",
      "Episode reward: 36.931269\n",
      "Episode reward: 41.558491\n",
      "Episode reward: 40.924239\n",
      "Episode reward: 97.968702\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.203    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1936     |\n",
      "|    fps              | 3399     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 83917    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00297  |\n",
      "|    n_updates        | 20954    |\n",
      "----------------------------------\n",
      "Episode reward: 39.893222\n",
      "Episode reward: 61.847573\n",
      "Episode reward: 44.719472\n",
      "Episode reward: 56.935286\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.201    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1940     |\n",
      "|    fps              | 3399     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 84122    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.17     |\n",
      "|    n_updates        | 21005    |\n",
      "----------------------------------\n",
      "Episode reward: 34.812008\n",
      "Episode reward: 82.596717\n",
      "Episode reward: 69.815821\n",
      "Episode reward: 85.119998\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.198    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1944     |\n",
      "|    fps              | 3395     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 84399    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00416  |\n",
      "|    n_updates        | 21074    |\n",
      "----------------------------------\n",
      "Episode reward: 52.864508\n",
      "Episode reward: 64.132667\n",
      "Episode reward: 47.94681\n",
      "Episode reward: 47.434465\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.196    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1948     |\n",
      "|    fps              | 3396     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 84615    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.18     |\n",
      "|    n_updates        | 21128    |\n",
      "----------------------------------\n",
      "Episode reward: 35.574096\n",
      "Episode reward: 47.923558\n",
      "Episode reward: 43.929981\n",
      "Episode reward: 77.133293\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 53.8     |\n",
      "|    exploration_rate | 0.194    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1952     |\n",
      "|    fps              | 3394     |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 84821    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.521    |\n",
      "|    n_updates        | 21180    |\n",
      "----------------------------------\n",
      "Episode reward: 30.885268\n",
      "Episode reward: 66.6372\n",
      "Episode reward: 42.69836\n",
      "Episode reward: 95.544699\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.192    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1956     |\n",
      "|    fps              | 3394     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 85083    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.26     |\n",
      "|    n_updates        | 21245    |\n",
      "----------------------------------\n",
      "Episode reward: 36.954396\n",
      "Episode reward: 55.644388\n",
      "Episode reward: 61.843584\n",
      "Episode reward: 48.789332\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.19     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1960     |\n",
      "|    fps              | 3390     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 85287    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.173    |\n",
      "|    n_updates        | 21296    |\n",
      "----------------------------------\n",
      "Episode reward: 34.957905\n",
      "Episode reward: 92.300253\n",
      "Episode reward: 87.830488\n",
      "Episode reward: 79.590805\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.187    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1964     |\n",
      "|    fps              | 3389     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 85591    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.163    |\n",
      "|    n_updates        | 21372    |\n",
      "----------------------------------\n",
      "Episode reward: 47.816307\n",
      "Episode reward: 43.807027\n",
      "Episode reward: 36.884603\n",
      "Episode reward: 80.626335\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.185    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1968     |\n",
      "|    fps              | 3388     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 85806    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 21426    |\n",
      "----------------------------------\n",
      "Episode reward: 49.894247\n",
      "Episode reward: 35.938984\n",
      "Episode reward: 44.620675\n",
      "Episode reward: 57.910339\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.183    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1972     |\n",
      "|    fps              | 3388     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 85995    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00304  |\n",
      "|    n_updates        | 21473    |\n",
      "----------------------------------\n",
      "Episode reward: 84.842823\n",
      "Episode reward: 39.9303\n",
      "Episode reward: 64.042684\n",
      "Episode reward: 41.926151\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.181    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1976     |\n",
      "|    fps              | 3385     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 86228    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00338  |\n",
      "|    n_updates        | 21531    |\n",
      "----------------------------------\n",
      "Episode reward: 61.541114\n",
      "Episode reward: 66.143154\n",
      "Episode reward: 64.624055\n",
      "Episode reward: 69.31607\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.178    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1980     |\n",
      "|    fps              | 3386     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 86495    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0549   |\n",
      "|    n_updates        | 21598    |\n",
      "----------------------------------\n",
      "Episode reward: 60.91313\n",
      "Episode reward: 92.276141\n",
      "Episode reward: 36.86122\n",
      "Episode reward: 56.784886\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.176    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1984     |\n",
      "|    fps              | 3387     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 86747    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.18     |\n",
      "|    n_updates        | 21661    |\n",
      "----------------------------------\n",
      "Episode reward: 41.72375\n",
      "Episode reward: 55.867369\n",
      "Episode reward: 39.504196\n",
      "Episode reward: 54.795739\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.174    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1988     |\n",
      "|    fps              | 3387     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 86942    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.139    |\n",
      "|    n_updates        | 21710    |\n",
      "----------------------------------\n",
      "Episode reward: 34.881302\n",
      "Episode reward: 36.868389\n",
      "Episode reward: 60.571089\n",
      "Episode reward: 50.494496\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.172    |\n",
      "| time/               |          |\n",
      "|    episodes         | 1992     |\n",
      "|    fps              | 3385     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 87126    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00342  |\n",
      "|    n_updates        | 21756    |\n",
      "----------------------------------\n",
      "Episode reward: 48.320519\n",
      "Episode reward: 61.782387\n",
      "Episode reward: 48.937364\n",
      "Episode reward: 52.428931\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.17     |\n",
      "| time/               |          |\n",
      "|    episodes         | 1996     |\n",
      "|    fps              | 3385     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 87339    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00314  |\n",
      "|    n_updates        | 21809    |\n",
      "----------------------------------\n",
      "Episode reward: 44.910906\n",
      "Episode reward: 35.9385\n",
      "Episode reward: 57.308387\n",
      "Episode reward: 70.481703\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.168    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2000     |\n",
      "|    fps              | 3385     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 87549    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.147    |\n",
      "|    n_updates        | 21862    |\n",
      "----------------------------------\n",
      "Episode reward: 56.769875\n",
      "Episode reward: 36.905171\n",
      "Episode reward: 49.300367\n",
      "Episode reward: 79.428013\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.166    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2004     |\n",
      "|    fps              | 3383     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 87781    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00183  |\n",
      "|    n_updates        | 21920    |\n",
      "----------------------------------\n",
      "Episode reward: 53.807138\n",
      "Episode reward: 45.929383\n",
      "Episode reward: 52.877638\n",
      "Episode reward: 33.956752\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.164    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2008     |\n",
      "|    fps              | 3383     |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 87968    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.184    |\n",
      "|    n_updates        | 21966    |\n",
      "----------------------------------\n",
      "Episode reward: 51.551606\n",
      "Episode reward: 61.695811\n",
      "Episode reward: 70.724001\n",
      "Episode reward: 64.065694\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.162    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2012     |\n",
      "|    fps              | 3383     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 88220    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 22029    |\n",
      "----------------------------------\n",
      "Episode reward: 50.820824\n",
      "Episode reward: 42.886184\n",
      "Episode reward: 55.091401\n",
      "Episode reward: 65.89744\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.16     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2016     |\n",
      "|    fps              | 3383     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 88436    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.281    |\n",
      "|    n_updates        | 22083    |\n",
      "----------------------------------\n",
      "Episode reward: 39.945244\n",
      "Episode reward: 39.765431\n",
      "Episode reward: 44.551455\n",
      "Episode reward: 73.716436\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.158    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2020     |\n",
      "|    fps              | 3382     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 88637    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00114  |\n",
      "|    n_updates        | 22134    |\n",
      "----------------------------------\n",
      "Episode reward: 36.953297\n",
      "Episode reward: 46.586688\n",
      "Episode reward: 39.786796\n",
      "Episode reward: 36.892635\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.156    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2024     |\n",
      "|    fps              | 3383     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 88798    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.112    |\n",
      "|    n_updates        | 22174    |\n",
      "----------------------------------\n",
      "Episode reward: 68.780531\n",
      "Episode reward: 77.778052\n",
      "Episode reward: 39.914798\n",
      "Episode reward: 38.90975\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.154    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2028     |\n",
      "|    fps              | 3380     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 89024    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00151  |\n",
      "|    n_updates        | 22230    |\n",
      "----------------------------------\n",
      "Episode reward: 36.942037\n",
      "Episode reward: 47.861708\n",
      "Episode reward: 47.879756\n",
      "Episode reward: 50.932467\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.153    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2032     |\n",
      "|    fps              | 3377     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 89208    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.164    |\n",
      "|    n_updates        | 22276    |\n",
      "----------------------------------\n",
      "Episode reward: 86.928327\n",
      "Episode reward: 50.277296\n",
      "Episode reward: 43.919045\n",
      "Episode reward: 42.881933\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2036     |\n",
      "|    fps              | 3377     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 89437    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.183    |\n",
      "|    n_updates        | 22334    |\n",
      "----------------------------------\n",
      "Episode reward: 47.37997\n",
      "Episode reward: 55.738726\n",
      "Episode reward: 40.898678\n",
      "Episode reward: 48.939905\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.149    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2040     |\n",
      "|    fps              | 3377     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 89631    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.23     |\n",
      "|    n_updates        | 22382    |\n",
      "----------------------------------\n",
      "Episode reward: 54.650372\n",
      "Episode reward: 94.721797\n",
      "Episode reward: 45.803729\n",
      "Episode reward: 52.860296\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.8     |\n",
      "|    ep_rew_mean      | 53.9     |\n",
      "|    exploration_rate | 0.146    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2044     |\n",
      "|    fps              | 3374     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 89880    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.164    |\n",
      "|    n_updates        | 22444    |\n",
      "----------------------------------\n",
      "Episode reward: 66.293779\n",
      "Episode reward: 39.813679\n",
      "Episode reward: 45.362295\n",
      "Episode reward: 63.71959\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 53.9     |\n",
      "|    exploration_rate | 0.144    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2048     |\n",
      "|    fps              | 3376     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 90100    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.476    |\n",
      "|    n_updates        | 22499    |\n",
      "----------------------------------\n",
      "Episode reward: 46.771649\n",
      "Episode reward: 67.720714\n",
      "Episode reward: 55.413672\n",
      "Episode reward: 32.855408\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 53.9     |\n",
      "|    exploration_rate | 0.142    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2052     |\n",
      "|    fps              | 3377     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 90308    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.181    |\n",
      "|    n_updates        | 22551    |\n",
      "----------------------------------\n",
      "Episode reward: 42.934517\n",
      "Episode reward: 40.60668\n",
      "Episode reward: 42.87097\n",
      "Episode reward: 40.900562\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.9     |\n",
      "|    ep_rew_mean      | 53.2     |\n",
      "|    exploration_rate | 0.14     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2056     |\n",
      "|    fps              | 3376     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 90476    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.177    |\n",
      "|    n_updates        | 22593    |\n",
      "----------------------------------\n",
      "Episode reward: 54.905447\n",
      "Episode reward: 33.742232\n",
      "Episode reward: 43.679977\n",
      "Episode reward: 75.205336\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54       |\n",
      "|    ep_rew_mean      | 53.2     |\n",
      "|    exploration_rate | 0.138    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2060     |\n",
      "|    fps              | 3375     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 90686    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.195    |\n",
      "|    n_updates        | 22646    |\n",
      "----------------------------------\n",
      "Episode reward: 38.934372\n",
      "Episode reward: 57.341699\n",
      "Episode reward: 45.936505\n",
      "Episode reward: 42.851677\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.8     |\n",
      "|    ep_rew_mean      | 52.1     |\n",
      "|    exploration_rate | 0.137    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2064     |\n",
      "|    fps              | 3375     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 90873    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.433    |\n",
      "|    n_updates        | 22693    |\n",
      "----------------------------------\n",
      "Episode reward: 47.909538\n",
      "Episode reward: 54.710571\n",
      "Episode reward: 43.780327\n",
      "Episode reward: 71.155935\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.9     |\n",
      "|    ep_rew_mean      | 52.2     |\n",
      "|    exploration_rate | 0.135    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2068     |\n",
      "|    fps              | 3374     |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 91096    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00147  |\n",
      "|    n_updates        | 22748    |\n",
      "----------------------------------\n",
      "Episode reward: 55.910204\n",
      "Episode reward: 31.916297\n",
      "Episode reward: 101.751052\n",
      "Episode reward: 48.824109\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.5     |\n",
      "|    ep_rew_mean      | 52.7     |\n",
      "|    exploration_rate | 0.132    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2072     |\n",
      "|    fps              | 3373     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 91341    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00482  |\n",
      "|    n_updates        | 22810    |\n",
      "----------------------------------\n",
      "Episode reward: 41.790061\n",
      "Episode reward: 51.93103\n",
      "Episode reward: 41.43098\n",
      "Episode reward: 50.552313\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53       |\n",
      "|    ep_rew_mean      | 52.3     |\n",
      "|    exploration_rate | 0.13     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2076     |\n",
      "|    fps              | 3374     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 91529    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.189    |\n",
      "|    n_updates        | 22857    |\n",
      "----------------------------------\n",
      "Episode reward: 42.487456\n",
      "Episode reward: 44.863585\n",
      "Episode reward: 60.145028\n",
      "Episode reward: 99.881393\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.8     |\n",
      "|    ep_rew_mean      | 52.1     |\n",
      "|    exploration_rate | 0.128    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2080     |\n",
      "|    fps              | 3371     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 91779    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.114    |\n",
      "|    n_updates        | 22919    |\n",
      "----------------------------------\n",
      "Episode reward: 37.661846\n",
      "Episode reward: 93.872755\n",
      "Episode reward: 68.662348\n",
      "Episode reward: 63.507406\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53       |\n",
      "|    ep_rew_mean      | 52.3     |\n",
      "|    exploration_rate | 0.126    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2084     |\n",
      "|    fps              | 3373     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 92047    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.429    |\n",
      "|    n_updates        | 22986    |\n",
      "----------------------------------\n",
      "Episode reward: 44.525926\n",
      "Episode reward: 48.658796\n",
      "Episode reward: 45.79715\n",
      "Episode reward: 36.864498\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.8     |\n",
      "|    ep_rew_mean      | 52.1     |\n",
      "|    exploration_rate | 0.124    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2088     |\n",
      "|    fps              | 3373     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 92224    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 23030    |\n",
      "----------------------------------\n",
      "Episode reward: 70.396258\n",
      "Episode reward: 76.422561\n",
      "Episode reward: 61.350853\n",
      "Episode reward: 52.646891\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.6     |\n",
      "|    ep_rew_mean      | 52.9     |\n",
      "|    exploration_rate | 0.121    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2092     |\n",
      "|    fps              | 3373     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 92487    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00302  |\n",
      "|    n_updates        | 23096    |\n",
      "----------------------------------\n",
      "Episode reward: 53.791387\n",
      "Episode reward: 44.907877\n",
      "Episode reward: 59.277753\n",
      "Episode reward: 30.943731\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.4     |\n",
      "|    ep_rew_mean      | 52.7     |\n",
      "|    exploration_rate | 0.12     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2096     |\n",
      "|    fps              | 3372     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 92677    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00965  |\n",
      "|    n_updates        | 23144    |\n",
      "----------------------------------\n",
      "Episode reward: 39.940561\n",
      "Episode reward: 52.851713\n",
      "Episode reward: 49.753404\n",
      "Episode reward: 49.455687\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.2     |\n",
      "|    ep_rew_mean      | 52.5     |\n",
      "|    exploration_rate | 0.118    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2100     |\n",
      "|    fps              | 3372     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 92870    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00354  |\n",
      "|    n_updates        | 23192    |\n",
      "----------------------------------\n",
      "Episode reward: 83.851235\n",
      "Episode reward: 55.312241\n",
      "Episode reward: 78.634737\n",
      "Episode reward: 72.575963\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.8     |\n",
      "|    ep_rew_mean      | 53.2     |\n",
      "|    exploration_rate | 0.115    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2104     |\n",
      "|    fps              | 3372     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 93162    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00661  |\n",
      "|    n_updates        | 23265    |\n",
      "----------------------------------\n",
      "Episode reward: 30.760265\n",
      "Episode reward: 46.732254\n",
      "Episode reward: 41.895577\n",
      "Episode reward: 42.858534\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.6     |\n",
      "|    ep_rew_mean      | 53       |\n",
      "|    exploration_rate | 0.113    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2108     |\n",
      "|    fps              | 3370     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 93325    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.188    |\n",
      "|    n_updates        | 23306    |\n",
      "----------------------------------\n",
      "Episode reward: 56.865834\n",
      "Episode reward: 52.763133\n",
      "Episode reward: 27.887889\n",
      "Episode reward: 76.857298\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.2     |\n",
      "|    ep_rew_mean      | 52.6     |\n",
      "|    exploration_rate | 0.111    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2112     |\n",
      "|    fps              | 3366     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 93540    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.206    |\n",
      "|    n_updates        | 23359    |\n",
      "----------------------------------\n",
      "Episode reward: 44.911339\n",
      "Episode reward: 54.298274\n",
      "Episode reward: 71.29406\n",
      "Episode reward: 39.953319\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.2     |\n",
      "|    ep_rew_mean      | 52.6     |\n",
      "|    exploration_rate | 0.109    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2116     |\n",
      "|    fps              | 3367     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 93755    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.401    |\n",
      "|    n_updates        | 23413    |\n",
      "----------------------------------\n",
      "Episode reward: 39.896499\n",
      "Episode reward: 50.720968\n",
      "Episode reward: 45.900477\n",
      "Episode reward: 54.881457\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.1     |\n",
      "|    ep_rew_mean      | 52.5     |\n",
      "|    exploration_rate | 0.108    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2120     |\n",
      "|    fps              | 3367     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 93947    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 23461    |\n",
      "----------------------------------\n",
      "Episode reward: 52.868494\n",
      "Episode reward: 74.288007\n",
      "Episode reward: 37.746816\n",
      "Episode reward: 33.902266\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.5     |\n",
      "|    ep_rew_mean      | 52.9     |\n",
      "|    exploration_rate | 0.106    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2124     |\n",
      "|    fps              | 3365     |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 94148    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.187    |\n",
      "|    n_updates        | 23511    |\n",
      "----------------------------------\n",
      "Episode reward: 33.9039\n",
      "Episode reward: 61.745668\n",
      "Episode reward: 81.822014\n",
      "Episode reward: 51.940775\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.5     |\n",
      "|    ep_rew_mean      | 52.9     |\n",
      "|    exploration_rate | 0.103    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2128     |\n",
      "|    fps              | 3364     |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 94378    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.369    |\n",
      "|    n_updates        | 23569    |\n",
      "----------------------------------\n",
      "Episode reward: 94.23771\n",
      "Episode reward: 40.914013\n",
      "Episode reward: 52.833041\n",
      "Episode reward: 49.776394\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.2     |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.101    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2132     |\n",
      "|    fps              | 3366     |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 94624    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00493  |\n",
      "|    n_updates        | 23630    |\n",
      "----------------------------------\n",
      "Episode reward: 53.926029\n",
      "Episode reward: 38.905142\n",
      "Episode reward: 51.840424\n",
      "Episode reward: 82.80849\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.2     |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.0989   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2136     |\n",
      "|    fps              | 3364     |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 94854    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.193    |\n",
      "|    n_updates        | 23688    |\n",
      "----------------------------------\n",
      "Episode reward: 65.118818\n",
      "Episode reward: 57.915577\n",
      "Episode reward: 52.805326\n",
      "Episode reward: 32.926083\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.3     |\n",
      "|    ep_rew_mean      | 53.7     |\n",
      "|    exploration_rate | 0.0969   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2140     |\n",
      "|    fps              | 3364     |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 95064    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.179    |\n",
      "|    n_updates        | 23740    |\n",
      "----------------------------------\n",
      "Episode reward: 70.915241\n",
      "Episode reward: 36.931528\n",
      "Episode reward: 41.866335\n",
      "Episode reward: 37.86577\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.7     |\n",
      "|    ep_rew_mean      | 53.1     |\n",
      "|    exploration_rate | 0.0951   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2144     |\n",
      "|    fps              | 3365     |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 95252    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.202    |\n",
      "|    n_updates        | 23787    |\n",
      "----------------------------------\n",
      "Episode reward: 81.87578\n",
      "Episode reward: 47.865815\n",
      "Episode reward: 42.888402\n",
      "Episode reward: 47.523157\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.7     |\n",
      "|    ep_rew_mean      | 53.1     |\n",
      "|    exploration_rate | 0.093    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2148     |\n",
      "|    fps              | 3363     |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 95473    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00182  |\n",
      "|    n_updates        | 23843    |\n",
      "----------------------------------\n",
      "Episode reward: 50.437038\n",
      "Episode reward: 50.720569\n",
      "Episode reward: 60.881029\n",
      "Episode reward: 36.906909\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.6     |\n",
      "|    ep_rew_mean      | 53.1     |\n",
      "|    exploration_rate | 0.0911   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2152     |\n",
      "|    fps              | 3363     |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 95673    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00259  |\n",
      "|    n_updates        | 23893    |\n",
      "----------------------------------\n",
      "Episode reward: 67.873936\n",
      "Episode reward: 41.931679\n",
      "Episode reward: 45.873901\n",
      "Episode reward: 60.916346\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.2     |\n",
      "|    ep_rew_mean      | 53.6     |\n",
      "|    exploration_rate | 0.089    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2156     |\n",
      "|    fps              | 3361     |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 95892    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.182    |\n",
      "|    n_updates        | 23947    |\n",
      "----------------------------------\n",
      "Episode reward: 41.739242\n",
      "Episode reward: 38.886678\n",
      "Episode reward: 42.843992\n",
      "Episode reward: 37.885547\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.7     |\n",
      "|    ep_rew_mean      | 53.1     |\n",
      "|    exploration_rate | 0.0875   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2160     |\n",
      "|    fps              | 3360     |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 96054    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00981  |\n",
      "|    n_updates        | 23988    |\n",
      "----------------------------------\n",
      "Episode reward: 65.7847\n",
      "Episode reward: 73.199755\n",
      "Episode reward: 50.745313\n",
      "Episode reward: 44.558545\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.2     |\n",
      "|    ep_rew_mean      | 53.6     |\n",
      "|    exploration_rate | 0.0852   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2164     |\n",
      "|    fps              | 3359     |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 96290    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.252    |\n",
      "|    n_updates        | 24047    |\n",
      "----------------------------------\n",
      "Episode reward: 69.293136\n",
      "Episode reward: 44.679446\n",
      "Episode reward: 50.935815\n",
      "Episode reward: 33.894104\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.9     |\n",
      "|    ep_rew_mean      | 53.4     |\n",
      "|    exploration_rate | 0.0833   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2168     |\n",
      "|    fps              | 3358     |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 96490    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.345    |\n",
      "|    n_updates        | 24097    |\n",
      "----------------------------------\n",
      "Episode reward: 52.431736\n",
      "Episode reward: 69.33183\n",
      "Episode reward: 57.921728\n",
      "Episode reward: 62.926418\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.9     |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.081    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2172     |\n",
      "|    fps              | 3358     |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 96735    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00275  |\n",
      "|    n_updates        | 24158    |\n",
      "----------------------------------\n",
      "Episode reward: 35.924195\n",
      "Episode reward: 55.790678\n",
      "Episode reward: 36.930301\n",
      "Episode reward: 53.911687\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.9     |\n",
      "|    ep_rew_mean      | 53.4     |\n",
      "|    exploration_rate | 0.0793   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2176     |\n",
      "|    fps              | 3356     |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 96918    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 24204    |\n",
      "----------------------------------\n",
      "Episode reward: 33.953936\n",
      "Episode reward: 42.927312\n",
      "Episode reward: 48.86767\n",
      "Episode reward: 67.154897\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.3     |\n",
      "|    ep_rew_mean      | 52.9     |\n",
      "|    exploration_rate | 0.0774   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2180     |\n",
      "|    fps              | 3356     |\n",
      "|    time_elapsed     | 28       |\n",
      "|    total_timesteps  | 97113    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.19     |\n",
      "|    n_updates        | 24253    |\n",
      "----------------------------------\n",
      "Episode reward: 42.792979\n",
      "Episode reward: 36.921061\n",
      "Episode reward: 66.695611\n",
      "Episode reward: 91.56319\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53       |\n",
      "|    ep_rew_mean      | 52.6     |\n",
      "|    exploration_rate | 0.0752   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2184     |\n",
      "|    fps              | 3355     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 97352    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00235  |\n",
      "|    n_updates        | 24312    |\n",
      "----------------------------------\n",
      "Episode reward: 43.424429\n",
      "Episode reward: 75.352865\n",
      "Episode reward: 40.838207\n",
      "Episode reward: 43.780921\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.3     |\n",
      "|    ep_rew_mean      | 52.9     |\n",
      "|    exploration_rate | 0.0732   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2188     |\n",
      "|    fps              | 3353     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 97558    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.399    |\n",
      "|    n_updates        | 24364    |\n",
      "----------------------------------\n",
      "Episode reward: 34.917788\n",
      "Episode reward: 56.895136\n",
      "Episode reward: 63.462828\n",
      "Episode reward: 37.93272\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.7     |\n",
      "|    ep_rew_mean      | 52.2     |\n",
      "|    exploration_rate | 0.0713   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2192     |\n",
      "|    fps              | 3353     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 97753    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.488    |\n",
      "|    n_updates        | 24413    |\n",
      "----------------------------------\n",
      "Episode reward: 46.786105\n",
      "Episode reward: 60.58832\n",
      "Episode reward: 32.919726\n",
      "Episode reward: 51.892794\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.7     |\n",
      "|    ep_rew_mean      | 52.3     |\n",
      "|    exploration_rate | 0.0695   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2196     |\n",
      "|    fps              | 3352     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 97946    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0587   |\n",
      "|    n_updates        | 24461    |\n",
      "----------------------------------\n",
      "Episode reward: 61.885801\n",
      "Episode reward: 76.438031\n",
      "Episode reward: 41.943703\n",
      "Episode reward: 60.329412\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.2     |\n",
      "|    ep_rew_mean      | 52.7     |\n",
      "|    exploration_rate | 0.0672   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2200     |\n",
      "|    fps              | 3350     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 98193    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.191    |\n",
      "|    n_updates        | 24523    |\n",
      "----------------------------------\n",
      "Episode reward: 71.840326\n",
      "Episode reward: 44.917139\n",
      "Episode reward: 67.327766\n",
      "Episode reward: 100.663441\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.2     |\n",
      "|    ep_rew_mean      | 52.7     |\n",
      "|    exploration_rate | 0.0644   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2204     |\n",
      "|    fps              | 3351     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 98480    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.203    |\n",
      "|    n_updates        | 24594    |\n",
      "----------------------------------\n",
      "Episode reward: 124.275467\n",
      "Episode reward: 62.755492\n",
      "Episode reward: 44.861106\n",
      "Episode reward: 35.935501\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.3     |\n",
      "|    ep_rew_mean      | 53.7     |\n",
      "|    exploration_rate | 0.0619   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2208     |\n",
      "|    fps              | 3350     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 98751    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 24662    |\n",
      "----------------------------------\n",
      "Episode reward: 45.773544\n",
      "Episode reward: 48.725254\n",
      "Episode reward: 61.863476\n",
      "Episode reward: 43.740638\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.1     |\n",
      "|    ep_rew_mean      | 53.6     |\n",
      "|    exploration_rate | 0.0599   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2212     |\n",
      "|    fps              | 3350     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 98953    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0012   |\n",
      "|    n_updates        | 24713    |\n",
      "----------------------------------\n",
      "Episode reward: 57.579495\n",
      "Episode reward: 35.935522\n",
      "Episode reward: 57.977322\n",
      "Episode reward: 47.879738\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54       |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.058    |\n",
      "| time/               |          |\n",
      "|    episodes         | 2216     |\n",
      "|    fps              | 3348     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 99155    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00245  |\n",
      "|    n_updates        | 24763    |\n",
      "----------------------------------\n",
      "Episode reward: 53.917012\n",
      "Episode reward: 43.588296\n",
      "Episode reward: 48.869948\n",
      "Episode reward: 44.977732\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54       |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.0562   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2220     |\n",
      "|    fps              | 3347     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 99348    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.184    |\n",
      "|    n_updates        | 24811    |\n",
      "----------------------------------\n",
      "Episode reward: 40.874718\n",
      "Episode reward: 38.955203\n",
      "Episode reward: 54.834458\n",
      "Episode reward: 66.701909\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54       |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.0543   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2224     |\n",
      "|    fps              | 3346     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 99550    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.19     |\n",
      "|    n_updates        | 24862    |\n",
      "----------------------------------\n",
      "Episode reward: 67.804813\n",
      "Episode reward: 74.883254\n",
      "Episode reward: 79.660318\n",
      "Episode reward: 48.443827\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 53.9     |\n",
      "|    exploration_rate | 0.0517   |\n",
      "| time/               |          |\n",
      "|    episodes         | 2228     |\n",
      "|    fps              | 3345     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 99824    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.374    |\n",
      "|    n_updates        | 24930    |\n",
      "----------------------------------\n",
      "Episode reward: 63.411127\n",
      "Episode reward: 52.49216\n",
      "Episode reward: 40.935517\n",
      "Episode reward: 39.90932\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54       |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2232     |\n",
      "|    fps              | 3345     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 100024   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.192    |\n",
      "|    n_updates        | 24980    |\n",
      "----------------------------------\n",
      "Episode reward: 37.950724\n",
      "Episode reward: 50.606633\n",
      "Episode reward: 55.90659\n",
      "Episode reward: 50.537763\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.7     |\n",
      "|    ep_rew_mean      | 53.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2236     |\n",
      "|    fps              | 3345     |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 100221   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.104    |\n",
      "|    n_updates        | 25030    |\n",
      "----------------------------------\n",
      "Episode reward: 59.67992\n",
      "Episode reward: 52.368721\n",
      "Episode reward: 51.926575\n",
      "Episode reward: 50.874608\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.8     |\n",
      "|    ep_rew_mean      | 53.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2240     |\n",
      "|    fps              | 3346     |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 100439   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.2      |\n",
      "|    n_updates        | 25084    |\n",
      "----------------------------------\n",
      "Episode reward: 58.823871\n",
      "Episode reward: 53.929472\n",
      "Episode reward: 64.900587\n",
      "Episode reward: 37.911319\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54       |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2244     |\n",
      "|    fps              | 3344     |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 100657   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.191    |\n",
      "|    n_updates        | 25139    |\n",
      "----------------------------------\n",
      "Episode reward: 56.567993\n",
      "Episode reward: 81.972919\n",
      "Episode reward: 68.561806\n",
      "Episode reward: 71.17808\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.7     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2248     |\n",
      "|    fps              | 3344     |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 100942   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000926 |\n",
      "|    n_updates        | 25210    |\n",
      "----------------------------------\n",
      "Episode reward: 60.037118\n",
      "Episode reward: 54.596353\n",
      "Episode reward: 37.888023\n",
      "Episode reward: 62.502178\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2252     |\n",
      "|    fps              | 3342     |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 101159   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00536  |\n",
      "|    n_updates        | 25264    |\n",
      "----------------------------------\n",
      "Episode reward: 43.822018\n",
      "Episode reward: 50.006998\n",
      "Episode reward: 45.910818\n",
      "Episode reward: 57.465894\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.7     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2256     |\n",
      "|    fps              | 3341     |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 101358   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.321    |\n",
      "|    n_updates        | 25314    |\n",
      "----------------------------------\n",
      "Episode reward: 62.483445\n",
      "Episode reward: 55.335834\n",
      "Episode reward: 46.871858\n",
      "Episode reward: 8.062288\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2260     |\n",
      "|    fps              | 3338     |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 101683   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 25395    |\n",
      "----------------------------------\n",
      "Episode reward: 74.880134\n",
      "Episode reward: 41.798071\n",
      "Episode reward: 55.493387\n",
      "Episode reward: 54.8488\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2264     |\n",
      "|    fps              | 3336     |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 101911   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000688 |\n",
      "|    n_updates        | 25452    |\n",
      "----------------------------------\n",
      "Episode reward: 36.856666\n",
      "Episode reward: 58.700923\n",
      "Episode reward: 63.001632\n",
      "Episode reward: 35.939471\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2268     |\n",
      "|    fps              | 3336     |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 102108   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.542    |\n",
      "|    n_updates        | 25501    |\n",
      "----------------------------------\n",
      "Episode reward: 47.723859\n",
      "Episode reward: 47.763197\n",
      "Episode reward: 38.791257\n",
      "Episode reward: 35.856065\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 53.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2272     |\n",
      "|    fps              | 3334     |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 102279   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00344  |\n",
      "|    n_updates        | 25544    |\n",
      "----------------------------------\n",
      "Episode reward: 67.536351\n",
      "Episode reward: 56.833932\n",
      "Episode reward: 45.892941\n",
      "Episode reward: 39.7686\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 53.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2276     |\n",
      "|    fps              | 3334     |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 102490   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.209    |\n",
      "|    n_updates        | 25597    |\n",
      "----------------------------------\n",
      "Episode reward: 37.770113\n",
      "Episode reward: 39.904745\n",
      "Episode reward: 58.463284\n",
      "Episode reward: 62.8722\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 53.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2280     |\n",
      "|    fps              | 3332     |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 102691   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.215    |\n",
      "|    n_updates        | 25647    |\n",
      "----------------------------------\n",
      "Episode reward: 52.850838\n",
      "Episode reward: 40.880977\n",
      "Episode reward: 74.88376\n",
      "Episode reward: 45.803242\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.5     |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2284     |\n",
      "|    fps              | 3332     |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 102906   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.43     |\n",
      "|    n_updates        | 25701    |\n",
      "----------------------------------\n",
      "Episode reward: 67.267406\n",
      "Episode reward: 51.819112\n",
      "Episode reward: 58.444022\n",
      "Episode reward: 51.65249\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 53.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2288     |\n",
      "|    fps              | 3332     |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 103139   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.588    |\n",
      "|    n_updates        | 25759    |\n",
      "----------------------------------\n",
      "Episode reward: 48.906326\n",
      "Episode reward: 35.915488\n",
      "Episode reward: 40.259226\n",
      "Episode reward: 46.833846\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2292     |\n",
      "|    fps              | 3330     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 103312   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 25802    |\n",
      "----------------------------------\n",
      "Episode reward: 61.406842\n",
      "Episode reward: 39.922438\n",
      "Episode reward: 53.843842\n",
      "Episode reward: 67.425834\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 53.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2296     |\n",
      "|    fps              | 3329     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 103538   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.556    |\n",
      "|    n_updates        | 25859    |\n",
      "----------------------------------\n",
      "Episode reward: 58.906512\n",
      "Episode reward: 70.41952\n",
      "Episode reward: 68.905595\n",
      "Episode reward: 73.428371\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2300     |\n",
      "|    fps              | 3327     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 103813   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00471  |\n",
      "|    n_updates        | 25928    |\n",
      "----------------------------------\n",
      "Episode reward: 34.879765\n",
      "Episode reward: 77.797672\n",
      "Episode reward: 38.897039\n",
      "Episode reward: 50.968125\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 53.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2304     |\n",
      "|    fps              | 3326     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 104018   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.168    |\n",
      "|    n_updates        | 25979    |\n",
      "----------------------------------\n",
      "Episode reward: 53.915997\n",
      "Episode reward: 65.854804\n",
      "Episode reward: 88.606493\n",
      "Episode reward: 48.569983\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 53.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2308     |\n",
      "|    fps              | 3328     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 104276   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00356  |\n",
      "|    n_updates        | 26043    |\n",
      "----------------------------------\n",
      "Episode reward: 50.879296\n",
      "Episode reward: 41.87495\n",
      "Episode reward: 67.500767\n",
      "Episode reward: 49.497103\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 53.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2312     |\n",
      "|    fps              | 3326     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 104487   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00697  |\n",
      "|    n_updates        | 26096    |\n",
      "----------------------------------\n",
      "Episode reward: 55.609256\n",
      "Episode reward: 37.951954\n",
      "Episode reward: 49.929643\n",
      "Episode reward: 46.936546\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 53.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2316     |\n",
      "|    fps              | 3325     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 104678   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0468   |\n",
      "|    n_updates        | 26144    |\n",
      "----------------------------------\n",
      "Episode reward: 36.66015\n",
      "Episode reward: 56.714048\n",
      "Episode reward: 59.658881\n",
      "Episode reward: 36.924105\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 53.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2320     |\n",
      "|    fps              | 3323     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 104870   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0023   |\n",
      "|    n_updates        | 26192    |\n",
      "----------------------------------\n",
      "Episode reward: 73.791447\n",
      "Episode reward: 43.893826\n",
      "Episode reward: 33.927797\n",
      "Episode reward: 64.276373\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 53.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2324     |\n",
      "|    fps              | 3323     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 105087   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000626 |\n",
      "|    n_updates        | 26246    |\n",
      "----------------------------------\n",
      "Episode reward: 58.643054\n",
      "Episode reward: 49.820962\n",
      "Episode reward: 72.863114\n",
      "Episode reward: 87.705081\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 53.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2328     |\n",
      "|    fps              | 3324     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 105362   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00157  |\n",
      "|    n_updates        | 26315    |\n",
      "----------------------------------\n",
      "Episode reward: 34.833516\n",
      "Episode reward: 43.92814\n",
      "Episode reward: 31.764814\n",
      "Episode reward: 38.899212\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 52.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2332     |\n",
      "|    fps              | 3322     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 105512   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0841   |\n",
      "|    n_updates        | 26352    |\n",
      "----------------------------------\n",
      "Episode reward: 58.781578\n",
      "Episode reward: 76.937623\n",
      "Episode reward: 68.277096\n",
      "Episode reward: 51.92065\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.5     |\n",
      "|    ep_rew_mean      | 53.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2336     |\n",
      "|    fps              | 3323     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 105773   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000841 |\n",
      "|    n_updates        | 26418    |\n",
      "----------------------------------\n",
      "Episode reward: 34.845266\n",
      "Episode reward: 35.674901\n",
      "Episode reward: 46.869237\n",
      "Episode reward: 31.705949\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.8     |\n",
      "|    ep_rew_mean      | 52.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2340     |\n",
      "|    fps              | 3323     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 105923   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000759 |\n",
      "|    n_updates        | 26455    |\n",
      "----------------------------------\n",
      "Episode reward: 64.266673\n",
      "Episode reward: 83.551894\n",
      "Episode reward: 50.898284\n",
      "Episode reward: 41.881429\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 53       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2344     |\n",
      "|    fps              | 3321     |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 106166   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.406    |\n",
      "|    n_updates        | 26516    |\n",
      "----------------------------------\n",
      "Episode reward: 67.877462\n",
      "Episode reward: 35.807772\n",
      "Episode reward: 68.333394\n",
      "Episode reward: 49.469327\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 52.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2348     |\n",
      "|    fps              | 3321     |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 106390   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00366  |\n",
      "|    n_updates        | 26572    |\n",
      "----------------------------------\n",
      "Episode reward: 121.00198\n",
      "Episode reward: 81.885554\n",
      "Episode reward: 99.079138\n",
      "Episode reward: 51.922027\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 53.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2352     |\n",
      "|    fps              | 3322     |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 106746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.212    |\n",
      "|    n_updates        | 26661    |\n",
      "----------------------------------\n",
      "Episode reward: 85.979296\n",
      "Episode reward: 68.747602\n",
      "Episode reward: 53.929222\n",
      "Episode reward: 78.745893\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2356     |\n",
      "|    fps              | 3323     |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 107036   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.429    |\n",
      "|    n_updates        | 26733    |\n",
      "----------------------------------\n",
      "Episode reward: 51.787644\n",
      "Episode reward: 65.529888\n",
      "Episode reward: 43.78987\n",
      "Episode reward: 44.755698\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2360     |\n",
      "|    fps              | 3321     |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 107243   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00936  |\n",
      "|    n_updates        | 26785    |\n",
      "----------------------------------\n",
      "Episode reward: 38.601678\n",
      "Episode reward: 43.831404\n",
      "Episode reward: 33.775733\n",
      "Episode reward: 51.725638\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55       |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2364     |\n",
      "|    fps              | 3321     |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 107412   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.185    |\n",
      "|    n_updates        | 26827    |\n",
      "----------------------------------\n",
      "Episode reward: 101.793973\n",
      "Episode reward: 39.817152\n",
      "Episode reward: 37.813395\n",
      "Episode reward: 41.951632\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2368     |\n",
      "|    fps              | 3318     |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 107634   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.206    |\n",
      "|    n_updates        | 26883    |\n",
      "----------------------------------\n",
      "Episode reward: 41.802423\n",
      "Episode reward: 36.882322\n",
      "Episode reward: 57.857614\n",
      "Episode reward: 70.50925\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2372     |\n",
      "|    fps              | 3317     |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 107848   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00849  |\n",
      "|    n_updates        | 26936    |\n",
      "----------------------------------\n",
      "Episode reward: 57.916721\n",
      "Episode reward: 89.531112\n",
      "Episode reward: 34.833752\n",
      "Episode reward: 70.335085\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2376     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 108109   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.228    |\n",
      "|    n_updates        | 27002    |\n",
      "----------------------------------\n",
      "Episode reward: 45.774887\n",
      "Episode reward: 36.939144\n",
      "Episode reward: 35.912734\n",
      "Episode reward: 49.945416\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2380     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 108278   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.178    |\n",
      "|    n_updates        | 27044    |\n",
      "----------------------------------\n",
      "Episode reward: 60.726032\n",
      "Episode reward: 55.916058\n",
      "Episode reward: 48.044775\n",
      "Episode reward: 61.024255\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2384     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 108507   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.21     |\n",
      "|    n_updates        | 27101    |\n",
      "----------------------------------\n",
      "Episode reward: 31.934118\n",
      "Episode reward: 52.914639\n",
      "Episode reward: 68.630889\n",
      "Episode reward: 63.754143\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2388     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 108725   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00728  |\n",
      "|    n_updates        | 27156    |\n",
      "----------------------------------\n",
      "Episode reward: 64.139271\n",
      "Episode reward: 38.907357\n",
      "Episode reward: 84.564679\n",
      "Episode reward: 53.907244\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2392     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 108972   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000667 |\n",
      "|    n_updates        | 27217    |\n",
      "----------------------------------\n",
      "Episode reward: 45.883092\n",
      "Episode reward: 34.924896\n",
      "Episode reward: 35.62819\n",
      "Episode reward: 57.953312\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2396     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 109149   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.208    |\n",
      "|    n_updates        | 27262    |\n",
      "----------------------------------\n",
      "Episode reward: 52.260353\n",
      "Episode reward: 44.625661\n",
      "Episode reward: 49.793584\n",
      "Episode reward: 52.447552\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2400     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 109350   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00293  |\n",
      "|    n_updates        | 27312    |\n",
      "----------------------------------\n",
      "Episode reward: 95.523239\n",
      "Episode reward: 56.582358\n",
      "Episode reward: 58.675551\n",
      "Episode reward: 50.14107\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2404     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 109613   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.458    |\n",
      "|    n_updates        | 27378    |\n",
      "----------------------------------\n",
      "Episode reward: 57.660407\n",
      "Episode reward: 54.903701\n",
      "Episode reward: 45.948808\n",
      "Episode reward: 38.941642\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2408     |\n",
      "|    fps              | 3307     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 109811   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.389    |\n",
      "|    n_updates        | 27427    |\n",
      "----------------------------------\n",
      "Episode reward: 45.871293\n",
      "Episode reward: 103.568661\n",
      "Episode reward: 38.947554\n",
      "Episode reward: 46.579395\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2412     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 110052   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.282    |\n",
      "|    n_updates        | 27487    |\n",
      "----------------------------------\n",
      "Episode reward: 52.124403\n",
      "Episode reward: 61.636983\n",
      "Episode reward: 73.121414\n",
      "Episode reward: 76.025666\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2416     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 110322   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00257  |\n",
      "|    n_updates        | 27555    |\n",
      "----------------------------------\n",
      "Episode reward: 96.383114\n",
      "Episode reward: 47.86533\n",
      "Episode reward: 72.552693\n",
      "Episode reward: 57.886223\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2420     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 110600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00197  |\n",
      "|    n_updates        | 27624    |\n",
      "----------------------------------\n",
      "Episode reward: 55.41974\n",
      "Episode reward: 45.546563\n",
      "Episode reward: 53.926436\n",
      "Episode reward: 96.809189\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2424     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 110854   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00288  |\n",
      "|    n_updates        | 27688    |\n",
      "----------------------------------\n",
      "Episode reward: 45.746239\n",
      "Episode reward: 42.723012\n",
      "Episode reward: 54.934348\n",
      "Episode reward: 61.104945\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2428     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 111060   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00301  |\n",
      "|    n_updates        | 27739    |\n",
      "----------------------------------\n",
      "Episode reward: 67.430067\n",
      "Episode reward: 59.683786\n",
      "Episode reward: 41.806901\n",
      "Episode reward: 49.573465\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2432     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 111280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00275  |\n",
      "|    n_updates        | 27794    |\n",
      "----------------------------------\n",
      "Episode reward: 87.70793\n",
      "Episode reward: 54.919331\n",
      "Episode reward: 60.855759\n",
      "Episode reward: 48.92678\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2436     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 111539   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00209  |\n",
      "|    n_updates        | 27859    |\n",
      "----------------------------------\n",
      "Episode reward: 41.778944\n",
      "Episode reward: 55.993201\n",
      "Episode reward: 62.897562\n",
      "Episode reward: 43.715312\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2440     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 111745   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.192    |\n",
      "|    n_updates        | 27911    |\n",
      "----------------------------------\n",
      "Episode reward: 39.885533\n",
      "Episode reward: 34.92657\n",
      "Episode reward: 75.590686\n",
      "Episode reward: 84.018639\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2444     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 111985   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.215    |\n",
      "|    n_updates        | 27971    |\n",
      "----------------------------------\n",
      "Episode reward: 77.887222\n",
      "Episode reward: 57.644143\n",
      "Episode reward: 55.846743\n",
      "Episode reward: 78.758147\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2448     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 112257   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.205    |\n",
      "|    n_updates        | 28039    |\n",
      "----------------------------------\n",
      "Episode reward: 39.754003\n",
      "Episode reward: 79.844096\n",
      "Episode reward: 44.926182\n",
      "Episode reward: 45.613173\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2452     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 112468   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.137    |\n",
      "|    n_updates        | 28091    |\n",
      "----------------------------------\n",
      "Episode reward: 80.92995\n",
      "Episode reward: 51.388673\n",
      "Episode reward: 53.912301\n",
      "Episode reward: 87.515018\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2456     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 112745   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.19     |\n",
      "|    n_updates        | 28161    |\n",
      "----------------------------------\n",
      "Episode reward: 37.835637\n",
      "Episode reward: 35.959085\n",
      "Episode reward: 51.533248\n",
      "Episode reward: 48.375652\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2460     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 112920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.388    |\n",
      "|    n_updates        | 28204    |\n",
      "----------------------------------\n",
      "Episode reward: 53.585081\n",
      "Episode reward: 38.937157\n",
      "Episode reward: 44.807033\n",
      "Episode reward: 97.526976\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2464     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 113156   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.121    |\n",
      "|    n_updates        | 28263    |\n",
      "----------------------------------\n",
      "Episode reward: 75.832211\n",
      "Episode reward: 36.938616\n",
      "Episode reward: 32.960766\n",
      "Episode reward: 52.900424\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2468     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 113356   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00323  |\n",
      "|    n_updates        | 28313    |\n",
      "----------------------------------\n",
      "Episode reward: 68.49101\n",
      "Episode reward: 36.912029\n",
      "Episode reward: 46.631556\n",
      "Episode reward: 47.859625\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2472     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 113557   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.251    |\n",
      "|    n_updates        | 28364    |\n",
      "----------------------------------\n",
      "Episode reward: 49.94364\n",
      "Episode reward: 39.939867\n",
      "Episode reward: 43.933192\n",
      "Episode reward: 55.799326\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2476     |\n",
      "|    fps              | 3296     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 113747   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.174    |\n",
      "|    n_updates        | 28411    |\n",
      "----------------------------------\n",
      "Episode reward: 44.69739\n",
      "Episode reward: 44.823771\n",
      "Episode reward: 38.883367\n",
      "Episode reward: 37.912621\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2480     |\n",
      "|    fps              | 3296     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 113914   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0405   |\n",
      "|    n_updates        | 28453    |\n",
      "----------------------------------\n",
      "Episode reward: 67.499275\n",
      "Episode reward: 48.885896\n",
      "Episode reward: 43.367898\n",
      "Episode reward: 70.574518\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2484     |\n",
      "|    fps              | 3297     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 114147   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.25     |\n",
      "|    n_updates        | 28511    |\n",
      "----------------------------------\n",
      "Episode reward: 53.787794\n",
      "Episode reward: 31.900101\n",
      "Episode reward: 47.564242\n",
      "Episode reward: 89.185745\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2488     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 114371   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.245    |\n",
      "|    n_updates        | 28567    |\n",
      "----------------------------------\n",
      "Episode reward: 44.882677\n",
      "Episode reward: 47.893755\n",
      "Episode reward: 32.89364\n",
      "Episode reward: 69.232193\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2492     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 114567   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.157    |\n",
      "|    n_updates        | 28616    |\n",
      "----------------------------------\n",
      "Episode reward: 54.395222\n",
      "Episode reward: 44.910016\n",
      "Episode reward: 49.654935\n",
      "Episode reward: 57.83484\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2496     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 114775   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00212  |\n",
      "|    n_updates        | 28668    |\n",
      "----------------------------------\n",
      "Episode reward: 44.951795\n",
      "Episode reward: 57.864408\n",
      "Episode reward: 57.834535\n",
      "Episode reward: 37.854749\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2500     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 114974   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00595  |\n",
      "|    n_updates        | 28718    |\n",
      "----------------------------------\n",
      "Episode reward: 45.840243\n",
      "Episode reward: 70.892856\n",
      "Episode reward: 54.903588\n",
      "Episode reward: 57.901301\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2504     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 115204   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0016   |\n",
      "|    n_updates        | 28775    |\n",
      "----------------------------------\n",
      "Episode reward: 47.948841\n",
      "Episode reward: 90.557619\n",
      "Episode reward: 51.495349\n",
      "Episode reward: 75.440488\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2508     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 115477   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.142    |\n",
      "|    n_updates        | 28844    |\n",
      "----------------------------------\n",
      "Episode reward: 40.906642\n",
      "Episode reward: 79.839255\n",
      "Episode reward: 43.929943\n",
      "Episode reward: 96.913213\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2512     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 115749   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00603  |\n",
      "|    n_updates        | 28912    |\n",
      "----------------------------------\n",
      "Episode reward: 49.354765\n",
      "Episode reward: 37.948121\n",
      "Episode reward: 34.875088\n",
      "Episode reward: 63.781044\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2516     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 115936   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.25     |\n",
      "|    n_updates        | 28958    |\n",
      "----------------------------------\n",
      "Episode reward: 123.178932\n",
      "Episode reward: 56.703948\n",
      "Episode reward: 70.301241\n",
      "Episode reward: 40.925094\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2520     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 116232   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00358  |\n",
      "|    n_updates        | 29032    |\n",
      "----------------------------------\n",
      "Episode reward: 58.917107\n",
      "Episode reward: 51.865071\n",
      "Episode reward: 73.094412\n",
      "Episode reward: 43.753587\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2524     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 116461   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00355  |\n",
      "|    n_updates        | 29090    |\n",
      "----------------------------------\n",
      "Episode reward: 72.951114\n",
      "Episode reward: 36.43287\n",
      "Episode reward: 69.814941\n",
      "Episode reward: 52.619262\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2528     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 116695   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.427    |\n",
      "|    n_updates        | 29148    |\n",
      "----------------------------------\n",
      "Episode reward: 49.935175\n",
      "Episode reward: 65.839753\n",
      "Episode reward: 50.942032\n",
      "Episode reward: 59.908264\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2532     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 116922   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0037   |\n",
      "|    n_updates        | 29205    |\n",
      "----------------------------------\n",
      "Episode reward: 63.578164\n",
      "Episode reward: 38.912376\n",
      "Episode reward: 44.819499\n",
      "Episode reward: 45.682497\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2536     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 117116   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.374    |\n",
      "|    n_updates        | 29253    |\n",
      "----------------------------------\n",
      "Episode reward: 42.758857\n",
      "Episode reward: 57.872109\n",
      "Episode reward: 42.520371\n",
      "Episode reward: 90.874514\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2540     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 117355   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00152  |\n",
      "|    n_updates        | 29313    |\n",
      "----------------------------------\n",
      "Episode reward: 76.665274\n",
      "Episode reward: 144.824241\n",
      "Episode reward: 34.828295\n",
      "Episode reward: 63.675775\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2544     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 117680   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00457  |\n",
      "|    n_updates        | 29394    |\n",
      "----------------------------------\n",
      "Episode reward: 52.693077\n",
      "Episode reward: 42.88402\n",
      "Episode reward: 99.449056\n",
      "Episode reward: 57.922784\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2548     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 117942   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.187    |\n",
      "|    n_updates        | 29460    |\n",
      "----------------------------------\n",
      "Episode reward: 33.811042\n",
      "Episode reward: 42.377076\n",
      "Episode reward: 54.766537\n",
      "Episode reward: 59.838743\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2552     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 118134   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.236    |\n",
      "|    n_updates        | 29508    |\n",
      "----------------------------------\n",
      "Episode reward: 39.925577\n",
      "Episode reward: 40.908108\n",
      "Episode reward: 56.46721\n",
      "Episode reward: 49.865696\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2556     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 118322   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.23     |\n",
      "|    n_updates        | 29555    |\n",
      "----------------------------------\n",
      "Episode reward: 138.107973\n",
      "Episode reward: 67.864065\n",
      "Episode reward: 42.515671\n",
      "Episode reward: 74.564737\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2560     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 118657   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00653  |\n",
      "|    n_updates        | 29639    |\n",
      "----------------------------------\n",
      "Episode reward: 70.879466\n",
      "Episode reward: 56.839534\n",
      "Episode reward: 32.771935\n",
      "Episode reward: 63.810761\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2564     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 118886   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0277   |\n",
      "|    n_updates        | 29696    |\n",
      "----------------------------------\n",
      "Episode reward: 67.447042\n",
      "Episode reward: 38.730523\n",
      "Episode reward: 57.862217\n",
      "Episode reward: 41.73977\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2568     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 119093   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0664   |\n",
      "|    n_updates        | 29748    |\n",
      "----------------------------------\n",
      "Episode reward: 35.934685\n",
      "Episode reward: 105.669928\n",
      "Episode reward: 48.898556\n",
      "Episode reward: 57.696519\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2572     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 119342   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.216    |\n",
      "|    n_updates        | 29810    |\n",
      "----------------------------------\n",
      "Episode reward: 45.936744\n",
      "Episode reward: 39.842587\n",
      "Episode reward: 89.780966\n",
      "Episode reward: 69.318643\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2576     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 119589   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.333    |\n",
      "|    n_updates        | 29872    |\n",
      "----------------------------------\n",
      "Episode reward: 59.503805\n",
      "Episode reward: 49.833735\n",
      "Episode reward: 54.963696\n",
      "Episode reward: 45.772017\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2580     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 119803   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.392    |\n",
      "|    n_updates        | 29925    |\n",
      "----------------------------------\n",
      "Episode reward: 51.576033\n",
      "Episode reward: 38.955981\n",
      "Episode reward: 38.868863\n",
      "Episode reward: 36.926249\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2584     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 119970   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00399  |\n",
      "|    n_updates        | 29967    |\n",
      "----------------------------------\n",
      "Episode reward: 109.494167\n",
      "Episode reward: 49.731734\n",
      "Episode reward: 48.451426\n",
      "Episode reward: 57.202192\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2588     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 120238   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00405  |\n",
      "|    n_updates        | 30034    |\n",
      "----------------------------------\n",
      "Episode reward: 85.618267\n",
      "Episode reward: 34.940735\n",
      "Episode reward: 54.56052\n",
      "Episode reward: 88.657805\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2592     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 120507   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00433  |\n",
      "|    n_updates        | 30101    |\n",
      "----------------------------------\n",
      "Episode reward: 69.133727\n",
      "Episode reward: 58.664748\n",
      "Episode reward: 54.875665\n",
      "Episode reward: 42.868062\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2596     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 120735   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 30158    |\n",
      "----------------------------------\n",
      "Episode reward: 50.977245\n",
      "Episode reward: 42.246093\n",
      "Episode reward: 75.888305\n",
      "Episode reward: 48.610181\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2600     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 120956   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.332    |\n",
      "|    n_updates        | 30213    |\n",
      "----------------------------------\n",
      "Episode reward: 59.288672\n",
      "Episode reward: 66.084673\n",
      "Episode reward: 51.687381\n",
      "Episode reward: 49.918924\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2604     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 121186   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.282    |\n",
      "|    n_updates        | 30271    |\n",
      "----------------------------------\n",
      "Episode reward: 69.544302\n",
      "Episode reward: 61.805211\n",
      "Episode reward: 77.638471\n",
      "Episode reward: 76.017724\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2608     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 121476   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.185    |\n",
      "|    n_updates        | 30343    |\n",
      "----------------------------------\n",
      "Episode reward: 47.862534\n",
      "Episode reward: 68.882457\n",
      "Episode reward: 53.717529\n",
      "Episode reward: 125.866461\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2612     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 121776   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.276    |\n",
      "|    n_updates        | 30418    |\n",
      "----------------------------------\n",
      "Episode reward: 41.931463\n",
      "Episode reward: 71.917658\n",
      "Episode reward: 53.706066\n",
      "Episode reward: 54.84016\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2616     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 121999   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00262  |\n",
      "|    n_updates        | 30474    |\n",
      "----------------------------------\n",
      "Episode reward: 66.004946\n",
      "Episode reward: 50.933101\n",
      "Episode reward: 31.938132\n",
      "Episode reward: 39.92504\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2620     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 36       |\n",
      "|    total_timesteps  | 122189   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00286  |\n",
      "|    n_updates        | 30522    |\n",
      "----------------------------------\n",
      "Episode reward: 128.36035\n",
      "Episode reward: 44.820674\n",
      "Episode reward: 56.099907\n",
      "Episode reward: 36.895973\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2624     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 122463   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.275    |\n",
      "|    n_updates        | 30590    |\n",
      "----------------------------------\n",
      "Episode reward: 30.932824\n",
      "Episode reward: 36.721164\n",
      "Episode reward: 71.031744\n",
      "Episode reward: 34.914276\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2628     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 122640   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00195  |\n",
      "|    n_updates        | 30634    |\n",
      "----------------------------------\n",
      "Episode reward: 71.838152\n",
      "Episode reward: 37.933266\n",
      "Episode reward: 44.85226\n",
      "Episode reward: 37.822694\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2632     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 122833   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.231    |\n",
      "|    n_updates        | 30683    |\n",
      "----------------------------------\n",
      "Episode reward: 66.154483\n",
      "Episode reward: 36.700502\n",
      "Episode reward: 58.388166\n",
      "Episode reward: 55.35851\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2636     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 123054   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.19     |\n",
      "|    n_updates        | 30738    |\n",
      "----------------------------------\n",
      "Episode reward: 59.437332\n",
      "Episode reward: 100.865439\n",
      "Episode reward: 66.794531\n",
      "Episode reward: 45.581658\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2640     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 123329   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.404    |\n",
      "|    n_updates        | 30807    |\n",
      "----------------------------------\n",
      "Episode reward: 32.879779\n",
      "Episode reward: 50.920266\n",
      "Episode reward: 37.953457\n",
      "Episode reward: 42.768118\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2644     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 123494   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00396  |\n",
      "|    n_updates        | 30848    |\n",
      "----------------------------------\n",
      "Episode reward: 105.161548\n",
      "Episode reward: 53.490659\n",
      "Episode reward: 34.925976\n",
      "Episode reward: 66.645798\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2648     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 123757   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00335  |\n",
      "|    n_updates        | 30914    |\n",
      "----------------------------------\n",
      "Episode reward: 52.534828\n",
      "Episode reward: 51.940762\n",
      "Episode reward: 36.856002\n",
      "Episode reward: 83.878514\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2652     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 123983   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00417  |\n",
      "|    n_updates        | 30970    |\n",
      "----------------------------------\n",
      "Episode reward: 32.960745\n",
      "Episode reward: 48.857566\n",
      "Episode reward: 48.656817\n",
      "Episode reward: 93.536518\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2656     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 124208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.298    |\n",
      "|    n_updates        | 31026    |\n",
      "----------------------------------\n",
      "Episode reward: 42.93389\n",
      "Episode reward: 29.654514\n",
      "Episode reward: 59.702563\n",
      "Episode reward: 65.773501\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2660     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 124407   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00405  |\n",
      "|    n_updates        | 31076    |\n",
      "----------------------------------\n",
      "Episode reward: 39.921722\n",
      "Episode reward: 38.890382\n",
      "Episode reward: 74.441478\n",
      "Episode reward: 59.556744\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2664     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 124621   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.155    |\n",
      "|    n_updates        | 31130    |\n",
      "----------------------------------\n",
      "Episode reward: 39.619584\n",
      "Episode reward: 94.899901\n",
      "Episode reward: 44.876985\n",
      "Episode reward: 57.930154\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2668     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 124864   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00286  |\n",
      "|    n_updates        | 31190    |\n",
      "----------------------------------\n",
      "Episode reward: 45.627875\n",
      "Episode reward: 40.884211\n",
      "Episode reward: 58.793619\n",
      "Episode reward: 79.787959\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2672     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 125090   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00265  |\n",
      "|    n_updates        | 31247    |\n",
      "----------------------------------\n",
      "Episode reward: 47.928249\n",
      "Episode reward: 43.79791\n",
      "Episode reward: 60.021365\n",
      "Episode reward: 38.752676\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2676     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 125282   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.158    |\n",
      "|    n_updates        | 31295    |\n",
      "----------------------------------\n",
      "Episode reward: 94.479466\n",
      "Episode reward: 35.876419\n",
      "Episode reward: 73.079464\n",
      "Episode reward: 42.883111\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2680     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 125533   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00334  |\n",
      "|    n_updates        | 31358    |\n",
      "----------------------------------\n",
      "Episode reward: 104.604192\n",
      "Episode reward: 83.578788\n",
      "Episode reward: 53.902808\n",
      "Episode reward: 52.840702\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2684     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 125830   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00616  |\n",
      "|    n_updates        | 31432    |\n",
      "----------------------------------\n",
      "Episode reward: 44.859594\n",
      "Episode reward: 52.743791\n",
      "Episode reward: 75.729377\n",
      "Episode reward: 83.777785\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2688     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 126089   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00214  |\n",
      "|    n_updates        | 31497    |\n",
      "----------------------------------\n",
      "Episode reward: 39.836488\n",
      "Episode reward: 42.939466\n",
      "Episode reward: 55.473579\n",
      "Episode reward: 55.871629\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2692     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 126284   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.409    |\n",
      "|    n_updates        | 31545    |\n",
      "----------------------------------\n",
      "Episode reward: 63.70229\n",
      "Episode reward: 55.858576\n",
      "Episode reward: 40.824223\n",
      "Episode reward: 88.863565\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2696     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 126534   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00256  |\n",
      "|    n_updates        | 31608    |\n",
      "----------------------------------\n",
      "Episode reward: 54.484592\n",
      "Episode reward: 58.449448\n",
      "Episode reward: 47.816197\n",
      "Episode reward: 34.748116\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2700     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 126732   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.166    |\n",
      "|    n_updates        | 31657    |\n",
      "----------------------------------\n",
      "Episode reward: 42.891111\n",
      "Episode reward: 45.906982\n",
      "Episode reward: 58.55582\n",
      "Episode reward: 49.637574\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2704     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 126931   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00577  |\n",
      "|    n_updates        | 31707    |\n",
      "----------------------------------\n",
      "Episode reward: 61.919637\n",
      "Episode reward: 63.922333\n",
      "Episode reward: 33.744831\n",
      "Episode reward: 40.740156\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2708     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 127132   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.21     |\n",
      "|    n_updates        | 31757    |\n",
      "----------------------------------\n",
      "Episode reward: 103.822331\n",
      "Episode reward: 44.880829\n",
      "Episode reward: 60.908641\n",
      "Episode reward: 67.878468\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2712     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 127412   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 31827    |\n",
      "----------------------------------\n",
      "Episode reward: 68.749969\n",
      "Episode reward: 51.346294\n",
      "Episode reward: 58.775596\n",
      "Episode reward: 38.895932\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2716     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 127631   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00354  |\n",
      "|    n_updates        | 31882    |\n",
      "----------------------------------\n",
      "Episode reward: 36.907657\n",
      "Episode reward: 39.779989\n",
      "Episode reward: 41.950518\n",
      "Episode reward: 48.865393\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2720     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 127799   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.252    |\n",
      "|    n_updates        | 31924    |\n",
      "----------------------------------\n",
      "Episode reward: 48.827329\n",
      "Episode reward: 67.828095\n",
      "Episode reward: 43.872905\n",
      "Episode reward: 48.731136\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.5     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2724     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 128010   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.218    |\n",
      "|    n_updates        | 31977    |\n",
      "----------------------------------\n",
      "Episode reward: 59.859124\n",
      "Episode reward: 38.933781\n",
      "Episode reward: 51.110015\n",
      "Episode reward: 53.381603\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2728     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 128215   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.568    |\n",
      "|    n_updates        | 32028    |\n",
      "----------------------------------\n",
      "Episode reward: 50.880416\n",
      "Episode reward: 60.579686\n",
      "Episode reward: 51.927201\n",
      "Episode reward: 46.496479\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2732     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 128426   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00316  |\n",
      "|    n_updates        | 32081    |\n",
      "----------------------------------\n",
      "Episode reward: 34.935438\n",
      "Episode reward: 60.93098\n",
      "Episode reward: 107.155471\n",
      "Episode reward: 44.810482\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2736     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 128675   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00186  |\n",
      "|    n_updates        | 32143    |\n",
      "----------------------------------\n",
      "Episode reward: 62.504209\n",
      "Episode reward: 50.686141\n",
      "Episode reward: 78.197794\n",
      "Episode reward: 45.717396\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2740     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 128917   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.24     |\n",
      "|    n_updates        | 32204    |\n",
      "----------------------------------\n",
      "Episode reward: 48.94212\n",
      "Episode reward: 71.846924\n",
      "Episode reward: 115.216715\n",
      "Episode reward: 31.911718\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2744     |\n",
      "|    fps              | 3296     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 129211   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.224    |\n",
      "|    n_updates        | 32277    |\n",
      "----------------------------------\n",
      "Episode reward: 57.162061\n",
      "Episode reward: 43.875614\n",
      "Episode reward: 35.84203\n",
      "Episode reward: 67.368238\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2748     |\n",
      "|    fps              | 3295     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 129418   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00488  |\n",
      "|    n_updates        | 32329    |\n",
      "----------------------------------\n",
      "Episode reward: 176.296373\n",
      "Episode reward: 43.942164\n",
      "Episode reward: 55.753343\n",
      "Episode reward: 75.158638\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2752     |\n",
      "|    fps              | 3297     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 129772   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00421  |\n",
      "|    n_updates        | 32417    |\n",
      "----------------------------------\n",
      "Episode reward: 59.908191\n",
      "Episode reward: 59.669762\n",
      "Episode reward: 71.919288\n",
      "Episode reward: 56.592894\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2756     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 130022   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.124    |\n",
      "|    n_updates        | 32480    |\n",
      "----------------------------------\n",
      "Episode reward: 37.959756\n",
      "Episode reward: 50.848262\n",
      "Episode reward: 51.916152\n",
      "Episode reward: 69.873112\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2760     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 130233   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.18     |\n",
      "|    n_updates        | 32533    |\n",
      "----------------------------------\n",
      "Episode reward: 50.894489\n",
      "Episode reward: 36.950397\n",
      "Episode reward: 55.369264\n",
      "Episode reward: 63.880056\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2764     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 130441   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.199    |\n",
      "|    n_updates        | 32585    |\n",
      "----------------------------------\n",
      "Episode reward: 46.919987\n",
      "Episode reward: 41.615602\n",
      "Episode reward: 93.849763\n",
      "Episode reward: 41.922211\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2768     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 130668   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00537  |\n",
      "|    n_updates        | 32641    |\n",
      "----------------------------------\n",
      "Episode reward: 49.905157\n",
      "Episode reward: 47.923192\n",
      "Episode reward: 42.371544\n",
      "Episode reward: 41.613142\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2772     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 130851   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.237    |\n",
      "|    n_updates        | 32687    |\n",
      "----------------------------------\n",
      "Episode reward: 36.934148\n",
      "Episode reward: 42.813278\n",
      "Episode reward: 33.882483\n",
      "Episode reward: 39.538685\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2776     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 131005   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.216    |\n",
      "|    n_updates        | 32726    |\n",
      "----------------------------------\n",
      "Episode reward: 75.839214\n",
      "Episode reward: 45.919741\n",
      "Episode reward: 51.703329\n",
      "Episode reward: 53.835899\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2780     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 131233   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.236    |\n",
      "|    n_updates        | 32783    |\n",
      "----------------------------------\n",
      "Episode reward: 60.666928\n",
      "Episode reward: 64.34152\n",
      "Episode reward: 54.718447\n",
      "Episode reward: 64.635508\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2784     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 131481   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 32845    |\n",
      "----------------------------------\n",
      "Episode reward: 113.829067\n",
      "Episode reward: 36.934569\n",
      "Episode reward: 60.911112\n",
      "Episode reward: 40.892983\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2788     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 131735   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 32908    |\n",
      "----------------------------------\n",
      "Episode reward: 51.810367\n",
      "Episode reward: 47.926604\n",
      "Episode reward: 65.774211\n",
      "Episode reward: 76.29938\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2792     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 131980   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00408  |\n",
      "|    n_updates        | 32969    |\n",
      "----------------------------------\n",
      "Episode reward: 55.730782\n",
      "Episode reward: 39.729673\n",
      "Episode reward: 55.749771\n",
      "Episode reward: 44.654359\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2796     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 132177   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.508    |\n",
      "|    n_updates        | 33019    |\n",
      "----------------------------------\n",
      "Episode reward: 51.845469\n",
      "Episode reward: 44.931696\n",
      "Episode reward: 94.36042\n",
      "Episode reward: 34.811432\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2800     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 132406   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0071   |\n",
      "|    n_updates        | 33076    |\n",
      "----------------------------------\n",
      "Episode reward: 37.897857\n",
      "Episode reward: 103.295448\n",
      "Episode reward: 34.953157\n",
      "Episode reward: 44.778125\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2804     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 132628   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.218    |\n",
      "|    n_updates        | 33131    |\n",
      "----------------------------------\n",
      "Episode reward: 56.273466\n",
      "Episode reward: 54.319995\n",
      "Episode reward: 79.746325\n",
      "Episode reward: 70.588236\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2808     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 132895   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0932   |\n",
      "|    n_updates        | 33198    |\n",
      "----------------------------------\n",
      "Episode reward: 60.933184\n",
      "Episode reward: 43.863206\n",
      "Episode reward: 41.814594\n",
      "Episode reward: 51.919668\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2812     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 133094   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0042   |\n",
      "|    n_updates        | 33248    |\n",
      "----------------------------------\n",
      "Episode reward: 58.726648\n",
      "Episode reward: 44.909775\n",
      "Episode reward: 70.259471\n",
      "Episode reward: 38.927084\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2816     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 133309   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.337    |\n",
      "|    n_updates        | 33302    |\n",
      "----------------------------------\n",
      "Episode reward: 101.757881\n",
      "Episode reward: 56.869569\n",
      "Episode reward: 51.892779\n",
      "Episode reward: 61.519384\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2820     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 133582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.193    |\n",
      "|    n_updates        | 33370    |\n",
      "----------------------------------\n",
      "Episode reward: 48.678885\n",
      "Episode reward: 49.856139\n",
      "Episode reward: 35.918822\n",
      "Episode reward: 58.899271\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2824     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 133776   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00985  |\n",
      "|    n_updates        | 33418    |\n",
      "----------------------------------\n",
      "Episode reward: 48.889744\n",
      "Episode reward: 48.82193\n",
      "Episode reward: 37.937295\n",
      "Episode reward: 55.73525\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2828     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 133968   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00551  |\n",
      "|    n_updates        | 33466    |\n",
      "----------------------------------\n",
      "Episode reward: 38.952133\n",
      "Episode reward: 34.839075\n",
      "Episode reward: 79.674368\n",
      "Episode reward: 35.687707\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2832     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 134162   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.236    |\n",
      "|    n_updates        | 33515    |\n",
      "----------------------------------\n",
      "Episode reward: 39.785081\n",
      "Episode reward: 82.872401\n",
      "Episode reward: 37.888948\n",
      "Episode reward: 80.28713\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2836     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 134404   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.173    |\n",
      "|    n_updates        | 33575    |\n",
      "----------------------------------\n",
      "Episode reward: 88.524933\n",
      "Episode reward: 52.817594\n",
      "Episode reward: 46.890046\n",
      "Episode reward: 91.232198\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2840     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 134686   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00327  |\n",
      "|    n_updates        | 33646    |\n",
      "----------------------------------\n",
      "Episode reward: 57.596692\n",
      "Episode reward: 64.893752\n",
      "Episode reward: 52.728\n",
      "Episode reward: 45.876659\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2844     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 134908   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.274    |\n",
      "|    n_updates        | 33701    |\n",
      "----------------------------------\n",
      "Episode reward: 64.869611\n",
      "Episode reward: 43.631138\n",
      "Episode reward: 94.845766\n",
      "Episode reward: 40.838142\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2848     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 135154   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00578  |\n",
      "|    n_updates        | 33763    |\n",
      "----------------------------------\n",
      "Episode reward: 58.478434\n",
      "Episode reward: 81.158984\n",
      "Episode reward: 70.225956\n",
      "Episode reward: 90.645087\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2852     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 135457   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.305    |\n",
      "|    n_updates        | 33839    |\n",
      "----------------------------------\n",
      "Episode reward: 51.908008\n",
      "Episode reward: 52.114842\n",
      "Episode reward: 79.821662\n",
      "Episode reward: 38.94344\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2856     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 135682   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00171  |\n",
      "|    n_updates        | 33895    |\n",
      "----------------------------------\n",
      "Episode reward: 40.872681\n",
      "Episode reward: 37.913691\n",
      "Episode reward: 67.671924\n",
      "Episode reward: 42.825513\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2860     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 135872   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.608    |\n",
      "|    n_updates        | 33942    |\n",
      "----------------------------------\n",
      "Episode reward: 77.466005\n",
      "Episode reward: 69.921635\n",
      "Episode reward: 107.56599\n",
      "Episode reward: 40.833788\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2864     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 136171   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00969  |\n",
      "|    n_updates        | 34017    |\n",
      "----------------------------------\n",
      "Episode reward: 49.878824\n",
      "Episode reward: 68.597423\n",
      "Episode reward: 90.115496\n",
      "Episode reward: 41.823727\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2868     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 136425   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.218    |\n",
      "|    n_updates        | 34081    |\n",
      "----------------------------------\n",
      "Episode reward: 35.759894\n",
      "Episode reward: 39.95284\n",
      "Episode reward: 45.923654\n",
      "Episode reward: 47.749636\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2872     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 136595   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.205    |\n",
      "|    n_updates        | 34123    |\n",
      "----------------------------------\n",
      "Episode reward: 50.821517\n",
      "Episode reward: 41.490305\n",
      "Episode reward: 49.263503\n",
      "Episode reward: 45.939278\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2876     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 136784   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00667  |\n",
      "|    n_updates        | 34170    |\n",
      "----------------------------------\n",
      "Episode reward: 46.965135\n",
      "Episode reward: 42.952015\n",
      "Episode reward: 40.949321\n",
      "Episode reward: 48.95155\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2880     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 136966   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.309    |\n",
      "|    n_updates        | 34216    |\n",
      "----------------------------------\n",
      "Episode reward: 100.645026\n",
      "Episode reward: 77.251966\n",
      "Episode reward: 57.751067\n",
      "Episode reward: 57.929758\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2884     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 137272   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00392  |\n",
      "|    n_updates        | 34292    |\n",
      "----------------------------------\n",
      "Episode reward: 55.917853\n",
      "Episode reward: 60.84867\n",
      "Episode reward: 88.750328\n",
      "Episode reward: 31.938547\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2888     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 137512   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.359    |\n",
      "|    n_updates        | 34352    |\n",
      "----------------------------------\n",
      "Episode reward: 75.725587\n",
      "Episode reward: 110.899345\n",
      "Episode reward: 49.877099\n",
      "Episode reward: 36.943363\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2892     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 137790   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.222    |\n",
      "|    n_updates        | 34422    |\n",
      "----------------------------------\n",
      "Episode reward: 102.183053\n",
      "Episode reward: 65.293957\n",
      "Episode reward: 50.406307\n",
      "Episode reward: 45.950041\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2896     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 138056   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.228    |\n",
      "|    n_updates        | 34488    |\n",
      "----------------------------------\n",
      "Episode reward: 59.242206\n",
      "Episode reward: 47.942678\n",
      "Episode reward: 30.87918\n",
      "Episode reward: 63.673158\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2900     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 138259   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.246    |\n",
      "|    n_updates        | 34539    |\n",
      "----------------------------------\n",
      "Episode reward: 48.762644\n",
      "Episode reward: 64.890623\n",
      "Episode reward: 84.822078\n",
      "Episode reward: 41.941544\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2904     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 138500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00248  |\n",
      "|    n_updates        | 34599    |\n",
      "----------------------------------\n",
      "Episode reward: 66.510139\n",
      "Episode reward: 44.861373\n",
      "Episode reward: 66.663691\n",
      "Episode reward: 65.887516\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2908     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 138746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.251    |\n",
      "|    n_updates        | 34661    |\n",
      "----------------------------------\n",
      "Episode reward: 49.909412\n",
      "Episode reward: 67.78233\n",
      "Episode reward: 50.902424\n",
      "Episode reward: 58.906507\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2912     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 138975   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0192   |\n",
      "|    n_updates        | 34718    |\n",
      "----------------------------------\n",
      "Episode reward: 77.80329\n",
      "Episode reward: 91.584872\n",
      "Episode reward: 36.939556\n",
      "Episode reward: 50.756939\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2916     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 139233   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00226  |\n",
      "|    n_updates        | 34783    |\n",
      "----------------------------------\n",
      "Episode reward: 57.712381\n",
      "Episode reward: 56.212618\n",
      "Episode reward: 38.922759\n",
      "Episode reward: 88.602351\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2920     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 139479   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.266    |\n",
      "|    n_updates        | 34844    |\n",
      "----------------------------------\n",
      "Episode reward: 77.402888\n",
      "Episode reward: 37.923598\n",
      "Episode reward: 42.944214\n",
      "Episode reward: 50.885819\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2924     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 139692   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00626  |\n",
      "|    n_updates        | 34897    |\n",
      "----------------------------------\n",
      "Episode reward: 53.932062\n",
      "Episode reward: 54.554211\n",
      "Episode reward: 36.882067\n",
      "Episode reward: 76.821851\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2928     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 139916   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.162    |\n",
      "|    n_updates        | 34953    |\n",
      "----------------------------------\n",
      "Episode reward: 58.879751\n",
      "Episode reward: 48.779972\n",
      "Episode reward: 48.584062\n",
      "Episode reward: 38.939586\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2932     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 140112   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00284  |\n",
      "|    n_updates        | 35002    |\n",
      "----------------------------------\n",
      "Episode reward: 68.724542\n",
      "Episode reward: 110.877834\n",
      "Episode reward: 94.933073\n",
      "Episode reward: 51.811425\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2936     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 140442   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.234    |\n",
      "|    n_updates        | 35085    |\n",
      "----------------------------------\n",
      "Episode reward: 34.837058\n",
      "Episode reward: 48.899021\n",
      "Episode reward: 43.890433\n",
      "Episode reward: 45.798066\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2940     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 140616   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.172    |\n",
      "|    n_updates        | 35128    |\n",
      "----------------------------------\n",
      "Episode reward: 27.937659\n",
      "Episode reward: 60.70235\n",
      "Episode reward: 40.934317\n",
      "Episode reward: 45.785419\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2944     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 140792   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.274    |\n",
      "|    n_updates        | 35172    |\n",
      "----------------------------------\n",
      "Episode reward: 61.751459\n",
      "Episode reward: 40.799934\n",
      "Episode reward: 63.265738\n",
      "Episode reward: 43.572723\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2948     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 141003   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.248    |\n",
      "|    n_updates        | 35225    |\n",
      "----------------------------------\n",
      "Episode reward: 58.562905\n",
      "Episode reward: 56.283087\n",
      "Episode reward: 32.89264\n",
      "Episode reward: 46.600074\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2952     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 141199   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.27     |\n",
      "|    n_updates        | 35274    |\n",
      "----------------------------------\n",
      "Episode reward: 57.894865\n",
      "Episode reward: 78.880771\n",
      "Episode reward: 93.943588\n",
      "Episode reward: 42.903264\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2956     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 141474   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.228    |\n",
      "|    n_updates        | 35343    |\n",
      "----------------------------------\n",
      "Episode reward: 58.807181\n",
      "Episode reward: 68.085438\n",
      "Episode reward: 56.31139\n",
      "Episode reward: 54.893261\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2960     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 141714   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0594   |\n",
      "|    n_updates        | 35403    |\n",
      "----------------------------------\n",
      "Episode reward: 58.261791\n",
      "Episode reward: 41.876267\n",
      "Episode reward: 69.892214\n",
      "Episode reward: 62.877392\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2964     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 141948   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00785  |\n",
      "|    n_updates        | 35461    |\n",
      "----------------------------------\n",
      "Episode reward: 54.83341\n",
      "Episode reward: 67.378134\n",
      "Episode reward: 61.33058\n",
      "Episode reward: 48.2923\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2968     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 142182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00144  |\n",
      "|    n_updates        | 35520    |\n",
      "----------------------------------\n",
      "Episode reward: 68.899698\n",
      "Episode reward: 38.935987\n",
      "Episode reward: 43.572387\n",
      "Episode reward: 56.516887\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2972     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 142391   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.252    |\n",
      "|    n_updates        | 35572    |\n",
      "----------------------------------\n",
      "Episode reward: 75.151354\n",
      "Episode reward: 51.943318\n",
      "Episode reward: 38.889547\n",
      "Episode reward: 46.79538\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2976     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 142605   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.298    |\n",
      "|    n_updates        | 35626    |\n",
      "----------------------------------\n",
      "Episode reward: 42.308172\n",
      "Episode reward: 33.761336\n",
      "Episode reward: 41.870404\n",
      "Episode reward: 39.909197\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2980     |\n",
      "|    fps              | 3296     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 142764   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0979   |\n",
      "|    n_updates        | 35665    |\n",
      "----------------------------------\n",
      "Episode reward: 152.615226\n",
      "Episode reward: 77.317392\n",
      "Episode reward: 56.900761\n",
      "Episode reward: 56.62939\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2984     |\n",
      "|    fps              | 3297     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 143111   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00144  |\n",
      "|    n_updates        | 35752    |\n",
      "----------------------------------\n",
      "Episode reward: 55.566896\n",
      "Episode reward: 50.941642\n",
      "Episode reward: 33.907717\n",
      "Episode reward: 90.652291\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2988     |\n",
      "|    fps              | 3297     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 143344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00213  |\n",
      "|    n_updates        | 35810    |\n",
      "----------------------------------\n",
      "Episode reward: 61.848282\n",
      "Episode reward: 49.842659\n",
      "Episode reward: 41.904622\n",
      "Episode reward: 37.918728\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2992     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 143536   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00254  |\n",
      "|    n_updates        | 35858    |\n",
      "----------------------------------\n",
      "Episode reward: 69.478693\n",
      "Episode reward: 41.901149\n",
      "Episode reward: 50.84437\n",
      "Episode reward: 71.818319\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 2996     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 143771   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.258    |\n",
      "|    n_updates        | 35917    |\n",
      "----------------------------------\n",
      "Episode reward: 95.752494\n",
      "Episode reward: 34.869232\n",
      "Episode reward: 33.913859\n",
      "Episode reward: 67.897858\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3000     |\n",
      "|    fps              | 3299     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 144005   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.245    |\n",
      "|    n_updates        | 35976    |\n",
      "----------------------------------\n",
      "Episode reward: 41.824507\n",
      "Episode reward: 99.755784\n",
      "Episode reward: 91.019893\n",
      "Episode reward: 53.935326\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3004     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 144295   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 36048    |\n",
      "----------------------------------\n",
      "Episode reward: 69.674704\n",
      "Episode reward: 78.762957\n",
      "Episode reward: 48.407442\n",
      "Episode reward: 35.897261\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3008     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 144529   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.316    |\n",
      "|    n_updates        | 36107    |\n",
      "----------------------------------\n",
      "Episode reward: 47.741367\n",
      "Episode reward: 38.758877\n",
      "Episode reward: 52.916499\n",
      "Episode reward: 32.918452\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3012     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 144702   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00492  |\n",
      "|    n_updates        | 36150    |\n",
      "----------------------------------\n",
      "Episode reward: 50.903962\n",
      "Episode reward: 59.205183\n",
      "Episode reward: 52.903902\n",
      "Episode reward: 34.914174\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3016     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 144901   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.256    |\n",
      "|    n_updates        | 36200    |\n",
      "----------------------------------\n",
      "Episode reward: 54.461277\n",
      "Episode reward: 119.9822\n",
      "Episode reward: 34.93483\n",
      "Episode reward: 50.792564\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3020     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 145190   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.269    |\n",
      "|    n_updates        | 36272    |\n",
      "----------------------------------\n",
      "Episode reward: 47.419814\n",
      "Episode reward: 66.242283\n",
      "Episode reward: 76.855504\n",
      "Episode reward: 74.487265\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3024     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 145459   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0014   |\n",
      "|    n_updates        | 36339    |\n",
      "----------------------------------\n",
      "Episode reward: 47.624104\n",
      "Episode reward: 63.895668\n",
      "Episode reward: 50.593792\n",
      "Episode reward: 43.6595\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3028     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 145666   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00184  |\n",
      "|    n_updates        | 36391    |\n",
      "----------------------------------\n",
      "Episode reward: 32.599862\n",
      "Episode reward: 33.948522\n",
      "Episode reward: 48.154175\n",
      "Episode reward: 79.060118\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3032     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 145862   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.239    |\n",
      "|    n_updates        | 36440    |\n",
      "----------------------------------\n",
      "Episode reward: 48.590178\n",
      "Episode reward: 61.821911\n",
      "Episode reward: 34.690646\n",
      "Episode reward: 43.571042\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3036     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 146052   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0995   |\n",
      "|    n_updates        | 36487    |\n",
      "----------------------------------\n",
      "Episode reward: 61.796867\n",
      "Episode reward: 70.559279\n",
      "Episode reward: 63.630544\n",
      "Episode reward: 42.881289\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3040     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 146292   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00817  |\n",
      "|    n_updates        | 36547    |\n",
      "----------------------------------\n",
      "Episode reward: 52.935263\n",
      "Episode reward: 47.857404\n",
      "Episode reward: 72.347415\n",
      "Episode reward: 80.621801\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3044     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 146550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.262    |\n",
      "|    n_updates        | 36612    |\n",
      "----------------------------------\n",
      "Episode reward: 46.868973\n",
      "Episode reward: 44.47912\n",
      "Episode reward: 80.133884\n",
      "Episode reward: 101.796152\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3048     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 146828   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.242    |\n",
      "|    n_updates        | 36681    |\n",
      "----------------------------------\n",
      "Episode reward: 94.833396\n",
      "Episode reward: 50.753062\n",
      "Episode reward: 40.811167\n",
      "Episode reward: 43.879419\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3052     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 147059   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00254  |\n",
      "|    n_updates        | 36739    |\n",
      "----------------------------------\n",
      "Episode reward: 45.889983\n",
      "Episode reward: 48.771447\n",
      "Episode reward: 53.87316\n",
      "Episode reward: 63.601613\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3056     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 147272   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 36792    |\n",
      "----------------------------------\n",
      "Episode reward: 58.354676\n",
      "Episode reward: 55.191501\n",
      "Episode reward: 46.657926\n",
      "Episode reward: 54.844996\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3060     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 147489   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.471    |\n",
      "|    n_updates        | 36847    |\n",
      "----------------------------------\n",
      "Episode reward: 46.841357\n",
      "Episode reward: 79.57935\n",
      "Episode reward: 47.37774\n",
      "Episode reward: 51.742691\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3064     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 147716   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00605  |\n",
      "|    n_updates        | 36903    |\n",
      "----------------------------------\n",
      "Episode reward: 88.387051\n",
      "Episode reward: 49.603571\n",
      "Episode reward: 51.042782\n",
      "Episode reward: 52.914016\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3068     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 147961   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00528  |\n",
      "|    n_updates        | 36965    |\n",
      "----------------------------------\n",
      "Episode reward: 50.896876\n",
      "Episode reward: 44.814385\n",
      "Episode reward: 68.403805\n",
      "Episode reward: 70.98701\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3072     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 148201   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 37025    |\n",
      "----------------------------------\n",
      "Episode reward: 37.825887\n",
      "Episode reward: 71.868843\n",
      "Episode reward: 97.842858\n",
      "Episode reward: 46.944671\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3076     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 148456   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0041   |\n",
      "|    n_updates        | 37088    |\n",
      "----------------------------------\n",
      "Episode reward: 57.602784\n",
      "Episode reward: 43.79955\n",
      "Episode reward: 51.915906\n",
      "Episode reward: 38.486731\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3080     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 148649   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.303    |\n",
      "|    n_updates        | 37137    |\n",
      "----------------------------------\n",
      "Episode reward: 36.958475\n",
      "Episode reward: 48.881774\n",
      "Episode reward: 76.243378\n",
      "Episode reward: 46.809381\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3084     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 148860   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00457  |\n",
      "|    n_updates        | 37189    |\n",
      "----------------------------------\n",
      "Episode reward: 52.893768\n",
      "Episode reward: 30.83079\n",
      "Episode reward: 48.873651\n",
      "Episode reward: 51.93891\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3088     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 149045   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.534    |\n",
      "|    n_updates        | 37236    |\n",
      "----------------------------------\n",
      "Episode reward: 49.810405\n",
      "Episode reward: 49.766127\n",
      "Episode reward: 66.127419\n",
      "Episode reward: 43.854024\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3092     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 149256   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.206    |\n",
      "|    n_updates        | 37288    |\n",
      "----------------------------------\n",
      "Episode reward: 116.392944\n",
      "Episode reward: 41.939343\n",
      "Episode reward: 41.805648\n",
      "Episode reward: 55.635211\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3096     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 149516   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00188  |\n",
      "|    n_updates        | 37353    |\n",
      "----------------------------------\n",
      "Episode reward: 33.456965\n",
      "Episode reward: 45.842487\n",
      "Episode reward: 51.700091\n",
      "Episode reward: 93.779878\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3100     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 149742   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00482  |\n",
      "|    n_updates        | 37410    |\n",
      "----------------------------------\n",
      "Episode reward: 60.892228\n",
      "Episode reward: 37.750687\n",
      "Episode reward: 39.893794\n",
      "Episode reward: 34.864509\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3104     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 149916   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00744  |\n",
      "|    n_updates        | 37453    |\n",
      "----------------------------------\n",
      "Episode reward: 99.731902\n",
      "Episode reward: 30.926843\n",
      "Episode reward: 46.839691\n",
      "Episode reward: 51.625325\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3108     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 150146   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0051   |\n",
      "|    n_updates        | 37511    |\n",
      "----------------------------------\n",
      "Episode reward: 92.51034\n",
      "Episode reward: 46.846409\n",
      "Episode reward: 54.392315\n",
      "Episode reward: 60.883077\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3112     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 150404   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00446  |\n",
      "|    n_updates        | 37575    |\n",
      "----------------------------------\n",
      "Episode reward: 53.878512\n",
      "Episode reward: 60.860599\n",
      "Episode reward: 53.192762\n",
      "Episode reward: 71.16661\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3116     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 150645   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.251    |\n",
      "|    n_updates        | 37636    |\n",
      "----------------------------------\n",
      "Episode reward: 40.856912\n",
      "Episode reward: 98.543659\n",
      "Episode reward: 57.094967\n",
      "Episode reward: 76.019035\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3120     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 150920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00217  |\n",
      "|    n_updates        | 37704    |\n",
      "----------------------------------\n",
      "Episode reward: 41.653629\n",
      "Episode reward: 57.80315\n",
      "Episode reward: 51.803574\n",
      "Episode reward: 55.638554\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3124     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 151128   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00193  |\n",
      "|    n_updates        | 37756    |\n",
      "----------------------------------\n",
      "Episode reward: 85.077572\n",
      "Episode reward: 52.429565\n",
      "Episode reward: 74.526155\n",
      "Episode reward: 56.905153\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3128     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 151399   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0689   |\n",
      "|    n_updates        | 37824    |\n",
      "----------------------------------\n",
      "Episode reward: 52.721153\n",
      "Episode reward: 50.775067\n",
      "Episode reward: 67.416152\n",
      "Episode reward: 37.958205\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3132     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 151611   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.244    |\n",
      "|    n_updates        | 37877    |\n",
      "----------------------------------\n",
      "Episode reward: 54.504424\n",
      "Episode reward: 84.710081\n",
      "Episode reward: 52.403197\n",
      "Episode reward: 111.155122\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3136     |\n",
      "|    fps              | 3307     |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 151916   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.17     |\n",
      "|    n_updates        | 37953    |\n",
      "----------------------------------\n",
      "Episode reward: 48.605572\n",
      "Episode reward: 65.14853\n",
      "Episode reward: 28.877654\n",
      "Episode reward: 43.948881\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3140     |\n",
      "|    fps              | 3307     |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 152105   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0312   |\n",
      "|    n_updates        | 38001    |\n",
      "----------------------------------\n",
      "Episode reward: 54.919251\n",
      "Episode reward: 56.789356\n",
      "Episode reward: 46.933926\n",
      "Episode reward: 87.692104\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3144     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 152352   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.306    |\n",
      "|    n_updates        | 38062    |\n",
      "----------------------------------\n",
      "Episode reward: 50.705013\n",
      "Episode reward: 49.939023\n",
      "Episode reward: 71.506615\n",
      "Episode reward: 99.79499\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3148     |\n",
      "|    fps              | 3307     |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 152632   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.204    |\n",
      "|    n_updates        | 38132    |\n",
      "----------------------------------\n",
      "Episode reward: 49.56362\n",
      "Episode reward: 36.804625\n",
      "Episode reward: 45.940222\n",
      "Episode reward: 63.520317\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3152     |\n",
      "|    fps              | 3307     |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 152829   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00372  |\n",
      "|    n_updates        | 38182    |\n",
      "----------------------------------\n",
      "Episode reward: 30.914007\n",
      "Episode reward: 31.748979\n",
      "Episode reward: 49.945252\n",
      "Episode reward: 35.949564\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3156     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 152978   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00849  |\n",
      "|    n_updates        | 38219    |\n",
      "----------------------------------\n",
      "Episode reward: 47.869647\n",
      "Episode reward: 106.054625\n",
      "Episode reward: 29.950233\n",
      "Episode reward: 73.804406\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3160     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 153240   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00522  |\n",
      "|    n_updates        | 38284    |\n",
      "----------------------------------\n",
      "Episode reward: 71.413835\n",
      "Episode reward: 34.830846\n",
      "Episode reward: 35.878564\n",
      "Episode reward: 32.678001\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3164     |\n",
      "|    fps              | 3309     |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 153416   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00459  |\n",
      "|    n_updates        | 38328    |\n",
      "----------------------------------\n",
      "Episode reward: 52.657164\n",
      "Episode reward: 55.551897\n",
      "Episode reward: 66.774221\n",
      "Episode reward: 59.495754\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3168     |\n",
      "|    fps              | 3309     |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 153652   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.226    |\n",
      "|    n_updates        | 38387    |\n",
      "----------------------------------\n",
      "Episode reward: 63.918049\n",
      "Episode reward: 52.939465\n",
      "Episode reward: 84.844698\n",
      "Episode reward: 44.940262\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3172     |\n",
      "|    fps              | 3309     |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 153900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.497    |\n",
      "|    n_updates        | 38449    |\n",
      "----------------------------------\n",
      "Episode reward: 52.62356\n",
      "Episode reward: 106.120624\n",
      "Episode reward: 45.857925\n",
      "Episode reward: 75.92041\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3176     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 154183   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 38520    |\n",
      "----------------------------------\n",
      "Episode reward: 81.575568\n",
      "Episode reward: 56.310009\n",
      "Episode reward: 51.898231\n",
      "Episode reward: 69.167012\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3180     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 154446   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0387   |\n",
      "|    n_updates        | 38586    |\n",
      "----------------------------------\n",
      "Episode reward: 53.710237\n",
      "Episode reward: 35.811838\n",
      "Episode reward: 37.888463\n",
      "Episode reward: 91.055248\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3184     |\n",
      "|    fps              | 3309     |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 154667   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0473   |\n",
      "|    n_updates        | 38641    |\n",
      "----------------------------------\n",
      "Episode reward: 107.75442\n",
      "Episode reward: 54.696645\n",
      "Episode reward: 76.409302\n",
      "Episode reward: 68.421455\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3188     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 154976   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 38718    |\n",
      "----------------------------------\n",
      "Episode reward: 50.816477\n",
      "Episode reward: 58.197819\n",
      "Episode reward: 54.924203\n",
      "Episode reward: 47.842807\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3192     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 155189   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00246  |\n",
      "|    n_updates        | 38772    |\n",
      "----------------------------------\n",
      "Episode reward: 40.831618\n",
      "Episode reward: 53.87439\n",
      "Episode reward: 46.119972\n",
      "Episode reward: 72.107675\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3196     |\n",
      "|    fps              | 3309     |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 155404   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.463    |\n",
      "|    n_updates        | 38825    |\n",
      "----------------------------------\n",
      "Episode reward: 52.666975\n",
      "Episode reward: 46.862449\n",
      "Episode reward: 49.361871\n",
      "Episode reward: 64.72039\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3200     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 155619   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.497    |\n",
      "|    n_updates        | 38879    |\n",
      "----------------------------------\n",
      "Episode reward: 67.600627\n",
      "Episode reward: 37.89547\n",
      "Episode reward: 53.655022\n",
      "Episode reward: 67.795833\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3204     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 155847   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.751    |\n",
      "|    n_updates        | 38936    |\n",
      "----------------------------------\n",
      "Episode reward: 74.835509\n",
      "Episode reward: 37.893674\n",
      "Episode reward: 53.703694\n",
      "Episode reward: 61.413561\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3208     |\n",
      "|    fps              | 3309     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 156076   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00374  |\n",
      "|    n_updates        | 38993    |\n",
      "----------------------------------\n",
      "Episode reward: 38.909265\n",
      "Episode reward: 44.894733\n",
      "Episode reward: 39.647858\n",
      "Episode reward: 89.76413\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3212     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 156290   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00275  |\n",
      "|    n_updates        | 39047    |\n",
      "----------------------------------\n",
      "Episode reward: 48.860698\n",
      "Episode reward: 51.565314\n",
      "Episode reward: 34.956322\n",
      "Episode reward: 34.929792\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3216     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 156461   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.178    |\n",
      "|    n_updates        | 39090    |\n",
      "----------------------------------\n",
      "Episode reward: 79.407219\n",
      "Episode reward: 37.896497\n",
      "Episode reward: 35.958349\n",
      "Episode reward: 46.720949\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3220     |\n",
      "|    fps              | 3309     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 156665   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00757  |\n",
      "|    n_updates        | 39141    |\n",
      "----------------------------------\n",
      "Episode reward: 44.885922\n",
      "Episode reward: 48.228701\n",
      "Episode reward: 82.643503\n",
      "Episode reward: 45.761932\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3224     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 156888   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.037    |\n",
      "|    n_updates        | 39196    |\n",
      "----------------------------------\n",
      "Episode reward: 59.049103\n",
      "Episode reward: 48.905395\n",
      "Episode reward: 55.843099\n",
      "Episode reward: 40.883999\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3228     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 157095   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00467  |\n",
      "|    n_updates        | 39248    |\n",
      "----------------------------------\n",
      "Episode reward: 56.759226\n",
      "Episode reward: 83.789678\n",
      "Episode reward: 40.943452\n",
      "Episode reward: 114.33509\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3232     |\n",
      "|    fps              | 3309     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 157393   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.193    |\n",
      "|    n_updates        | 39323    |\n",
      "----------------------------------\n",
      "Episode reward: 63.71352\n",
      "Episode reward: 33.890172\n",
      "Episode reward: 36.8441\n",
      "Episode reward: 80.342282\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3236     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 157610   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.266    |\n",
      "|    n_updates        | 39377    |\n",
      "----------------------------------\n",
      "Episode reward: 68.719167\n",
      "Episode reward: 38.952268\n",
      "Episode reward: 30.655918\n",
      "Episode reward: 58.113677\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3240     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 157808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.255    |\n",
      "|    n_updates        | 39426    |\n",
      "----------------------------------\n",
      "Episode reward: 40.88506\n",
      "Episode reward: 38.926672\n",
      "Episode reward: 54.804083\n",
      "Episode reward: 63.15945\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3244     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 158007   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.47     |\n",
      "|    n_updates        | 39476    |\n",
      "----------------------------------\n",
      "Episode reward: 35.734981\n",
      "Episode reward: 44.665993\n",
      "Episode reward: 42.892329\n",
      "Episode reward: 54.930843\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.5     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3248     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 158186   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00419  |\n",
      "|    n_updates        | 39521    |\n",
      "----------------------------------\n",
      "Episode reward: 85.543995\n",
      "Episode reward: 83.556275\n",
      "Episode reward: 84.479968\n",
      "Episode reward: 40.917021\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3252     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 158482   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00465  |\n",
      "|    n_updates        | 39595    |\n",
      "----------------------------------\n",
      "Episode reward: 46.869398\n",
      "Episode reward: 48.883235\n",
      "Episode reward: 61.572151\n",
      "Episode reward: 37.591698\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3256     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 158679   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0872   |\n",
      "|    n_updates        | 39644    |\n",
      "----------------------------------\n",
      "Episode reward: 46.832662\n",
      "Episode reward: 49.846611\n",
      "Episode reward: 36.942334\n",
      "Episode reward: 38.871964\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3260     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 158852   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.299    |\n",
      "|    n_updates        | 39687    |\n",
      "----------------------------------\n",
      "Episode reward: 52.840905\n",
      "Episode reward: 56.549024\n",
      "Episode reward: 35.87776\n",
      "Episode reward: 32.964653\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3264     |\n",
      "|    fps              | 3309     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 159031   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00465  |\n",
      "|    n_updates        | 39732    |\n",
      "----------------------------------\n",
      "Episode reward: 69.867058\n",
      "Episode reward: 41.831189\n",
      "Episode reward: 123.766421\n",
      "Episode reward: 35.92278\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3268     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 159303   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.087    |\n",
      "|    n_updates        | 39800    |\n",
      "----------------------------------\n",
      "Episode reward: 77.895813\n",
      "Episode reward: 55.866679\n",
      "Episode reward: 83.459036\n",
      "Episode reward: 35.850692\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3272     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 159559   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00269  |\n",
      "|    n_updates        | 39864    |\n",
      "----------------------------------\n",
      "Episode reward: 55.887823\n",
      "Episode reward: 55.601949\n",
      "Episode reward: 77.522521\n",
      "Episode reward: 46.772892\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3276     |\n",
      "|    fps              | 3311     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 159797   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00533  |\n",
      "|    n_updates        | 39924    |\n",
      "----------------------------------\n",
      "Episode reward: 53.495315\n",
      "Episode reward: 50.774977\n",
      "Episode reward: 64.707437\n",
      "Episode reward: 38.93303\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3280     |\n",
      "|    fps              | 3311     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 160006   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.285    |\n",
      "|    n_updates        | 39976    |\n",
      "----------------------------------\n",
      "Episode reward: 67.857839\n",
      "Episode reward: 64.204798\n",
      "Episode reward: 70.357275\n",
      "Episode reward: 37.939933\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3284     |\n",
      "|    fps              | 3311     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 160251   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.223    |\n",
      "|    n_updates        | 40037    |\n",
      "----------------------------------\n",
      "Episode reward: 61.363335\n",
      "Episode reward: 34.884528\n",
      "Episode reward: 56.589381\n",
      "Episode reward: 39.936742\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.7     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3288     |\n",
      "|    fps              | 3311     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 160446   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.229    |\n",
      "|    n_updates        | 40086    |\n",
      "----------------------------------\n",
      "Episode reward: 34.70255\n",
      "Episode reward: 102.678604\n",
      "Episode reward: 66.886394\n",
      "Episode reward: 62.366787\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3292     |\n",
      "|    fps              | 3311     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 160715   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.257    |\n",
      "|    n_updates        | 40153    |\n",
      "----------------------------------\n",
      "Episode reward: 52.936418\n",
      "Episode reward: 47.933477\n",
      "Episode reward: 95.455783\n",
      "Episode reward: 47.877397\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3296     |\n",
      "|    fps              | 3311     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 160960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00646  |\n",
      "|    n_updates        | 40214    |\n",
      "----------------------------------\n",
      "Episode reward: 37.826984\n",
      "Episode reward: 43.818818\n",
      "Episode reward: 38.828618\n",
      "Episode reward: 67.71098\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3300     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 161149   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 40262    |\n",
      "----------------------------------\n",
      "Episode reward: 44.496103\n",
      "Episode reward: 44.888446\n",
      "Episode reward: 47.937838\n",
      "Episode reward: 52.066836\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3304     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 161340   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.28     |\n",
      "|    n_updates        | 40309    |\n",
      "----------------------------------\n",
      "Episode reward: 44.871275\n",
      "Episode reward: 35.895147\n",
      "Episode reward: 45.93648\n",
      "Episode reward: 35.953893\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.3     |\n",
      "|    ep_rew_mean      | 53.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3308     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 161503   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 40350    |\n",
      "----------------------------------\n",
      "Episode reward: 33.872407\n",
      "Episode reward: 45.529217\n",
      "Episode reward: 74.826868\n",
      "Episode reward: 60.853533\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.3     |\n",
      "|    ep_rew_mean      | 53.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3312     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 161719   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.112    |\n",
      "|    n_updates        | 40404    |\n",
      "----------------------------------\n",
      "Episode reward: 63.213413\n",
      "Episode reward: 41.944153\n",
      "Episode reward: 55.48282\n",
      "Episode reward: 32.683427\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3316     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 161914   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.197    |\n",
      "|    n_updates        | 40453    |\n",
      "----------------------------------\n",
      "Episode reward: 77.882838\n",
      "Episode reward: 57.896788\n",
      "Episode reward: 60.579034\n",
      "Episode reward: 28.834705\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.8     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3320     |\n",
      "|    fps              | 3311     |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 162140   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.255    |\n",
      "|    n_updates        | 40509    |\n",
      "----------------------------------\n",
      "Episode reward: 54.181811\n",
      "Episode reward: 62.851953\n",
      "Episode reward: 50.817805\n",
      "Episode reward: 64.799781\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3324     |\n",
      "|    fps              | 3311     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 162374   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00224  |\n",
      "|    n_updates        | 40568    |\n",
      "----------------------------------\n",
      "Episode reward: 81.78032\n",
      "Episode reward: 36.794776\n",
      "Episode reward: 75.226699\n",
      "Episode reward: 67.803766\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3328     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 162637   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 40634    |\n",
      "----------------------------------\n",
      "Episode reward: 54.888575\n",
      "Episode reward: 50.933468\n",
      "Episode reward: 67.546062\n",
      "Episode reward: 37.752833\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.6     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3332     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 162849   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.264    |\n",
      "|    n_updates        | 40687    |\n",
      "----------------------------------\n",
      "Episode reward: 35.826304\n",
      "Episode reward: 48.889428\n",
      "Episode reward: 57.922501\n",
      "Episode reward: 71.5952\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3336     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 163064   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00605  |\n",
      "|    n_updates        | 40740    |\n",
      "----------------------------------\n",
      "Episode reward: 66.698075\n",
      "Episode reward: 75.328346\n",
      "Episode reward: 39.843432\n",
      "Episode reward: 41.882577\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.8     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3340     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 163290   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00529  |\n",
      "|    n_updates        | 40797    |\n",
      "----------------------------------\n",
      "Episode reward: 49.459007\n",
      "Episode reward: 84.726342\n",
      "Episode reward: 51.650583\n",
      "Episode reward: 63.531061\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3344     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 163541   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00403  |\n",
      "|    n_updates        | 40860    |\n",
      "----------------------------------\n",
      "Episode reward: 79.466339\n",
      "Episode reward: 49.895538\n",
      "Episode reward: 49.798449\n",
      "Episode reward: 58.691277\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3348     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 163780   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.478    |\n",
      "|    n_updates        | 40919    |\n",
      "----------------------------------\n",
      "Episode reward: 52.769527\n",
      "Episode reward: 32.860509\n",
      "Episode reward: 40.934796\n",
      "Episode reward: 39.922371\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.6     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3352     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 163947   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.436    |\n",
      "|    n_updates        | 40961    |\n",
      "----------------------------------\n",
      "Episode reward: 68.906805\n",
      "Episode reward: 100.456515\n",
      "Episode reward: 73.843311\n",
      "Episode reward: 29.859778\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3356     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 164221   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00362  |\n",
      "|    n_updates        | 41030    |\n",
      "----------------------------------\n",
      "Episode reward: 53.760271\n",
      "Episode reward: 38.772591\n",
      "Episode reward: 52.453525\n",
      "Episode reward: 53.856751\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3360     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 164421   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00244  |\n",
      "|    n_updates        | 41080    |\n",
      "----------------------------------\n",
      "Episode reward: 37.729787\n",
      "Episode reward: 42.93914\n",
      "Episode reward: 70.742444\n",
      "Episode reward: 76.691292\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3364     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 164650   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00585  |\n",
      "|    n_updates        | 41137    |\n",
      "----------------------------------\n",
      "Episode reward: 36.912077\n",
      "Episode reward: 90.620789\n",
      "Episode reward: 64.249534\n",
      "Episode reward: 66.733529\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3368     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 164911   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00655  |\n",
      "|    n_updates        | 41202    |\n",
      "----------------------------------\n",
      "Episode reward: 59.73698\n",
      "Episode reward: 55.606169\n",
      "Episode reward: 36.955781\n",
      "Episode reward: 52.696738\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3372     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 165117   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.32     |\n",
      "|    n_updates        | 41254    |\n",
      "----------------------------------\n",
      "Episode reward: 40.880695\n",
      "Episode reward: 68.653863\n",
      "Episode reward: 33.636853\n",
      "Episode reward: 41.882986\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3376     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 165303   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.186    |\n",
      "|    n_updates        | 41300    |\n",
      "----------------------------------\n",
      "Episode reward: 72.865211\n",
      "Episode reward: 75.83867\n",
      "Episode reward: 40.724827\n",
      "Episode reward: 130.589487\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3380     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 165624   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.328    |\n",
      "|    n_updates        | 41380    |\n",
      "----------------------------------\n",
      "Episode reward: 76.911922\n",
      "Episode reward: 49.684737\n",
      "Episode reward: 67.489409\n",
      "Episode reward: 47.914831\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3384     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 165867   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00186  |\n",
      "|    n_updates        | 41441    |\n",
      "----------------------------------\n",
      "Episode reward: 36.824893\n",
      "Episode reward: 45.941789\n",
      "Episode reward: 53.936877\n",
      "Episode reward: 40.949355\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3388     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 166045   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0033   |\n",
      "|    n_updates        | 41486    |\n",
      "----------------------------------\n",
      "Episode reward: 52.792249\n",
      "Episode reward: 54.937148\n",
      "Episode reward: 63.463326\n",
      "Episode reward: 50.899959\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.5     |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3392     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 166268   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.257    |\n",
      "|    n_updates        | 41541    |\n",
      "----------------------------------\n",
      "Episode reward: 56.621746\n",
      "Episode reward: 35.879942\n",
      "Episode reward: 44.839481\n",
      "Episode reward: 95.741957\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3396     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 166502   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.264    |\n",
      "|    n_updates        | 41600    |\n",
      "----------------------------------\n",
      "Episode reward: 87.862071\n",
      "Episode reward: 67.707292\n",
      "Episode reward: 57.704837\n",
      "Episode reward: 54.896642\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3400     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 166772   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.301    |\n",
      "|    n_updates        | 41667    |\n",
      "----------------------------------\n",
      "Episode reward: 37.940424\n",
      "Episode reward: 58.888543\n",
      "Episode reward: 63.849586\n",
      "Episode reward: 44.907229\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3404     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 166978   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.663    |\n",
      "|    n_updates        | 41719    |\n",
      "----------------------------------\n",
      "Episode reward: 126.820185\n",
      "Episode reward: 48.654988\n",
      "Episode reward: 108.094595\n",
      "Episode reward: 66.861898\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3408     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 167331   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00424  |\n",
      "|    n_updates        | 41807    |\n",
      "----------------------------------\n",
      "Episode reward: 29.857156\n",
      "Episode reward: 31.904387\n",
      "Episode reward: 116.483263\n",
      "Episode reward: 74.914259\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3412     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 167591   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.238    |\n",
      "|    n_updates        | 41872    |\n",
      "----------------------------------\n",
      "Episode reward: 44.328008\n",
      "Episode reward: 36.882171\n",
      "Episode reward: 73.792183\n",
      "Episode reward: 44.897001\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3416     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 167792   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00429  |\n",
      "|    n_updates        | 41922    |\n",
      "----------------------------------\n",
      "Episode reward: 45.525147\n",
      "Episode reward: 35.900836\n",
      "Episode reward: 44.949933\n",
      "Episode reward: 75.873372\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3420     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 167995   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00311  |\n",
      "|    n_updates        | 41973    |\n",
      "----------------------------------\n",
      "Episode reward: 50.871061\n",
      "Episode reward: 62.878826\n",
      "Episode reward: 42.517948\n",
      "Episode reward: 40.84704\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3424     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 168193   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.181    |\n",
      "|    n_updates        | 42023    |\n",
      "----------------------------------\n",
      "Episode reward: 35.897655\n",
      "Episode reward: 79.804595\n",
      "Episode reward: 47.927933\n",
      "Episode reward: 67.532794\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3428     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 168428   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.219    |\n",
      "|    n_updates        | 42081    |\n",
      "----------------------------------\n",
      "Episode reward: 41.867749\n",
      "Episode reward: 42.886017\n",
      "Episode reward: 38.932945\n",
      "Episode reward: 57.877323\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3432     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 168610   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 42127    |\n",
      "----------------------------------\n",
      "Episode reward: 52.773267\n",
      "Episode reward: 41.818319\n",
      "Episode reward: 70.91074\n",
      "Episode reward: 40.578552\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3436     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 168817   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.186    |\n",
      "|    n_updates        | 42179    |\n",
      "----------------------------------\n",
      "Episode reward: 115.493933\n",
      "Episode reward: 84.29761\n",
      "Episode reward: 66.244301\n",
      "Episode reward: 74.762009\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3440     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 169162   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0067   |\n",
      "|    n_updates        | 42265    |\n",
      "----------------------------------\n",
      "Episode reward: 51.823759\n",
      "Episode reward: 69.758184\n",
      "Episode reward: 54.933095\n",
      "Episode reward: 77.838494\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3444     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 169417   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00505  |\n",
      "|    n_updates        | 42329    |\n",
      "----------------------------------\n",
      "Episode reward: 71.701684\n",
      "Episode reward: 53.680194\n",
      "Episode reward: 54.917776\n",
      "Episode reward: 43.941153\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3448     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 169642   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00915  |\n",
      "|    n_updates        | 42385    |\n",
      "----------------------------------\n",
      "Episode reward: 37.825432\n",
      "Episode reward: 43.93187\n",
      "Episode reward: 78.558988\n",
      "Episode reward: 49.845143\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3452     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 169853   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00168  |\n",
      "|    n_updates        | 42438    |\n",
      "----------------------------------\n",
      "Episode reward: 43.838652\n",
      "Episode reward: 50.805949\n",
      "Episode reward: 62.303868\n",
      "Episode reward: 61.495379\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3456     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 170074   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.021    |\n",
      "|    n_updates        | 42493    |\n",
      "----------------------------------\n",
      "Episode reward: 50.906386\n",
      "Episode reward: 39.912992\n",
      "Episode reward: 67.89171\n",
      "Episode reward: 56.608987\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3460     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 170290   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.219    |\n",
      "|    n_updates        | 42547    |\n",
      "----------------------------------\n",
      "Episode reward: 60.654883\n",
      "Episode reward: 42.781094\n",
      "Episode reward: 53.19747\n",
      "Episode reward: 58.896134\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3464     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 170507   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.247    |\n",
      "|    n_updates        | 42601    |\n",
      "----------------------------------\n",
      "Episode reward: 60.910177\n",
      "Episode reward: 71.792427\n",
      "Episode reward: 51.943825\n",
      "Episode reward: 30.938356\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3468     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 170723   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00461  |\n",
      "|    n_updates        | 42655    |\n",
      "----------------------------------\n",
      "Episode reward: 44.925059\n",
      "Episode reward: 34.701475\n",
      "Episode reward: 50.794002\n",
      "Episode reward: 78.707735\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3472     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 170933   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.463    |\n",
      "|    n_updates        | 42708    |\n",
      "----------------------------------\n",
      "Episode reward: 47.870833\n",
      "Episode reward: 37.943034\n",
      "Episode reward: 49.672538\n",
      "Episode reward: 48.910204\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3476     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 171118   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 42754    |\n",
      "----------------------------------\n",
      "Episode reward: 33.679344\n",
      "Episode reward: 63.685059\n",
      "Episode reward: 44.635148\n",
      "Episode reward: 101.879913\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3480     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 171363   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00409  |\n",
      "|    n_updates        | 42815    |\n",
      "----------------------------------\n",
      "Episode reward: 69.771061\n",
      "Episode reward: 54.111614\n",
      "Episode reward: 43.781324\n",
      "Episode reward: 42.886755\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3484     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 171575   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00313  |\n",
      "|    n_updates        | 42868    |\n",
      "----------------------------------\n",
      "Episode reward: 50.222568\n",
      "Episode reward: 87.962081\n",
      "Episode reward: 69.574547\n",
      "Episode reward: 52.819752\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3488     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 171840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00609  |\n",
      "|    n_updates        | 42934    |\n",
      "----------------------------------\n",
      "Episode reward: 59.687596\n",
      "Episode reward: 59.804996\n",
      "Episode reward: 76.670183\n",
      "Episode reward: 59.915087\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3492     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 172098   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.261    |\n",
      "|    n_updates        | 42999    |\n",
      "----------------------------------\n",
      "Episode reward: 32.936291\n",
      "Episode reward: 35.834159\n",
      "Episode reward: 59.815286\n",
      "Episode reward: 42.912378\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3496     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 172270   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.263    |\n",
      "|    n_updates        | 43042    |\n",
      "----------------------------------\n",
      "Episode reward: 57.558389\n",
      "Episode reward: 124.336186\n",
      "Episode reward: 94.861296\n",
      "Episode reward: 45.520048\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3500     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 172594   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.898    |\n",
      "|    n_updates        | 43123    |\n",
      "----------------------------------\n",
      "Episode reward: 70.370777\n",
      "Episode reward: 48.850078\n",
      "Episode reward: 64.384044\n",
      "Episode reward: 51.714496\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3504     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 172831   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00179  |\n",
      "|    n_updates        | 43182    |\n",
      "----------------------------------\n",
      "Episode reward: 95.388948\n",
      "Episode reward: 135.467766\n",
      "Episode reward: 86.484027\n",
      "Episode reward: 47.887472\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3508     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 173198   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00394  |\n",
      "|    n_updates        | 43274    |\n",
      "----------------------------------\n",
      "Episode reward: 59.855818\n",
      "Episode reward: 58.76573\n",
      "Episode reward: 42.654385\n",
      "Episode reward: 37.933236\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3512     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 173398   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.272    |\n",
      "|    n_updates        | 43324    |\n",
      "----------------------------------\n",
      "Episode reward: 57.912607\n",
      "Episode reward: 49.923425\n",
      "Episode reward: 57.66856\n",
      "Episode reward: 62.49302\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3516     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 173627   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00167  |\n",
      "|    n_updates        | 43381    |\n",
      "----------------------------------\n",
      "Episode reward: 37.947705\n",
      "Episode reward: 93.806837\n",
      "Episode reward: 47.066964\n",
      "Episode reward: 51.701856\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3520     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 173859   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0807   |\n",
      "|    n_updates        | 43439    |\n",
      "----------------------------------\n",
      "Episode reward: 76.57127\n",
      "Episode reward: 34.670176\n",
      "Episode reward: 56.883896\n",
      "Episode reward: 38.674508\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3524     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 174067   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.092    |\n",
      "|    n_updates        | 43491    |\n",
      "----------------------------------\n",
      "Episode reward: 37.806286\n",
      "Episode reward: 34.909166\n",
      "Episode reward: 35.808066\n",
      "Episode reward: 57.859172\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3528     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 174234   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.353    |\n",
      "|    n_updates        | 43533    |\n",
      "----------------------------------\n",
      "Episode reward: 38.410416\n",
      "Episode reward: 79.36283\n",
      "Episode reward: 43.57293\n",
      "Episode reward: 33.784558\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3532     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 174431   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.258    |\n",
      "|    n_updates        | 43582    |\n",
      "----------------------------------\n",
      "Episode reward: 37.737297\n",
      "Episode reward: 30.947111\n",
      "Episode reward: 44.762245\n",
      "Episode reward: 53.919137\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3536     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 174599   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 43624    |\n",
      "----------------------------------\n",
      "Episode reward: 45.774887\n",
      "Episode reward: 50.843365\n",
      "Episode reward: 53.935903\n",
      "Episode reward: 52.870085\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3540     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 174803   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.394    |\n",
      "|    n_updates        | 43675    |\n",
      "----------------------------------\n",
      "Episode reward: 62.291989\n",
      "Episode reward: 45.662905\n",
      "Episode reward: 63.743533\n",
      "Episode reward: 60.913969\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3544     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 175037   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0033   |\n",
      "|    n_updates        | 43734    |\n",
      "----------------------------------\n",
      "Episode reward: 65.053474\n",
      "Episode reward: 54.905909\n",
      "Episode reward: 45.79812\n",
      "Episode reward: 40.932254\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3548     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 175245   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.758    |\n",
      "|    n_updates        | 43786    |\n",
      "----------------------------------\n",
      "Episode reward: 44.817835\n",
      "Episode reward: 39.593262\n",
      "Episode reward: 49.855798\n",
      "Episode reward: 67.659859\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3552     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 175448   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.281    |\n",
      "|    n_updates        | 43836    |\n",
      "----------------------------------\n",
      "Episode reward: 35.701438\n",
      "Episode reward: 50.943305\n",
      "Episode reward: 61.333433\n",
      "Episode reward: 82.589301\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3556     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 175681   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.613    |\n",
      "|    n_updates        | 43895    |\n",
      "----------------------------------\n",
      "Episode reward: 91.2013\n",
      "Episode reward: 54.896186\n",
      "Episode reward: 54.91621\n",
      "Episode reward: 46.916847\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3560     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 175930   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.231    |\n",
      "|    n_updates        | 43957    |\n",
      "----------------------------------\n",
      "Episode reward: 75.910429\n",
      "Episode reward: 167.786532\n",
      "Episode reward: 49.620015\n",
      "Episode reward: 62.908597\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3564     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 176287   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.181    |\n",
      "|    n_updates        | 44046    |\n",
      "----------------------------------\n",
      "Episode reward: 56.901401\n",
      "Episode reward: 39.947493\n",
      "Episode reward: 57.863619\n",
      "Episode reward: 56.901433\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3568     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 176499   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.416    |\n",
      "|    n_updates        | 44099    |\n",
      "----------------------------------\n",
      "Episode reward: 46.544433\n",
      "Episode reward: 43.681616\n",
      "Episode reward: 75.358675\n",
      "Episode reward: 67.760901\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3572     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 176734   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.235    |\n",
      "|    n_updates        | 44158    |\n",
      "----------------------------------\n",
      "Episode reward: 42.789132\n",
      "Episode reward: 52.706307\n",
      "Episode reward: 71.896988\n",
      "Episode reward: 43.72761\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3576     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 176946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00395  |\n",
      "|    n_updates        | 44211    |\n",
      "----------------------------------\n",
      "Episode reward: 51.873488\n",
      "Episode reward: 85.904186\n",
      "Episode reward: 38.960344\n",
      "Episode reward: 65.849691\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3580     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 177189   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00863  |\n",
      "|    n_updates        | 44272    |\n",
      "----------------------------------\n",
      "Episode reward: 47.745074\n",
      "Episode reward: 100.558\n",
      "Episode reward: 56.91379\n",
      "Episode reward: 36.930624\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3584     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 177442   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.473    |\n",
      "|    n_updates        | 44335    |\n",
      "----------------------------------\n",
      "Episode reward: 45.828316\n",
      "Episode reward: 99.19106\n",
      "Episode reward: 42.775251\n",
      "Episode reward: 72.774339\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3588     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 177705   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00325  |\n",
      "|    n_updates        | 44401    |\n",
      "----------------------------------\n",
      "Episode reward: 38.955764\n",
      "Episode reward: 41.878156\n",
      "Episode reward: 40.934094\n",
      "Episode reward: 48.764623\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3592     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 177876   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.229    |\n",
      "|    n_updates        | 44443    |\n",
      "----------------------------------\n",
      "Episode reward: 72.904115\n",
      "Episode reward: 63.916913\n",
      "Episode reward: 86.354369\n",
      "Episode reward: 41.915945\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3596     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 178143   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00167  |\n",
      "|    n_updates        | 44510    |\n",
      "----------------------------------\n",
      "Episode reward: 63.630532\n",
      "Episode reward: 68.617407\n",
      "Episode reward: 44.928484\n",
      "Episode reward: 26.840497\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3600     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 178348   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.174    |\n",
      "|    n_updates        | 44561    |\n",
      "----------------------------------\n",
      "Episode reward: 57.912517\n",
      "Episode reward: 79.430551\n",
      "Episode reward: 71.903557\n",
      "Episode reward: 56.354352\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3604     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 178615   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.112    |\n",
      "|    n_updates        | 44628    |\n",
      "----------------------------------\n",
      "Episode reward: 60.888668\n",
      "Episode reward: 51.946462\n",
      "Episode reward: 59.799166\n",
      "Episode reward: 55.686577\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3608     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 178844   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.261    |\n",
      "|    n_updates        | 44685    |\n",
      "----------------------------------\n",
      "Episode reward: 58.539628\n",
      "Episode reward: 50.920265\n",
      "Episode reward: 49.92775\n",
      "Episode reward: 86.559488\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3612     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 179091   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00721  |\n",
      "|    n_updates        | 44747    |\n",
      "----------------------------------\n",
      "Episode reward: 64.758425\n",
      "Episode reward: 37.820487\n",
      "Episode reward: 50.831997\n",
      "Episode reward: 58.930372\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3616     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 179304   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.298    |\n",
      "|    n_updates        | 44800    |\n",
      "----------------------------------\n",
      "Episode reward: 48.935427\n",
      "Episode reward: 53.572692\n",
      "Episode reward: 82.356631\n",
      "Episode reward: 35.86818\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3620     |\n",
      "|    fps              | 3317     |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 179527   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.293    |\n",
      "|    n_updates        | 44856    |\n",
      "----------------------------------\n",
      "Episode reward: 70.804943\n",
      "Episode reward: 73.888672\n",
      "Episode reward: 41.930871\n",
      "Episode reward: 99.072602\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3624     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 179814   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.242    |\n",
      "|    n_updates        | 44928    |\n",
      "----------------------------------\n",
      "Episode reward: 33.925979\n",
      "Episode reward: 91.543066\n",
      "Episode reward: 44.794614\n",
      "Episode reward: 43.895692\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3628     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 180029   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0542   |\n",
      "|    n_updates        | 44982    |\n",
      "----------------------------------\n",
      "Episode reward: 81.231318\n",
      "Episode reward: 45.876033\n",
      "Episode reward: 63.001729\n",
      "Episode reward: 45.782882\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3632     |\n",
      "|    fps              | 3317     |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 180267   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0065   |\n",
      "|    n_updates        | 45041    |\n",
      "----------------------------------\n",
      "Episode reward: 76.395873\n",
      "Episode reward: 49.828875\n",
      "Episode reward: 49.904683\n",
      "Episode reward: 38.546821\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3636     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 180483   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.564    |\n",
      "|    n_updates        | 45095    |\n",
      "----------------------------------\n",
      "Episode reward: 64.894195\n",
      "Episode reward: 60.861016\n",
      "Episode reward: 49.623989\n",
      "Episode reward: 44.944227\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3640     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 180704   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00817  |\n",
      "|    n_updates        | 45150    |\n",
      "----------------------------------\n",
      "Episode reward: 51.298553\n",
      "Episode reward: 49.820029\n",
      "Episode reward: 37.760862\n",
      "Episode reward: 77.881781\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3644     |\n",
      "|    fps              | 3317     |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 180922   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.379    |\n",
      "|    n_updates        | 45205    |\n",
      "----------------------------------\n",
      "Episode reward: 66.914707\n",
      "Episode reward: 94.764833\n",
      "Episode reward: 45.850719\n",
      "Episode reward: 48.616354\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3648     |\n",
      "|    fps              | 3317     |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 181179   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.24     |\n",
      "|    n_updates        | 45269    |\n",
      "----------------------------------\n",
      "Episode reward: 63.710143\n",
      "Episode reward: 58.704103\n",
      "Episode reward: 72.920141\n",
      "Episode reward: 59.69155\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3652     |\n",
      "|    fps              | 3318     |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 181435   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 45333    |\n",
      "----------------------------------\n",
      "Episode reward: 38.891526\n",
      "Episode reward: 35.869908\n",
      "Episode reward: 54.934545\n",
      "Episode reward: 68.365129\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3656     |\n",
      "|    fps              | 3317     |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 181634   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0398   |\n",
      "|    n_updates        | 45383    |\n",
      "----------------------------------\n",
      "Episode reward: 65.858313\n",
      "Episode reward: 47.941709\n",
      "Episode reward: 46.851321\n",
      "Episode reward: 45.417943\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3660     |\n",
      "|    fps              | 3317     |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 181841   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.496    |\n",
      "|    n_updates        | 45435    |\n",
      "----------------------------------\n",
      "Episode reward: 48.75334\n",
      "Episode reward: 68.803191\n",
      "Episode reward: 38.82249\n",
      "Episode reward: 77.883982\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3664     |\n",
      "|    fps              | 3317     |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 182077   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.177    |\n",
      "|    n_updates        | 45494    |\n",
      "----------------------------------\n",
      "Episode reward: 39.657726\n",
      "Episode reward: 44.905317\n",
      "Episode reward: 60.576183\n",
      "Episode reward: 56.479589\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3668     |\n",
      "|    fps              | 3317     |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 182280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00417  |\n",
      "|    n_updates        | 45544    |\n",
      "----------------------------------\n",
      "Episode reward: 62.541572\n",
      "Episode reward: 34.945267\n",
      "Episode reward: 77.88111\n",
      "Episode reward: 44.730705\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3672     |\n",
      "|    fps              | 3317     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 182501   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00615  |\n",
      "|    n_updates        | 45600    |\n",
      "----------------------------------\n",
      "Episode reward: 64.901631\n",
      "Episode reward: 73.400737\n",
      "Episode reward: 46.897007\n",
      "Episode reward: 75.900221\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3676     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 182763   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00646  |\n",
      "|    n_updates        | 45665    |\n",
      "----------------------------------\n",
      "Episode reward: 48.943202\n",
      "Episode reward: 55.759871\n",
      "Episode reward: 30.829077\n",
      "Episode reward: 54.714597\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3680     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 182954   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00577  |\n",
      "|    n_updates        | 45713    |\n",
      "----------------------------------\n",
      "Episode reward: 52.908645\n",
      "Episode reward: 54.923512\n",
      "Episode reward: 40.71598\n",
      "Episode reward: 42.904839\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3684     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 183146   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0894   |\n",
      "|    n_updates        | 45761    |\n",
      "----------------------------------\n",
      "Episode reward: 57.698479\n",
      "Episode reward: 56.90199\n",
      "Episode reward: 37.601949\n",
      "Episode reward: 59.90164\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3688     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 183359   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00278  |\n",
      "|    n_updates        | 45814    |\n",
      "----------------------------------\n",
      "Episode reward: 69.825014\n",
      "Episode reward: 41.910695\n",
      "Episode reward: 65.894406\n",
      "Episode reward: 59.867206\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3692     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 183597   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 45874    |\n",
      "----------------------------------\n",
      "Episode reward: 35.806908\n",
      "Episode reward: 86.883994\n",
      "Episode reward: 36.773743\n",
      "Episode reward: 57.918287\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3696     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 183815   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.235    |\n",
      "|    n_updates        | 45928    |\n",
      "----------------------------------\n",
      "Episode reward: 48.900833\n",
      "Episode reward: 69.162325\n",
      "Episode reward: 57.464885\n",
      "Episode reward: 46.940159\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3700     |\n",
      "|    fps              | 3316     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 184040   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.361    |\n",
      "|    n_updates        | 45984    |\n",
      "----------------------------------\n",
      "Episode reward: 40.900653\n",
      "Episode reward: 82.306802\n",
      "Episode reward: 80.395625\n",
      "Episode reward: 48.837515\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3704     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 184295   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.268    |\n",
      "|    n_updates        | 46048    |\n",
      "----------------------------------\n",
      "Episode reward: 67.805233\n",
      "Episode reward: 78.035299\n",
      "Episode reward: 38.92502\n",
      "Episode reward: 52.711077\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3708     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 184534   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.391    |\n",
      "|    n_updates        | 46108    |\n",
      "----------------------------------\n",
      "Episode reward: 47.916183\n",
      "Episode reward: 45.934389\n",
      "Episode reward: 111.616289\n",
      "Episode reward: 39.930249\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3712     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 184780   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00169  |\n",
      "|    n_updates        | 46169    |\n",
      "----------------------------------\n",
      "Episode reward: 39.807188\n",
      "Episode reward: 68.730782\n",
      "Episode reward: 40.347823\n",
      "Episode reward: 52.918776\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3716     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 184983   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.189    |\n",
      "|    n_updates        | 46220    |\n",
      "----------------------------------\n",
      "Episode reward: 74.1402\n",
      "Episode reward: 45.93193\n",
      "Episode reward: 51.961275\n",
      "Episode reward: 46.923682\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3720     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 185204   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.104    |\n",
      "|    n_updates        | 46275    |\n",
      "----------------------------------\n",
      "Episode reward: 56.903712\n",
      "Episode reward: 37.839908\n",
      "Episode reward: 40.586484\n",
      "Episode reward: 83.619243\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3724     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 185425   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.004    |\n",
      "|    n_updates        | 46331    |\n",
      "----------------------------------\n",
      "Episode reward: 40.940152\n",
      "Episode reward: 48.940937\n",
      "Episode reward: 43.548689\n",
      "Episode reward: 82.799644\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3728     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 185642   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.154    |\n",
      "|    n_updates        | 46385    |\n",
      "----------------------------------\n",
      "Episode reward: 41.685786\n",
      "Episode reward: 84.863978\n",
      "Episode reward: 76.515202\n",
      "Episode reward: 51.650697\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3732     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 185898   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00397  |\n",
      "|    n_updates        | 46449    |\n",
      "----------------------------------\n",
      "Episode reward: 51.943818\n",
      "Episode reward: 61.672956\n",
      "Episode reward: 45.737622\n",
      "Episode reward: 42.878028\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3736     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 186101   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.162    |\n",
      "|    n_updates        | 46500    |\n",
      "----------------------------------\n",
      "Episode reward: 87.724817\n",
      "Episode reward: 61.418837\n",
      "Episode reward: 63.725295\n",
      "Episode reward: 121.739867\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3740     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 186439   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00472  |\n",
      "|    n_updates        | 46584    |\n",
      "----------------------------------\n",
      "Episode reward: 42.680206\n",
      "Episode reward: 47.517165\n",
      "Episode reward: 167.6821\n",
      "Episode reward: 62.757129\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3744     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 186765   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.256    |\n",
      "|    n_updates        | 46666    |\n",
      "----------------------------------\n",
      "Episode reward: 43.927164\n",
      "Episode reward: 33.933318\n",
      "Episode reward: 87.353555\n",
      "Episode reward: 39.926869\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3748     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 186971   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00924  |\n",
      "|    n_updates        | 46717    |\n",
      "----------------------------------\n",
      "Episode reward: 76.741417\n",
      "Episode reward: 48.947486\n",
      "Episode reward: 38.817747\n",
      "Episode reward: 105.812053\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3752     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 187243   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.028    |\n",
      "|    n_updates        | 46785    |\n",
      "----------------------------------\n",
      "Episode reward: 61.63385\n",
      "Episode reward: 34.783444\n",
      "Episode reward: 61.895229\n",
      "Episode reward: 76.771167\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3756     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 187479   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.446    |\n",
      "|    n_updates        | 46844    |\n",
      "----------------------------------\n",
      "Episode reward: 54.691249\n",
      "Episode reward: 45.933578\n",
      "Episode reward: 48.918329\n",
      "Episode reward: 43.918742\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3760     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 187673   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.216    |\n",
      "|    n_updates        | 46893    |\n",
      "----------------------------------\n",
      "Episode reward: 67.83031\n",
      "Episode reward: 42.884901\n",
      "Episode reward: 40.946695\n",
      "Episode reward: 36.912716\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3764     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 187862   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.179    |\n",
      "|    n_updates        | 46940    |\n",
      "----------------------------------\n",
      "Episode reward: 45.673729\n",
      "Episode reward: 67.835232\n",
      "Episode reward: 74.461425\n",
      "Episode reward: 45.872337\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3768     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 188097   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0298   |\n",
      "|    n_updates        | 46999    |\n",
      "----------------------------------\n",
      "Episode reward: 63.886207\n",
      "Episode reward: 131.7553\n",
      "Episode reward: 51.918557\n",
      "Episode reward: 47.940636\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3772     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 188396   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00376  |\n",
      "|    n_updates        | 47073    |\n",
      "----------------------------------\n",
      "Episode reward: 41.171573\n",
      "Episode reward: 66.772437\n",
      "Episode reward: 49.913697\n",
      "Episode reward: 89.373976\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3776     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 188645   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.135    |\n",
      "|    n_updates        | 47136    |\n",
      "----------------------------------\n",
      "Episode reward: 32.765406\n",
      "Episode reward: 35.901246\n",
      "Episode reward: 30.931975\n",
      "Episode reward: 48.934233\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3780     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 188794   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.164    |\n",
      "|    n_updates        | 47173    |\n",
      "----------------------------------\n",
      "Episode reward: 54.557493\n",
      "Episode reward: 43.50303\n",
      "Episode reward: 48.583365\n",
      "Episode reward: 40.896252\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3784     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 188983   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00242  |\n",
      "|    n_updates        | 47220    |\n",
      "----------------------------------\n",
      "Episode reward: 63.7938\n",
      "Episode reward: 85.773847\n",
      "Episode reward: 45.895003\n",
      "Episode reward: 44.912849\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3788     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 189224   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00458  |\n",
      "|    n_updates        | 47280    |\n",
      "----------------------------------\n",
      "Episode reward: 64.893869\n",
      "Episode reward: 58.558718\n",
      "Episode reward: 42.923306\n",
      "Episode reward: 62.737956\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3792     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 189454   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00461  |\n",
      "|    n_updates        | 47338    |\n",
      "----------------------------------\n",
      "Episode reward: 85.015859\n",
      "Episode reward: 55.939779\n",
      "Episode reward: 41.933543\n",
      "Episode reward: 83.044467\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3796     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 189724   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0845   |\n",
      "|    n_updates        | 47405    |\n",
      "----------------------------------\n",
      "Episode reward: 75.42929\n",
      "Episode reward: 46.854778\n",
      "Episode reward: 70.785314\n",
      "Episode reward: 35.901539\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3800     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 189954   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.231    |\n",
      "|    n_updates        | 47463    |\n",
      "----------------------------------\n",
      "Episode reward: 41.683567\n",
      "Episode reward: 51.92023\n",
      "Episode reward: 48.877537\n",
      "Episode reward: 63.920606\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3804     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 190161   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0283   |\n",
      "|    n_updates        | 47515    |\n",
      "----------------------------------\n",
      "Episode reward: 70.598727\n",
      "Episode reward: 52.58999\n",
      "Episode reward: 93.426253\n",
      "Episode reward: 89.083965\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3808     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 190469   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.21     |\n",
      "|    n_updates        | 47592    |\n",
      "----------------------------------\n",
      "Episode reward: 39.926918\n",
      "Episode reward: 67.875832\n",
      "Episode reward: 59.951729\n",
      "Episode reward: 96.798813\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3812     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 190735   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.256    |\n",
      "|    n_updates        | 47658    |\n",
      "----------------------------------\n",
      "Episode reward: 98.755467\n",
      "Episode reward: 62.559739\n",
      "Episode reward: 55.941789\n",
      "Episode reward: 41.934526\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3816     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 190997   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00522  |\n",
      "|    n_updates        | 47724    |\n",
      "----------------------------------\n",
      "Episode reward: 44.895168\n",
      "Episode reward: 38.495873\n",
      "Episode reward: 39.905992\n",
      "Episode reward: 75.753803\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3820     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 191198   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.201    |\n",
      "|    n_updates        | 47774    |\n",
      "----------------------------------\n",
      "Episode reward: 37.847604\n",
      "Episode reward: 34.940479\n",
      "Episode reward: 37.908242\n",
      "Episode reward: 60.343759\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3824     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 191370   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.231    |\n",
      "|    n_updates        | 47817    |\n",
      "----------------------------------\n",
      "Episode reward: 63.594372\n",
      "Episode reward: 86.771941\n",
      "Episode reward: 46.858808\n",
      "Episode reward: 41.65781\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3828     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 191610   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00324  |\n",
      "|    n_updates        | 47877    |\n",
      "----------------------------------\n",
      "Episode reward: 39.948127\n",
      "Episode reward: 41.580197\n",
      "Episode reward: 46.909192\n",
      "Episode reward: 50.717857\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3832     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 191791   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00232  |\n",
      "|    n_updates        | 47922    |\n",
      "----------------------------------\n",
      "Episode reward: 53.771673\n",
      "Episode reward: 50.799014\n",
      "Episode reward: 42.931231\n",
      "Episode reward: 55.844445\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3836     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 191995   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0489   |\n",
      "|    n_updates        | 47973    |\n",
      "----------------------------------\n",
      "Episode reward: 47.845196\n",
      "Episode reward: 44.920319\n",
      "Episode reward: 84.107527\n",
      "Episode reward: 39.745358\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3840     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 192213   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00386  |\n",
      "|    n_updates        | 48028    |\n",
      "----------------------------------\n",
      "Episode reward: 53.90153\n",
      "Episode reward: 88.792221\n",
      "Episode reward: 37.944502\n",
      "Episode reward: 40.8866\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3844     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 192435   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00472  |\n",
      "|    n_updates        | 48083    |\n",
      "----------------------------------\n",
      "Episode reward: 34.858296\n",
      "Episode reward: 48.943509\n",
      "Episode reward: 42.953002\n",
      "Episode reward: 32.767935\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3848     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 192595   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00681  |\n",
      "|    n_updates        | 48123    |\n",
      "----------------------------------\n",
      "Episode reward: 74.28474\n",
      "Episode reward: 60.910881\n",
      "Episode reward: 57.723757\n",
      "Episode reward: 98.328952\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3852     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 192888   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0021   |\n",
      "|    n_updates        | 48196    |\n",
      "----------------------------------\n",
      "Episode reward: 55.781892\n",
      "Episode reward: 98.183061\n",
      "Episode reward: 47.861372\n",
      "Episode reward: 100.670239\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3856     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 193194   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.396    |\n",
      "|    n_updates        | 48273    |\n",
      "----------------------------------\n",
      "Episode reward: 52.689258\n",
      "Episode reward: 36.727238\n",
      "Episode reward: 43.704794\n",
      "Episode reward: 88.855104\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3860     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 193417   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.221    |\n",
      "|    n_updates        | 48329    |\n",
      "----------------------------------\n",
      "Episode reward: 45.866364\n",
      "Episode reward: 71.520703\n",
      "Episode reward: 64.78137\n",
      "Episode reward: 52.914372\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3864     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 193653   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.153    |\n",
      "|    n_updates        | 48388    |\n",
      "----------------------------------\n",
      "Episode reward: 94.930312\n",
      "Episode reward: 40.889927\n",
      "Episode reward: 55.909384\n",
      "Episode reward: 91.871061\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3868     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 193938   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00101  |\n",
      "|    n_updates        | 48459    |\n",
      "----------------------------------\n",
      "Episode reward: 108.30872\n",
      "Episode reward: 45.947865\n",
      "Episode reward: 34.935901\n",
      "Episode reward: 53.934148\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3872     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 194182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0979   |\n",
      "|    n_updates        | 48520    |\n",
      "----------------------------------\n",
      "Episode reward: 60.848283\n",
      "Episode reward: 50.938627\n",
      "Episode reward: 48.939329\n",
      "Episode reward: 44.864988\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3876     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 194388   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.397    |\n",
      "|    n_updates        | 48571    |\n",
      "----------------------------------\n",
      "Episode reward: 60.918851\n",
      "Episode reward: 54.834201\n",
      "Episode reward: 58.56146\n",
      "Episode reward: 48.730426\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3880     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 194612   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.681    |\n",
      "|    n_updates        | 48627    |\n",
      "----------------------------------\n",
      "Episode reward: 49.928591\n",
      "Episode reward: 35.82415\n",
      "Episode reward: 60.707333\n",
      "Episode reward: 57.403337\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3884     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 194817   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00525  |\n",
      "|    n_updates        | 48679    |\n",
      "----------------------------------\n",
      "Episode reward: 40.500635\n",
      "Episode reward: 95.683666\n",
      "Episode reward: 47.736069\n",
      "Episode reward: 77.844664\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3888     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 195080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0043   |\n",
      "|    n_updates        | 48744    |\n",
      "----------------------------------\n",
      "Episode reward: 69.900057\n",
      "Episode reward: 42.931198\n",
      "Episode reward: 44.907322\n",
      "Episode reward: 35.726259\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3892     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 195274   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00527  |\n",
      "|    n_updates        | 48793    |\n",
      "----------------------------------\n",
      "Episode reward: 90.291488\n",
      "Episode reward: 40.824565\n",
      "Episode reward: 87.414968\n",
      "Episode reward: 49.296372\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3896     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 195546   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 48861    |\n",
      "----------------------------------\n",
      "Episode reward: 53.891818\n",
      "Episode reward: 49.88196\n",
      "Episode reward: 45.892981\n",
      "Episode reward: 44.523068\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3900     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 195741   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.273    |\n",
      "|    n_updates        | 48910    |\n",
      "----------------------------------\n",
      "Episode reward: 76.608496\n",
      "Episode reward: 43.777765\n",
      "Episode reward: 52.765673\n",
      "Episode reward: 61.913522\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3904     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 195977   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0711   |\n",
      "|    n_updates        | 48969    |\n",
      "----------------------------------\n",
      "Episode reward: 61.688849\n",
      "Episode reward: 72.622825\n",
      "Episode reward: 78.886716\n",
      "Episode reward: 45.923014\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3908     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 196237   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.15     |\n",
      "|    n_updates        | 49034    |\n",
      "----------------------------------\n",
      "Episode reward: 43.933721\n",
      "Episode reward: 41.902265\n",
      "Episode reward: 67.503171\n",
      "Episode reward: 58.906968\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3912     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 196450   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.511    |\n",
      "|    n_updates        | 49087    |\n",
      "----------------------------------\n",
      "Episode reward: 81.802608\n",
      "Episode reward: 53.662635\n",
      "Episode reward: 77.454722\n",
      "Episode reward: 65.899784\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3916     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 196730   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.251    |\n",
      "|    n_updates        | 49157    |\n",
      "----------------------------------\n",
      "Episode reward: 95.822008\n",
      "Episode reward: 99.607456\n",
      "Episode reward: 53.912\n",
      "Episode reward: 61.831507\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3920     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 197044   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00171  |\n",
      "|    n_updates        | 49235    |\n",
      "----------------------------------\n",
      "Episode reward: 58.608406\n",
      "Episode reward: 44.843258\n",
      "Episode reward: 37.804536\n",
      "Episode reward: 45.877374\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3924     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 197232   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.175    |\n",
      "|    n_updates        | 49282    |\n",
      "----------------------------------\n",
      "Episode reward: 46.708196\n",
      "Episode reward: 38.536816\n",
      "Episode reward: 64.233029\n",
      "Episode reward: 37.921184\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3928     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 197421   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.184    |\n",
      "|    n_updates        | 49330    |\n",
      "----------------------------------\n",
      "Episode reward: 50.922955\n",
      "Episode reward: 42.924445\n",
      "Episode reward: 36.932662\n",
      "Episode reward: 55.932031\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3932     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 197608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00395  |\n",
      "|    n_updates        | 49376    |\n",
      "----------------------------------\n",
      "Episode reward: 50.905574\n",
      "Episode reward: 35.878564\n",
      "Episode reward: 70.348693\n",
      "Episode reward: 43.924449\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3936     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 197810   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.736    |\n",
      "|    n_updates        | 49427    |\n",
      "----------------------------------\n",
      "Episode reward: 53.920191\n",
      "Episode reward: 42.901115\n",
      "Episode reward: 50.884693\n",
      "Episode reward: 68.901902\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3940     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 198027   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00122  |\n",
      "|    n_updates        | 49481    |\n",
      "----------------------------------\n",
      "Episode reward: 47.930524\n",
      "Episode reward: 43.875984\n",
      "Episode reward: 80.914119\n",
      "Episode reward: 39.869825\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3944     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 198240   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.295    |\n",
      "|    n_updates        | 49534    |\n",
      "----------------------------------\n",
      "Episode reward: 37.902695\n",
      "Episode reward: 68.916299\n",
      "Episode reward: 40.938566\n",
      "Episode reward: 39.931274\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3948     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 198428   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.161    |\n",
      "|    n_updates        | 49581    |\n",
      "----------------------------------\n",
      "Episode reward: 95.853201\n",
      "Episode reward: 40.82516\n",
      "Episode reward: 72.237161\n",
      "Episode reward: 66.496738\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3952     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 198705   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00664  |\n",
      "|    n_updates        | 49651    |\n",
      "----------------------------------\n",
      "Episode reward: 34.813761\n",
      "Episode reward: 49.746853\n",
      "Episode reward: 74.827819\n",
      "Episode reward: 69.866581\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3956     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 198935   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00292  |\n",
      "|    n_updates        | 49708    |\n",
      "----------------------------------\n",
      "Episode reward: 42.820642\n",
      "Episode reward: 58.76551\n",
      "Episode reward: 38.955459\n",
      "Episode reward: 45.82258\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3960     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 199122   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00207  |\n",
      "|    n_updates        | 49755    |\n",
      "----------------------------------\n",
      "Episode reward: 82.256541\n",
      "Episode reward: 125.84253\n",
      "Episode reward: 47.667552\n",
      "Episode reward: 56.866513\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3964     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 199436   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00333  |\n",
      "|    n_updates        | 49833    |\n",
      "----------------------------------\n",
      "Episode reward: 33.900781\n",
      "Episode reward: 56.925891\n",
      "Episode reward: 57.880448\n",
      "Episode reward: 46.257967\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3968     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 199632   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00317  |\n",
      "|    n_updates        | 49882    |\n",
      "----------------------------------\n",
      "Episode reward: 43.950013\n",
      "Episode reward: 41.863198\n",
      "Episode reward: 39.910614\n",
      "Episode reward: 84.620015\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3972     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 199843   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.766    |\n",
      "|    n_updates        | 49935    |\n",
      "----------------------------------\n",
      "Episode reward: 67.830431\n",
      "Episode reward: 81.879467\n",
      "Episode reward: 41.926531\n",
      "Episode reward: 46.924298\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3976     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 200082   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 49995    |\n",
      "----------------------------------\n",
      "Episode reward: 66.442003\n",
      "Episode reward: 35.734462\n",
      "Episode reward: 44.878155\n",
      "Episode reward: 45.651861\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3980     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 200276   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00698  |\n",
      "|    n_updates        | 50043    |\n",
      "----------------------------------\n",
      "Episode reward: 43.482479\n",
      "Episode reward: 78.321432\n",
      "Episode reward: 51.794103\n",
      "Episode reward: 40.739575\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3984     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 200493   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00321  |\n",
      "|    n_updates        | 50098    |\n",
      "----------------------------------\n",
      "Episode reward: 57.81514\n",
      "Episode reward: 49.421994\n",
      "Episode reward: 98.349405\n",
      "Episode reward: 34.734434\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3988     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 200736   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 50158    |\n",
      "----------------------------------\n",
      "Episode reward: 45.92767\n",
      "Episode reward: 36.949223\n",
      "Episode reward: 94.610935\n",
      "Episode reward: 55.87526\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3992     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 200972   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.145    |\n",
      "|    n_updates        | 50217    |\n",
      "----------------------------------\n",
      "Episode reward: 35.754008\n",
      "Episode reward: 86.468804\n",
      "Episode reward: 52.920092\n",
      "Episode reward: 68.535546\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 3996     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 201217   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.278    |\n",
      "|    n_updates        | 50279    |\n",
      "----------------------------------\n",
      "Episode reward: 61.854462\n",
      "Episode reward: 39.766929\n",
      "Episode reward: 94.302726\n",
      "Episode reward: 62.776713\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4000     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 201477   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.31     |\n",
      "|    n_updates        | 50344    |\n",
      "----------------------------------\n",
      "Episode reward: 33.865502\n",
      "Episode reward: 73.886651\n",
      "Episode reward: 43.89052\n",
      "Episode reward: 44.847926\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4004     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 201674   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00576  |\n",
      "|    n_updates        | 50393    |\n",
      "----------------------------------\n",
      "Episode reward: 78.731705\n",
      "Episode reward: 68.490845\n",
      "Episode reward: 65.479023\n",
      "Episode reward: 66.997263\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4008     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 201956   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.336    |\n",
      "|    n_updates        | 50463    |\n",
      "----------------------------------\n",
      "Episode reward: 33.813426\n",
      "Episode reward: 72.503673\n",
      "Episode reward: 45.796323\n",
      "Episode reward: 69.848796\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4012     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 60       |\n",
      "|    total_timesteps  | 202179   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.134    |\n",
      "|    n_updates        | 50519    |\n",
      "----------------------------------\n",
      "Episode reward: 43.808246\n",
      "Episode reward: 53.800231\n",
      "Episode reward: 33.940436\n",
      "Episode reward: 61.757702\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4016     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 202373   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.232    |\n",
      "|    n_updates        | 50568    |\n",
      "----------------------------------\n",
      "Episode reward: 39.94834\n",
      "Episode reward: 61.816089\n",
      "Episode reward: 43.920871\n",
      "Episode reward: 41.858617\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4020     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 202561   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00863  |\n",
      "|    n_updates        | 50615    |\n",
      "----------------------------------\n",
      "Episode reward: 33.787486\n",
      "Episode reward: 43.73872\n",
      "Episode reward: 75.856593\n",
      "Episode reward: 123.691129\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4024     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 202841   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.366    |\n",
      "|    n_updates        | 50685    |\n",
      "----------------------------------\n",
      "Episode reward: 32.953695\n",
      "Episode reward: 64.163702\n",
      "Episode reward: 79.65785\n",
      "Episode reward: 53.902073\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4028     |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 203073   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 50743    |\n",
      "----------------------------------\n",
      "Episode reward: 38.87929\n",
      "Episode reward: 59.77695\n",
      "Episode reward: 61.405881\n",
      "Episode reward: 54.904817\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4032     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 203289   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.533    |\n",
      "|    n_updates        | 50797    |\n",
      "----------------------------------\n",
      "Episode reward: 54.678518\n",
      "Episode reward: 46.944558\n",
      "Episode reward: 26.928605\n",
      "Episode reward: 34.78727\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4036     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 203453   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 50838    |\n",
      "----------------------------------\n",
      "Episode reward: 46.936639\n",
      "Episode reward: 43.838401\n",
      "Episode reward: 53.832859\n",
      "Episode reward: 36.82061\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4040     |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 203635   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00699  |\n",
      "|    n_updates        | 50883    |\n",
      "----------------------------------\n",
      "Episode reward: 76.277988\n",
      "Episode reward: 65.885469\n",
      "Episode reward: 38.902726\n",
      "Episode reward: 42.935526\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4044     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 203860   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 50939    |\n",
      "----------------------------------\n",
      "Episode reward: 68.799818\n",
      "Episode reward: 65.356267\n",
      "Episode reward: 27.940242\n",
      "Episode reward: 39.936327\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4048     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 204063   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.486    |\n",
      "|    n_updates        | 50990    |\n",
      "----------------------------------\n",
      "Episode reward: 77.810041\n",
      "Episode reward: 39.589322\n",
      "Episode reward: 50.748535\n",
      "Episode reward: 45.592486\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4052     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 204278   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.752    |\n",
      "|    n_updates        | 51044    |\n",
      "----------------------------------\n",
      "Episode reward: 34.946205\n",
      "Episode reward: 47.3392\n",
      "Episode reward: 66.402605\n",
      "Episode reward: 41.907104\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4056     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 204470   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00382  |\n",
      "|    n_updates        | 51092    |\n",
      "----------------------------------\n",
      "Episode reward: 79.835256\n",
      "Episode reward: 39.912708\n",
      "Episode reward: 49.452669\n",
      "Episode reward: 47.932075\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4060     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 204688   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.209    |\n",
      "|    n_updates        | 51146    |\n",
      "----------------------------------\n",
      "Episode reward: 33.941564\n",
      "Episode reward: 37.747378\n",
      "Episode reward: 93.924912\n",
      "Episode reward: 42.913481\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.6     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4064     |\n",
      "|    fps              | 3313     |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 204899   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 51199    |\n",
      "----------------------------------\n",
      "Episode reward: 45.928756\n",
      "Episode reward: 59.920564\n",
      "Episode reward: 41.807875\n",
      "Episode reward: 33.868511\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4068     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 205082   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00418  |\n",
      "|    n_updates        | 51245    |\n",
      "----------------------------------\n",
      "Episode reward: 62.90276\n",
      "Episode reward: 44.465464\n",
      "Episode reward: 99.091365\n",
      "Episode reward: 47.910456\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55       |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4072     |\n",
      "|    fps              | 3312     |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 205338   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 51309    |\n",
      "----------------------------------\n",
      "Episode reward: 54.859983\n",
      "Episode reward: 44.917632\n",
      "Episode reward: 58.934771\n",
      "Episode reward: 35.918207\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4076     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 205533   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00592  |\n",
      "|    n_updates        | 51358    |\n",
      "----------------------------------\n",
      "Episode reward: 76.718451\n",
      "Episode reward: 40.941394\n",
      "Episode reward: 50.312575\n",
      "Episode reward: 43.724252\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.7     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4080     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 205746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.183    |\n",
      "|    n_updates        | 51411    |\n",
      "----------------------------------\n",
      "Episode reward: 47.070544\n",
      "Episode reward: 48.82931\n",
      "Episode reward: 49.612524\n",
      "Episode reward: 81.90103\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.8     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4084     |\n",
      "|    fps              | 3311     |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 205975   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00809  |\n",
      "|    n_updates        | 51468    |\n",
      "----------------------------------\n",
      "Episode reward: 81.793141\n",
      "Episode reward: 42.793386\n",
      "Episode reward: 66.864057\n",
      "Episode reward: 56.445567\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4088     |\n",
      "|    fps              | 3311     |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 206224   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00703  |\n",
      "|    n_updates        | 51530    |\n",
      "----------------------------------\n",
      "Episode reward: 44.467885\n",
      "Episode reward: 36.930181\n",
      "Episode reward: 62.904529\n",
      "Episode reward: 35.937144\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.3     |\n",
      "|    ep_rew_mean      | 54       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4092     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 206405   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0587   |\n",
      "|    n_updates        | 51576    |\n",
      "----------------------------------\n",
      "Episode reward: 50.92539\n",
      "Episode reward: 48.547156\n",
      "Episode reward: 54.707383\n",
      "Episode reward: 62.926714\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.1     |\n",
      "|    ep_rew_mean      | 53.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4096     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 206623   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.166    |\n",
      "|    n_updates        | 51630    |\n",
      "----------------------------------\n",
      "Episode reward: 38.956857\n",
      "Episode reward: 49.804418\n",
      "Episode reward: 42.778183\n",
      "Episode reward: 73.745227\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.5     |\n",
      "|    ep_rew_mean      | 53.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4100     |\n",
      "|    fps              | 3309     |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 206829   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.243    |\n",
      "|    n_updates        | 51682    |\n",
      "----------------------------------\n",
      "Episode reward: 50.900238\n",
      "Episode reward: 57.883571\n",
      "Episode reward: 109.800269\n",
      "Episode reward: 77.124143\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4104     |\n",
      "|    fps              | 3309     |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 207126   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0038   |\n",
      "|    n_updates        | 51756    |\n",
      "----------------------------------\n",
      "Episode reward: 42.942945\n",
      "Episode reward: 92.659419\n",
      "Episode reward: 59.276281\n",
      "Episode reward: 32.885156\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54       |\n",
      "|    ep_rew_mean      | 53.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4108     |\n",
      "|    fps              | 3309     |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 207356   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00466  |\n",
      "|    n_updates        | 51813    |\n",
      "----------------------------------\n",
      "Episode reward: 59.798493\n",
      "Episode reward: 74.88779\n",
      "Episode reward: 42.895356\n",
      "Episode reward: 36.768567\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.9     |\n",
      "|    ep_rew_mean      | 53.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4112     |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 207571   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.416    |\n",
      "|    n_updates        | 51867    |\n",
      "----------------------------------\n",
      "Episode reward: 59.715857\n",
      "Episode reward: 43.943188\n",
      "Episode reward: 42.90343\n",
      "Episode reward: 33.933821\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.8     |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4116     |\n",
      "|    fps              | 3309     |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 207752   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00249  |\n",
      "|    n_updates        | 51912    |\n",
      "----------------------------------\n",
      "Episode reward: 57.927695\n",
      "Episode reward: 50.924213\n",
      "Episode reward: 55.811539\n",
      "Episode reward: 60.808163\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.2     |\n",
      "|    ep_rew_mean      | 53.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4120     |\n",
      "|    fps              | 3309     |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 207978   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00557  |\n",
      "|    n_updates        | 51969    |\n",
      "----------------------------------\n",
      "Episode reward: 58.91622\n",
      "Episode reward: 88.870401\n",
      "Episode reward: 43.75675\n",
      "Episode reward: 38.902055\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.7     |\n",
      "|    ep_rew_mean      | 53.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4124     |\n",
      "|    fps              | 3309     |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 208209   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.193    |\n",
      "|    n_updates        | 52027    |\n",
      "----------------------------------\n",
      "Episode reward: 75.90462\n",
      "Episode reward: 64.709835\n",
      "Episode reward: 49.876565\n",
      "Episode reward: 46.92687\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.8     |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4128     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 208448   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00882  |\n",
      "|    n_updates        | 52086    |\n",
      "----------------------------------\n",
      "Episode reward: 44.831691\n",
      "Episode reward: 37.954949\n",
      "Episode reward: 60.734953\n",
      "Episode reward: 38.780154\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.4     |\n",
      "|    ep_rew_mean      | 53.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4132     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 208631   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.397    |\n",
      "|    n_updates        | 52132    |\n",
      "----------------------------------\n",
      "Episode reward: 79.053684\n",
      "Episode reward: 43.596105\n",
      "Episode reward: 71.601025\n",
      "Episode reward: 58.903782\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.3     |\n",
      "|    ep_rew_mean      | 54       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4136     |\n",
      "|    fps              | 3307     |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 208886   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00326  |\n",
      "|    n_updates        | 52196    |\n",
      "----------------------------------\n",
      "Episode reward: 128.203293\n",
      "Episode reward: 48.888048\n",
      "Episode reward: 121.089718\n",
      "Episode reward: 34.868811\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4140     |\n",
      "|    fps              | 3307     |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 209222   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.136    |\n",
      "|    n_updates        | 52280    |\n",
      "----------------------------------\n",
      "Episode reward: 42.956152\n",
      "Episode reward: 45.908444\n",
      "Episode reward: 63.734567\n",
      "Episode reward: 43.945088\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4144     |\n",
      "|    fps              | 3307     |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 209419   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0048   |\n",
      "|    n_updates        | 52329    |\n",
      "----------------------------------\n",
      "Episode reward: 49.936981\n",
      "Episode reward: 46.934738\n",
      "Episode reward: 72.670154\n",
      "Episode reward: 102.055855\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4148     |\n",
      "|    fps              | 3307     |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 209692   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00472  |\n",
      "|    n_updates        | 52397    |\n",
      "----------------------------------\n",
      "Episode reward: 45.766211\n",
      "Episode reward: 85.235918\n",
      "Episode reward: 72.472658\n",
      "Episode reward: 52.587865\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4152     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 209950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00225  |\n",
      "|    n_updates        | 52462    |\n",
      "----------------------------------\n",
      "Episode reward: 53.762446\n",
      "Episode reward: 38.925474\n",
      "Episode reward: 53.876872\n",
      "Episode reward: 51.86441\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4156     |\n",
      "|    fps              | 3307     |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 210149   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00859  |\n",
      "|    n_updates        | 52512    |\n",
      "----------------------------------\n",
      "Episode reward: 76.414214\n",
      "Episode reward: 48.481565\n",
      "Episode reward: 55.906378\n",
      "Episode reward: 50.882688\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4160     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 210383   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.284    |\n",
      "|    n_updates        | 52570    |\n",
      "----------------------------------\n",
      "Episode reward: 49.862153\n",
      "Episode reward: 94.851384\n",
      "Episode reward: 60.92344\n",
      "Episode reward: 52.632019\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4164     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 210642   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0773   |\n",
      "|    n_updates        | 52635    |\n",
      "----------------------------------\n",
      "Episode reward: 48.942568\n",
      "Episode reward: 82.660748\n",
      "Episode reward: 34.945231\n",
      "Episode reward: 49.925978\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4168     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 210859   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 52689    |\n",
      "----------------------------------\n",
      "Episode reward: 28.945097\n",
      "Episode reward: 37.94823\n",
      "Episode reward: 38.877996\n",
      "Episode reward: 32.907165\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4172     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 210998   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 52724    |\n",
      "----------------------------------\n",
      "Episode reward: 73.803041\n",
      "Episode reward: 37.953885\n",
      "Episode reward: 68.38106\n",
      "Episode reward: 50.546102\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4176     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 211231   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00508  |\n",
      "|    n_updates        | 52782    |\n",
      "----------------------------------\n",
      "Episode reward: 47.92947\n",
      "Episode reward: 47.917508\n",
      "Episode reward: 45.657329\n",
      "Episode reward: 40.948997\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4180     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 211414   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00471  |\n",
      "|    n_updates        | 52828    |\n",
      "----------------------------------\n",
      "Episode reward: 45.913033\n",
      "Episode reward: 40.765054\n",
      "Episode reward: 72.627685\n",
      "Episode reward: 82.885261\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4184     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 211657   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 52889    |\n",
      "----------------------------------\n",
      "Episode reward: 37.880274\n",
      "Episode reward: 40.706094\n",
      "Episode reward: 67.620161\n",
      "Episode reward: 45.908208\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4188     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 211850   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00531  |\n",
      "|    n_updates        | 52937    |\n",
      "----------------------------------\n",
      "Episode reward: 52.893766\n",
      "Episode reward: 39.883279\n",
      "Episode reward: 54.8424\n",
      "Episode reward: 34.9376\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4192     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 212033   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00612  |\n",
      "|    n_updates        | 52983    |\n",
      "----------------------------------\n",
      "Episode reward: 46.738861\n",
      "Episode reward: 47.91358\n",
      "Episode reward: 57.797525\n",
      "Episode reward: 67.729596\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4196     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 212254   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00996  |\n",
      "|    n_updates        | 53038    |\n",
      "----------------------------------\n",
      "Episode reward: 58.350564\n",
      "Episode reward: 40.956549\n",
      "Episode reward: 37.937606\n",
      "Episode reward: 50.871946\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4200     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 212444   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.227    |\n",
      "|    n_updates        | 53085    |\n",
      "----------------------------------\n",
      "Episode reward: 43.898571\n",
      "Episode reward: 40.94542\n",
      "Episode reward: 51.893877\n",
      "Episode reward: 52.927745\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4204     |\n",
      "|    fps              | 3308     |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 212634   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0309   |\n",
      "|    n_updates        | 53133    |\n",
      "----------------------------------\n",
      "Episode reward: 41.713558\n",
      "Episode reward: 57.894911\n",
      "Episode reward: 79.494812\n",
      "Episode reward: 54.911887\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4208     |\n",
      "|    fps              | 3307     |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 212869   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.416    |\n",
      "|    n_updates        | 53192    |\n",
      "----------------------------------\n",
      "Episode reward: 41.684242\n",
      "Episode reward: 55.7727\n",
      "Episode reward: 51.596515\n",
      "Episode reward: 38.951879\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4212     |\n",
      "|    fps              | 3307     |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 213058   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0513   |\n",
      "|    n_updates        | 53239    |\n",
      "----------------------------------\n",
      "Episode reward: 34.879094\n",
      "Episode reward: 49.926986\n",
      "Episode reward: 59.831595\n",
      "Episode reward: 58.919319\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4216     |\n",
      "|    fps              | 3307     |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 213262   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.442    |\n",
      "|    n_updates        | 53290    |\n",
      "----------------------------------\n",
      "Episode reward: 52.83279\n",
      "Episode reward: 60.444968\n",
      "Episode reward: 49.928321\n",
      "Episode reward: 45.325688\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4220     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 213472   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.231    |\n",
      "|    n_updates        | 53342    |\n",
      "----------------------------------\n",
      "Episode reward: 76.810518\n",
      "Episode reward: 41.685364\n",
      "Episode reward: 93.291049\n",
      "Episode reward: 47.912773\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4224     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 213736   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.143    |\n",
      "|    n_updates        | 53408    |\n",
      "----------------------------------\n",
      "Episode reward: 71.876553\n",
      "Episode reward: 55.800203\n",
      "Episode reward: 59.834837\n",
      "Episode reward: 75.656396\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.5     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4228     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 214000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.266    |\n",
      "|    n_updates        | 53474    |\n",
      "----------------------------------\n",
      "Episode reward: 51.894475\n",
      "Episode reward: 86.822366\n",
      "Episode reward: 51.912149\n",
      "Episode reward: 124.775117\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4232     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 214316   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00683  |\n",
      "|    n_updates        | 53553    |\n",
      "----------------------------------\n",
      "Episode reward: 49.936408\n",
      "Episode reward: 49.901552\n",
      "Episode reward: 27.75576\n",
      "Episode reward: 44.858322\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4236     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 214489   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00484  |\n",
      "|    n_updates        | 53597    |\n",
      "----------------------------------\n",
      "Episode reward: 45.822691\n",
      "Episode reward: 59.752798\n",
      "Episode reward: 69.54515\n",
      "Episode reward: 57.639696\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55       |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4240     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 214723   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.171    |\n",
      "|    n_updates        | 53655    |\n",
      "----------------------------------\n",
      "Episode reward: 39.899568\n",
      "Episode reward: 64.865462\n",
      "Episode reward: 58.723403\n",
      "Episode reward: 53.900164\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4244     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 214941   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0994   |\n",
      "|    n_updates        | 53710    |\n",
      "----------------------------------\n",
      "Episode reward: 60.799845\n",
      "Episode reward: 38.881352\n",
      "Episode reward: 39.931115\n",
      "Episode reward: 44.743999\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.3     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4248     |\n",
      "|    fps              | 3307     |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 215126   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.195    |\n",
      "|    n_updates        | 53756    |\n",
      "----------------------------------\n",
      "Episode reward: 67.673738\n",
      "Episode reward: 56.915806\n",
      "Episode reward: 61.810275\n",
      "Episode reward: 51.247494\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.1     |\n",
      "|    ep_rew_mean      | 53.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4252     |\n",
      "|    fps              | 3307     |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 215365   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00581  |\n",
      "|    n_updates        | 53816    |\n",
      "----------------------------------\n",
      "Episode reward: 64.615306\n",
      "Episode reward: 52.939365\n",
      "Episode reward: 42.907887\n",
      "Episode reward: 33.939868\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.1     |\n",
      "|    ep_rew_mean      | 53.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4256     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 215560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00215  |\n",
      "|    n_updates        | 53864    |\n",
      "----------------------------------\n",
      "Episode reward: 87.571896\n",
      "Episode reward: 46.944148\n",
      "Episode reward: 69.291484\n",
      "Episode reward: 40.929815\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.2     |\n",
      "|    ep_rew_mean      | 54       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4260     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 215806   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00832  |\n",
      "|    n_updates        | 53926    |\n",
      "----------------------------------\n",
      "Episode reward: 42.857411\n",
      "Episode reward: 32.923531\n",
      "Episode reward: 50.929391\n",
      "Episode reward: 60.298563\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.5     |\n",
      "|    ep_rew_mean      | 53.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4264     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 215994   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0035   |\n",
      "|    n_updates        | 53973    |\n",
      "----------------------------------\n",
      "Episode reward: 50.875482\n",
      "Episode reward: 38.78394\n",
      "Episode reward: 29.923901\n",
      "Episode reward: 41.914112\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53       |\n",
      "|    ep_rew_mean      | 52.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4268     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 216156   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0313   |\n",
      "|    n_updates        | 54013    |\n",
      "----------------------------------\n",
      "Episode reward: 62.548368\n",
      "Episode reward: 52.231813\n",
      "Episode reward: 65.925857\n",
      "Episode reward: 45.840485\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.9     |\n",
      "|    ep_rew_mean      | 53.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4272     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 216384   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.247    |\n",
      "|    n_updates        | 54070    |\n",
      "----------------------------------\n",
      "Episode reward: 73.988938\n",
      "Episode reward: 38.810566\n",
      "Episode reward: 36.936553\n",
      "Episode reward: 32.873675\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.4     |\n",
      "|    ep_rew_mean      | 53.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4276     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 216569   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00674  |\n",
      "|    n_updates        | 54117    |\n",
      "----------------------------------\n",
      "Episode reward: 53.925115\n",
      "Episode reward: 46.666991\n",
      "Episode reward: 67.544107\n",
      "Episode reward: 58.891201\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.8     |\n",
      "|    ep_rew_mean      | 53.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4280     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 216797   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.256    |\n",
      "|    n_updates        | 54174    |\n",
      "----------------------------------\n",
      "Episode reward: 29.85524\n",
      "Episode reward: 33.871925\n",
      "Episode reward: 45.842224\n",
      "Episode reward: 61.877689\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.1     |\n",
      "|    ep_rew_mean      | 52.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4284     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 216969   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0033   |\n",
      "|    n_updates        | 54217    |\n",
      "----------------------------------\n",
      "Episode reward: 66.881786\n",
      "Episode reward: 37.938413\n",
      "Episode reward: 33.706106\n",
      "Episode reward: 75.830005\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.4     |\n",
      "|    ep_rew_mean      | 53.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4288     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 217185   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00256  |\n",
      "|    n_updates        | 54271    |\n",
      "----------------------------------\n",
      "Episode reward: 54.894864\n",
      "Episode reward: 36.795672\n",
      "Episode reward: 70.878175\n",
      "Episode reward: 47.916143\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.6     |\n",
      "|    ep_rew_mean      | 53.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4292     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 217396   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00716  |\n",
      "|    n_updates        | 54323    |\n",
      "----------------------------------\n",
      "Episode reward: 85.375266\n",
      "Episode reward: 39.804509\n",
      "Episode reward: 105.676535\n",
      "Episode reward: 48.449214\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.3     |\n",
      "|    ep_rew_mean      | 53.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4296     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 217680   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00199  |\n",
      "|    n_updates        | 54394    |\n",
      "----------------------------------\n",
      "Episode reward: 49.939566\n",
      "Episode reward: 95.232165\n",
      "Episode reward: 45.938745\n",
      "Episode reward: 50.803033\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.8     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4300     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 217923   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00497  |\n",
      "|    n_updates        | 54455    |\n",
      "----------------------------------\n",
      "Episode reward: 49.897864\n",
      "Episode reward: 39.94049\n",
      "Episode reward: 49.924589\n",
      "Episode reward: 99.567717\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4304     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 218166   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00928  |\n",
      "|    n_updates        | 54516    |\n",
      "----------------------------------\n",
      "Episode reward: 56.486416\n",
      "Episode reward: 39.903652\n",
      "Episode reward: 52.731315\n",
      "Episode reward: 71.809426\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4308     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 218388   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.2      |\n",
      "|    n_updates        | 54571    |\n",
      "----------------------------------\n",
      "Episode reward: 40.946187\n",
      "Episode reward: 148.772634\n",
      "Episode reward: 32.882242\n",
      "Episode reward: 52.944371\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4312     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 218664   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.161    |\n",
      "|    n_updates        | 54640    |\n",
      "----------------------------------\n",
      "Episode reward: 45.8977\n",
      "Episode reward: 54.643484\n",
      "Episode reward: 39.83374\n",
      "Episode reward: 61.382911\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4316     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 218867   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0912   |\n",
      "|    n_updates        | 54691    |\n",
      "----------------------------------\n",
      "Episode reward: 42.693013\n",
      "Episode reward: 41.806899\n",
      "Episode reward: 40.882002\n",
      "Episode reward: 69.910418\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4320     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 219063   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00286  |\n",
      "|    n_updates        | 54740    |\n",
      "----------------------------------\n",
      "Episode reward: 45.663234\n",
      "Episode reward: 35.785247\n",
      "Episode reward: 65.235932\n",
      "Episode reward: 54.735912\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4324     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 219267   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00425  |\n",
      "|    n_updates        | 54791    |\n",
      "----------------------------------\n",
      "Episode reward: 46.816315\n",
      "Episode reward: 38.849838\n",
      "Episode reward: 59.749819\n",
      "Episode reward: 65.92069\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.8     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4328     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 219479   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.104    |\n",
      "|    n_updates        | 54844    |\n",
      "----------------------------------\n",
      "Episode reward: 54.922655\n",
      "Episode reward: 36.91412\n",
      "Episode reward: 33.934277\n",
      "Episode reward: 40.92703\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.3     |\n",
      "|    ep_rew_mean      | 53       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4332     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 219646   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0066   |\n",
      "|    n_updates        | 54886    |\n",
      "----------------------------------\n",
      "Episode reward: 79.93989\n",
      "Episode reward: 70.922281\n",
      "Episode reward: 56.914802\n",
      "Episode reward: 60.668239\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.3     |\n",
      "|    ep_rew_mean      | 53.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4336     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 219916   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0049   |\n",
      "|    n_updates        | 54953    |\n",
      "----------------------------------\n",
      "Episode reward: 95.872061\n",
      "Episode reward: 63.590275\n",
      "Episode reward: 69.882417\n",
      "Episode reward: 35.922574\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.6     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4340     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 220182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00515  |\n",
      "|    n_updates        | 55020    |\n",
      "----------------------------------\n",
      "Episode reward: 44.796163\n",
      "Episode reward: 35.846106\n",
      "Episode reward: 45.944649\n",
      "Episode reward: 59.831146\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.3     |\n",
      "|    ep_rew_mean      | 54       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4344     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 220369   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.35     |\n",
      "|    n_updates        | 55067    |\n",
      "----------------------------------\n",
      "Episode reward: 51.93329\n",
      "Episode reward: 39.794927\n",
      "Episode reward: 54.912237\n",
      "Episode reward: 52.824677\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.4     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4348     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 220569   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0727   |\n",
      "|    n_updates        | 55117    |\n",
      "----------------------------------\n",
      "Episode reward: 34.86377\n",
      "Episode reward: 81.389658\n",
      "Episode reward: 39.670647\n",
      "Episode reward: 60.916902\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.2     |\n",
      "|    ep_rew_mean      | 53.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4352     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 220787   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.478    |\n",
      "|    n_updates        | 55171    |\n",
      "----------------------------------\n",
      "Episode reward: 125.864433\n",
      "Episode reward: 114.84428\n",
      "Episode reward: 46.908403\n",
      "Episode reward: 96.795673\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4356     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 221176   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.058    |\n",
      "|    n_updates        | 55268    |\n",
      "----------------------------------\n",
      "Episode reward: 59.834749\n",
      "Episode reward: 54.92698\n",
      "Episode reward: 55.924058\n",
      "Episode reward: 78.688578\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4360     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 221426   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.155    |\n",
      "|    n_updates        | 55331    |\n",
      "----------------------------------\n",
      "Episode reward: 48.886274\n",
      "Episode reward: 83.877789\n",
      "Episode reward: 72.705744\n",
      "Episode reward: 71.845744\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4364     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 221707   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00519  |\n",
      "|    n_updates        | 55401    |\n",
      "----------------------------------\n",
      "Episode reward: 39.953583\n",
      "Episode reward: 47.839984\n",
      "Episode reward: 104.652156\n",
      "Episode reward: 37.958848\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4368     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 221938   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.261    |\n",
      "|    n_updates        | 55459    |\n",
      "----------------------------------\n",
      "Episode reward: 55.648575\n",
      "Episode reward: 64.219744\n",
      "Episode reward: 42.917984\n",
      "Episode reward: 51.876713\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4372     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 222154   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.217    |\n",
      "|    n_updates        | 55513    |\n",
      "----------------------------------\n",
      "Episode reward: 45.793126\n",
      "Episode reward: 63.658946\n",
      "Episode reward: 44.576318\n",
      "Episode reward: 57.706182\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4376     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 222367   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 55566    |\n",
      "----------------------------------\n",
      "Episode reward: 41.874567\n",
      "Episode reward: 30.819099\n",
      "Episode reward: 54.934708\n",
      "Episode reward: 73.89206\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4380     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 222569   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00747  |\n",
      "|    n_updates        | 55617    |\n",
      "----------------------------------\n",
      "Episode reward: 99.696909\n",
      "Episode reward: 37.949779\n",
      "Episode reward: 31.622619\n",
      "Episode reward: 98.020683\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4384     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 222839   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00267  |\n",
      "|    n_updates        | 55684    |\n",
      "----------------------------------\n",
      "Episode reward: 42.72117\n",
      "Episode reward: 47.889369\n",
      "Episode reward: 60.90772\n",
      "Episode reward: 46.94799\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4388     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 223038   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0696   |\n",
      "|    n_updates        | 55734    |\n",
      "----------------------------------\n",
      "Episode reward: 47.939924\n",
      "Episode reward: 70.877385\n",
      "Episode reward: 47.330283\n",
      "Episode reward: 33.945118\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4392     |\n",
      "|    fps              | 3307     |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 223239   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.131    |\n",
      "|    n_updates        | 55784    |\n",
      "----------------------------------\n",
      "Episode reward: 55.930831\n",
      "Episode reward: 61.621928\n",
      "Episode reward: 46.913908\n",
      "Episode reward: 44.94633\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4396     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 223449   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00335  |\n",
      "|    n_updates        | 55837    |\n",
      "----------------------------------\n",
      "Episode reward: 57.376451\n",
      "Episode reward: 57.768587\n",
      "Episode reward: 34.960025\n",
      "Episode reward: 52.521998\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4400     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 223653   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00498  |\n",
      "|    n_updates        | 55888    |\n",
      "----------------------------------\n",
      "Episode reward: 74.229956\n",
      "Episode reward: 58.854259\n",
      "Episode reward: 77.402248\n",
      "Episode reward: 40.785298\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4404     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 223908   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00163  |\n",
      "|    n_updates        | 55951    |\n",
      "----------------------------------\n",
      "Episode reward: 48.568877\n",
      "Episode reward: 49.696823\n",
      "Episode reward: 35.815712\n",
      "Episode reward: 31.95273\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4408     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 224075   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00275  |\n",
      "|    n_updates        | 55993    |\n",
      "----------------------------------\n",
      "Episode reward: 58.720026\n",
      "Episode reward: 41.921551\n",
      "Episode reward: 48.723603\n",
      "Episode reward: 66.92071\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4412     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 224292   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00502  |\n",
      "|    n_updates        | 56047    |\n",
      "----------------------------------\n",
      "Episode reward: 63.479989\n",
      "Episode reward: 65.627811\n",
      "Episode reward: 64.887845\n",
      "Episode reward: 41.934659\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4416     |\n",
      "|    fps              | 3307     |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 224529   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00878  |\n",
      "|    n_updates        | 56107    |\n",
      "----------------------------------\n",
      "Episode reward: 37.934071\n",
      "Episode reward: 52.932121\n",
      "Episode reward: 43.765056\n",
      "Episode reward: 80.536018\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4420     |\n",
      "|    fps              | 3307     |\n",
      "|    time_elapsed     | 67       |\n",
      "|    total_timesteps  | 224745   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.223    |\n",
      "|    n_updates        | 56161    |\n",
      "----------------------------------\n",
      "Episode reward: 83.415624\n",
      "Episode reward: 43.901706\n",
      "Episode reward: 40.506166\n",
      "Episode reward: 33.901193\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4424     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 224948   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00208  |\n",
      "|    n_updates        | 56211    |\n",
      "----------------------------------\n",
      "Episode reward: 72.902003\n",
      "Episode reward: 78.731562\n",
      "Episode reward: 52.899873\n",
      "Episode reward: 47.940342\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4428     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 225201   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.232    |\n",
      "|    n_updates        | 56275    |\n",
      "----------------------------------\n",
      "Episode reward: 83.107509\n",
      "Episode reward: 69.901986\n",
      "Episode reward: 81.610871\n",
      "Episode reward: 37.944494\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4432     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 225477   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.304    |\n",
      "|    n_updates        | 56344    |\n",
      "----------------------------------\n",
      "Episode reward: 53.399819\n",
      "Episode reward: 40.919914\n",
      "Episode reward: 62.794737\n",
      "Episode reward: 40.920216\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4436     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 225676   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00353  |\n",
      "|    n_updates        | 56393    |\n",
      "----------------------------------\n",
      "Episode reward: 41.856394\n",
      "Episode reward: 41.811216\n",
      "Episode reward: 44.941997\n",
      "Episode reward: 46.902265\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4440     |\n",
      "|    fps              | 3306     |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 225852   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00488  |\n",
      "|    n_updates        | 56437    |\n",
      "----------------------------------\n",
      "Episode reward: 57.010063\n",
      "Episode reward: 58.832367\n",
      "Episode reward: 48.851919\n",
      "Episode reward: 41.838504\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4444     |\n",
      "|    fps              | 3305     |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 226060   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00501  |\n",
      "|    n_updates        | 56489    |\n",
      "----------------------------------\n",
      "Episode reward: 55.901458\n",
      "Episode reward: 45.895808\n",
      "Episode reward: 79.662219\n",
      "Episode reward: 38.851363\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4448     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 226281   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00318  |\n",
      "|    n_updates        | 56545    |\n",
      "----------------------------------\n",
      "Episode reward: 47.92138\n",
      "Episode reward: 47.732023\n",
      "Episode reward: 40.587439\n",
      "Episode reward: 40.715691\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4452     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 226459   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.128    |\n",
      "|    n_updates        | 56589    |\n",
      "----------------------------------\n",
      "Episode reward: 47.883721\n",
      "Episode reward: 140.150777\n",
      "Episode reward: 45.950696\n",
      "Episode reward: 72.69117\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4456     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 226768   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.405    |\n",
      "|    n_updates        | 56666    |\n",
      "----------------------------------\n",
      "Episode reward: 60.011756\n",
      "Episode reward: 49.764181\n",
      "Episode reward: 78.839696\n",
      "Episode reward: 58.784113\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4460     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 227017   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00903  |\n",
      "|    n_updates        | 56729    |\n",
      "----------------------------------\n",
      "Episode reward: 51.440599\n",
      "Episode reward: 44.734651\n",
      "Episode reward: 43.939904\n",
      "Episode reward: 33.938743\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4464     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 227192   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.125    |\n",
      "|    n_updates        | 56772    |\n",
      "----------------------------------\n",
      "Episode reward: 52.930968\n",
      "Episode reward: 45.938802\n",
      "Episode reward: 58.761413\n",
      "Episode reward: 58.718375\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.7     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4468     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 227409   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.157    |\n",
      "|    n_updates        | 56827    |\n",
      "----------------------------------\n",
      "Episode reward: 83.875992\n",
      "Episode reward: 38.914671\n",
      "Episode reward: 68.761177\n",
      "Episode reward: 41.934806\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4472     |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 227643   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00375  |\n",
      "|    n_updates        | 56885    |\n",
      "----------------------------------\n",
      "Episode reward: 61.903498\n",
      "Episode reward: 54.876593\n",
      "Episode reward: 53.922849\n",
      "Episode reward: 90.584228\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4476     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 227905   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.305    |\n",
      "|    n_updates        | 56951    |\n",
      "----------------------------------\n",
      "Episode reward: 63.219904\n",
      "Episode reward: 69.834783\n",
      "Episode reward: 79.739576\n",
      "Episode reward: 57.156179\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4480     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 228177   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00449  |\n",
      "|    n_updates        | 57019    |\n",
      "----------------------------------\n",
      "Episode reward: 33.935755\n",
      "Episode reward: 58.843359\n",
      "Episode reward: 42.837444\n",
      "Episode reward: 53.668235\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4484     |\n",
      "|    fps              | 3303     |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 228367   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.253    |\n",
      "|    n_updates        | 57066    |\n",
      "----------------------------------\n",
      "Episode reward: 69.571784\n",
      "Episode reward: 43.88425\n",
      "Episode reward: 38.607134\n",
      "Episode reward: 33.955022\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4488     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 228554   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00501  |\n",
      "|    n_updates        | 57113    |\n",
      "----------------------------------\n",
      "Episode reward: 64.710493\n",
      "Episode reward: 44.922941\n",
      "Episode reward: 66.813396\n",
      "Episode reward: 54.936367\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.5     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4492     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 228786   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00661  |\n",
      "|    n_updates        | 57171    |\n",
      "----------------------------------\n",
      "Episode reward: 51.867739\n",
      "Episode reward: 46.882597\n",
      "Episode reward: 62.3814\n",
      "Episode reward: 58.665417\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4496     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 229008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00258  |\n",
      "|    n_updates        | 57226    |\n",
      "----------------------------------\n",
      "Episode reward: 40.949516\n",
      "Episode reward: 49.891893\n",
      "Episode reward: 57.849451\n",
      "Episode reward: 62.860163\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4500     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 229220   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 57279    |\n",
      "----------------------------------\n",
      "Episode reward: 44.806223\n",
      "Episode reward: 45.93814\n",
      "Episode reward: 34.77225\n",
      "Episode reward: 48.851212\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4504     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 229395   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.189    |\n",
      "|    n_updates        | 57323    |\n",
      "----------------------------------\n",
      "Episode reward: 43.859127\n",
      "Episode reward: 39.956459\n",
      "Episode reward: 53.868499\n",
      "Episode reward: 104.754304\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4508     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 229638   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.205    |\n",
      "|    n_updates        | 57384    |\n",
      "----------------------------------\n",
      "Episode reward: 52.225996\n",
      "Episode reward: 39.905711\n",
      "Episode reward: 44.945918\n",
      "Episode reward: 83.737083\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4512     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 229860   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00766  |\n",
      "|    n_updates        | 57439    |\n",
      "----------------------------------\n",
      "Episode reward: 66.865408\n",
      "Episode reward: 75.887699\n",
      "Episode reward: 53.743592\n",
      "Episode reward: 48.371757\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4516     |\n",
      "|    fps              | 3302     |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 230106   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0228   |\n",
      "|    n_updates        | 57501    |\n",
      "----------------------------------\n",
      "Episode reward: 43.867649\n",
      "Episode reward: 44.927878\n",
      "Episode reward: 35.781208\n",
      "Episode reward: 78.31794\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4520     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 230310   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.345    |\n",
      "|    n_updates        | 57552    |\n",
      "----------------------------------\n",
      "Episode reward: 41.888432\n",
      "Episode reward: 52.90154\n",
      "Episode reward: 60.822599\n",
      "Episode reward: 41.951181\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4524     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 230508   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00343  |\n",
      "|    n_updates        | 57601    |\n",
      "----------------------------------\n",
      "Episode reward: 35.957657\n",
      "Episode reward: 41.944858\n",
      "Episode reward: 72.906224\n",
      "Episode reward: 54.85808\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4528     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 230714   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00465  |\n",
      "|    n_updates        | 57653    |\n",
      "----------------------------------\n",
      "Episode reward: 37.905384\n",
      "Episode reward: 41.883563\n",
      "Episode reward: 41.826898\n",
      "Episode reward: 39.94809\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54       |\n",
      "|    ep_rew_mean      | 53.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4532     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 69       |\n",
      "|    total_timesteps  | 230876   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.147    |\n",
      "|    n_updates        | 57693    |\n",
      "----------------------------------\n",
      "Episode reward: 36.788312\n",
      "Episode reward: 55.755685\n",
      "Episode reward: 77.894947\n",
      "Episode reward: 49.345758\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.2     |\n",
      "|    ep_rew_mean      | 54       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4536     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 231097   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.211    |\n",
      "|    n_updates        | 57749    |\n",
      "----------------------------------\n",
      "Episode reward: 77.911272\n",
      "Episode reward: 52.864848\n",
      "Episode reward: 36.919635\n",
      "Episode reward: 71.911898\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4540     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 231337   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.176    |\n",
      "|    n_updates        | 57809    |\n",
      "----------------------------------\n",
      "Episode reward: 39.955399\n",
      "Episode reward: 55.925039\n",
      "Episode reward: 50.849966\n",
      "Episode reward: 35.881859\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.6     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4544     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 231520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 57854    |\n",
      "----------------------------------\n",
      "Episode reward: 46.9212\n",
      "Episode reward: 41.683415\n",
      "Episode reward: 50.912975\n",
      "Episode reward: 53.915237\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.3     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4548     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 231714   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00573  |\n",
      "|    n_updates        | 57903    |\n",
      "----------------------------------\n",
      "Episode reward: 67.017751\n",
      "Episode reward: 46.947282\n",
      "Episode reward: 63.639242\n",
      "Episode reward: 89.97346\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4552     |\n",
      "|    fps              | 3301     |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 231985   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.189    |\n",
      "|    n_updates        | 57971    |\n",
      "----------------------------------\n",
      "Episode reward: 39.929515\n",
      "Episode reward: 75.70779\n",
      "Episode reward: 72.830284\n",
      "Episode reward: 53.614928\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.6     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4556     |\n",
      "|    fps              | 3300     |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 232228   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.154    |\n",
      "|    n_updates        | 58031    |\n",
      "----------------------------------\n",
      "Episode reward: 38.939553\n",
      "Episode reward: 58.316427\n",
      "Episode reward: 35.818271\n",
      "Episode reward: 45.923011\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.9     |\n",
      "|    ep_rew_mean      | 53.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4560     |\n",
      "|    fps              | 3298     |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 232408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0593   |\n",
      "|    n_updates        | 58076    |\n",
      "----------------------------------\n",
      "Episode reward: 35.574175\n",
      "Episode reward: 48.926145\n",
      "Episode reward: 62.864767\n",
      "Episode reward: 43.940007\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.1     |\n",
      "|    ep_rew_mean      | 53.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4564     |\n",
      "|    fps              | 3297     |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 232600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00539  |\n",
      "|    n_updates        | 58124    |\n",
      "----------------------------------\n",
      "Episode reward: 63.783074\n",
      "Episode reward: 66.500422\n",
      "Episode reward: 67.811444\n",
      "Episode reward: 41.921083\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.3     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4568     |\n",
      "|    fps              | 3297     |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 232841   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 58185    |\n",
      "----------------------------------\n",
      "Episode reward: 39.866197\n",
      "Episode reward: 62.522113\n",
      "Episode reward: 54.327391\n",
      "Episode reward: 37.947843\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.9     |\n",
      "|    ep_rew_mean      | 53.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4572     |\n",
      "|    fps              | 3297     |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 233037   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0464   |\n",
      "|    n_updates        | 58234    |\n",
      "----------------------------------\n",
      "Episode reward: 80.84767\n",
      "Episode reward: 58.84693\n",
      "Episode reward: 105.645044\n",
      "Episode reward: 60.650297\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.4     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4576     |\n",
      "|    fps              | 3297     |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 233344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00307  |\n",
      "|    n_updates        | 58310    |\n",
      "----------------------------------\n",
      "Episode reward: 62.397745\n",
      "Episode reward: 104.136286\n",
      "Episode reward: 38.925845\n",
      "Episode reward: 52.54716\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.3     |\n",
      "|    ep_rew_mean      | 54       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4580     |\n",
      "|    fps              | 3297     |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 233606   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00465  |\n",
      "|    n_updates        | 58376    |\n",
      "----------------------------------\n",
      "Episode reward: 46.676131\n",
      "Episode reward: 42.955015\n",
      "Episode reward: 49.903228\n",
      "Episode reward: 52.915486\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.3     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4584     |\n",
      "|    fps              | 3297     |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 233799   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00448  |\n",
      "|    n_updates        | 58424    |\n",
      "----------------------------------\n",
      "Episode reward: 54.905764\n",
      "Episode reward: 41.887695\n",
      "Episode reward: 53.672679\n",
      "Episode reward: 28.94306\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.2     |\n",
      "|    ep_rew_mean      | 54       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4588     |\n",
      "|    fps              | 3296     |\n",
      "|    time_elapsed     | 70       |\n",
      "|    total_timesteps  | 233979   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0329   |\n",
      "|    n_updates        | 58469    |\n",
      "----------------------------------\n",
      "Episode reward: 37.867638\n",
      "Episode reward: 55.928073\n",
      "Episode reward: 41.689527\n",
      "Episode reward: 52.873258\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.8     |\n",
      "|    ep_rew_mean      | 53.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4592     |\n",
      "|    fps              | 3296     |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 234168   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.27     |\n",
      "|    n_updates        | 58516    |\n",
      "----------------------------------\n",
      "Episode reward: 65.644104\n",
      "Episode reward: 63.603575\n",
      "Episode reward: 42.795792\n",
      "Episode reward: 32.934827\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.7     |\n",
      "|    ep_rew_mean      | 53.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4596     |\n",
      "|    fps              | 3295     |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 234374   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.003    |\n",
      "|    n_updates        | 58568    |\n",
      "----------------------------------\n",
      "Episode reward: 61.148203\n",
      "Episode reward: 46.793081\n",
      "Episode reward: 38.77068\n",
      "Episode reward: 33.918428\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.4     |\n",
      "|    ep_rew_mean      | 53.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4600     |\n",
      "|    fps              | 3294     |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 234556   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0071   |\n",
      "|    n_updates        | 58613    |\n",
      "----------------------------------\n",
      "Episode reward: 73.524952\n",
      "Episode reward: 73.864493\n",
      "Episode reward: 35.524693\n",
      "Episode reward: 46.925626\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.9     |\n",
      "|    ep_rew_mean      | 53.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4604     |\n",
      "|    fps              | 3295     |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 234787   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00615  |\n",
      "|    n_updates        | 58671    |\n",
      "----------------------------------\n",
      "Episode reward: 38.560599\n",
      "Episode reward: 69.181555\n",
      "Episode reward: 62.025213\n",
      "Episode reward: 94.615878\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.2     |\n",
      "|    ep_rew_mean      | 53.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4608     |\n",
      "|    fps              | 3293     |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 235054   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00661  |\n",
      "|    n_updates        | 58738    |\n",
      "----------------------------------\n",
      "Episode reward: 61.889409\n",
      "Episode reward: 61.42076\n",
      "Episode reward: 61.644724\n",
      "Episode reward: 65.911646\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4612     |\n",
      "|    fps              | 3293     |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 235306   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00442  |\n",
      "|    n_updates        | 58801    |\n",
      "----------------------------------\n",
      "Episode reward: 49.896391\n",
      "Episode reward: 55.787073\n",
      "Episode reward: 71.904569\n",
      "Episode reward: 58.927459\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.4     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4616     |\n",
      "|    fps              | 3293     |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 235543   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00566  |\n",
      "|    n_updates        | 58860    |\n",
      "----------------------------------\n",
      "Episode reward: 43.893517\n",
      "Episode reward: 73.902958\n",
      "Episode reward: 81.34176\n",
      "Episode reward: 35.791565\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.7     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4620     |\n",
      "|    fps              | 3293     |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 235779   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00526  |\n",
      "|    n_updates        | 58919    |\n",
      "----------------------------------\n",
      "Episode reward: 56.896588\n",
      "Episode reward: 37.703515\n",
      "Episode reward: 45.750677\n",
      "Episode reward: 38.922018\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4624     |\n",
      "|    fps              | 3293     |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 235959   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00834  |\n",
      "|    n_updates        | 58964    |\n",
      "----------------------------------\n",
      "Episode reward: 48.934592\n",
      "Episode reward: 56.698217\n",
      "Episode reward: 69.920893\n",
      "Episode reward: 37.870827\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.6     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4628     |\n",
      "|    fps              | 3292     |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 236173   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.198    |\n",
      "|    n_updates        | 59018    |\n",
      "----------------------------------\n",
      "Episode reward: 54.742358\n",
      "Episode reward: 52.680464\n",
      "Episode reward: 65.898475\n",
      "Episode reward: 36.928053\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4632     |\n",
      "|    fps              | 3291     |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 236384   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00551  |\n",
      "|    n_updates        | 59070    |\n",
      "----------------------------------\n",
      "Episode reward: 44.882747\n",
      "Episode reward: 83.897779\n",
      "Episode reward: 52.938685\n",
      "Episode reward: 65.80428\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4636     |\n",
      "|    fps              | 3291     |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 236633   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0412   |\n",
      "|    n_updates        | 59133    |\n",
      "----------------------------------\n",
      "Episode reward: 37.580438\n",
      "Episode reward: 39.7298\n",
      "Episode reward: 42.905727\n",
      "Episode reward: 43.634233\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.6     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4640     |\n",
      "|    fps              | 3292     |\n",
      "|    time_elapsed     | 71       |\n",
      "|    total_timesteps  | 236798   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00416  |\n",
      "|    n_updates        | 59174    |\n",
      "----------------------------------\n",
      "Episode reward: 36.904896\n",
      "Episode reward: 74.773139\n",
      "Episode reward: 84.742021\n",
      "Episode reward: 41.774695\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4644     |\n",
      "|    fps              | 3291     |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 237037   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00606  |\n",
      "|    n_updates        | 59234    |\n",
      "----------------------------------\n",
      "Episode reward: 57.81676\n",
      "Episode reward: 52.65712\n",
      "Episode reward: 52.913113\n",
      "Episode reward: 56.941796\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4648     |\n",
      "|    fps              | 3291     |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 237258   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00876  |\n",
      "|    n_updates        | 59289    |\n",
      "----------------------------------\n",
      "Episode reward: 58.884886\n",
      "Episode reward: 51.912384\n",
      "Episode reward: 36.791916\n",
      "Episode reward: 66.916316\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4652     |\n",
      "|    fps              | 3290     |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 237473   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.339    |\n",
      "|    n_updates        | 59343    |\n",
      "----------------------------------\n",
      "Episode reward: 92.108446\n",
      "Episode reward: 40.809133\n",
      "Episode reward: 38.838131\n",
      "Episode reward: 33.904094\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4656     |\n",
      "|    fps              | 3291     |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 237680   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.169    |\n",
      "|    n_updates        | 59394    |\n",
      "----------------------------------\n",
      "Episode reward: 33.881706\n",
      "Episode reward: 67.154575\n",
      "Episode reward: 31.911339\n",
      "Episode reward: 59.805301\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.7     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4660     |\n",
      "|    fps              | 3291     |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 237874   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.446    |\n",
      "|    n_updates        | 59443    |\n",
      "----------------------------------\n",
      "Episode reward: 63.84486\n",
      "Episode reward: 38.840639\n",
      "Episode reward: 52.925443\n",
      "Episode reward: 46.89003\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.8     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4664     |\n",
      "|    fps              | 3291     |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 238077   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00907  |\n",
      "|    n_updates        | 59494    |\n",
      "----------------------------------\n",
      "Episode reward: 62.686443\n",
      "Episode reward: 45.93617\n",
      "Episode reward: 45.916092\n",
      "Episode reward: 32.949002\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.2     |\n",
      "|    ep_rew_mean      | 54       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4668     |\n",
      "|    fps              | 3291     |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 238265   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0525   |\n",
      "|    n_updates        | 59541    |\n",
      "----------------------------------\n",
      "Episode reward: 59.889645\n",
      "Episode reward: 48.907063\n",
      "Episode reward: 40.854175\n",
      "Episode reward: 45.702418\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.2     |\n",
      "|    ep_rew_mean      | 54       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4672     |\n",
      "|    fps              | 3291     |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 238461   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.286    |\n",
      "|    n_updates        | 59590    |\n",
      "----------------------------------\n",
      "Episode reward: 68.904941\n",
      "Episode reward: 88.744793\n",
      "Episode reward: 49.932052\n",
      "Episode reward: 52.260022\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.8     |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4676     |\n",
      "|    fps              | 3291     |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 238722   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00715  |\n",
      "|    n_updates        | 59655    |\n",
      "----------------------------------\n",
      "Episode reward: 41.888015\n",
      "Episode reward: 69.914383\n",
      "Episode reward: 79.789275\n",
      "Episode reward: 65.818765\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.7     |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4680     |\n",
      "|    fps              | 3291     |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 238980   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.003    |\n",
      "|    n_updates        | 59719    |\n",
      "----------------------------------\n",
      "Episode reward: 71.43032\n",
      "Episode reward: 45.924103\n",
      "Episode reward: 81.845379\n",
      "Episode reward: 51.864036\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.3     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4684     |\n",
      "|    fps              | 3292     |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 239232   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 59782    |\n",
      "----------------------------------\n",
      "Episode reward: 60.267096\n",
      "Episode reward: 33.932213\n",
      "Episode reward: 69.864168\n",
      "Episode reward: 41.906267\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.6     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4688     |\n",
      "|    fps              | 3291     |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 239439   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0339   |\n",
      "|    n_updates        | 59834    |\n",
      "----------------------------------\n",
      "Episode reward: 63.919737\n",
      "Episode reward: 54.833194\n",
      "Episode reward: 68.883345\n",
      "Episode reward: 72.865566\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4692     |\n",
      "|    fps              | 3291     |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 239700   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00248  |\n",
      "|    n_updates        | 59899    |\n",
      "----------------------------------\n",
      "Episode reward: 30.918315\n",
      "Episode reward: 39.932021\n",
      "Episode reward: 33.953454\n",
      "Episode reward: 54.862979\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4696     |\n",
      "|    fps              | 3290     |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 239861   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00328  |\n",
      "|    n_updates        | 59940    |\n",
      "----------------------------------\n",
      "Episode reward: 73.480199\n",
      "Episode reward: 79.034775\n",
      "Episode reward: 39.918701\n",
      "Episode reward: 76.878921\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4700     |\n",
      "|    fps              | 3290     |\n",
      "|    time_elapsed     | 72       |\n",
      "|    total_timesteps  | 240132   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.209    |\n",
      "|    n_updates        | 60007    |\n",
      "----------------------------------\n",
      "Episode reward: 46.556857\n",
      "Episode reward: 43.862145\n",
      "Episode reward: 69.906208\n",
      "Episode reward: 62.817866\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4704     |\n",
      "|    fps              | 3289     |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 240356   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0294   |\n",
      "|    n_updates        | 60063    |\n",
      "----------------------------------\n",
      "Episode reward: 65.890053\n",
      "Episode reward: 33.825476\n",
      "Episode reward: 66.676826\n",
      "Episode reward: 34.942558\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55       |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4708     |\n",
      "|    fps              | 3288     |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 240558   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.558    |\n",
      "|    n_updates        | 60114    |\n",
      "----------------------------------\n",
      "Episode reward: 43.780189\n",
      "Episode reward: 80.843337\n",
      "Episode reward: 51.935765\n",
      "Episode reward: 72.832995\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55       |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4712     |\n",
      "|    fps              | 3288     |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 240808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00607  |\n",
      "|    n_updates        | 60176    |\n",
      "----------------------------------\n",
      "Episode reward: 44.732715\n",
      "Episode reward: 32.960238\n",
      "Episode reward: 35.950151\n",
      "Episode reward: 54.682748\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.3     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4716     |\n",
      "|    fps              | 3288     |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 240977   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00634  |\n",
      "|    n_updates        | 60219    |\n",
      "----------------------------------\n",
      "Episode reward: 110.88145\n",
      "Episode reward: 45.94668\n",
      "Episode reward: 38.937997\n",
      "Episode reward: 47.123773\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.4     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4720     |\n",
      "|    fps              | 3288     |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 241221   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00361  |\n",
      "|    n_updates        | 60280    |\n",
      "----------------------------------\n",
      "Episode reward: 80.475926\n",
      "Episode reward: 36.899461\n",
      "Episode reward: 70.643843\n",
      "Episode reward: 68.817007\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4724     |\n",
      "|    fps              | 3288     |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 241479   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00173  |\n",
      "|    n_updates        | 60344    |\n",
      "----------------------------------\n",
      "Episode reward: 43.950833\n",
      "Episode reward: 52.500121\n",
      "Episode reward: 60.915696\n",
      "Episode reward: 61.872385\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4728     |\n",
      "|    fps              | 3288     |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 241699   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00733  |\n",
      "|    n_updates        | 60399    |\n",
      "----------------------------------\n",
      "Episode reward: 105.190831\n",
      "Episode reward: 55.714593\n",
      "Episode reward: 43.951915\n",
      "Episode reward: 70.309626\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4732     |\n",
      "|    fps              | 3286     |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 241976   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00524  |\n",
      "|    n_updates        | 60468    |\n",
      "----------------------------------\n",
      "Episode reward: 58.921352\n",
      "Episode reward: 124.789546\n",
      "Episode reward: 60.334186\n",
      "Episode reward: 43.943422\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4736     |\n",
      "|    fps              | 3286     |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 242265   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.17     |\n",
      "|    n_updates        | 60541    |\n",
      "----------------------------------\n",
      "Episode reward: 36.949019\n",
      "Episode reward: 37.931361\n",
      "Episode reward: 67.100121\n",
      "Episode reward: 91.894748\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4740     |\n",
      "|    fps              | 3285     |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 242500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0366   |\n",
      "|    n_updates        | 60599    |\n",
      "----------------------------------\n",
      "Episode reward: 43.779937\n",
      "Episode reward: 37.92647\n",
      "Episode reward: 59.694625\n",
      "Episode reward: 45.944561\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4744     |\n",
      "|    fps              | 3284     |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 242688   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.141    |\n",
      "|    n_updates        | 60646    |\n",
      "----------------------------------\n",
      "Episode reward: 57.872554\n",
      "Episode reward: 32.905063\n",
      "Episode reward: 38.906972\n",
      "Episode reward: 39.799736\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4748     |\n",
      "|    fps              | 3283     |\n",
      "|    time_elapsed     | 73       |\n",
      "|    total_timesteps  | 242858   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 60689    |\n",
      "----------------------------------\n",
      "Episode reward: 56.724794\n",
      "Episode reward: 38.929161\n",
      "Episode reward: 52.87039\n",
      "Episode reward: 40.92112\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4752     |\n",
      "|    fps              | 3282     |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 243048   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00448  |\n",
      "|    n_updates        | 60736    |\n",
      "----------------------------------\n",
      "Episode reward: 61.928131\n",
      "Episode reward: 123.589914\n",
      "Episode reward: 58.864489\n",
      "Episode reward: 37.895973\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4756     |\n",
      "|    fps              | 3280     |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 243331   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.208    |\n",
      "|    n_updates        | 60807    |\n",
      "----------------------------------\n",
      "Episode reward: 102.564414\n",
      "Episode reward: 89.340971\n",
      "Episode reward: 77.8298\n",
      "Episode reward: 93.319437\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4760     |\n",
      "|    fps              | 3278     |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 243696   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00822  |\n",
      "|    n_updates        | 60898    |\n",
      "----------------------------------\n",
      "Episode reward: 36.954818\n",
      "Episode reward: 47.922101\n",
      "Episode reward: 47.82802\n",
      "Episode reward: 80.835215\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4764     |\n",
      "|    fps              | 3278     |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 243910   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00829  |\n",
      "|    n_updates        | 60952    |\n",
      "----------------------------------\n",
      "Episode reward: 40.698918\n",
      "Episode reward: 47.919688\n",
      "Episode reward: 50.918099\n",
      "Episode reward: 90.793621\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4768     |\n",
      "|    fps              | 3278     |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 244141   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0048   |\n",
      "|    n_updates        | 61010    |\n",
      "----------------------------------\n",
      "Episode reward: 52.743671\n",
      "Episode reward: 81.873045\n",
      "Episode reward: 90.369699\n",
      "Episode reward: 47.933469\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4772     |\n",
      "|    fps              | 3278     |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 244415   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00338  |\n",
      "|    n_updates        | 61078    |\n",
      "----------------------------------\n",
      "Episode reward: 48.690959\n",
      "Episode reward: 39.926798\n",
      "Episode reward: 73.592753\n",
      "Episode reward: 44.754181\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4776     |\n",
      "|    fps              | 3278     |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 244624   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00657  |\n",
      "|    n_updates        | 61130    |\n",
      "----------------------------------\n",
      "Episode reward: 45.950579\n",
      "Episode reward: 56.937446\n",
      "Episode reward: 56.797727\n",
      "Episode reward: 35.849209\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4780     |\n",
      "|    fps              | 3277     |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 244820   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00441  |\n",
      "|    n_updates        | 61179    |\n",
      "----------------------------------\n",
      "Episode reward: 55.900011\n",
      "Episode reward: 38.832594\n",
      "Episode reward: 85.848229\n",
      "Episode reward: 57.912245\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4784     |\n",
      "|    fps              | 3277     |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 245059   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.4      |\n",
      "|    n_updates        | 61239    |\n",
      "----------------------------------\n",
      "Episode reward: 75.793794\n",
      "Episode reward: 56.857226\n",
      "Episode reward: 97.603567\n",
      "Episode reward: 66.537728\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4788     |\n",
      "|    fps              | 3277     |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 245357   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00604  |\n",
      "|    n_updates        | 61314    |\n",
      "----------------------------------\n",
      "Episode reward: 57.515307\n",
      "Episode reward: 108.871028\n",
      "Episode reward: 46.936362\n",
      "Episode reward: 86.894314\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4792     |\n",
      "|    fps              | 3276     |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 245658   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.033    |\n",
      "|    n_updates        | 61389    |\n",
      "----------------------------------\n",
      "Episode reward: 40.852008\n",
      "Episode reward: 57.673973\n",
      "Episode reward: 62.555261\n",
      "Episode reward: 68.724018\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4796     |\n",
      "|    fps              | 3276     |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 245889   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.151    |\n",
      "|    n_updates        | 61447    |\n",
      "----------------------------------\n",
      "Episode reward: 36.919513\n",
      "Episode reward: 56.861655\n",
      "Episode reward: 46.466944\n",
      "Episode reward: 91.612499\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4800     |\n",
      "|    fps              | 3275     |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 246122   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00331  |\n",
      "|    n_updates        | 61505    |\n",
      "----------------------------------\n",
      "Episode reward: 54.941617\n",
      "Episode reward: 61.752792\n",
      "Episode reward: 51.908717\n",
      "Episode reward: 46.928098\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4804     |\n",
      "|    fps              | 3274     |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 246338   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.27     |\n",
      "|    n_updates        | 61559    |\n",
      "----------------------------------\n",
      "Episode reward: 51.879854\n",
      "Episode reward: 104.661747\n",
      "Episode reward: 86.777796\n",
      "Episode reward: 68.555969\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4808     |\n",
      "|    fps              | 3275     |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 246651   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00388  |\n",
      "|    n_updates        | 61637    |\n",
      "----------------------------------\n",
      "Episode reward: 56.842938\n",
      "Episode reward: 53.866703\n",
      "Episode reward: 67.395872\n",
      "Episode reward: 47.91946\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4812     |\n",
      "|    fps              | 3275     |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 246878   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.152    |\n",
      "|    n_updates        | 61694    |\n",
      "----------------------------------\n",
      "Episode reward: 76.90946\n",
      "Episode reward: 42.590474\n",
      "Episode reward: 41.919074\n",
      "Episode reward: 33.821303\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4816     |\n",
      "|    fps              | 3275     |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 247074   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.247    |\n",
      "|    n_updates        | 61743    |\n",
      "----------------------------------\n",
      "Episode reward: 75.581655\n",
      "Episode reward: 53.862099\n",
      "Episode reward: 33.942188\n",
      "Episode reward: 69.343865\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4820     |\n",
      "|    fps              | 3275     |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 247308   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00576  |\n",
      "|    n_updates        | 61801    |\n",
      "----------------------------------\n",
      "Episode reward: 50.84526\n",
      "Episode reward: 57.542607\n",
      "Episode reward: 126.646672\n",
      "Episode reward: 55.892568\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4824     |\n",
      "|    fps              | 3275     |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 247602   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0723   |\n",
      "|    n_updates        | 61875    |\n",
      "----------------------------------\n",
      "Episode reward: 49.783332\n",
      "Episode reward: 43.875961\n",
      "Episode reward: 47.940044\n",
      "Episode reward: 69.697718\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4828     |\n",
      "|    fps              | 3275     |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 247814   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0056   |\n",
      "|    n_updates        | 61928    |\n",
      "----------------------------------\n",
      "Episode reward: 74.601683\n",
      "Episode reward: 50.891089\n",
      "Episode reward: 35.527026\n",
      "Episode reward: 56.550227\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4832     |\n",
      "|    fps              | 3274     |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 248033   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00364  |\n",
      "|    n_updates        | 61983    |\n",
      "----------------------------------\n",
      "Episode reward: 69.871341\n",
      "Episode reward: 45.80997\n",
      "Episode reward: 31.846542\n",
      "Episode reward: 43.89866\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4836     |\n",
      "|    fps              | 3274     |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 248225   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0195   |\n",
      "|    n_updates        | 62031    |\n",
      "----------------------------------\n",
      "Episode reward: 63.93162\n",
      "Episode reward: 44.940719\n",
      "Episode reward: 32.797658\n",
      "Episode reward: 47.848228\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4840     |\n",
      "|    fps              | 3273     |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 248415   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00369  |\n",
      "|    n_updates        | 62078    |\n",
      "----------------------------------\n",
      "Episode reward: 39.939744\n",
      "Episode reward: 54.932375\n",
      "Episode reward: 40.881356\n",
      "Episode reward: 60.848928\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4844     |\n",
      "|    fps              | 3274     |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 248612   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00238  |\n",
      "|    n_updates        | 62127    |\n",
      "----------------------------------\n",
      "Episode reward: 53.78196\n",
      "Episode reward: 50.828868\n",
      "Episode reward: 44.888185\n",
      "Episode reward: 52.923705\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4848     |\n",
      "|    fps              | 3274     |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 248815   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0511   |\n",
      "|    n_updates        | 62178    |\n",
      "----------------------------------\n",
      "Episode reward: 41.949504\n",
      "Episode reward: 53.846641\n",
      "Episode reward: 59.765409\n",
      "Episode reward: 60.918236\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4852     |\n",
      "|    fps              | 3274     |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 249032   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.128    |\n",
      "|    n_updates        | 62232    |\n",
      "----------------------------------\n",
      "Episode reward: 76.814152\n",
      "Episode reward: 31.9301\n",
      "Episode reward: 66.914452\n",
      "Episode reward: 54.940542\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4856     |\n",
      "|    fps              | 3273     |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 249263   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0669   |\n",
      "|    n_updates        | 62290    |\n",
      "----------------------------------\n",
      "Episode reward: 38.946753\n",
      "Episode reward: 66.80505\n",
      "Episode reward: 45.911595\n",
      "Episode reward: 81.831758\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4860     |\n",
      "|    fps              | 3273     |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 249497   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 62349    |\n",
      "----------------------------------\n",
      "Episode reward: 56.789473\n",
      "Episode reward: 61.790255\n",
      "Episode reward: 54.601248\n",
      "Episode reward: 67.91949\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4864     |\n",
      "|    fps              | 3273     |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 249739   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00341  |\n",
      "|    n_updates        | 62409    |\n",
      "----------------------------------\n",
      "Episode reward: 53.860238\n",
      "Episode reward: 43.908847\n",
      "Episode reward: 65.151988\n",
      "Episode reward: 63.502012\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4868     |\n",
      "|    fps              | 3273     |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 249968   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0805   |\n",
      "|    n_updates        | 62466    |\n",
      "----------------------------------\n",
      "Episode reward: 65.771015\n",
      "Episode reward: 49.730827\n",
      "Episode reward: 72.882167\n",
      "Episode reward: 42.893218\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4872     |\n",
      "|    fps              | 3273     |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 250200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 62524    |\n",
      "----------------------------------\n",
      "Episode reward: 56.531647\n",
      "Episode reward: 111.81235\n",
      "Episode reward: 30.940521\n",
      "Episode reward: 57.762073\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4876     |\n",
      "|    fps              | 3272     |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 250458   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.334    |\n",
      "|    n_updates        | 62589    |\n",
      "----------------------------------\n",
      "Episode reward: 54.914828\n",
      "Episode reward: 72.651827\n",
      "Episode reward: 41.919645\n",
      "Episode reward: 53.939306\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4880     |\n",
      "|    fps              | 3272     |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 250682   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00767  |\n",
      "|    n_updates        | 62645    |\n",
      "----------------------------------\n",
      "Episode reward: 41.912886\n",
      "Episode reward: 33.958133\n",
      "Episode reward: 50.850379\n",
      "Episode reward: 67.715273\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4884     |\n",
      "|    fps              | 3271     |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 250879   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00399  |\n",
      "|    n_updates        | 62694    |\n",
      "----------------------------------\n",
      "Episode reward: 43.929989\n",
      "Episode reward: 48.862938\n",
      "Episode reward: 79.207272\n",
      "Episode reward: 58.87809\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4888     |\n",
      "|    fps              | 3270     |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 251111   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00654  |\n",
      "|    n_updates        | 62752    |\n",
      "----------------------------------\n",
      "Episode reward: 50.614339\n",
      "Episode reward: 52.87148\n",
      "Episode reward: 38.837239\n",
      "Episode reward: 33.902122\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4892     |\n",
      "|    fps              | 3270     |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 251288   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.172    |\n",
      "|    n_updates        | 62796    |\n",
      "----------------------------------\n",
      "Episode reward: 91.33406\n",
      "Episode reward: 34.835051\n",
      "Episode reward: 58.703556\n",
      "Episode reward: 73.137363\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4896     |\n",
      "|    fps              | 3269     |\n",
      "|    time_elapsed     | 76       |\n",
      "|    total_timesteps  | 251550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00666  |\n",
      "|    n_updates        | 62862    |\n",
      "----------------------------------\n",
      "Episode reward: 48.922087\n",
      "Episode reward: 129.757899\n",
      "Episode reward: 48.939778\n",
      "Episode reward: 73.778525\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4900     |\n",
      "|    fps              | 3270     |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 251852   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00304  |\n",
      "|    n_updates        | 62937    |\n",
      "----------------------------------\n",
      "Episode reward: 47.537494\n",
      "Episode reward: 76.748938\n",
      "Episode reward: 44.836527\n",
      "Episode reward: 45.873925\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4904     |\n",
      "|    fps              | 3270     |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 252068   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 62991    |\n",
      "----------------------------------\n",
      "Episode reward: 49.863011\n",
      "Episode reward: 47.945248\n",
      "Episode reward: 47.443962\n",
      "Episode reward: 66.89822\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4908     |\n",
      "|    fps              | 3269     |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 252281   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 63045    |\n",
      "----------------------------------\n",
      "Episode reward: 45.737327\n",
      "Episode reward: 40.936513\n",
      "Episode reward: 84.415794\n",
      "Episode reward: 60.917117\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4912     |\n",
      "|    fps              | 3268     |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 252514   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00363  |\n",
      "|    n_updates        | 63103    |\n",
      "----------------------------------\n",
      "Episode reward: 47.887514\n",
      "Episode reward: 59.196264\n",
      "Episode reward: 76.343168\n",
      "Episode reward: 57.448973\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4916     |\n",
      "|    fps              | 3269     |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 252757   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00269  |\n",
      "|    n_updates        | 63164    |\n",
      "----------------------------------\n",
      "Episode reward: 48.83999\n",
      "Episode reward: 68.781254\n",
      "Episode reward: 36.888955\n",
      "Episode reward: 49.841336\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4920     |\n",
      "|    fps              | 3269     |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 252962   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00747  |\n",
      "|    n_updates        | 63215    |\n",
      "----------------------------------\n",
      "Episode reward: 83.885585\n",
      "Episode reward: 105.339989\n",
      "Episode reward: 71.606697\n",
      "Episode reward: 57.868716\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4924     |\n",
      "|    fps              | 3269     |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 253283   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00229  |\n",
      "|    n_updates        | 63295    |\n",
      "----------------------------------\n",
      "Episode reward: 50.923461\n",
      "Episode reward: 60.866344\n",
      "Episode reward: 88.83449\n",
      "Episode reward: 43.828517\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4928     |\n",
      "|    fps              | 3268     |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 253528   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0866   |\n",
      "|    n_updates        | 63356    |\n",
      "----------------------------------\n",
      "Episode reward: 41.487157\n",
      "Episode reward: 82.169864\n",
      "Episode reward: 64.813785\n",
      "Episode reward: 49.897299\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4932     |\n",
      "|    fps              | 3267     |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 253768   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00245  |\n",
      "|    n_updates        | 63416    |\n",
      "----------------------------------\n",
      "Episode reward: 66.880899\n",
      "Episode reward: 56.839563\n",
      "Episode reward: 52.593723\n",
      "Episode reward: 62.561673\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4936     |\n",
      "|    fps              | 3268     |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 254008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0754   |\n",
      "|    n_updates        | 63476    |\n",
      "----------------------------------\n",
      "Episode reward: 59.206932\n",
      "Episode reward: 58.904956\n",
      "Episode reward: 57.715533\n",
      "Episode reward: 51.922277\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4940     |\n",
      "|    fps              | 3267     |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 254237   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0469   |\n",
      "|    n_updates        | 63534    |\n",
      "----------------------------------\n",
      "Episode reward: 48.89457\n",
      "Episode reward: 40.751409\n",
      "Episode reward: 43.837682\n",
      "Episode reward: 37.944257\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4944     |\n",
      "|    fps              | 3267     |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 254409   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0427   |\n",
      "|    n_updates        | 63577    |\n",
      "----------------------------------\n",
      "Episode reward: 45.515265\n",
      "Episode reward: 57.752787\n",
      "Episode reward: 58.39878\n",
      "Episode reward: 45.589926\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4948     |\n",
      "|    fps              | 3268     |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 254618   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00509  |\n",
      "|    n_updates        | 63629    |\n",
      "----------------------------------\n",
      "Episode reward: 37.947608\n",
      "Episode reward: 106.237616\n",
      "Episode reward: 43.601967\n",
      "Episode reward: 96.869705\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4952     |\n",
      "|    fps              | 3268     |\n",
      "|    time_elapsed     | 77       |\n",
      "|    total_timesteps  | 254906   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.236    |\n",
      "|    n_updates        | 63701    |\n",
      "----------------------------------\n",
      "Episode reward: 47.930205\n",
      "Episode reward: 35.835345\n",
      "Episode reward: 51.867234\n",
      "Episode reward: 31.92738\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4956     |\n",
      "|    fps              | 3268     |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 255074   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0058   |\n",
      "|    n_updates        | 63743    |\n",
      "----------------------------------\n",
      "Episode reward: 48.932987\n",
      "Episode reward: 82.889976\n",
      "Episode reward: 46.893027\n",
      "Episode reward: 50.908171\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4960     |\n",
      "|    fps              | 3267     |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 255304   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0067   |\n",
      "|    n_updates        | 63800    |\n",
      "----------------------------------\n",
      "Episode reward: 50.331566\n",
      "Episode reward: 112.818151\n",
      "Episode reward: 55.921526\n",
      "Episode reward: 33.905594\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4964     |\n",
      "|    fps              | 3267     |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 255560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0217   |\n",
      "|    n_updates        | 63864    |\n",
      "----------------------------------\n",
      "Episode reward: 64.846619\n",
      "Episode reward: 49.849072\n",
      "Episode reward: 43.918346\n",
      "Episode reward: 66.648071\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4968     |\n",
      "|    fps              | 3266     |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 255786   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 63921    |\n",
      "----------------------------------\n",
      "Episode reward: 35.774288\n",
      "Episode reward: 53.758862\n",
      "Episode reward: 49.880427\n",
      "Episode reward: 123.625465\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4972     |\n",
      "|    fps              | 3265     |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 256050   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0092   |\n",
      "|    n_updates        | 63987    |\n",
      "----------------------------------\n",
      "Episode reward: 63.702725\n",
      "Episode reward: 36.944627\n",
      "Episode reward: 46.894504\n",
      "Episode reward: 42.896197\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4976     |\n",
      "|    fps              | 3265     |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 256241   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.215    |\n",
      "|    n_updates        | 64035    |\n",
      "----------------------------------\n",
      "Episode reward: 61.900399\n",
      "Episode reward: 40.933444\n",
      "Episode reward: 65.886891\n",
      "Episode reward: 41.78495\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4980     |\n",
      "|    fps              | 3265     |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 256452   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0421   |\n",
      "|    n_updates        | 64087    |\n",
      "----------------------------------\n",
      "Episode reward: 50.665205\n",
      "Episode reward: 55.614985\n",
      "Episode reward: 66.632991\n",
      "Episode reward: 36.716775\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4984     |\n",
      "|    fps              | 3264     |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 256663   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.152    |\n",
      "|    n_updates        | 64140    |\n",
      "----------------------------------\n",
      "Episode reward: 46.908687\n",
      "Episode reward: 59.755294\n",
      "Episode reward: 76.351032\n",
      "Episode reward: 64.921529\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4988     |\n",
      "|    fps              | 3264     |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 256912   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.133    |\n",
      "|    n_updates        | 64202    |\n",
      "----------------------------------\n",
      "Episode reward: 36.924388\n",
      "Episode reward: 73.818026\n",
      "Episode reward: 65.916987\n",
      "Episode reward: 62.738359\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4992     |\n",
      "|    fps              | 3263     |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 257152   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0902   |\n",
      "|    n_updates        | 64262    |\n",
      "----------------------------------\n",
      "Episode reward: 69.702939\n",
      "Episode reward: 48.935868\n",
      "Episode reward: 43.942764\n",
      "Episode reward: 31.942937\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 4996     |\n",
      "|    fps              | 3262     |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 257347   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00375  |\n",
      "|    n_updates        | 64311    |\n",
      "----------------------------------\n",
      "Episode reward: 38.944858\n",
      "Episode reward: 74.236726\n",
      "Episode reward: 31.882075\n",
      "Episode reward: 85.61926\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5000     |\n",
      "|    fps              | 3261     |\n",
      "|    time_elapsed     | 78       |\n",
      "|    total_timesteps  | 257579   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00518  |\n",
      "|    n_updates        | 64369    |\n",
      "----------------------------------\n",
      "Episode reward: 73.354079\n",
      "Episode reward: 46.947185\n",
      "Episode reward: 54.894526\n",
      "Episode reward: 64.743507\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5004     |\n",
      "|    fps              | 3259     |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 257821   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.311    |\n",
      "|    n_updates        | 64430    |\n",
      "----------------------------------\n",
      "Episode reward: 70.807955\n",
      "Episode reward: 44.887155\n",
      "Episode reward: 42.88869\n",
      "Episode reward: 37.877841\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5008     |\n",
      "|    fps              | 3258     |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 258018   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00329  |\n",
      "|    n_updates        | 64479    |\n",
      "----------------------------------\n",
      "Episode reward: 56.786592\n",
      "Episode reward: 36.83053\n",
      "Episode reward: 48.732879\n",
      "Episode reward: 32.778196\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5012     |\n",
      "|    fps              | 3258     |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 258194   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.182    |\n",
      "|    n_updates        | 64523    |\n",
      "----------------------------------\n",
      "Episode reward: 41.943602\n",
      "Episode reward: 45.778604\n",
      "Episode reward: 35.688728\n",
      "Episode reward: 52.981598\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5016     |\n",
      "|    fps              | 3257     |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 258372   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0298   |\n",
      "|    n_updates        | 64567    |\n",
      "----------------------------------\n",
      "Episode reward: 46.891706\n",
      "Episode reward: 60.833527\n",
      "Episode reward: 39.518253\n",
      "Episode reward: 32.953737\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5020     |\n",
      "|    fps              | 3257     |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 258553   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00526  |\n",
      "|    n_updates        | 64613    |\n",
      "----------------------------------\n",
      "Episode reward: 43.58182\n",
      "Episode reward: 41.920749\n",
      "Episode reward: 107.783705\n",
      "Episode reward: 43.887476\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5024     |\n",
      "|    fps              | 3257     |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 258792   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.137    |\n",
      "|    n_updates        | 64672    |\n",
      "----------------------------------\n",
      "Episode reward: 88.978705\n",
      "Episode reward: 45.682124\n",
      "Episode reward: 41.70849\n",
      "Episode reward: 57.925014\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55       |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5028     |\n",
      "|    fps              | 3257     |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 259028   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00535  |\n",
      "|    n_updates        | 64731    |\n",
      "----------------------------------\n",
      "Episode reward: 63.709399\n",
      "Episode reward: 61.335789\n",
      "Episode reward: 43.665844\n",
      "Episode reward: 65.304823\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55       |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5032     |\n",
      "|    fps              | 3257     |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 259264   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00269  |\n",
      "|    n_updates        | 64790    |\n",
      "----------------------------------\n",
      "Episode reward: 43.86718\n",
      "Episode reward: 53.930474\n",
      "Episode reward: 88.670343\n",
      "Episode reward: 60.889195\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55       |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5036     |\n",
      "|    fps              | 3257     |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 259513   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00513  |\n",
      "|    n_updates        | 64853    |\n",
      "----------------------------------\n",
      "Episode reward: 47.575359\n",
      "Episode reward: 42.820793\n",
      "Episode reward: 45.921482\n",
      "Episode reward: 39.832429\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5040     |\n",
      "|    fps              | 3257     |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 259690   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00677  |\n",
      "|    n_updates        | 64897    |\n",
      "----------------------------------\n",
      "Episode reward: 56.924199\n",
      "Episode reward: 52.812273\n",
      "Episode reward: 49.74058\n",
      "Episode reward: 33.936218\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.8     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5044     |\n",
      "|    fps              | 3257     |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 259884   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00644  |\n",
      "|    n_updates        | 64945    |\n",
      "----------------------------------\n",
      "Episode reward: 114.807109\n",
      "Episode reward: 63.924164\n",
      "Episode reward: 55.270966\n",
      "Episode reward: 53.887931\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.5     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5048     |\n",
      "|    fps              | 3257     |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 260173   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.1      |\n",
      "|    n_updates        | 65018    |\n",
      "----------------------------------\n",
      "Episode reward: 32.840676\n",
      "Episode reward: 49.878136\n",
      "Episode reward: 44.863365\n",
      "Episode reward: 46.308881\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.4     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5052     |\n",
      "|    fps              | 3257     |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 260348   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0854   |\n",
      "|    n_updates        | 65061    |\n",
      "----------------------------------\n",
      "Episode reward: 46.626906\n",
      "Episode reward: 43.813402\n",
      "Episode reward: 49.94458\n",
      "Episode reward: 42.95046\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.6     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5056     |\n",
      "|    fps              | 3256     |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 260532   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.366    |\n",
      "|    n_updates        | 65107    |\n",
      "----------------------------------\n",
      "Episode reward: 47.939759\n",
      "Episode reward: 60.847785\n",
      "Episode reward: 76.869173\n",
      "Episode reward: 52.876578\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.7     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5060     |\n",
      "|    fps              | 3256     |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 260771   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 65167    |\n",
      "----------------------------------\n",
      "Episode reward: 45.892011\n",
      "Episode reward: 37.915535\n",
      "Episode reward: 46.815063\n",
      "Episode reward: 42.936155\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.9     |\n",
      "|    ep_rew_mean      | 53.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5064     |\n",
      "|    fps              | 3256     |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 260945   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00602  |\n",
      "|    n_updates        | 65211    |\n",
      "----------------------------------\n",
      "Episode reward: 61.661736\n",
      "Episode reward: 52.590518\n",
      "Episode reward: 47.817699\n",
      "Episode reward: 30.79963\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.5     |\n",
      "|    ep_rew_mean      | 53.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5068     |\n",
      "|    fps              | 3255     |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 261139   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00563  |\n",
      "|    n_updates        | 65259    |\n",
      "----------------------------------\n",
      "Episode reward: 48.933605\n",
      "Episode reward: 57.214849\n",
      "Episode reward: 50.85027\n",
      "Episode reward: 32.881729\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.8     |\n",
      "|    ep_rew_mean      | 52.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5072     |\n",
      "|    fps              | 3254     |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 261330   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0763   |\n",
      "|    n_updates        | 65307    |\n",
      "----------------------------------\n",
      "Episode reward: 40.930017\n",
      "Episode reward: 89.821036\n",
      "Episode reward: 49.868485\n",
      "Episode reward: 38.944354\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.1     |\n",
      "|    ep_rew_mean      | 52.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5076     |\n",
      "|    fps              | 3255     |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 261550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.195    |\n",
      "|    n_updates        | 65362    |\n",
      "----------------------------------\n",
      "Episode reward: 35.813421\n",
      "Episode reward: 59.928708\n",
      "Episode reward: 59.735723\n",
      "Episode reward: 38.824231\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.9     |\n",
      "|    ep_rew_mean      | 52.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5080     |\n",
      "|    fps              | 3254     |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 261745   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00924  |\n",
      "|    n_updates        | 65411    |\n",
      "----------------------------------\n",
      "Episode reward: 68.869267\n",
      "Episode reward: 61.497907\n",
      "Episode reward: 37.840389\n",
      "Episode reward: 43.887958\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53       |\n",
      "|    ep_rew_mean      | 52.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5084     |\n",
      "|    fps              | 3253     |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 261960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00739  |\n",
      "|    n_updates        | 65464    |\n",
      "----------------------------------\n",
      "Episode reward: 52.618778\n",
      "Episode reward: 49.86846\n",
      "Episode reward: 45.942527\n",
      "Episode reward: 38.924905\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.4     |\n",
      "|    ep_rew_mean      | 52.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5088     |\n",
      "|    fps              | 3252     |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 262148   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00445  |\n",
      "|    n_updates        | 65511    |\n",
      "----------------------------------\n",
      "Episode reward: 63.906573\n",
      "Episode reward: 44.894534\n",
      "Episode reward: 65.610535\n",
      "Episode reward: 97.692011\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.7     |\n",
      "|    ep_rew_mean      | 52.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5092     |\n",
      "|    fps              | 3252     |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 262422   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0967   |\n",
      "|    n_updates        | 65580    |\n",
      "----------------------------------\n",
      "Episode reward: 44.941887\n",
      "Episode reward: 32.923187\n",
      "Episode reward: 51.867197\n",
      "Episode reward: 62.680778\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.7     |\n",
      "|    ep_rew_mean      | 52.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5096     |\n",
      "|    fps              | 3252     |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 262615   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00834  |\n",
      "|    n_updates        | 65628    |\n",
      "----------------------------------\n",
      "Episode reward: 52.930482\n",
      "Episode reward: 40.930539\n",
      "Episode reward: 59.862222\n",
      "Episode reward: 94.575494\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.9     |\n",
      "|    ep_rew_mean      | 52.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5100     |\n",
      "|    fps              | 3251     |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 262864   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 65690    |\n",
      "----------------------------------\n",
      "Episode reward: 39.870699\n",
      "Episode reward: 75.706077\n",
      "Episode reward: 37.671801\n",
      "Episode reward: 34.952218\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.3     |\n",
      "|    ep_rew_mean      | 52       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5104     |\n",
      "|    fps              | 3250     |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 263053   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00571  |\n",
      "|    n_updates        | 65738    |\n",
      "----------------------------------\n",
      "Episode reward: 59.823659\n",
      "Episode reward: 40.915776\n",
      "Episode reward: 32.860642\n",
      "Episode reward: 68.801938\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.4     |\n",
      "|    ep_rew_mean      | 52.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5108     |\n",
      "|    fps              | 3250     |\n",
      "|    time_elapsed     | 80       |\n",
      "|    total_timesteps  | 263256   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00724  |\n",
      "|    n_updates        | 65788    |\n",
      "----------------------------------\n",
      "Episode reward: 81.80893\n",
      "Episode reward: 42.928474\n",
      "Episode reward: 51.330578\n",
      "Episode reward: 52.668739\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.9     |\n",
      "|    ep_rew_mean      | 52.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5112     |\n",
      "|    fps              | 3250     |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 263486   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0393   |\n",
      "|    n_updates        | 65846    |\n",
      "----------------------------------\n",
      "Episode reward: 43.897475\n",
      "Episode reward: 64.714396\n",
      "Episode reward: 93.69836\n",
      "Episode reward: 54.913813\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.7     |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5116     |\n",
      "|    fps              | 3250     |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 263744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0234   |\n",
      "|    n_updates        | 65910    |\n",
      "----------------------------------\n",
      "Episode reward: 47.906309\n",
      "Episode reward: 54.834269\n",
      "Episode reward: 65.926619\n",
      "Episode reward: 63.044256\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.2     |\n",
      "|    ep_rew_mean      | 54       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5120     |\n",
      "|    fps              | 3250     |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 263977   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.3      |\n",
      "|    n_updates        | 65969    |\n",
      "----------------------------------\n",
      "Episode reward: 36.856807\n",
      "Episode reward: 61.800105\n",
      "Episode reward: 49.727885\n",
      "Episode reward: 39.898903\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.7     |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5124     |\n",
      "|    fps              | 3250     |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 264166   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 66016    |\n",
      "----------------------------------\n",
      "Episode reward: 146.562104\n",
      "Episode reward: 38.949055\n",
      "Episode reward: 62.868039\n",
      "Episode reward: 38.926135\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.3     |\n",
      "|    ep_rew_mean      | 54       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5128     |\n",
      "|    fps              | 3250     |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 264454   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0871   |\n",
      "|    n_updates        | 66088    |\n",
      "----------------------------------\n",
      "Episode reward: 50.778429\n",
      "Episode reward: 67.900951\n",
      "Episode reward: 91.208118\n",
      "Episode reward: 51.915971\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5132     |\n",
      "|    fps              | 3250     |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 264717   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00508  |\n",
      "|    n_updates        | 66154    |\n",
      "----------------------------------\n",
      "Episode reward: 45.924003\n",
      "Episode reward: 46.945393\n",
      "Episode reward: 69.695172\n",
      "Episode reward: 80.876335\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5136     |\n",
      "|    fps              | 3249     |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 264962   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00508  |\n",
      "|    n_updates        | 66215    |\n",
      "----------------------------------\n",
      "Episode reward: 47.561065\n",
      "Episode reward: 49.256278\n",
      "Episode reward: 60.787137\n",
      "Episode reward: 50.748991\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.8     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5140     |\n",
      "|    fps              | 3248     |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 265172   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.413    |\n",
      "|    n_updates        | 66267    |\n",
      "----------------------------------\n",
      "Episode reward: 111.319612\n",
      "Episode reward: 39.935197\n",
      "Episode reward: 45.922419\n",
      "Episode reward: 39.951237\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5144     |\n",
      "|    fps              | 3248     |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 265410   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 66327    |\n",
      "----------------------------------\n",
      "Episode reward: 37.595391\n",
      "Episode reward: 36.831646\n",
      "Episode reward: 49.923444\n",
      "Episode reward: 39.952247\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54       |\n",
      "|    ep_rew_mean      | 53.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5148     |\n",
      "|    fps              | 3248     |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 265575   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00824  |\n",
      "|    n_updates        | 66368    |\n",
      "----------------------------------\n",
      "Episode reward: 47.919892\n",
      "Episode reward: 35.951124\n",
      "Episode reward: 41.494308\n",
      "Episode reward: 56.84672\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.1     |\n",
      "|    ep_rew_mean      | 53.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5152     |\n",
      "|    fps              | 3248     |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 265758   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.286    |\n",
      "|    n_updates        | 66414    |\n",
      "----------------------------------\n",
      "Episode reward: 49.948216\n",
      "Episode reward: 91.841087\n",
      "Episode reward: 33.948367\n",
      "Episode reward: 39.904132\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.4     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5156     |\n",
      "|    fps              | 3246     |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 265974   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00858  |\n",
      "|    n_updates        | 66468    |\n",
      "----------------------------------\n",
      "Episode reward: 39.888393\n",
      "Episode reward: 55.634047\n",
      "Episode reward: 103.728767\n",
      "Episode reward: 71.917285\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.8     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5160     |\n",
      "|    fps              | 3247     |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 266247   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 66536    |\n",
      "----------------------------------\n",
      "Episode reward: 111.793596\n",
      "Episode reward: 47.723579\n",
      "Episode reward: 120.974414\n",
      "Episode reward: 59.538802\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5164     |\n",
      "|    fps              | 3246     |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 266589   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 66622    |\n",
      "----------------------------------\n",
      "Episode reward: 55.861263\n",
      "Episode reward: 40.866259\n",
      "Episode reward: 71.639404\n",
      "Episode reward: 131.85234\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5168     |\n",
      "|    fps              | 3247     |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 266890   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.254    |\n",
      "|    n_updates        | 66697    |\n",
      "----------------------------------\n",
      "Episode reward: 50.944325\n",
      "Episode reward: 55.571275\n",
      "Episode reward: 53.915329\n",
      "Episode reward: 96.762465\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5172     |\n",
      "|    fps              | 3246     |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 267149   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0203   |\n",
      "|    n_updates        | 66762    |\n",
      "----------------------------------\n",
      "Episode reward: 48.909804\n",
      "Episode reward: 48.848565\n",
      "Episode reward: 51.931012\n",
      "Episode reward: 34.870908\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5176     |\n",
      "|    fps              | 3247     |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 267334   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00415  |\n",
      "|    n_updates        | 66808    |\n",
      "----------------------------------\n",
      "Episode reward: 41.95496\n",
      "Episode reward: 61.68859\n",
      "Episode reward: 60.717585\n",
      "Episode reward: 43.94651\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5180     |\n",
      "|    fps              | 3246     |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 267543   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00663  |\n",
      "|    n_updates        | 66860    |\n",
      "----------------------------------\n",
      "Episode reward: 48.71849\n",
      "Episode reward: 51.930809\n",
      "Episode reward: 74.884768\n",
      "Episode reward: 39.859649\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5184     |\n",
      "|    fps              | 3245     |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 267759   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00485  |\n",
      "|    n_updates        | 66914    |\n",
      "----------------------------------\n",
      "Episode reward: 35.92159\n",
      "Episode reward: 47.935247\n",
      "Episode reward: 34.941666\n",
      "Episode reward: 44.931686\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5188     |\n",
      "|    fps              | 3244     |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 267923   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 66955    |\n",
      "----------------------------------\n",
      "Episode reward: 70.684846\n",
      "Episode reward: 62.693826\n",
      "Episode reward: 35.884636\n",
      "Episode reward: 45.747334\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5192     |\n",
      "|    fps              | 3243     |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 268139   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0911   |\n",
      "|    n_updates        | 67009    |\n",
      "----------------------------------\n",
      "Episode reward: 99.758891\n",
      "Episode reward: 39.831738\n",
      "Episode reward: 39.924103\n",
      "Episode reward: 71.703697\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5196     |\n",
      "|    fps              | 3242     |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 268391   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 67072    |\n",
      "----------------------------------\n",
      "Episode reward: 77.960745\n",
      "Episode reward: 57.865275\n",
      "Episode reward: 36.956302\n",
      "Episode reward: 45.758311\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5200     |\n",
      "|    fps              | 3243     |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 268611   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00507  |\n",
      "|    n_updates        | 67127    |\n",
      "----------------------------------\n",
      "Episode reward: 45.75287\n",
      "Episode reward: 43.860745\n",
      "Episode reward: 61.8835\n",
      "Episode reward: 57.530514\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5204     |\n",
      "|    fps              | 3241     |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 268821   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00414  |\n",
      "|    n_updates        | 67180    |\n",
      "----------------------------------\n",
      "Episode reward: 38.740994\n",
      "Episode reward: 73.533537\n",
      "Episode reward: 33.943586\n",
      "Episode reward: 92.857899\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5208     |\n",
      "|    fps              | 3241     |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 269061   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00457  |\n",
      "|    n_updates        | 67240    |\n",
      "----------------------------------\n",
      "Episode reward: 52.73276\n",
      "Episode reward: 45.903937\n",
      "Episode reward: 72.808443\n",
      "Episode reward: 40.929453\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5212     |\n",
      "|    fps              | 3241     |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 269275   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0064   |\n",
      "|    n_updates        | 67293    |\n",
      "----------------------------------\n",
      "Episode reward: 53.782344\n",
      "Episode reward: 56.822319\n",
      "Episode reward: 58.469039\n",
      "Episode reward: 50.818921\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5216     |\n",
      "|    fps              | 3241     |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 269496   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00553  |\n",
      "|    n_updates        | 67348    |\n",
      "----------------------------------\n",
      "Episode reward: 50.938038\n",
      "Episode reward: 47.940414\n",
      "Episode reward: 105.843209\n",
      "Episode reward: 47.782857\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5220     |\n",
      "|    fps              | 3237     |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 269749   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 67412    |\n",
      "----------------------------------\n",
      "Episode reward: 42.84958\n",
      "Episode reward: 47.736359\n",
      "Episode reward: 81.787853\n",
      "Episode reward: 64.634217\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5224     |\n",
      "|    fps              | 3236     |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 269987   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00634  |\n",
      "|    n_updates        | 67471    |\n",
      "----------------------------------\n",
      "Episode reward: 53.648054\n",
      "Episode reward: 57.577961\n",
      "Episode reward: 39.866687\n",
      "Episode reward: 41.92708\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5228     |\n",
      "|    fps              | 3236     |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 270181   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.125    |\n",
      "|    n_updates        | 67520    |\n",
      "----------------------------------\n",
      "Episode reward: 40.772075\n",
      "Episode reward: 75.485934\n",
      "Episode reward: 44.941117\n",
      "Episode reward: 62.918021\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5232     |\n",
      "|    fps              | 3235     |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 270406   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00506  |\n",
      "|    n_updates        | 67576    |\n",
      "----------------------------------\n",
      "Episode reward: 44.948197\n",
      "Episode reward: 43.715613\n",
      "Episode reward: 49.490268\n",
      "Episode reward: 37.92532\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5236     |\n",
      "|    fps              | 3235     |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 270583   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 67620    |\n",
      "----------------------------------\n",
      "Episode reward: 53.888341\n",
      "Episode reward: 39.473324\n",
      "Episode reward: 59.711872\n",
      "Episode reward: 34.749576\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5240     |\n",
      "|    fps              | 3234     |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 270772   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00832  |\n",
      "|    n_updates        | 67667    |\n",
      "----------------------------------\n",
      "Episode reward: 76.846534\n",
      "Episode reward: 39.914482\n",
      "Episode reward: 80.878069\n",
      "Episode reward: 56.924462\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5244     |\n",
      "|    fps              | 3234     |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 271027   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.161    |\n",
      "|    n_updates        | 67731    |\n",
      "----------------------------------\n",
      "Episode reward: 45.720648\n",
      "Episode reward: 65.797663\n",
      "Episode reward: 45.927429\n",
      "Episode reward: 73.783105\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5248     |\n",
      "|    fps              | 3233     |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 271259   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00917  |\n",
      "|    n_updates        | 67789    |\n",
      "----------------------------------\n",
      "Episode reward: 40.656499\n",
      "Episode reward: 60.776516\n",
      "Episode reward: 49.483736\n",
      "Episode reward: 47.578766\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5252     |\n",
      "|    fps              | 3233     |\n",
      "|    time_elapsed     | 83       |\n",
      "|    total_timesteps  | 271459   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0964   |\n",
      "|    n_updates        | 67839    |\n",
      "----------------------------------\n",
      "Episode reward: 42.830073\n",
      "Episode reward: 46.81527\n",
      "Episode reward: 83.934168\n",
      "Episode reward: 56.86968\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5256     |\n",
      "|    fps              | 3233     |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 271691   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00833  |\n",
      "|    n_updates        | 67897    |\n",
      "----------------------------------\n",
      "Episode reward: 54.831777\n",
      "Episode reward: 48.904551\n",
      "Episode reward: 33.958451\n",
      "Episode reward: 91.856921\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5260     |\n",
      "|    fps              | 3231     |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 271922   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0536   |\n",
      "|    n_updates        | 67955    |\n",
      "----------------------------------\n",
      "Episode reward: 46.6303\n",
      "Episode reward: 120.165056\n",
      "Episode reward: 43.850154\n",
      "Episode reward: 32.964804\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5264     |\n",
      "|    fps              | 3231     |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 272172   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00378  |\n",
      "|    n_updates        | 68017    |\n",
      "----------------------------------\n",
      "Episode reward: 55.514253\n",
      "Episode reward: 45.931147\n",
      "Episode reward: 42.950842\n",
      "Episode reward: 72.643945\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55       |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5268     |\n",
      "|    fps              | 3231     |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 272390   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.278    |\n",
      "|    n_updates        | 68072    |\n",
      "----------------------------------\n",
      "Episode reward: 59.519096\n",
      "Episode reward: 38.905585\n",
      "Episode reward: 55.615463\n",
      "Episode reward: 80.46466\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.8     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5272     |\n",
      "|    fps              | 3230     |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 272626   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0088   |\n",
      "|    n_updates        | 68131    |\n",
      "----------------------------------\n",
      "Episode reward: 35.712509\n",
      "Episode reward: 47.925794\n",
      "Episode reward: 96.126114\n",
      "Episode reward: 133.14945\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5276     |\n",
      "|    fps              | 3231     |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 272950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00554  |\n",
      "|    n_updates        | 68212    |\n",
      "----------------------------------\n",
      "Episode reward: 72.799907\n",
      "Episode reward: 78.785776\n",
      "Episode reward: 63.731901\n",
      "Episode reward: 48.58612\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5280     |\n",
      "|    fps              | 3230     |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 273219   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0196   |\n",
      "|    n_updates        | 68279    |\n",
      "----------------------------------\n",
      "Episode reward: 58.761612\n",
      "Episode reward: 37.920044\n",
      "Episode reward: 42.862604\n",
      "Episode reward: 41.925751\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5284     |\n",
      "|    fps              | 3230     |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 273401   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0483   |\n",
      "|    n_updates        | 68325    |\n",
      "----------------------------------\n",
      "Episode reward: 73.597625\n",
      "Episode reward: 90.339869\n",
      "Episode reward: 43.874715\n",
      "Episode reward: 93.758688\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5288     |\n",
      "|    fps              | 3230     |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 273704   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0296   |\n",
      "|    n_updates        | 68400    |\n",
      "----------------------------------\n",
      "Episode reward: 47.192496\n",
      "Episode reward: 35.960741\n",
      "Episode reward: 106.855806\n",
      "Episode reward: 57.194578\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5292     |\n",
      "|    fps              | 3230     |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 273953   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0782   |\n",
      "|    n_updates        | 68463    |\n",
      "----------------------------------\n",
      "Episode reward: 107.778052\n",
      "Episode reward: 75.766766\n",
      "Episode reward: 48.917523\n",
      "Episode reward: 37.950108\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5296     |\n",
      "|    fps              | 3229     |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 274224   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00459  |\n",
      "|    n_updates        | 68530    |\n",
      "----------------------------------\n",
      "Episode reward: 43.880907\n",
      "Episode reward: 70.507458\n",
      "Episode reward: 71.859587\n",
      "Episode reward: 68.827503\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5300     |\n",
      "|    fps              | 3229     |\n",
      "|    time_elapsed     | 84       |\n",
      "|    total_timesteps  | 274481   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00416  |\n",
      "|    n_updates        | 68595    |\n",
      "----------------------------------\n",
      "Episode reward: 79.904047\n",
      "Episode reward: 77.417823\n",
      "Episode reward: 40.784848\n",
      "Episode reward: 35.953379\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5304     |\n",
      "|    fps              | 3229     |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 274716   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00624  |\n",
      "|    n_updates        | 68653    |\n",
      "----------------------------------\n",
      "Episode reward: 87.803025\n",
      "Episode reward: 43.841344\n",
      "Episode reward: 38.943837\n",
      "Episode reward: 62.927589\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5308     |\n",
      "|    fps              | 3229     |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 274950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00875  |\n",
      "|    n_updates        | 68712    |\n",
      "----------------------------------\n",
      "Episode reward: 41.942251\n",
      "Episode reward: 80.754068\n",
      "Episode reward: 83.626592\n",
      "Episode reward: 47.919951\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5312     |\n",
      "|    fps              | 3229     |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 275205   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00512  |\n",
      "|    n_updates        | 68776    |\n",
      "----------------------------------\n",
      "Episode reward: 43.94539\n",
      "Episode reward: 47.852674\n",
      "Episode reward: 70.779949\n",
      "Episode reward: 76.488873\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5316     |\n",
      "|    fps              | 3228     |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 275445   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00954  |\n",
      "|    n_updates        | 68836    |\n",
      "----------------------------------\n",
      "Episode reward: 35.871543\n",
      "Episode reward: 60.924405\n",
      "Episode reward: 39.946634\n",
      "Episode reward: 55.882511\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5320     |\n",
      "|    fps              | 3228     |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 275638   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00963  |\n",
      "|    n_updates        | 68884    |\n",
      "----------------------------------\n",
      "Episode reward: 40.955285\n",
      "Episode reward: 64.712242\n",
      "Episode reward: 71.454949\n",
      "Episode reward: 41.775904\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5324     |\n",
      "|    fps              | 3228     |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 275858   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00677  |\n",
      "|    n_updates        | 68939    |\n",
      "----------------------------------\n",
      "Episode reward: 33.837219\n",
      "Episode reward: 47.928035\n",
      "Episode reward: 51.778848\n",
      "Episode reward: 54.387814\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5328     |\n",
      "|    fps              | 3227     |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 276047   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 68986    |\n",
      "----------------------------------\n",
      "Episode reward: 75.852555\n",
      "Episode reward: 78.838039\n",
      "Episode reward: 87.896065\n",
      "Episode reward: 59.697445\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5332     |\n",
      "|    fps              | 3228     |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 276350   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00307  |\n",
      "|    n_updates        | 69062    |\n",
      "----------------------------------\n",
      "Episode reward: 63.906209\n",
      "Episode reward: 132.310048\n",
      "Episode reward: 58.844833\n",
      "Episode reward: 42.923065\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5336     |\n",
      "|    fps              | 3228     |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 276652   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00388  |\n",
      "|    n_updates        | 69137    |\n",
      "----------------------------------\n",
      "Episode reward: 36.935731\n",
      "Episode reward: 36.774647\n",
      "Episode reward: 32.920234\n",
      "Episode reward: 45.920933\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5340     |\n",
      "|    fps              | 3228     |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 276805   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00605  |\n",
      "|    n_updates        | 69176    |\n",
      "----------------------------------\n",
      "Episode reward: 107.709022\n",
      "Episode reward: 75.887403\n",
      "Episode reward: 36.927974\n",
      "Episode reward: 107.999877\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5344     |\n",
      "|    fps              | 3227     |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 277136   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00544  |\n",
      "|    n_updates        | 69258    |\n",
      "----------------------------------\n",
      "Episode reward: 63.505102\n",
      "Episode reward: 58.780479\n",
      "Episode reward: 44.943825\n",
      "Episode reward: 33.949419\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5348     |\n",
      "|    fps              | 3227     |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 277339   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00416  |\n",
      "|    n_updates        | 69309    |\n",
      "----------------------------------\n",
      "Episode reward: 52.309552\n",
      "Episode reward: 64.696106\n",
      "Episode reward: 38.88805\n",
      "Episode reward: 55.837952\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5352     |\n",
      "|    fps              | 3227     |\n",
      "|    time_elapsed     | 85       |\n",
      "|    total_timesteps  | 277552   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.168    |\n",
      "|    n_updates        | 69362    |\n",
      "----------------------------------\n",
      "Episode reward: 62.980695\n",
      "Episode reward: 42.932858\n",
      "Episode reward: 67.917648\n",
      "Episode reward: 95.380806\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5356     |\n",
      "|    fps              | 3227     |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 277823   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 69430    |\n",
      "----------------------------------\n",
      "Episode reward: 49.930155\n",
      "Episode reward: 49.817223\n",
      "Episode reward: 48.879892\n",
      "Episode reward: 47.745992\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5360     |\n",
      "|    fps              | 3227     |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 278020   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 69479    |\n",
      "----------------------------------\n",
      "Episode reward: 46.876051\n",
      "Episode reward: 63.856326\n",
      "Episode reward: 51.162342\n",
      "Episode reward: 79.435755\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5364     |\n",
      "|    fps              | 3226     |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 278263   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00502  |\n",
      "|    n_updates        | 69540    |\n",
      "----------------------------------\n",
      "Episode reward: 48.749358\n",
      "Episode reward: 81.90778\n",
      "Episode reward: 58.44057\n",
      "Episode reward: 55.60323\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5368     |\n",
      "|    fps              | 3226     |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 278509   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00823  |\n",
      "|    n_updates        | 69602    |\n",
      "----------------------------------\n",
      "Episode reward: 113.870568\n",
      "Episode reward: 63.933303\n",
      "Episode reward: 90.166992\n",
      "Episode reward: 45.844596\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5372     |\n",
      "|    fps              | 3226     |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 278828   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00295  |\n",
      "|    n_updates        | 69681    |\n",
      "----------------------------------\n",
      "Episode reward: 54.623809\n",
      "Episode reward: 45.683304\n",
      "Episode reward: 45.908827\n",
      "Episode reward: 54.87529\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5376     |\n",
      "|    fps              | 3226     |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 279030   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 69732    |\n",
      "----------------------------------\n",
      "Episode reward: 57.82569\n",
      "Episode reward: 28.88547\n",
      "Episode reward: 56.880798\n",
      "Episode reward: 66.915837\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5380     |\n",
      "|    fps              | 3225     |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 279241   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00871  |\n",
      "|    n_updates        | 69785    |\n",
      "----------------------------------\n",
      "Episode reward: 71.470622\n",
      "Episode reward: 129.122715\n",
      "Episode reward: 59.74496\n",
      "Episode reward: 68.19075\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5384     |\n",
      "|    fps              | 3225     |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 279574   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0251   |\n",
      "|    n_updates        | 69868    |\n",
      "----------------------------------\n",
      "Episode reward: 126.372194\n",
      "Episode reward: 70.536824\n",
      "Episode reward: 87.364583\n",
      "Episode reward: 39.877538\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5388     |\n",
      "|    fps              | 3225     |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 279903   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 69950    |\n",
      "----------------------------------\n",
      "Episode reward: 59.857659\n",
      "Episode reward: 46.944014\n",
      "Episode reward: 36.929988\n",
      "Episode reward: 48.773391\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5392     |\n",
      "|    fps              | 3225     |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 280096   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0389   |\n",
      "|    n_updates        | 69998    |\n",
      "----------------------------------\n",
      "Episode reward: 46.874493\n",
      "Episode reward: 66.871174\n",
      "Episode reward: 33.82269\n",
      "Episode reward: 49.89777\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5396     |\n",
      "|    fps              | 3224     |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 280294   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00874  |\n",
      "|    n_updates        | 70048    |\n",
      "----------------------------------\n",
      "Episode reward: 77.599385\n",
      "Episode reward: 44.892116\n",
      "Episode reward: 71.122437\n",
      "Episode reward: 32.930767\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5400     |\n",
      "|    fps              | 3223     |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 280522   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0924   |\n",
      "|    n_updates        | 70105    |\n",
      "----------------------------------\n",
      "Episode reward: 36.763269\n",
      "Episode reward: 37.753651\n",
      "Episode reward: 42.729349\n",
      "Episode reward: 56.633805\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5404     |\n",
      "|    fps              | 3223     |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 280697   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.183    |\n",
      "|    n_updates        | 70149    |\n",
      "----------------------------------\n",
      "Episode reward: 52.871854\n",
      "Episode reward: 56.502216\n",
      "Episode reward: 56.762796\n",
      "Episode reward: 40.943036\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5408     |\n",
      "|    fps              | 3222     |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 280905   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.381    |\n",
      "|    n_updates        | 70201    |\n",
      "----------------------------------\n",
      "Episode reward: 91.326413\n",
      "Episode reward: 83.514717\n",
      "Episode reward: 72.846607\n",
      "Episode reward: 60.81313\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5412     |\n",
      "|    fps              | 3222     |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 281215   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00435  |\n",
      "|    n_updates        | 70278    |\n",
      "----------------------------------\n",
      "Episode reward: 48.897547\n",
      "Episode reward: 47.930998\n",
      "Episode reward: 44.9338\n",
      "Episode reward: 30.946222\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5416     |\n",
      "|    fps              | 3221     |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 281388   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0053   |\n",
      "|    n_updates        | 70321    |\n",
      "----------------------------------\n",
      "Episode reward: 66.916164\n",
      "Episode reward: 55.827024\n",
      "Episode reward: 58.654155\n",
      "Episode reward: 61.364863\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5420     |\n",
      "|    fps              | 3222     |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 281632   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0324   |\n",
      "|    n_updates        | 70382    |\n",
      "----------------------------------\n",
      "Episode reward: 62.363223\n",
      "Episode reward: 55.73522\n",
      "Episode reward: 63.678053\n",
      "Episode reward: 60.907556\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5424     |\n",
      "|    fps              | 3221     |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 281876   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.114    |\n",
      "|    n_updates        | 70443    |\n",
      "----------------------------------\n",
      "Episode reward: 118.061918\n",
      "Episode reward: 44.928302\n",
      "Episode reward: 56.183006\n",
      "Episode reward: 39.739162\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5428     |\n",
      "|    fps              | 3221     |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 282138   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00739  |\n",
      "|    n_updates        | 70509    |\n",
      "----------------------------------\n",
      "Episode reward: 42.889228\n",
      "Episode reward: 49.860226\n",
      "Episode reward: 55.877523\n",
      "Episode reward: 52.763664\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5432     |\n",
      "|    fps              | 3221     |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 282340   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00545  |\n",
      "|    n_updates        | 70559    |\n",
      "----------------------------------\n",
      "Episode reward: 41.90003\n",
      "Episode reward: 44.836463\n",
      "Episode reward: 60.263859\n",
      "Episode reward: 55.939446\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5436     |\n",
      "|    fps              | 3220     |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 282545   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00762  |\n",
      "|    n_updates        | 70611    |\n",
      "----------------------------------\n",
      "Episode reward: 34.886397\n",
      "Episode reward: 38.938944\n",
      "Episode reward: 32.945641\n",
      "Episode reward: 41.865042\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5440     |\n",
      "|    fps              | 3220     |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 282694   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00981  |\n",
      "|    n_updates        | 70648    |\n",
      "----------------------------------\n",
      "Episode reward: 50.460767\n",
      "Episode reward: 44.798634\n",
      "Episode reward: 64.768156\n",
      "Episode reward: 59.676435\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5444     |\n",
      "|    fps              | 3220     |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 282915   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.108    |\n",
      "|    n_updates        | 70703    |\n",
      "----------------------------------\n",
      "Episode reward: 39.907334\n",
      "Episode reward: 39.826246\n",
      "Episode reward: 59.735342\n",
      "Episode reward: 51.519912\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5448     |\n",
      "|    fps              | 3219     |\n",
      "|    time_elapsed     | 87       |\n",
      "|    total_timesteps  | 283107   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0116   |\n",
      "|    n_updates        | 70751    |\n",
      "----------------------------------\n",
      "Episode reward: 90.883503\n",
      "Episode reward: 91.357203\n",
      "Episode reward: 39.931969\n",
      "Episode reward: 74.894199\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5452     |\n",
      "|    fps              | 3219     |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 283406   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 70826    |\n",
      "----------------------------------\n",
      "Episode reward: 96.125631\n",
      "Episode reward: 71.724344\n",
      "Episode reward: 59.934408\n",
      "Episode reward: 63.833321\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5456     |\n",
      "|    fps              | 3219     |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 283700   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00525  |\n",
      "|    n_updates        | 70899    |\n",
      "----------------------------------\n",
      "Episode reward: 50.922785\n",
      "Episode reward: 45.925315\n",
      "Episode reward: 37.94232\n",
      "Episode reward: 49.720838\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5460     |\n",
      "|    fps              | 3219     |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 283885   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 70946    |\n",
      "----------------------------------\n",
      "Episode reward: 73.646811\n",
      "Episode reward: 58.877101\n",
      "Episode reward: 74.700803\n",
      "Episode reward: 75.752016\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5464     |\n",
      "|    fps              | 3219     |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 284169   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 71017    |\n",
      "----------------------------------\n",
      "Episode reward: 40.743692\n",
      "Episode reward: 43.929473\n",
      "Episode reward: 65.29114\n",
      "Episode reward: 90.87803\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5468     |\n",
      "|    fps              | 3219     |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 284411   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00499  |\n",
      "|    n_updates        | 71077    |\n",
      "----------------------------------\n",
      "Episode reward: 57.856122\n",
      "Episode reward: 62.877092\n",
      "Episode reward: 58.886982\n",
      "Episode reward: 45.641551\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5472     |\n",
      "|    fps              | 3219     |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 284637   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0349   |\n",
      "|    n_updates        | 71134    |\n",
      "----------------------------------\n",
      "Episode reward: 40.858767\n",
      "Episode reward: 69.483692\n",
      "Episode reward: 48.802255\n",
      "Episode reward: 32.937298\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5476     |\n",
      "|    fps              | 3218     |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 284830   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00442  |\n",
      "|    n_updates        | 71182    |\n",
      "----------------------------------\n",
      "Episode reward: 46.951414\n",
      "Episode reward: 30.936213\n",
      "Episode reward: 34.931026\n",
      "Episode reward: 35.9224\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5480     |\n",
      "|    fps              | 3219     |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 284979   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00328  |\n",
      "|    n_updates        | 71219    |\n",
      "----------------------------------\n",
      "Episode reward: 68.229732\n",
      "Episode reward: 33.92548\n",
      "Episode reward: 51.92189\n",
      "Episode reward: 70.676986\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5484     |\n",
      "|    fps              | 3219     |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 285205   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.116    |\n",
      "|    n_updates        | 71276    |\n",
      "----------------------------------\n",
      "Episode reward: 89.760958\n",
      "Episode reward: 73.790737\n",
      "Episode reward: 75.146421\n",
      "Episode reward: 69.850967\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5488     |\n",
      "|    fps              | 3219     |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 285516   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0379   |\n",
      "|    n_updates        | 71353    |\n",
      "----------------------------------\n",
      "Episode reward: 47.897662\n",
      "Episode reward: 55.926185\n",
      "Episode reward: 59.682059\n",
      "Episode reward: 66.770731\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5492     |\n",
      "|    fps              | 3219     |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 285747   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00433  |\n",
      "|    n_updates        | 71411    |\n",
      "----------------------------------\n",
      "Episode reward: 70.552064\n",
      "Episode reward: 89.852761\n",
      "Episode reward: 46.868695\n",
      "Episode reward: 49.538848\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5496     |\n",
      "|    fps              | 3218     |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 286005   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0729   |\n",
      "|    n_updates        | 71476    |\n",
      "----------------------------------\n",
      "Episode reward: 47.858492\n",
      "Episode reward: 35.815934\n",
      "Episode reward: 36.810315\n",
      "Episode reward: 52.890556\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5500     |\n",
      "|    fps              | 3217     |\n",
      "|    time_elapsed     | 88       |\n",
      "|    total_timesteps  | 286179   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0731   |\n",
      "|    n_updates        | 71519    |\n",
      "----------------------------------\n",
      "Episode reward: 51.894441\n",
      "Episode reward: 52.538951\n",
      "Episode reward: 49.666902\n",
      "Episode reward: 39.88249\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5504     |\n",
      "|    fps              | 3217     |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 286374   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00609  |\n",
      "|    n_updates        | 71568    |\n",
      "----------------------------------\n",
      "Episode reward: 46.794652\n",
      "Episode reward: 43.534086\n",
      "Episode reward: 37.858791\n",
      "Episode reward: 36.871063\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5508     |\n",
      "|    fps              | 3217     |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 286540   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00388  |\n",
      "|    n_updates        | 71609    |\n",
      "----------------------------------\n",
      "Episode reward: 42.944062\n",
      "Episode reward: 39.937571\n",
      "Episode reward: 47.913598\n",
      "Episode reward: 49.777558\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5512     |\n",
      "|    fps              | 3215     |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 286721   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 71655    |\n",
      "----------------------------------\n",
      "Episode reward: 64.831757\n",
      "Episode reward: 33.952817\n",
      "Episode reward: 48.946599\n",
      "Episode reward: 47.801322\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5516     |\n",
      "|    fps              | 3215     |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 286917   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 71704    |\n",
      "----------------------------------\n",
      "Episode reward: 40.867023\n",
      "Episode reward: 69.072216\n",
      "Episode reward: 45.928414\n",
      "Episode reward: 67.513788\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5520     |\n",
      "|    fps              | 3213     |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 287142   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00436  |\n",
      "|    n_updates        | 71760    |\n",
      "----------------------------------\n",
      "Episode reward: 52.858968\n",
      "Episode reward: 39.67079\n",
      "Episode reward: 35.930978\n",
      "Episode reward: 33.662145\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.3     |\n",
      "|    ep_rew_mean      | 54       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5524     |\n",
      "|    fps              | 3213     |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 287305   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00954  |\n",
      "|    n_updates        | 71801    |\n",
      "----------------------------------\n",
      "Episode reward: 48.943243\n",
      "Episode reward: 34.834095\n",
      "Episode reward: 73.303328\n",
      "Episode reward: 47.930959\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.7     |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5528     |\n",
      "|    fps              | 3212     |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 287511   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.272    |\n",
      "|    n_updates        | 71852    |\n",
      "----------------------------------\n",
      "Episode reward: 82.847204\n",
      "Episode reward: 56.737602\n",
      "Episode reward: 53.756836\n",
      "Episode reward: 70.393032\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.4     |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5532     |\n",
      "|    fps              | 3213     |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 287776   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 71918    |\n",
      "----------------------------------\n",
      "Episode reward: 48.941704\n",
      "Episode reward: 54.939114\n",
      "Episode reward: 61.484843\n",
      "Episode reward: 46.882902\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.4     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5536     |\n",
      "|    fps              | 3212     |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 287989   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00578  |\n",
      "|    n_updates        | 71972    |\n",
      "----------------------------------\n",
      "Episode reward: 89.820615\n",
      "Episode reward: 44.906465\n",
      "Episode reward: 47.668249\n",
      "Episode reward: 36.791644\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5540     |\n",
      "|    fps              | 3212     |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 288209   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00417  |\n",
      "|    n_updates        | 72027    |\n",
      "----------------------------------\n",
      "Episode reward: 53.927785\n",
      "Episode reward: 37.698042\n",
      "Episode reward: 42.868002\n",
      "Episode reward: 39.922724\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.7     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5544     |\n",
      "|    fps              | 3212     |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 288384   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 72070    |\n",
      "----------------------------------\n",
      "Episode reward: 33.918911\n",
      "Episode reward: 45.883958\n",
      "Episode reward: 34.964116\n",
      "Episode reward: 58.640931\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5548     |\n",
      "|    fps              | 3212     |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 288558   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0451   |\n",
      "|    n_updates        | 72114    |\n",
      "----------------------------------\n",
      "Episode reward: 60.595173\n",
      "Episode reward: 48.891235\n",
      "Episode reward: 35.953413\n",
      "Episode reward: 38.878774\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.4     |\n",
      "|    ep_rew_mean      | 53.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5552     |\n",
      "|    fps              | 3211     |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 288743   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.471    |\n",
      "|    n_updates        | 72160    |\n",
      "----------------------------------\n",
      "Episode reward: 37.69837\n",
      "Episode reward: 46.944735\n",
      "Episode reward: 63.888296\n",
      "Episode reward: 57.829999\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 52.5     |\n",
      "|    ep_rew_mean      | 52.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5556     |\n",
      "|    fps              | 3211     |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 288951   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.334    |\n",
      "|    n_updates        | 72212    |\n",
      "----------------------------------\n",
      "Episode reward: 68.633862\n",
      "Episode reward: 49.867401\n",
      "Episode reward: 58.852396\n",
      "Episode reward: 72.754451\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.2     |\n",
      "|    ep_rew_mean      | 52.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5560     |\n",
      "|    fps              | 3211     |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 289202   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 72275    |\n",
      "----------------------------------\n",
      "Episode reward: 35.931364\n",
      "Episode reward: 69.530031\n",
      "Episode reward: 87.773196\n",
      "Episode reward: 103.001256\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.3     |\n",
      "|    ep_rew_mean      | 53.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5564     |\n",
      "|    fps              | 3211     |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 289500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.316    |\n",
      "|    n_updates        | 72349    |\n",
      "----------------------------------\n",
      "Episode reward: 58.905904\n",
      "Episode reward: 109.154857\n",
      "Episode reward: 103.547414\n",
      "Episode reward: 54.642508\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.2     |\n",
      "|    ep_rew_mean      | 53.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5568     |\n",
      "|    fps              | 3211     |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 289828   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00935  |\n",
      "|    n_updates        | 72431    |\n",
      "----------------------------------\n",
      "Episode reward: 74.460409\n",
      "Episode reward: 83.204267\n",
      "Episode reward: 43.733128\n",
      "Episode reward: 54.265301\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5572     |\n",
      "|    fps              | 3209     |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 290089   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 72497    |\n",
      "----------------------------------\n",
      "Episode reward: 65.441224\n",
      "Episode reward: 37.958052\n",
      "Episode reward: 41.815316\n",
      "Episode reward: 78.708286\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.8     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5576     |\n",
      "|    fps              | 3209     |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 290314   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.231    |\n",
      "|    n_updates        | 72553    |\n",
      "----------------------------------\n",
      "Episode reward: 59.634309\n",
      "Episode reward: 55.844621\n",
      "Episode reward: 57.859545\n",
      "Episode reward: 123.624948\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5580     |\n",
      "|    fps              | 3207     |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 290612   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.194    |\n",
      "|    n_updates        | 72627    |\n",
      "----------------------------------\n",
      "Episode reward: 37.90446\n",
      "Episode reward: 73.853387\n",
      "Episode reward: 38.820116\n",
      "Episode reward: 44.905922\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5584     |\n",
      "|    fps              | 3207     |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 290808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00277  |\n",
      "|    n_updates        | 72676    |\n",
      "----------------------------------\n",
      "Episode reward: 65.883521\n",
      "Episode reward: 46.866997\n",
      "Episode reward: 45.681946\n",
      "Episode reward: 41.94299\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5588     |\n",
      "|    fps              | 3206     |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 291009   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00764  |\n",
      "|    n_updates        | 72727    |\n",
      "----------------------------------\n",
      "Episode reward: 67.80148\n",
      "Episode reward: 45.818583\n",
      "Episode reward: 57.847588\n",
      "Episode reward: 34.942886\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.7     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5592     |\n",
      "|    fps              | 3206     |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 291216   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00351  |\n",
      "|    n_updates        | 72778    |\n",
      "----------------------------------\n",
      "Episode reward: 53.904964\n",
      "Episode reward: 68.656412\n",
      "Episode reward: 57.903311\n",
      "Episode reward: 71.337885\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.6     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5596     |\n",
      "|    fps              | 3205     |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 291470   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.211    |\n",
      "|    n_updates        | 72842    |\n",
      "----------------------------------\n",
      "Episode reward: 35.873665\n",
      "Episode reward: 57.934049\n",
      "Episode reward: 37.951102\n",
      "Episode reward: 51.849706\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.8     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5600     |\n",
      "|    fps              | 3205     |\n",
      "|    time_elapsed     | 90       |\n",
      "|    total_timesteps  | 291654   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00383  |\n",
      "|    n_updates        | 72888    |\n",
      "----------------------------------\n",
      "Episode reward: 39.942628\n",
      "Episode reward: 40.935373\n",
      "Episode reward: 44.824313\n",
      "Episode reward: 41.845188\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5604     |\n",
      "|    fps              | 3205     |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 291822   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 72930    |\n",
      "----------------------------------\n",
      "Episode reward: 50.897158\n",
      "Episode reward: 77.527651\n",
      "Episode reward: 45.726789\n",
      "Episode reward: 40.728248\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55       |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5608     |\n",
      "|    fps              | 3204     |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 292039   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0066   |\n",
      "|    n_updates        | 72984    |\n",
      "----------------------------------\n",
      "Episode reward: 73.345788\n",
      "Episode reward: 58.362056\n",
      "Episode reward: 43.919496\n",
      "Episode reward: 46.267859\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5612     |\n",
      "|    fps              | 3204     |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 292263   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00473  |\n",
      "|    n_updates        | 73040    |\n",
      "----------------------------------\n",
      "Episode reward: 73.860489\n",
      "Episode reward: 51.843189\n",
      "Episode reward: 44.94048\n",
      "Episode reward: 35.764633\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.5     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5616     |\n",
      "|    fps              | 3203     |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 292470   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 73092    |\n",
      "----------------------------------\n",
      "Episode reward: 59.915136\n",
      "Episode reward: 53.515768\n",
      "Episode reward: 41.627173\n",
      "Episode reward: 37.776534\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5620     |\n",
      "|    fps              | 3203     |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 292664   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00982  |\n",
      "|    n_updates        | 73140    |\n",
      "----------------------------------\n",
      "Episode reward: 94.720342\n",
      "Episode reward: 59.478587\n",
      "Episode reward: 68.892057\n",
      "Episode reward: 37.901085\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5624     |\n",
      "|    fps              | 3203     |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 292926   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 73206    |\n",
      "----------------------------------\n",
      "Episode reward: 55.858691\n",
      "Episode reward: 39.902884\n",
      "Episode reward: 54.92145\n",
      "Episode reward: 40.698672\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5628     |\n",
      "|    fps              | 3202     |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 293118   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 73254    |\n",
      "----------------------------------\n",
      "Episode reward: 96.38057\n",
      "Episode reward: 47.581463\n",
      "Episode reward: 30.881737\n",
      "Episode reward: 51.829426\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5632     |\n",
      "|    fps              | 3202     |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 293347   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.23     |\n",
      "|    n_updates        | 73311    |\n",
      "----------------------------------\n",
      "Episode reward: 83.826077\n",
      "Episode reward: 109.511999\n",
      "Episode reward: 36.960902\n",
      "Episode reward: 56.355552\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5636     |\n",
      "|    fps              | 3201     |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 293635   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0042   |\n",
      "|    n_updates        | 73383    |\n",
      "----------------------------------\n",
      "Episode reward: 59.883822\n",
      "Episode reward: 65.551061\n",
      "Episode reward: 42.921066\n",
      "Episode reward: 49.833421\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5640     |\n",
      "|    fps              | 3201     |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 293854   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 73438    |\n",
      "----------------------------------\n",
      "Episode reward: 52.90748\n",
      "Episode reward: 51.894349\n",
      "Episode reward: 41.586756\n",
      "Episode reward: 56.92016\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5644     |\n",
      "|    fps              | 3201     |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 294058   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0378   |\n",
      "|    n_updates        | 73489    |\n",
      "----------------------------------\n",
      "Episode reward: 100.822678\n",
      "Episode reward: 81.280979\n",
      "Episode reward: 47.842102\n",
      "Episode reward: 66.656341\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5648     |\n",
      "|    fps              | 3201     |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 294356   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0718   |\n",
      "|    n_updates        | 73563    |\n",
      "----------------------------------\n",
      "Episode reward: 60.78617\n",
      "Episode reward: 54.402264\n",
      "Episode reward: 38.920777\n",
      "Episode reward: 68.359665\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5652     |\n",
      "|    fps              | 3201     |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 294580   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00405  |\n",
      "|    n_updates        | 73619    |\n",
      "----------------------------------\n",
      "Episode reward: 35.931248\n",
      "Episode reward: 50.891269\n",
      "Episode reward: 67.481168\n",
      "Episode reward: 31.934725\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5656     |\n",
      "|    fps              | 3200     |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 294767   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0311   |\n",
      "|    n_updates        | 73666    |\n",
      "----------------------------------\n",
      "Episode reward: 46.906249\n",
      "Episode reward: 111.727225\n",
      "Episode reward: 35.941966\n",
      "Episode reward: 68.82641\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5660     |\n",
      "|    fps              | 3199     |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 295031   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00454  |\n",
      "|    n_updates        | 73732    |\n",
      "----------------------------------\n",
      "Episode reward: 44.845729\n",
      "Episode reward: 48.641336\n",
      "Episode reward: 54.600913\n",
      "Episode reward: 38.820135\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5664     |\n",
      "|    fps              | 3199     |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 295219   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00662  |\n",
      "|    n_updates        | 73779    |\n",
      "----------------------------------\n",
      "Episode reward: 54.915074\n",
      "Episode reward: 55.840106\n",
      "Episode reward: 77.837241\n",
      "Episode reward: 38.946094\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5668     |\n",
      "|    fps              | 3200     |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 295447   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 73836    |\n",
      "----------------------------------\n",
      "Episode reward: 39.711318\n",
      "Episode reward: 56.735002\n",
      "Episode reward: 56.885828\n",
      "Episode reward: 61.90315\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5672     |\n",
      "|    fps              | 3200     |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 295663   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.108    |\n",
      "|    n_updates        | 73890    |\n",
      "----------------------------------\n",
      "Episode reward: 95.866247\n",
      "Episode reward: 66.885188\n",
      "Episode reward: 54.897541\n",
      "Episode reward: 86.418727\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5676     |\n",
      "|    fps              | 3199     |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 295972   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.262    |\n",
      "|    n_updates        | 73967    |\n",
      "----------------------------------\n",
      "Episode reward: 86.897876\n",
      "Episode reward: 82.533258\n",
      "Episode reward: 91.647886\n",
      "Episode reward: 118.938951\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5680     |\n",
      "|    fps              | 3198     |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 296359   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0332   |\n",
      "|    n_updates        | 74064    |\n",
      "----------------------------------\n",
      "Episode reward: 49.88707\n",
      "Episode reward: 85.874827\n",
      "Episode reward: 50.878882\n",
      "Episode reward: 48.79615\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5684     |\n",
      "|    fps              | 3197     |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 296596   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00701  |\n",
      "|    n_updates        | 74123    |\n",
      "----------------------------------\n",
      "Episode reward: 33.943596\n",
      "Episode reward: 58.872399\n",
      "Episode reward: 63.01851\n",
      "Episode reward: 66.840854\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5688     |\n",
      "|    fps              | 3197     |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 296820   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.25     |\n",
      "|    n_updates        | 74179    |\n",
      "----------------------------------\n",
      "Episode reward: 32.960088\n",
      "Episode reward: 68.915826\n",
      "Episode reward: 57.140312\n",
      "Episode reward: 59.861243\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5692     |\n",
      "|    fps              | 3196     |\n",
      "|    time_elapsed     | 92       |\n",
      "|    total_timesteps  | 297040   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0776   |\n",
      "|    n_updates        | 74234    |\n",
      "----------------------------------\n",
      "Episode reward: 74.99518\n",
      "Episode reward: 45.723816\n",
      "Episode reward: 86.64177\n",
      "Episode reward: 86.136534\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5696     |\n",
      "|    fps              | 3196     |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 297336   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00966  |\n",
      "|    n_updates        | 74308    |\n",
      "----------------------------------\n",
      "Episode reward: 67.904472\n",
      "Episode reward: 44.92492\n",
      "Episode reward: 30.860364\n",
      "Episode reward: 41.92342\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5700     |\n",
      "|    fps              | 3195     |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 297522   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 74355    |\n",
      "----------------------------------\n",
      "Episode reward: 65.391587\n",
      "Episode reward: 35.943408\n",
      "Episode reward: 37.940601\n",
      "Episode reward: 65.902002\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5704     |\n",
      "|    fps              | 3195     |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 297728   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 74406    |\n",
      "----------------------------------\n",
      "Episode reward: 89.767242\n",
      "Episode reward: 34.913496\n",
      "Episode reward: 95.82405\n",
      "Episode reward: 49.890522\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5708     |\n",
      "|    fps              | 3194     |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 298004   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.255    |\n",
      "|    n_updates        | 74475    |\n",
      "----------------------------------\n",
      "Episode reward: 51.737295\n",
      "Episode reward: 45.702462\n",
      "Episode reward: 62.831543\n",
      "Episode reward: 35.841532\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5712     |\n",
      "|    fps              | 3194     |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 298201   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 74525    |\n",
      "----------------------------------\n",
      "Episode reward: 50.696945\n",
      "Episode reward: 51.892199\n",
      "Episode reward: 56.900572\n",
      "Episode reward: 57.860769\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5716     |\n",
      "|    fps              | 3194     |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 298419   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0973   |\n",
      "|    n_updates        | 74579    |\n",
      "----------------------------------\n",
      "Episode reward: 49.927677\n",
      "Episode reward: 88.64473\n",
      "Episode reward: 58.938305\n",
      "Episode reward: 108.452645\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5720     |\n",
      "|    fps              | 3194     |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 298726   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.138    |\n",
      "|    n_updates        | 74656    |\n",
      "----------------------------------\n",
      "Episode reward: 49.937979\n",
      "Episode reward: 86.871277\n",
      "Episode reward: 77.86986\n",
      "Episode reward: 58.919415\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5724     |\n",
      "|    fps              | 3194     |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 299000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00238  |\n",
      "|    n_updates        | 74724    |\n",
      "----------------------------------\n",
      "Episode reward: 56.928581\n",
      "Episode reward: 35.956332\n",
      "Episode reward: 38.766201\n",
      "Episode reward: 34.952408\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5728     |\n",
      "|    fps              | 3194     |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 299167   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.196    |\n",
      "|    n_updates        | 74766    |\n",
      "----------------------------------\n",
      "Episode reward: 96.733458\n",
      "Episode reward: 49.814996\n",
      "Episode reward: 36.832123\n",
      "Episode reward: 42.94489\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5732     |\n",
      "|    fps              | 3194     |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 299395   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00542  |\n",
      "|    n_updates        | 74823    |\n",
      "----------------------------------\n",
      "Episode reward: 57.229605\n",
      "Episode reward: 33.81914\n",
      "Episode reward: 74.818835\n",
      "Episode reward: 51.891691\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5736     |\n",
      "|    fps              | 3193     |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 299614   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 74878    |\n",
      "----------------------------------\n",
      "Episode reward: 41.913982\n",
      "Episode reward: 47.914386\n",
      "Episode reward: 35.935389\n",
      "Episode reward: 67.332137\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5740     |\n",
      "|    fps              | 3193     |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 299808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00615  |\n",
      "|    n_updates        | 74926    |\n",
      "----------------------------------\n",
      "Episode reward: 55.652515\n",
      "Episode reward: 58.921696\n",
      "Episode reward: 49.909334\n",
      "Episode reward: 51.844491\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5744     |\n",
      "|    fps              | 3193     |\n",
      "|    time_elapsed     | 93       |\n",
      "|    total_timesteps  | 300025   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.142    |\n",
      "|    n_updates        | 74981    |\n",
      "----------------------------------\n",
      "Episode reward: 99.252992\n",
      "Episode reward: 69.785865\n",
      "Episode reward: 71.902212\n",
      "Episode reward: 53.835844\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5748     |\n",
      "|    fps              | 3192     |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 300323   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00788  |\n",
      "|    n_updates        | 75055    |\n",
      "----------------------------------\n",
      "Episode reward: 38.908603\n",
      "Episode reward: 57.678963\n",
      "Episode reward: 36.955459\n",
      "Episode reward: 64.184401\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5752     |\n",
      "|    fps              | 3192     |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 300522   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 75105    |\n",
      "----------------------------------\n",
      "Episode reward: 43.922561\n",
      "Episode reward: 65.035886\n",
      "Episode reward: 52.538425\n",
      "Episode reward: 44.564518\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5756     |\n",
      "|    fps              | 3192     |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 300730   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 75157    |\n",
      "----------------------------------\n",
      "Episode reward: 53.929957\n",
      "Episode reward: 45.932028\n",
      "Episode reward: 50.887302\n",
      "Episode reward: 36.930419\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5760     |\n",
      "|    fps              | 3192     |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 300918   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 75204    |\n",
      "----------------------------------\n",
      "Episode reward: 62.88513\n",
      "Episode reward: 82.819942\n",
      "Episode reward: 63.787838\n",
      "Episode reward: 48.802152\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5764     |\n",
      "|    fps              | 3192     |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 301177   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.1      |\n",
      "|    n_updates        | 75269    |\n",
      "----------------------------------\n",
      "Episode reward: 66.603877\n",
      "Episode reward: 37.668417\n",
      "Episode reward: 39.891464\n",
      "Episode reward: 55.533118\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5768     |\n",
      "|    fps              | 3192     |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 301378   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0999   |\n",
      "|    n_updates        | 75319    |\n",
      "----------------------------------\n",
      "Episode reward: 50.627044\n",
      "Episode reward: 71.488209\n",
      "Episode reward: 60.865224\n",
      "Episode reward: 74.842506\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5772     |\n",
      "|    fps              | 3192     |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 301637   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 75384    |\n",
      "----------------------------------\n",
      "Episode reward: 64.782791\n",
      "Episode reward: 43.721573\n",
      "Episode reward: 88.897978\n",
      "Episode reward: 79.835267\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5776     |\n",
      "|    fps              | 3192     |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 301915   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.126    |\n",
      "|    n_updates        | 75453    |\n",
      "----------------------------------\n",
      "Episode reward: 49.913315\n",
      "Episode reward: 76.122848\n",
      "Episode reward: 90.07261\n",
      "Episode reward: 47.928453\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5780     |\n",
      "|    fps              | 3191     |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 302182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00514  |\n",
      "|    n_updates        | 75520    |\n",
      "----------------------------------\n",
      "Episode reward: 49.849138\n",
      "Episode reward: 69.875492\n",
      "Episode reward: 87.400157\n",
      "Episode reward: 108.839757\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5784     |\n",
      "|    fps              | 3191     |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 302499   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.106    |\n",
      "|    n_updates        | 75599    |\n",
      "----------------------------------\n",
      "Episode reward: 53.913121\n",
      "Episode reward: 49.572338\n",
      "Episode reward: 36.907566\n",
      "Episode reward: 58.915477\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5788     |\n",
      "|    fps              | 3191     |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 302699   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0865   |\n",
      "|    n_updates        | 75649    |\n",
      "----------------------------------\n",
      "Episode reward: 54.852642\n",
      "Episode reward: 63.890851\n",
      "Episode reward: 60.462076\n",
      "Episode reward: 58.893051\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5792     |\n",
      "|    fps              | 3191     |\n",
      "|    time_elapsed     | 94       |\n",
      "|    total_timesteps  | 302938   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0295   |\n",
      "|    n_updates        | 75709    |\n",
      "----------------------------------\n",
      "Episode reward: 63.904596\n",
      "Episode reward: 70.43829\n",
      "Episode reward: 97.497957\n",
      "Episode reward: 59.907468\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5796     |\n",
      "|    fps              | 3191     |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 303233   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.173    |\n",
      "|    n_updates        | 75783    |\n",
      "----------------------------------\n",
      "Episode reward: 35.951215\n",
      "Episode reward: 55.689657\n",
      "Episode reward: 58.871524\n",
      "Episode reward: 50.928553\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5800     |\n",
      "|    fps              | 3191     |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 303435   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00878  |\n",
      "|    n_updates        | 75833    |\n",
      "----------------------------------\n",
      "Episode reward: 65.839441\n",
      "Episode reward: 53.892768\n",
      "Episode reward: 57.889365\n",
      "Episode reward: 32.862463\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5804     |\n",
      "|    fps              | 3191     |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 303646   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 75886    |\n",
      "----------------------------------\n",
      "Episode reward: 45.606205\n",
      "Episode reward: 54.558727\n",
      "Episode reward: 51.873933\n",
      "Episode reward: 66.660433\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5808     |\n",
      "|    fps              | 3191     |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 303866   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.058    |\n",
      "|    n_updates        | 75941    |\n",
      "----------------------------------\n",
      "Episode reward: 64.995335\n",
      "Episode reward: 80.836355\n",
      "Episode reward: 38.850736\n",
      "Episode reward: 65.594008\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5812     |\n",
      "|    fps              | 3191     |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 304118   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.133    |\n",
      "|    n_updates        | 76004    |\n",
      "----------------------------------\n",
      "Episode reward: 55.893072\n",
      "Episode reward: 55.845527\n",
      "Episode reward: 87.873769\n",
      "Episode reward: 42.948624\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5816     |\n",
      "|    fps              | 3191     |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 304361   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0369   |\n",
      "|    n_updates        | 76065    |\n",
      "----------------------------------\n",
      "Episode reward: 82.772096\n",
      "Episode reward: 49.921568\n",
      "Episode reward: 40.905987\n",
      "Episode reward: 46.942882\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5820     |\n",
      "|    fps              | 3191     |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 304582   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00656  |\n",
      "|    n_updates        | 76120    |\n",
      "----------------------------------\n",
      "Episode reward: 79.862482\n",
      "Episode reward: 67.726928\n",
      "Episode reward: 53.308041\n",
      "Episode reward: 67.590806\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5824     |\n",
      "|    fps              | 3191     |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 304852   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.497    |\n",
      "|    n_updates        | 76187    |\n",
      "----------------------------------\n",
      "Episode reward: 59.909326\n",
      "Episode reward: 31.946235\n",
      "Episode reward: 51.908517\n",
      "Episode reward: 141.687224\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5828     |\n",
      "|    fps              | 3190     |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 305139   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0107   |\n",
      "|    n_updates        | 76259    |\n",
      "----------------------------------\n",
      "Episode reward: 114.99529\n",
      "Episode reward: 53.864219\n",
      "Episode reward: 58.736549\n",
      "Episode reward: 63.79884\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5832     |\n",
      "|    fps              | 3190     |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 305433   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00799  |\n",
      "|    n_updates        | 76333    |\n",
      "----------------------------------\n",
      "Episode reward: 29.803861\n",
      "Episode reward: 62.732552\n",
      "Episode reward: 41.908156\n",
      "Episode reward: 54.675721\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5836     |\n",
      "|    fps              | 3191     |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 305623   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 76380    |\n",
      "----------------------------------\n",
      "Episode reward: 39.88197\n",
      "Episode reward: 78.677071\n",
      "Episode reward: 49.803702\n",
      "Episode reward: 91.848847\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5840     |\n",
      "|    fps              | 3190     |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 305885   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.168    |\n",
      "|    n_updates        | 76446    |\n",
      "----------------------------------\n",
      "Episode reward: 41.933851\n",
      "Episode reward: 43.90363\n",
      "Episode reward: 48.832352\n",
      "Episode reward: 60.77053\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5844     |\n",
      "|    fps              | 3190     |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 306081   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00618  |\n",
      "|    n_updates        | 76495    |\n",
      "----------------------------------\n",
      "Episode reward: 41.754508\n",
      "Episode reward: 98.562562\n",
      "Episode reward: 57.970646\n",
      "Episode reward: 53.930178\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5848     |\n",
      "|    fps              | 3190     |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 306336   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 76558    |\n",
      "----------------------------------\n",
      "Episode reward: 67.875885\n",
      "Episode reward: 89.555899\n",
      "Episode reward: 38.943673\n",
      "Episode reward: 51.931578\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5852     |\n",
      "|    fps              | 3190     |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 306588   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 76621    |\n",
      "----------------------------------\n",
      "Episode reward: 66.573044\n",
      "Episode reward: 31.944022\n",
      "Episode reward: 55.892602\n",
      "Episode reward: 54.867678\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5856     |\n",
      "|    fps              | 3190     |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 306798   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.147    |\n",
      "|    n_updates        | 76674    |\n",
      "----------------------------------\n",
      "Episode reward: 51.63516\n",
      "Episode reward: 44.900288\n",
      "Episode reward: 58.037851\n",
      "Episode reward: 62.872597\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5860     |\n",
      "|    fps              | 3189     |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 307017   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00727  |\n",
      "|    n_updates        | 76729    |\n",
      "----------------------------------\n",
      "Episode reward: 58.855239\n",
      "Episode reward: 71.726759\n",
      "Episode reward: 50.926738\n",
      "Episode reward: 46.898858\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5864     |\n",
      "|    fps              | 3189     |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 307246   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.041    |\n",
      "|    n_updates        | 76786    |\n",
      "----------------------------------\n",
      "Episode reward: 56.57263\n",
      "Episode reward: 87.807254\n",
      "Episode reward: 87.667368\n",
      "Episode reward: 32.918001\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5868     |\n",
      "|    fps              | 3189     |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 307516   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00982  |\n",
      "|    n_updates        | 76853    |\n",
      "----------------------------------\n",
      "Episode reward: 41.728169\n",
      "Episode reward: 59.785584\n",
      "Episode reward: 94.869025\n",
      "Episode reward: 37.808899\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5872     |\n",
      "|    fps              | 3188     |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 307751   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00818  |\n",
      "|    n_updates        | 76912    |\n",
      "----------------------------------\n",
      "Episode reward: 51.933452\n",
      "Episode reward: 37.467313\n",
      "Episode reward: 40.889181\n",
      "Episode reward: 40.735126\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5876     |\n",
      "|    fps              | 3188     |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 307923   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.143    |\n",
      "|    n_updates        | 76955    |\n",
      "----------------------------------\n",
      "Episode reward: 98.502206\n",
      "Episode reward: 75.879162\n",
      "Episode reward: 84.874392\n",
      "Episode reward: 57.865189\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5880     |\n",
      "|    fps              | 3188     |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 308241   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00898  |\n",
      "|    n_updates        | 77035    |\n",
      "----------------------------------\n",
      "Episode reward: 98.129802\n",
      "Episode reward: 70.828766\n",
      "Episode reward: 56.863632\n",
      "Episode reward: 51.935441\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5884     |\n",
      "|    fps              | 3187     |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 308521   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.362    |\n",
      "|    n_updates        | 77105    |\n",
      "----------------------------------\n",
      "Episode reward: 55.684379\n",
      "Episode reward: 53.857389\n",
      "Episode reward: 40.849486\n",
      "Episode reward: 51.921217\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5888     |\n",
      "|    fps              | 3188     |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 308724   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 77155    |\n",
      "----------------------------------\n",
      "Episode reward: 84.379967\n",
      "Episode reward: 51.895882\n",
      "Episode reward: 34.766827\n",
      "Episode reward: 48.93769\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5892     |\n",
      "|    fps              | 3188     |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 308949   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.394    |\n",
      "|    n_updates        | 77212    |\n",
      "----------------------------------\n",
      "Episode reward: 86.734041\n",
      "Episode reward: 58.926924\n",
      "Episode reward: 67.881088\n",
      "Episode reward: 57.914499\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5896     |\n",
      "|    fps              | 3188     |\n",
      "|    time_elapsed     | 96       |\n",
      "|    total_timesteps  | 309221   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0923   |\n",
      "|    n_updates        | 77280    |\n",
      "----------------------------------\n",
      "Episode reward: 31.940476\n",
      "Episode reward: 57.897568\n",
      "Episode reward: 52.924709\n",
      "Episode reward: 80.858332\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5900     |\n",
      "|    fps              | 3187     |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 309445   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.094    |\n",
      "|    n_updates        | 77336    |\n",
      "----------------------------------\n",
      "Episode reward: 72.702722\n",
      "Episode reward: 35.882443\n",
      "Episode reward: 78.79506\n",
      "Episode reward: 56.841481\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5904     |\n",
      "|    fps              | 3188     |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 309690   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00837  |\n",
      "|    n_updates        | 77397    |\n",
      "----------------------------------\n",
      "Episode reward: 70.776004\n",
      "Episode reward: 40.936491\n",
      "Episode reward: 46.892303\n",
      "Episode reward: 36.868214\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5908     |\n",
      "|    fps              | 3188     |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 309888   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00425  |\n",
      "|    n_updates        | 77446    |\n",
      "----------------------------------\n",
      "Episode reward: 56.552754\n",
      "Episode reward: 67.720083\n",
      "Episode reward: 43.941806\n",
      "Episode reward: 93.426179\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5912     |\n",
      "|    fps              | 3188     |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 310152   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 77512    |\n",
      "----------------------------------\n",
      "Episode reward: 44.904008\n",
      "Episode reward: 44.934817\n",
      "Episode reward: 91.331154\n",
      "Episode reward: 59.869724\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5916     |\n",
      "|    fps              | 3188     |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 310395   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 77573    |\n",
      "----------------------------------\n",
      "Episode reward: 55.790699\n",
      "Episode reward: 61.835479\n",
      "Episode reward: 37.889008\n",
      "Episode reward: 33.897307\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5920     |\n",
      "|    fps              | 3188     |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 310585   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00792  |\n",
      "|    n_updates        | 77621    |\n",
      "----------------------------------\n",
      "Episode reward: 51.46739\n",
      "Episode reward: 100.732407\n",
      "Episode reward: 34.901686\n",
      "Episode reward: 40.880634\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5924     |\n",
      "|    fps              | 3188     |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 310815   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 77678    |\n",
      "----------------------------------\n",
      "Episode reward: 41.905205\n",
      "Episode reward: 78.481441\n",
      "Episode reward: 62.886198\n",
      "Episode reward: 59.886288\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5928     |\n",
      "|    fps              | 3187     |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 311059   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00593  |\n",
      "|    n_updates        | 77739    |\n",
      "----------------------------------\n",
      "Episode reward: 64.683085\n",
      "Episode reward: 38.867481\n",
      "Episode reward: 36.867451\n",
      "Episode reward: 98.4353\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5932     |\n",
      "|    fps              | 3186     |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 311299   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 77799    |\n",
      "----------------------------------\n",
      "Episode reward: 53.337121\n",
      "Episode reward: 64.730125\n",
      "Episode reward: 28.94026\n",
      "Episode reward: 67.77669\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5936     |\n",
      "|    fps              | 3186     |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 311516   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.282    |\n",
      "|    n_updates        | 77853    |\n",
      "----------------------------------\n",
      "Episode reward: 57.907217\n",
      "Episode reward: 79.690761\n",
      "Episode reward: 41.934746\n",
      "Episode reward: 56.751305\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5940     |\n",
      "|    fps              | 3186     |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 311753   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 77913    |\n",
      "----------------------------------\n",
      "Episode reward: 52.557037\n",
      "Episode reward: 53.837139\n",
      "Episode reward: 49.930961\n",
      "Episode reward: 73.873441\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5944     |\n",
      "|    fps              | 3186     |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 311985   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00708  |\n",
      "|    n_updates        | 77971    |\n",
      "----------------------------------\n",
      "Episode reward: 94.156937\n",
      "Episode reward: 67.746227\n",
      "Episode reward: 43.947495\n",
      "Episode reward: 58.625035\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5948     |\n",
      "|    fps              | 3185     |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 312253   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 78038    |\n",
      "----------------------------------\n",
      "Episode reward: 38.927742\n",
      "Episode reward: 41.921646\n",
      "Episode reward: 50.533894\n",
      "Episode reward: 63.907909\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5952     |\n",
      "|    fps              | 3185     |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 312449   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.33     |\n",
      "|    n_updates        | 78087    |\n",
      "----------------------------------\n",
      "Episode reward: 39.956438\n",
      "Episode reward: 63.880375\n",
      "Episode reward: 55.979779\n",
      "Episode reward: 40.942184\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5956     |\n",
      "|    fps              | 3185     |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 312651   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0232   |\n",
      "|    n_updates        | 78137    |\n",
      "----------------------------------\n",
      "Episode reward: 70.906196\n",
      "Episode reward: 38.779768\n",
      "Episode reward: 50.904298\n",
      "Episode reward: 47.51189\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5960     |\n",
      "|    fps              | 3184     |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 312860   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.176    |\n",
      "|    n_updates        | 78189    |\n",
      "----------------------------------\n",
      "Episode reward: 43.90327\n",
      "Episode reward: 44.913494\n",
      "Episode reward: 50.726529\n",
      "Episode reward: 128.407514\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5964     |\n",
      "|    fps              | 3184     |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 313132   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.151    |\n",
      "|    n_updates        | 78257    |\n",
      "----------------------------------\n",
      "Episode reward: 34.850384\n",
      "Episode reward: 52.919612\n",
      "Episode reward: 51.891813\n",
      "Episode reward: 37.923021\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5968     |\n",
      "|    fps              | 3183     |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 313310   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.149    |\n",
      "|    n_updates        | 78302    |\n",
      "----------------------------------\n",
      "Episode reward: 47.912209\n",
      "Episode reward: 47.876747\n",
      "Episode reward: 45.922926\n",
      "Episode reward: 157.538082\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5972     |\n",
      "|    fps              | 3182     |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 313612   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0232   |\n",
      "|    n_updates        | 78377    |\n",
      "----------------------------------\n",
      "Episode reward: 46.663132\n",
      "Episode reward: 50.400578\n",
      "Episode reward: 63.915103\n",
      "Episode reward: 60.096702\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5976     |\n",
      "|    fps              | 3182     |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 313835   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.34     |\n",
      "|    n_updates        | 78433    |\n",
      "----------------------------------\n",
      "Episode reward: 47.587651\n",
      "Episode reward: 78.890129\n",
      "Episode reward: 55.850432\n",
      "Episode reward: 40.915202\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5980     |\n",
      "|    fps              | 3181     |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 314059   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0079   |\n",
      "|    n_updates        | 78489    |\n",
      "----------------------------------\n",
      "Episode reward: 59.564064\n",
      "Episode reward: 66.404167\n",
      "Episode reward: 54.926242\n",
      "Episode reward: 45.916735\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5984     |\n",
      "|    fps              | 3181     |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 314287   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00587  |\n",
      "|    n_updates        | 78546    |\n",
      "----------------------------------\n",
      "Episode reward: 58.399664\n",
      "Episode reward: 56.899557\n",
      "Episode reward: 56.911701\n",
      "Episode reward: 82.309645\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5988     |\n",
      "|    fps              | 3181     |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 314543   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00905  |\n",
      "|    n_updates        | 78610    |\n",
      "----------------------------------\n",
      "Episode reward: 68.367267\n",
      "Episode reward: 100.189546\n",
      "Episode reward: 73.676945\n",
      "Episode reward: 50.428083\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5992     |\n",
      "|    fps              | 3181     |\n",
      "|    time_elapsed     | 98       |\n",
      "|    total_timesteps  | 314838   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 78684    |\n",
      "----------------------------------\n",
      "Episode reward: 46.949112\n",
      "Episode reward: 72.588596\n",
      "Episode reward: 54.690743\n",
      "Episode reward: 117.378453\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 5996     |\n",
      "|    fps              | 3180     |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 315155   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 78763    |\n",
      "----------------------------------\n",
      "Episode reward: 50.908248\n",
      "Episode reward: 54.281149\n",
      "Episode reward: 73.016649\n",
      "Episode reward: 49.923816\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6000     |\n",
      "|    fps              | 3180     |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 315387   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 78821    |\n",
      "----------------------------------\n",
      "Episode reward: 53.929809\n",
      "Episode reward: 57.745693\n",
      "Episode reward: 39.952433\n",
      "Episode reward: 62.89649\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6004     |\n",
      "|    fps              | 3179     |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 315602   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00341  |\n",
      "|    n_updates        | 78875    |\n",
      "----------------------------------\n",
      "Episode reward: 40.899509\n",
      "Episode reward: 36.923611\n",
      "Episode reward: 50.937503\n",
      "Episode reward: 65.722104\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6008     |\n",
      "|    fps              | 3179     |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 315797   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00915  |\n",
      "|    n_updates        | 78924    |\n",
      "----------------------------------\n",
      "Episode reward: 79.645445\n",
      "Episode reward: 46.855071\n",
      "Episode reward: 46.950012\n",
      "Episode reward: 118.762388\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6012     |\n",
      "|    fps              | 3179     |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 316091   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 78997    |\n",
      "----------------------------------\n",
      "Episode reward: 33.937577\n",
      "Episode reward: 45.945692\n",
      "Episode reward: 62.913346\n",
      "Episode reward: 56.918262\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6016     |\n",
      "|    fps              | 3179     |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 316291   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 79047    |\n",
      "----------------------------------\n",
      "Episode reward: 61.72973\n",
      "Episode reward: 45.690555\n",
      "Episode reward: 85.335077\n",
      "Episode reward: 53.856423\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6020     |\n",
      "|    fps              | 3179     |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 316540   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 79109    |\n",
      "----------------------------------\n",
      "Episode reward: 57.47481\n",
      "Episode reward: 49.676303\n",
      "Episode reward: 44.387389\n",
      "Episode reward: 64.647525\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6024     |\n",
      "|    fps              | 3179     |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 316758   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.132    |\n",
      "|    n_updates        | 79164    |\n",
      "----------------------------------\n",
      "Episode reward: 53.765538\n",
      "Episode reward: 59.926798\n",
      "Episode reward: 73.485316\n",
      "Episode reward: 74.444787\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6028     |\n",
      "|    fps              | 3178     |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 317023   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.229    |\n",
      "|    n_updates        | 79230    |\n",
      "----------------------------------\n",
      "Episode reward: 55.889338\n",
      "Episode reward: 51.888126\n",
      "Episode reward: 34.953276\n",
      "Episode reward: 32.92988\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6032     |\n",
      "|    fps              | 3178     |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 317199   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00538  |\n",
      "|    n_updates        | 79274    |\n",
      "----------------------------------\n",
      "Episode reward: 38.955781\n",
      "Episode reward: 37.910149\n",
      "Episode reward: 53.591776\n",
      "Episode reward: 49.852341\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6036     |\n",
      "|    fps              | 3178     |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 317380   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0825   |\n",
      "|    n_updates        | 79319    |\n",
      "----------------------------------\n",
      "Episode reward: 44.942275\n",
      "Episode reward: 42.805651\n",
      "Episode reward: 59.831893\n",
      "Episode reward: 43.916783\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6040     |\n",
      "|    fps              | 3177     |\n",
      "|    time_elapsed     | 99       |\n",
      "|    total_timesteps  | 317572   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.162    |\n",
      "|    n_updates        | 79367    |\n",
      "----------------------------------\n",
      "Episode reward: 41.932262\n",
      "Episode reward: 30.930234\n",
      "Episode reward: 134.923775\n",
      "Episode reward: 37.69822\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6044     |\n",
      "|    fps              | 3177     |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 317820   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.153    |\n",
      "|    n_updates        | 79429    |\n",
      "----------------------------------\n",
      "Episode reward: 47.91652\n",
      "Episode reward: 79.846322\n",
      "Episode reward: 32.918848\n",
      "Episode reward: 57.778243\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6048     |\n",
      "|    fps              | 3177     |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 318041   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0373   |\n",
      "|    n_updates        | 79485    |\n",
      "----------------------------------\n",
      "Episode reward: 39.772113\n",
      "Episode reward: 29.930873\n",
      "Episode reward: 67.80262\n",
      "Episode reward: 64.763985\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6052     |\n",
      "|    fps              | 3177     |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 318244   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.146    |\n",
      "|    n_updates        | 79535    |\n",
      "----------------------------------\n",
      "Episode reward: 49.773297\n",
      "Episode reward: 80.869601\n",
      "Episode reward: 78.09128\n",
      "Episode reward: 65.768161\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6056     |\n",
      "|    fps              | 3176     |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 318520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 79604    |\n",
      "----------------------------------\n",
      "Episode reward: 57.914848\n",
      "Episode reward: 37.93895\n",
      "Episode reward: 49.838185\n",
      "Episode reward: 35.869987\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6060     |\n",
      "|    fps              | 3176     |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 318702   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 79650    |\n",
      "----------------------------------\n",
      "Episode reward: 34.908859\n",
      "Episode reward: 86.70482\n",
      "Episode reward: 71.897165\n",
      "Episode reward: 64.896084\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6064     |\n",
      "|    fps              | 3176     |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 318961   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0844   |\n",
      "|    n_updates        | 79715    |\n",
      "----------------------------------\n",
      "Episode reward: 48.918078\n",
      "Episode reward: 65.856167\n",
      "Episode reward: 43.885209\n",
      "Episode reward: 60.796506\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6068     |\n",
      "|    fps              | 3176     |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 319181   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.235    |\n",
      "|    n_updates        | 79770    |\n",
      "----------------------------------\n",
      "Episode reward: 50.87595\n",
      "Episode reward: 68.832377\n",
      "Episode reward: 49.91842\n",
      "Episode reward: 57.247499\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6072     |\n",
      "|    fps              | 3176     |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 319409   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00864  |\n",
      "|    n_updates        | 79827    |\n",
      "----------------------------------\n",
      "Episode reward: 47.869785\n",
      "Episode reward: 50.838201\n",
      "Episode reward: 43.92523\n",
      "Episode reward: 55.83928\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6076     |\n",
      "|    fps              | 3176     |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 319610   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00723  |\n",
      "|    n_updates        | 79877    |\n",
      "----------------------------------\n",
      "Episode reward: 74.706631\n",
      "Episode reward: 51.923293\n",
      "Episode reward: 41.91915\n",
      "Episode reward: 45.937716\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6080     |\n",
      "|    fps              | 3175     |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 319825   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0312   |\n",
      "|    n_updates        | 79931    |\n",
      "----------------------------------\n",
      "Episode reward: 59.730792\n",
      "Episode reward: 47.919481\n",
      "Episode reward: 47.918772\n",
      "Episode reward: 48.786834\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6084     |\n",
      "|    fps              | 3175     |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 320030   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.221    |\n",
      "|    n_updates        | 79982    |\n",
      "----------------------------------\n",
      "Episode reward: 77.384865\n",
      "Episode reward: 66.669205\n",
      "Episode reward: 36.854066\n",
      "Episode reward: 56.856431\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6088     |\n",
      "|    fps              | 3174     |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 320269   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00652  |\n",
      "|    n_updates        | 80042    |\n",
      "----------------------------------\n",
      "Episode reward: 67.508144\n",
      "Episode reward: 50.93864\n",
      "Episode reward: 47.909139\n",
      "Episode reward: 38.896664\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6092     |\n",
      "|    fps              | 3173     |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 320475   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.03     |\n",
      "|    n_updates        | 80093    |\n",
      "----------------------------------\n",
      "Episode reward: 51.922957\n",
      "Episode reward: 50.754824\n",
      "Episode reward: 52.931517\n",
      "Episode reward: 53.904864\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6096     |\n",
      "|    fps              | 3173     |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 320685   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 80146    |\n",
      "----------------------------------\n",
      "Episode reward: 43.935895\n",
      "Episode reward: 59.908657\n",
      "Episode reward: 36.903279\n",
      "Episode reward: 57.7188\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55       |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6100     |\n",
      "|    fps              | 3172     |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 320884   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00895  |\n",
      "|    n_updates        | 80195    |\n",
      "----------------------------------\n",
      "Episode reward: 51.784775\n",
      "Episode reward: 49.85171\n",
      "Episode reward: 31.848274\n",
      "Episode reward: 32.92854\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6104     |\n",
      "|    fps              | 3172     |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 321051   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 80237    |\n",
      "----------------------------------\n",
      "Episode reward: 48.941876\n",
      "Episode reward: 38.933088\n",
      "Episode reward: 52.909109\n",
      "Episode reward: 68.612169\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.6     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6108     |\n",
      "|    fps              | 3172     |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 321261   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00467  |\n",
      "|    n_updates        | 80290    |\n",
      "----------------------------------\n",
      "Episode reward: 42.810039\n",
      "Episode reward: 44.41748\n",
      "Episode reward: 118.476038\n",
      "Episode reward: 34.950205\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.1     |\n",
      "|    ep_rew_mean      | 53.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6112     |\n",
      "|    fps              | 3172     |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 321503   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 80350    |\n",
      "----------------------------------\n",
      "Episode reward: 98.782337\n",
      "Episode reward: 59.899711\n",
      "Episode reward: 53.826474\n",
      "Episode reward: 78.676212\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55       |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6116     |\n",
      "|    fps              | 3172     |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 321795   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0543   |\n",
      "|    n_updates        | 80423    |\n",
      "----------------------------------\n",
      "Episode reward: 39.69766\n",
      "Episode reward: 67.838839\n",
      "Episode reward: 51.932789\n",
      "Episode reward: 64.765992\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.8     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6120     |\n",
      "|    fps              | 3171     |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 322020   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00719  |\n",
      "|    n_updates        | 80479    |\n",
      "----------------------------------\n",
      "Episode reward: 33.923807\n",
      "Episode reward: 107.423523\n",
      "Episode reward: 52.668392\n",
      "Episode reward: 59.820281\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6124     |\n",
      "|    fps              | 3172     |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 322278   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.163    |\n",
      "|    n_updates        | 80544    |\n",
      "----------------------------------\n",
      "Episode reward: 54.557445\n",
      "Episode reward: 36.902352\n",
      "Episode reward: 42.921819\n",
      "Episode reward: 56.710028\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.5     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6128     |\n",
      "|    fps              | 3171     |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 322470   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 80592    |\n",
      "----------------------------------\n",
      "Episode reward: 46.944405\n",
      "Episode reward: 63.658944\n",
      "Episode reward: 74.868756\n",
      "Episode reward: 31.876549\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6132     |\n",
      "|    fps              | 3170     |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 322690   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.159    |\n",
      "|    n_updates        | 80647    |\n",
      "----------------------------------\n",
      "Episode reward: 51.793446\n",
      "Episode reward: 65.617042\n",
      "Episode reward: 36.924281\n",
      "Episode reward: 48.709595\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6136     |\n",
      "|    fps              | 3170     |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 322894   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 80698    |\n",
      "----------------------------------\n",
      "Episode reward: 43.840405\n",
      "Episode reward: 49.875996\n",
      "Episode reward: 60.067323\n",
      "Episode reward: 56.916865\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6140     |\n",
      "|    fps              | 3169     |\n",
      "|    time_elapsed     | 101      |\n",
      "|    total_timesteps  | 323106   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.442    |\n",
      "|    n_updates        | 80751    |\n",
      "----------------------------------\n",
      "Episode reward: 63.911428\n",
      "Episode reward: 55.396789\n",
      "Episode reward: 69.879632\n",
      "Episode reward: 58.854239\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6144     |\n",
      "|    fps              | 3169     |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 323355   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00663  |\n",
      "|    n_updates        | 80813    |\n",
      "----------------------------------\n",
      "Episode reward: 39.935252\n",
      "Episode reward: 40.936595\n",
      "Episode reward: 60.880258\n",
      "Episode reward: 69.281901\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6148     |\n",
      "|    fps              | 3168     |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 323567   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00656  |\n",
      "|    n_updates        | 80866    |\n",
      "----------------------------------\n",
      "Episode reward: 37.935087\n",
      "Episode reward: 41.924335\n",
      "Episode reward: 38.695611\n",
      "Episode reward: 59.888534\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55       |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6152     |\n",
      "|    fps              | 3168     |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 323746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.22     |\n",
      "|    n_updates        | 80911    |\n",
      "----------------------------------\n",
      "Episode reward: 50.857994\n",
      "Episode reward: 54.395864\n",
      "Episode reward: 39.638091\n",
      "Episode reward: 89.483773\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.6     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6156     |\n",
      "|    fps              | 3167     |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 323982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0192   |\n",
      "|    n_updates        | 80970    |\n",
      "----------------------------------\n",
      "Episode reward: 34.927034\n",
      "Episode reward: 44.875166\n",
      "Episode reward: 74.912279\n",
      "Episode reward: 51.763371\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6160     |\n",
      "|    fps              | 3166     |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 324193   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00496  |\n",
      "|    n_updates        | 81023    |\n",
      "----------------------------------\n",
      "Episode reward: 41.942949\n",
      "Episode reward: 63.87734\n",
      "Episode reward: 88.829397\n",
      "Episode reward: 60.858561\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6164     |\n",
      "|    fps              | 3166     |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 324449   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0404   |\n",
      "|    n_updates        | 81087    |\n",
      "----------------------------------\n",
      "Episode reward: 106.371182\n",
      "Episode reward: 39.928815\n",
      "Episode reward: 54.654638\n",
      "Episode reward: 52.917513\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6168     |\n",
      "|    fps              | 3165     |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 324704   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.197    |\n",
      "|    n_updates        | 81150    |\n",
      "----------------------------------\n",
      "Episode reward: 61.466178\n",
      "Episode reward: 36.854468\n",
      "Episode reward: 40.886946\n",
      "Episode reward: 58.923797\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6172     |\n",
      "|    fps              | 3166     |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 324903   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.202    |\n",
      "|    n_updates        | 81200    |\n",
      "----------------------------------\n",
      "Episode reward: 56.87709\n",
      "Episode reward: 59.874729\n",
      "Episode reward: 51.913357\n",
      "Episode reward: 65.646169\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6176     |\n",
      "|    fps              | 3165     |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 325138   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0849   |\n",
      "|    n_updates        | 81259    |\n",
      "----------------------------------\n",
      "Episode reward: 102.757166\n",
      "Episode reward: 57.754799\n",
      "Episode reward: 75.209453\n",
      "Episode reward: 47.950343\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6180     |\n",
      "|    fps              | 3166     |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 325423   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 81330    |\n",
      "----------------------------------\n",
      "Episode reward: 33.92858\n",
      "Episode reward: 41.888566\n",
      "Episode reward: 39.95731\n",
      "Episode reward: 63.272676\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6184     |\n",
      "|    fps              | 3165     |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 325603   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 81375    |\n",
      "----------------------------------\n",
      "Episode reward: 63.757543\n",
      "Episode reward: 81.266586\n",
      "Episode reward: 72.825779\n",
      "Episode reward: 52.912961\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6188     |\n",
      "|    fps              | 3165     |\n",
      "|    time_elapsed     | 102      |\n",
      "|    total_timesteps  | 325875   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.189    |\n",
      "|    n_updates        | 81443    |\n",
      "----------------------------------\n",
      "Episode reward: 82.673322\n",
      "Episode reward: 81.793583\n",
      "Episode reward: 65.359541\n",
      "Episode reward: 82.821284\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6192     |\n",
      "|    fps              | 3165     |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 326190   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 81522    |\n",
      "----------------------------------\n",
      "Episode reward: 42.913412\n",
      "Episode reward: 70.200658\n",
      "Episode reward: 47.786639\n",
      "Episode reward: 59.573187\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6196     |\n",
      "|    fps              | 3164     |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 326412   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0755   |\n",
      "|    n_updates        | 81577    |\n",
      "----------------------------------\n",
      "Episode reward: 63.822955\n",
      "Episode reward: 44.816818\n",
      "Episode reward: 47.86668\n",
      "Episode reward: 48.555297\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6200     |\n",
      "|    fps              | 3164     |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 326618   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0262   |\n",
      "|    n_updates        | 81629    |\n",
      "----------------------------------\n",
      "Episode reward: 104.856085\n",
      "Episode reward: 54.890421\n",
      "Episode reward: 53.412701\n",
      "Episode reward: 69.270208\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6204     |\n",
      "|    fps              | 3164     |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 326903   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00769  |\n",
      "|    n_updates        | 81700    |\n",
      "----------------------------------\n",
      "Episode reward: 58.68445\n",
      "Episode reward: 60.863659\n",
      "Episode reward: 58.689003\n",
      "Episode reward: 47.764647\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6208     |\n",
      "|    fps              | 3163     |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 327130   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00591  |\n",
      "|    n_updates        | 81757    |\n",
      "----------------------------------\n",
      "Episode reward: 56.865909\n",
      "Episode reward: 54.921034\n",
      "Episode reward: 74.868389\n",
      "Episode reward: 44.828366\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6212     |\n",
      "|    fps              | 3162     |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 327362   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.189    |\n",
      "|    n_updates        | 81815    |\n",
      "----------------------------------\n",
      "Episode reward: 74.901237\n",
      "Episode reward: 40.914767\n",
      "Episode reward: 59.859411\n",
      "Episode reward: 59.90545\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6216     |\n",
      "|    fps              | 3162     |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 327598   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.246    |\n",
      "|    n_updates        | 81874    |\n",
      "----------------------------------\n",
      "Episode reward: 61.862453\n",
      "Episode reward: 80.88244\n",
      "Episode reward: 52.843757\n",
      "Episode reward: 51.911225\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6220     |\n",
      "|    fps              | 3161     |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 327846   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 81936    |\n",
      "----------------------------------\n",
      "Episode reward: 59.895751\n",
      "Episode reward: 39.944771\n",
      "Episode reward: 52.73034\n",
      "Episode reward: 135.600953\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6224     |\n",
      "|    fps              | 3161     |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 328135   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00465  |\n",
      "|    n_updates        | 82008    |\n",
      "----------------------------------\n",
      "Episode reward: 65.923431\n",
      "Episode reward: 99.698696\n",
      "Episode reward: 36.873184\n",
      "Episode reward: 98.299098\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6228     |\n",
      "|    fps              | 3161     |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 328441   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.217    |\n",
      "|    n_updates        | 82085    |\n",
      "----------------------------------\n",
      "Episode reward: 60.697043\n",
      "Episode reward: 42.949414\n",
      "Episode reward: 48.53745\n",
      "Episode reward: 100.759625\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6232     |\n",
      "|    fps              | 3161     |\n",
      "|    time_elapsed     | 103      |\n",
      "|    total_timesteps  | 328701   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.153    |\n",
      "|    n_updates        | 82150    |\n",
      "----------------------------------\n",
      "Episode reward: 46.937339\n",
      "Episode reward: 125.73257\n",
      "Episode reward: 45.742427\n",
      "Episode reward: 36.951597\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6236     |\n",
      "|    fps              | 3161     |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 328957   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00679  |\n",
      "|    n_updates        | 82214    |\n",
      "----------------------------------\n",
      "Episode reward: 48.859167\n",
      "Episode reward: 113.749477\n",
      "Episode reward: 78.856012\n",
      "Episode reward: 85.80795\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6240     |\n",
      "|    fps              | 3160     |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 329290   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00905  |\n",
      "|    n_updates        | 82297    |\n",
      "----------------------------------\n",
      "Episode reward: 36.814427\n",
      "Episode reward: 73.855658\n",
      "Episode reward: 44.902759\n",
      "Episode reward: 43.938066\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6244     |\n",
      "|    fps              | 3160     |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 329490   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00617  |\n",
      "|    n_updates        | 82347    |\n",
      "----------------------------------\n",
      "Episode reward: 39.869798\n",
      "Episode reward: 50.871061\n",
      "Episode reward: 61.163091\n",
      "Episode reward: 38.924753\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6248     |\n",
      "|    fps              | 3160     |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 329682   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00657  |\n",
      "|    n_updates        | 82395    |\n",
      "----------------------------------\n",
      "Episode reward: 45.882127\n",
      "Episode reward: 35.805529\n",
      "Episode reward: 41.945274\n",
      "Episode reward: 43.864462\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6252     |\n",
      "|    fps              | 3159     |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 329850   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.127    |\n",
      "|    n_updates        | 82437    |\n",
      "----------------------------------\n",
      "Episode reward: 47.949649\n",
      "Episode reward: 39.901649\n",
      "Episode reward: 48.85494\n",
      "Episode reward: 76.724105\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6256     |\n",
      "|    fps              | 3159     |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 330064   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.302    |\n",
      "|    n_updates        | 82490    |\n",
      "----------------------------------\n",
      "Episode reward: 59.40471\n",
      "Episode reward: 64.188237\n",
      "Episode reward: 53.890941\n",
      "Episode reward: 80.147934\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6260     |\n",
      "|    fps              | 3159     |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 330325   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00736  |\n",
      "|    n_updates        | 82556    |\n",
      "----------------------------------\n",
      "Episode reward: 40.83088\n",
      "Episode reward: 76.073259\n",
      "Episode reward: 96.531592\n",
      "Episode reward: 45.912944\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6264     |\n",
      "|    fps              | 3158     |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 330588   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00682  |\n",
      "|    n_updates        | 82621    |\n",
      "----------------------------------\n",
      "Episode reward: 41.92239\n",
      "Episode reward: 45.80733\n",
      "Episode reward: 60.920159\n",
      "Episode reward: 78.048492\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6268     |\n",
      "|    fps              | 3158     |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 330817   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 82679    |\n",
      "----------------------------------\n",
      "Episode reward: 47.928196\n",
      "Episode reward: 51.934329\n",
      "Episode reward: 58.300906\n",
      "Episode reward: 68.891526\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6272     |\n",
      "|    fps              | 3157     |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 331045   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.137    |\n",
      "|    n_updates        | 82736    |\n",
      "----------------------------------\n",
      "Episode reward: 42.939688\n",
      "Episode reward: 44.910042\n",
      "Episode reward: 68.853688\n",
      "Episode reward: 56.902179\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6276     |\n",
      "|    fps              | 3156     |\n",
      "|    time_elapsed     | 104      |\n",
      "|    total_timesteps  | 331259   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 82789    |\n",
      "----------------------------------\n",
      "Episode reward: 47.642714\n",
      "Episode reward: 37.940298\n",
      "Episode reward: 60.537882\n",
      "Episode reward: 95.656717\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6280     |\n",
      "|    fps              | 3155     |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 331502   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.068    |\n",
      "|    n_updates        | 82850    |\n",
      "----------------------------------\n",
      "Episode reward: 31.951979\n",
      "Episode reward: 63.904757\n",
      "Episode reward: 45.600335\n",
      "Episode reward: 52.764252\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6284     |\n",
      "|    fps              | 3155     |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 331697   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.326    |\n",
      "|    n_updates        | 82899    |\n",
      "----------------------------------\n",
      "Episode reward: 54.404142\n",
      "Episode reward: 85.785031\n",
      "Episode reward: 36.848611\n",
      "Episode reward: 60.929639\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6288     |\n",
      "|    fps              | 3154     |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 331936   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.186    |\n",
      "|    n_updates        | 82958    |\n",
      "----------------------------------\n",
      "Episode reward: 71.769811\n",
      "Episode reward: 88.593654\n",
      "Episode reward: 46.932566\n",
      "Episode reward: 43.772115\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6292     |\n",
      "|    fps              | 3154     |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 332188   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00936  |\n",
      "|    n_updates        | 83021    |\n",
      "----------------------------------\n",
      "Episode reward: 49.902997\n",
      "Episode reward: 56.601953\n",
      "Episode reward: 53.890913\n",
      "Episode reward: 44.949948\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6296     |\n",
      "|    fps              | 3154     |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 332394   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00692  |\n",
      "|    n_updates        | 83073    |\n",
      "----------------------------------\n",
      "Episode reward: 44.704332\n",
      "Episode reward: 57.878473\n",
      "Episode reward: 39.806344\n",
      "Episode reward: 66.2408\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6300     |\n",
      "|    fps              | 3154     |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 332604   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.143    |\n",
      "|    n_updates        | 83125    |\n",
      "----------------------------------\n",
      "Episode reward: 48.653795\n",
      "Episode reward: 57.902525\n",
      "Episode reward: 51.853774\n",
      "Episode reward: 41.954319\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6304     |\n",
      "|    fps              | 3154     |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 332805   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.183    |\n",
      "|    n_updates        | 83176    |\n",
      "----------------------------------\n",
      "Episode reward: 37.917089\n",
      "Episode reward: 47.832662\n",
      "Episode reward: 46.942515\n",
      "Episode reward: 103.354217\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6308     |\n",
      "|    fps              | 3153     |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 333044   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 83235    |\n",
      "----------------------------------\n",
      "Episode reward: 39.922766\n",
      "Episode reward: 83.492582\n",
      "Episode reward: 87.773725\n",
      "Episode reward: 44.934956\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6312     |\n",
      "|    fps              | 3153     |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 333303   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00606  |\n",
      "|    n_updates        | 83300    |\n",
      "----------------------------------\n",
      "Episode reward: 65.698426\n",
      "Episode reward: 81.854038\n",
      "Episode reward: 48.807073\n",
      "Episode reward: 65.814607\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6316     |\n",
      "|    fps              | 3153     |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 333566   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 83366    |\n",
      "----------------------------------\n",
      "Episode reward: 39.467716\n",
      "Episode reward: 64.870483\n",
      "Episode reward: 66.824764\n",
      "Episode reward: 37.68296\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6320     |\n",
      "|    fps              | 3153     |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 333776   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 83418    |\n",
      "----------------------------------\n",
      "Episode reward: 43.950199\n",
      "Episode reward: 50.864056\n",
      "Episode reward: 53.894702\n",
      "Episode reward: 40.819615\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6324     |\n",
      "|    fps              | 3152     |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 333966   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00809  |\n",
      "|    n_updates        | 83466    |\n",
      "----------------------------------\n",
      "Episode reward: 41.649175\n",
      "Episode reward: 53.757703\n",
      "Episode reward: 41.935103\n",
      "Episode reward: 54.359393\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6328     |\n",
      "|    fps              | 3152     |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 334159   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.201    |\n",
      "|    n_updates        | 83514    |\n",
      "----------------------------------\n",
      "Episode reward: 63.88296\n",
      "Episode reward: 98.701237\n",
      "Episode reward: 33.902742\n",
      "Episode reward: 40.869759\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6332     |\n",
      "|    fps              | 3152     |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 334397   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0067   |\n",
      "|    n_updates        | 83574    |\n",
      "----------------------------------\n",
      "Episode reward: 44.774367\n",
      "Episode reward: 56.805247\n",
      "Episode reward: 57.165777\n",
      "Episode reward: 51.858033\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6336     |\n",
      "|    fps              | 3151     |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 334609   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.147    |\n",
      "|    n_updates        | 83627    |\n",
      "----------------------------------\n",
      "Episode reward: 78.40659\n",
      "Episode reward: 40.951113\n",
      "Episode reward: 37.951607\n",
      "Episode reward: 37.943317\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6340     |\n",
      "|    fps              | 3151     |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 334805   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0756   |\n",
      "|    n_updates        | 83676    |\n",
      "----------------------------------\n",
      "Episode reward: 66.896426\n",
      "Episode reward: 39.722461\n",
      "Episode reward: 33.903399\n",
      "Episode reward: 58.929506\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6344     |\n",
      "|    fps              | 3151     |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 335005   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00625  |\n",
      "|    n_updates        | 83726    |\n",
      "----------------------------------\n",
      "Episode reward: 45.799834\n",
      "Episode reward: 65.847663\n",
      "Episode reward: 66.762921\n",
      "Episode reward: 80.663882\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6348     |\n",
      "|    fps              | 3151     |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 335265   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 83791    |\n",
      "----------------------------------\n",
      "Episode reward: 41.809918\n",
      "Episode reward: 49.732624\n",
      "Episode reward: 68.810125\n",
      "Episode reward: 54.504544\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6352     |\n",
      "|    fps              | 3151     |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 335481   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.159    |\n",
      "|    n_updates        | 83845    |\n",
      "----------------------------------\n",
      "Episode reward: 32.947987\n",
      "Episode reward: 53.891155\n",
      "Episode reward: 39.948089\n",
      "Episode reward: 51.937451\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6356     |\n",
      "|    fps              | 3151     |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 335660   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 83889    |\n",
      "----------------------------------\n",
      "Episode reward: 50.861333\n",
      "Episode reward: 45.735203\n",
      "Episode reward: 71.541631\n",
      "Episode reward: 68.890729\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6360     |\n",
      "|    fps              | 3150     |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 335898   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 83949    |\n",
      "----------------------------------\n",
      "Episode reward: 50.92271\n",
      "Episode reward: 59.671718\n",
      "Episode reward: 56.878856\n",
      "Episode reward: 50.640891\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6364     |\n",
      "|    fps              | 3149     |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 336117   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0588   |\n",
      "|    n_updates        | 84004    |\n",
      "----------------------------------\n",
      "Episode reward: 82.748499\n",
      "Episode reward: 40.936034\n",
      "Episode reward: 66.578782\n",
      "Episode reward: 53.783568\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.5     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6368     |\n",
      "|    fps              | 3149     |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 336362   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 84065    |\n",
      "----------------------------------\n",
      "Episode reward: 75.333239\n",
      "Episode reward: 60.892416\n",
      "Episode reward: 83.093777\n",
      "Episode reward: 53.903239\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6372     |\n",
      "|    fps              | 3149     |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 336637   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.024    |\n",
      "|    n_updates        | 84134    |\n",
      "----------------------------------\n",
      "Episode reward: 43.886507\n",
      "Episode reward: 43.912943\n",
      "Episode reward: 45.933876\n",
      "Episode reward: 60.320601\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6376     |\n",
      "|    fps              | 3149     |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 336833   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.234    |\n",
      "|    n_updates        | 84183    |\n",
      "----------------------------------\n",
      "Episode reward: 50.77955\n",
      "Episode reward: 34.923647\n",
      "Episode reward: 57.725709\n",
      "Episode reward: 53.860092\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6380     |\n",
      "|    fps              | 3149     |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 337031   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 84232    |\n",
      "----------------------------------\n",
      "Episode reward: 58.670624\n",
      "Episode reward: 38.926006\n",
      "Episode reward: 38.937834\n",
      "Episode reward: 67.541137\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6384     |\n",
      "|    fps              | 3148     |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 337236   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.237    |\n",
      "|    n_updates        | 84283    |\n",
      "----------------------------------\n",
      "Episode reward: 48.827496\n",
      "Episode reward: 61.723175\n",
      "Episode reward: 48.945679\n",
      "Episode reward: 57.918188\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6388     |\n",
      "|    fps              | 3148     |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 337454   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00258  |\n",
      "|    n_updates        | 84338    |\n",
      "----------------------------------\n",
      "Episode reward: 68.895784\n",
      "Episode reward: 36.814791\n",
      "Episode reward: 41.939096\n",
      "Episode reward: 55.878466\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.7     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6392     |\n",
      "|    fps              | 3148     |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 337658   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00836  |\n",
      "|    n_updates        | 84389    |\n",
      "----------------------------------\n",
      "Episode reward: 46.891563\n",
      "Episode reward: 81.824542\n",
      "Episode reward: 48.670661\n",
      "Episode reward: 42.926914\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6396     |\n",
      "|    fps              | 3147     |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 337879   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.019    |\n",
      "|    n_updates        | 84444    |\n",
      "----------------------------------\n",
      "Episode reward: 50.914909\n",
      "Episode reward: 42.930526\n",
      "Episode reward: 44.909473\n",
      "Episode reward: 48.858241\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.6     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6400     |\n",
      "|    fps              | 3147     |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 338067   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00743  |\n",
      "|    n_updates        | 84491    |\n",
      "----------------------------------\n",
      "Episode reward: 41.908404\n",
      "Episode reward: 50.784054\n",
      "Episode reward: 73.8744\n",
      "Episode reward: 33.820103\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.6     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6404     |\n",
      "|    fps              | 3147     |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 338268   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 84541    |\n",
      "----------------------------------\n",
      "Episode reward: 66.692278\n",
      "Episode reward: 43.433145\n",
      "Episode reward: 55.737655\n",
      "Episode reward: 48.890947\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.4     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6408     |\n",
      "|    fps              | 3147     |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 338484   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.1      |\n",
      "|    n_updates        | 84595    |\n",
      "----------------------------------\n",
      "Episode reward: 53.762438\n",
      "Episode reward: 38.939366\n",
      "Episode reward: 101.536976\n",
      "Episode reward: 40.944205\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.2     |\n",
      "|    ep_rew_mean      | 53.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6412     |\n",
      "|    fps              | 3146     |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 338722   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00458  |\n",
      "|    n_updates        | 84655    |\n",
      "----------------------------------\n",
      "Episode reward: 87.863348\n",
      "Episode reward: 38.691074\n",
      "Episode reward: 78.041201\n",
      "Episode reward: 44.912753\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.1     |\n",
      "|    ep_rew_mean      | 53.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6416     |\n",
      "|    fps              | 3146     |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 338974   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.148    |\n",
      "|    n_updates        | 84718    |\n",
      "----------------------------------\n",
      "Episode reward: 58.471524\n",
      "Episode reward: 45.451055\n",
      "Episode reward: 41.952882\n",
      "Episode reward: 44.661534\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.9     |\n",
      "|    ep_rew_mean      | 53.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6420     |\n",
      "|    fps              | 3146     |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 339166   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0387   |\n",
      "|    n_updates        | 84766    |\n",
      "----------------------------------\n",
      "Episode reward: 37.68301\n",
      "Episode reward: 69.881901\n",
      "Episode reward: 62.88596\n",
      "Episode reward: 83.51863\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.6     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6424     |\n",
      "|    fps              | 3145     |\n",
      "|    time_elapsed     | 107      |\n",
      "|    total_timesteps  | 339422   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0905   |\n",
      "|    n_updates        | 84830    |\n",
      "----------------------------------\n",
      "Episode reward: 60.772919\n",
      "Episode reward: 48.90543\n",
      "Episode reward: 76.649784\n",
      "Episode reward: 38.898892\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6428     |\n",
      "|    fps              | 3144     |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 339648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 84886    |\n",
      "----------------------------------\n",
      "Episode reward: 43.589525\n",
      "Episode reward: 98.673674\n",
      "Episode reward: 54.473599\n",
      "Episode reward: 31.939877\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.8     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6432     |\n",
      "|    fps              | 3144     |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 339879   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 84944    |\n",
      "----------------------------------\n",
      "Episode reward: 53.853069\n",
      "Episode reward: 78.600247\n",
      "Episode reward: 44.945828\n",
      "Episode reward: 95.782224\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6436     |\n",
      "|    fps              | 3144     |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 340153   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0296   |\n",
      "|    n_updates        | 85013    |\n",
      "----------------------------------\n",
      "Episode reward: 63.946797\n",
      "Episode reward: 55.87866\n",
      "Episode reward: 114.404787\n",
      "Episode reward: 41.910674\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6440     |\n",
      "|    fps              | 3143     |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 340447   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0228   |\n",
      "|    n_updates        | 85086    |\n",
      "----------------------------------\n",
      "Episode reward: 73.833375\n",
      "Episode reward: 57.458208\n",
      "Episode reward: 30.817466\n",
      "Episode reward: 81.747912\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6444     |\n",
      "|    fps              | 3143     |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 340692   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 85147    |\n",
      "----------------------------------\n",
      "Episode reward: 78.539643\n",
      "Episode reward: 45.797149\n",
      "Episode reward: 42.867183\n",
      "Episode reward: 42.827641\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6448     |\n",
      "|    fps              | 3143     |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 340903   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0159   |\n",
      "|    n_updates        | 85200    |\n",
      "----------------------------------\n",
      "Episode reward: 68.124642\n",
      "Episode reward: 69.063136\n",
      "Episode reward: 132.461703\n",
      "Episode reward: 45.951751\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6452     |\n",
      "|    fps              | 3143     |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 341221   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 85280    |\n",
      "----------------------------------\n",
      "Episode reward: 47.926353\n",
      "Episode reward: 54.855622\n",
      "Episode reward: 57.843577\n",
      "Episode reward: 66.285797\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6456     |\n",
      "|    fps              | 3143     |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 341449   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00564  |\n",
      "|    n_updates        | 85337    |\n",
      "----------------------------------\n",
      "Episode reward: 58.766666\n",
      "Episode reward: 39.846844\n",
      "Episode reward: 56.86063\n",
      "Episode reward: 64.839339\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6460     |\n",
      "|    fps              | 3143     |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 341670   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.184    |\n",
      "|    n_updates        | 85392    |\n",
      "----------------------------------\n",
      "Episode reward: 65.897107\n",
      "Episode reward: 116.957789\n",
      "Episode reward: 46.853257\n",
      "Episode reward: 65.794919\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6464     |\n",
      "|    fps              | 3143     |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 341969   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00886  |\n",
      "|    n_updates        | 85467    |\n",
      "----------------------------------\n",
      "Episode reward: 32.892579\n",
      "Episode reward: 60.277602\n",
      "Episode reward: 74.812619\n",
      "Episode reward: 36.653549\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6468     |\n",
      "|    fps              | 3142     |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 342175   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 85518    |\n",
      "----------------------------------\n",
      "Episode reward: 50.763774\n",
      "Episode reward: 38.786262\n",
      "Episode reward: 53.837873\n",
      "Episode reward: 45.89224\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6472     |\n",
      "|    fps              | 3142     |\n",
      "|    time_elapsed     | 108      |\n",
      "|    total_timesteps  | 342365   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 85566    |\n",
      "----------------------------------\n",
      "Episode reward: 41.909755\n",
      "Episode reward: 91.708874\n",
      "Episode reward: 50.613008\n",
      "Episode reward: 81.219536\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6476     |\n",
      "|    fps              | 3142     |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 342633   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 85633    |\n",
      "----------------------------------\n",
      "Episode reward: 74.600031\n",
      "Episode reward: 70.463492\n",
      "Episode reward: 35.790788\n",
      "Episode reward: 61.320966\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6480     |\n",
      "|    fps              | 3142     |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 342879   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 85694    |\n",
      "----------------------------------\n",
      "Episode reward: 59.37724\n",
      "Episode reward: 45.880611\n",
      "Episode reward: 48.775046\n",
      "Episode reward: 86.879045\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6484     |\n",
      "|    fps              | 3142     |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 343121   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 85755    |\n",
      "----------------------------------\n",
      "Episode reward: 53.14009\n",
      "Episode reward: 50.43274\n",
      "Episode reward: 75.697059\n",
      "Episode reward: 49.76847\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6488     |\n",
      "|    fps              | 3142     |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 343352   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.131    |\n",
      "|    n_updates        | 85812    |\n",
      "----------------------------------\n",
      "Episode reward: 44.902195\n",
      "Episode reward: 45.941421\n",
      "Episode reward: 85.434219\n",
      "Episode reward: 44.369252\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6492     |\n",
      "|    fps              | 3141     |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 343574   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.288    |\n",
      "|    n_updates        | 85868    |\n",
      "----------------------------------\n",
      "Episode reward: 53.677307\n",
      "Episode reward: 46.477608\n",
      "Episode reward: 60.701274\n",
      "Episode reward: 49.93938\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6496     |\n",
      "|    fps              | 3141     |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 343786   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 85921    |\n",
      "----------------------------------\n",
      "Episode reward: 37.929444\n",
      "Episode reward: 72.841019\n",
      "Episode reward: 44.93984\n",
      "Episode reward: 60.287953\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6500     |\n",
      "|    fps              | 3140     |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 344003   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0058   |\n",
      "|    n_updates        | 85975    |\n",
      "----------------------------------\n",
      "Episode reward: 52.770435\n",
      "Episode reward: 61.824545\n",
      "Episode reward: 52.675839\n",
      "Episode reward: 57.780768\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6504     |\n",
      "|    fps              | 3140     |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 344229   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 86032    |\n",
      "----------------------------------\n",
      "Episode reward: 41.89048\n",
      "Episode reward: 44.826263\n",
      "Episode reward: 48.61759\n",
      "Episode reward: 63.604782\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6508     |\n",
      "|    fps              | 3139     |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 344429   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 86082    |\n",
      "----------------------------------\n",
      "Episode reward: 55.78029\n",
      "Episode reward: 54.924735\n",
      "Episode reward: 51.3957\n",
      "Episode reward: 38.876905\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6512     |\n",
      "|    fps              | 3139     |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 344631   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.158    |\n",
      "|    n_updates        | 86132    |\n",
      "----------------------------------\n",
      "Episode reward: 45.840037\n",
      "Episode reward: 68.729343\n",
      "Episode reward: 56.660443\n",
      "Episode reward: 37.878723\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6516     |\n",
      "|    fps              | 3138     |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 344841   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.178    |\n",
      "|    n_updates        | 86185    |\n",
      "----------------------------------\n",
      "Episode reward: 40.878964\n",
      "Episode reward: 48.921245\n",
      "Episode reward: 70.478632\n",
      "Episode reward: 40.929015\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6520     |\n",
      "|    fps              | 3138     |\n",
      "|    time_elapsed     | 109      |\n",
      "|    total_timesteps  | 345045   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0092   |\n",
      "|    n_updates        | 86236    |\n",
      "----------------------------------\n",
      "Episode reward: 71.646797\n",
      "Episode reward: 40.91489\n",
      "Episode reward: 53.806928\n",
      "Episode reward: 55.574409\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6524     |\n",
      "|    fps              | 3138     |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 345268   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00409  |\n",
      "|    n_updates        | 86291    |\n",
      "----------------------------------\n",
      "Episode reward: 69.710436\n",
      "Episode reward: 95.750826\n",
      "Episode reward: 44.586489\n",
      "Episode reward: 58.910172\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6528     |\n",
      "|    fps              | 3137     |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 345538   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.205    |\n",
      "|    n_updates        | 86359    |\n",
      "----------------------------------\n",
      "Episode reward: 48.942125\n",
      "Episode reward: 52.921571\n",
      "Episode reward: 61.812787\n",
      "Episode reward: 48.92737\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6532     |\n",
      "|    fps              | 3137     |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 345751   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.276    |\n",
      "|    n_updates        | 86412    |\n",
      "----------------------------------\n",
      "Episode reward: 37.947738\n",
      "Episode reward: 54.047506\n",
      "Episode reward: 69.888076\n",
      "Episode reward: 36.93046\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6536     |\n",
      "|    fps              | 3137     |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 345951   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00474  |\n",
      "|    n_updates        | 86462    |\n",
      "----------------------------------\n",
      "Episode reward: 47.721013\n",
      "Episode reward: 59.855527\n",
      "Episode reward: 45.948955\n",
      "Episode reward: 74.397486\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6540     |\n",
      "|    fps              | 3136     |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 346180   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.21     |\n",
      "|    n_updates        | 86519    |\n",
      "----------------------------------\n",
      "Episode reward: 62.950819\n",
      "Episode reward: 80.820079\n",
      "Episode reward: 45.575506\n",
      "Episode reward: 32.943402\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6544     |\n",
      "|    fps              | 3136     |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 346404   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 86575    |\n",
      "----------------------------------\n",
      "Episode reward: 45.848411\n",
      "Episode reward: 43.930305\n",
      "Episode reward: 47.889746\n",
      "Episode reward: 71.280011\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6548     |\n",
      "|    fps              | 3136     |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 346614   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.164    |\n",
      "|    n_updates        | 86628    |\n",
      "----------------------------------\n",
      "Episode reward: 56.313606\n",
      "Episode reward: 50.881791\n",
      "Episode reward: 52.641135\n",
      "Episode reward: 47.937008\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6552     |\n",
      "|    fps              | 3136     |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 346823   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 86680    |\n",
      "----------------------------------\n",
      "Episode reward: 54.801802\n",
      "Episode reward: 114.926133\n",
      "Episode reward: 40.883359\n",
      "Episode reward: 36.95827\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6556     |\n",
      "|    fps              | 3135     |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 347072   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.2      |\n",
      "|    n_updates        | 86742    |\n",
      "----------------------------------\n",
      "Episode reward: 73.704351\n",
      "Episode reward: 37.94891\n",
      "Episode reward: 39.871278\n",
      "Episode reward: 50.417731\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6560     |\n",
      "|    fps              | 3136     |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 347275   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00686  |\n",
      "|    n_updates        | 86793    |\n",
      "----------------------------------\n",
      "Episode reward: 64.868764\n",
      "Episode reward: 37.943173\n",
      "Episode reward: 45.929855\n",
      "Episode reward: 43.916652\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55       |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6564     |\n",
      "|    fps              | 3135     |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 347468   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00833  |\n",
      "|    n_updates        | 86841    |\n",
      "----------------------------------\n",
      "Episode reward: 57.871985\n",
      "Episode reward: 58.521278\n",
      "Episode reward: 57.91849\n",
      "Episode reward: 57.849373\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6568     |\n",
      "|    fps              | 3135     |\n",
      "|    time_elapsed     | 110      |\n",
      "|    total_timesteps  | 347701   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 86900    |\n",
      "----------------------------------\n",
      "Episode reward: 69.812836\n",
      "Episode reward: 55.175567\n",
      "Episode reward: 86.783489\n",
      "Episode reward: 70.229792\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6572     |\n",
      "|    fps              | 3134     |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 347986   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.51     |\n",
      "|    n_updates        | 86971    |\n",
      "----------------------------------\n",
      "Episode reward: 44.571264\n",
      "Episode reward: 67.820638\n",
      "Episode reward: 90.624713\n",
      "Episode reward: 54.801713\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6576     |\n",
      "|    fps              | 3134     |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 348245   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0211   |\n",
      "|    n_updates        | 87036    |\n",
      "----------------------------------\n",
      "Episode reward: 68.809757\n",
      "Episode reward: 37.923946\n",
      "Episode reward: 62.718073\n",
      "Episode reward: 50.929681\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6580     |\n",
      "|    fps              | 3134     |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 348466   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00996  |\n",
      "|    n_updates        | 87091    |\n",
      "----------------------------------\n",
      "Episode reward: 75.266162\n",
      "Episode reward: 40.819768\n",
      "Episode reward: 40.850992\n",
      "Episode reward: 57.847427\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6584     |\n",
      "|    fps              | 3133     |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 348684   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.216    |\n",
      "|    n_updates        | 87145    |\n",
      "----------------------------------\n",
      "Episode reward: 36.907589\n",
      "Episode reward: 66.88488\n",
      "Episode reward: 47.857386\n",
      "Episode reward: 35.769746\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6588     |\n",
      "|    fps              | 3133     |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 348872   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.019    |\n",
      "|    n_updates        | 87192    |\n",
      "----------------------------------\n",
      "Episode reward: 42.590639\n",
      "Episode reward: 85.792331\n",
      "Episode reward: 34.921682\n",
      "Episode reward: 48.871463\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6592     |\n",
      "|    fps              | 3132     |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 349085   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.183    |\n",
      "|    n_updates        | 87246    |\n",
      "----------------------------------\n",
      "Episode reward: 53.822244\n",
      "Episode reward: 47.93237\n",
      "Episode reward: 76.742102\n",
      "Episode reward: 35.932722\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6596     |\n",
      "|    fps              | 3133     |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 349300   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.203    |\n",
      "|    n_updates        | 87299    |\n",
      "----------------------------------\n",
      "Episode reward: 37.943296\n",
      "Episode reward: 88.394095\n",
      "Episode reward: 38.697632\n",
      "Episode reward: 47.576243\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6600     |\n",
      "|    fps              | 3132     |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 349517   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.238    |\n",
      "|    n_updates        | 87354    |\n",
      "----------------------------------\n",
      "Episode reward: 53.875594\n",
      "Episode reward: 59.800441\n",
      "Episode reward: 55.605886\n",
      "Episode reward: 81.782278\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6604     |\n",
      "|    fps              | 3132     |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 349769   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.226    |\n",
      "|    n_updates        | 87417    |\n",
      "----------------------------------\n",
      "Episode reward: 34.928038\n",
      "Episode reward: 37.941467\n",
      "Episode reward: 45.899075\n",
      "Episode reward: 46.924557\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6608     |\n",
      "|    fps              | 3132     |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 349935   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0185   |\n",
      "|    n_updates        | 87458    |\n",
      "----------------------------------\n",
      "Episode reward: 58.902287\n",
      "Episode reward: 45.705825\n",
      "Episode reward: 49.940232\n",
      "Episode reward: 34.961864\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6612     |\n",
      "|    fps              | 3132     |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 350125   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0626   |\n",
      "|    n_updates        | 87506    |\n",
      "----------------------------------\n",
      "Episode reward: 51.733983\n",
      "Episode reward: 58.840751\n",
      "Episode reward: 58.522012\n",
      "Episode reward: 35.941397\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6616     |\n",
      "|    fps              | 3132     |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 350332   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.15     |\n",
      "|    n_updates        | 87557    |\n",
      "----------------------------------\n",
      "Episode reward: 60.873106\n",
      "Episode reward: 60.079482\n",
      "Episode reward: 74.710522\n",
      "Episode reward: 75.902785\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6620     |\n",
      "|    fps              | 3132     |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 350607   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0086   |\n",
      "|    n_updates        | 87626    |\n",
      "----------------------------------\n",
      "Episode reward: 56.875386\n",
      "Episode reward: 61.869993\n",
      "Episode reward: 35.669604\n",
      "Episode reward: 88.777971\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6624     |\n",
      "|    fps              | 3132     |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 350851   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.195    |\n",
      "|    n_updates        | 87687    |\n",
      "----------------------------------\n",
      "Episode reward: 51.879439\n",
      "Episode reward: 45.659659\n",
      "Episode reward: 39.905731\n",
      "Episode reward: 38.925651\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6628     |\n",
      "|    fps              | 3131     |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 351028   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 87731    |\n",
      "----------------------------------\n",
      "Episode reward: 61.895446\n",
      "Episode reward: 48.929763\n",
      "Episode reward: 76.796595\n",
      "Episode reward: 72.20536\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6632     |\n",
      "|    fps              | 3131     |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 351292   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.226    |\n",
      "|    n_updates        | 87797    |\n",
      "----------------------------------\n",
      "Episode reward: 82.826493\n",
      "Episode reward: 59.911124\n",
      "Episode reward: 38.874703\n",
      "Episode reward: 84.50373\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6636     |\n",
      "|    fps              | 3130     |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 351559   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0425   |\n",
      "|    n_updates        | 87864    |\n",
      "----------------------------------\n",
      "Episode reward: 50.916923\n",
      "Episode reward: 82.74766\n",
      "Episode reward: 54.860015\n",
      "Episode reward: 48.820208\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6640     |\n",
      "|    fps              | 3130     |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 351797   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.227    |\n",
      "|    n_updates        | 87924    |\n",
      "----------------------------------\n",
      "Episode reward: 58.863203\n",
      "Episode reward: 57.832332\n",
      "Episode reward: 65.88198\n",
      "Episode reward: 48.45846\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6644     |\n",
      "|    fps              | 3130     |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 352029   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.192    |\n",
      "|    n_updates        | 87982    |\n",
      "----------------------------------\n",
      "Episode reward: 44.851564\n",
      "Episode reward: 40.944461\n",
      "Episode reward: 133.519917\n",
      "Episode reward: 59.544007\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6648     |\n",
      "|    fps              | 3129     |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 352309   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00787  |\n",
      "|    n_updates        | 88052    |\n",
      "----------------------------------\n",
      "Episode reward: 46.929253\n",
      "Episode reward: 79.581266\n",
      "Episode reward: 58.912638\n",
      "Episode reward: 44.841855\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6652     |\n",
      "|    fps              | 3129     |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 352541   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00477  |\n",
      "|    n_updates        | 88110    |\n",
      "----------------------------------\n",
      "Episode reward: 70.572452\n",
      "Episode reward: 82.533544\n",
      "Episode reward: 62.921168\n",
      "Episode reward: 37.845513\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6656     |\n",
      "|    fps              | 3129     |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 352799   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.182    |\n",
      "|    n_updates        | 88174    |\n",
      "----------------------------------\n",
      "Episode reward: 41.95113\n",
      "Episode reward: 46.89064\n",
      "Episode reward: 89.449803\n",
      "Episode reward: 46.780532\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6660     |\n",
      "|    fps              | 3129     |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 353025   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.186    |\n",
      "|    n_updates        | 88231    |\n",
      "----------------------------------\n",
      "Episode reward: 76.18004\n",
      "Episode reward: 129.370039\n",
      "Episode reward: 49.891165\n",
      "Episode reward: 93.528883\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6664     |\n",
      "|    fps              | 3129     |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 353380   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 88319    |\n",
      "----------------------------------\n",
      "Episode reward: 39.905205\n",
      "Episode reward: 64.989457\n",
      "Episode reward: 50.168796\n",
      "Episode reward: 79.504062\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6668     |\n",
      "|    fps              | 3128     |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 353617   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0948   |\n",
      "|    n_updates        | 88379    |\n",
      "----------------------------------\n",
      "Episode reward: 61.851251\n",
      "Episode reward: 52.500446\n",
      "Episode reward: 41.899549\n",
      "Episode reward: 82.29827\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6672     |\n",
      "|    fps              | 3128     |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 353857   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 88439    |\n",
      "----------------------------------\n",
      "Episode reward: 63.841867\n",
      "Episode reward: 40.59763\n",
      "Episode reward: 54.906971\n",
      "Episode reward: 45.904577\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6676     |\n",
      "|    fps              | 3128     |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 354063   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.371    |\n",
      "|    n_updates        | 88490    |\n",
      "----------------------------------\n",
      "Episode reward: 34.936607\n",
      "Episode reward: 52.924614\n",
      "Episode reward: 48.922008\n",
      "Episode reward: 49.306322\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6680     |\n",
      "|    fps              | 3128     |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 354250   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0253   |\n",
      "|    n_updates        | 88537    |\n",
      "----------------------------------\n",
      "Episode reward: 80.611941\n",
      "Episode reward: 99.023044\n",
      "Episode reward: 40.872749\n",
      "Episode reward: 41.938858\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6684     |\n",
      "|    fps              | 3127     |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 354516   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 88603    |\n",
      "----------------------------------\n",
      "Episode reward: 46.917562\n",
      "Episode reward: 99.85784\n",
      "Episode reward: 91.859429\n",
      "Episode reward: 56.902319\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6688     |\n",
      "|    fps              | 3127     |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 354815   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00844  |\n",
      "|    n_updates        | 88678    |\n",
      "----------------------------------\n",
      "Episode reward: 68.822751\n",
      "Episode reward: 59.912918\n",
      "Episode reward: 128.514011\n",
      "Episode reward: 85.62869\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6692     |\n",
      "|    fps              | 3127     |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 355162   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 88765    |\n",
      "----------------------------------\n",
      "Episode reward: 53.76677\n",
      "Episode reward: 52.908439\n",
      "Episode reward: 90.847449\n",
      "Episode reward: 64.749242\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6696     |\n",
      "|    fps              | 3127     |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 355426   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00437  |\n",
      "|    n_updates        | 88831    |\n",
      "----------------------------------\n",
      "Episode reward: 97.513966\n",
      "Episode reward: 63.653104\n",
      "Episode reward: 65.840554\n",
      "Episode reward: 93.77966\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 61.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6700     |\n",
      "|    fps              | 3127     |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 355748   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 88911    |\n",
      "----------------------------------\n",
      "Episode reward: 65.464894\n",
      "Episode reward: 68.829659\n",
      "Episode reward: 58.862311\n",
      "Episode reward: 64.268992\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6704     |\n",
      "|    fps              | 3127     |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 356008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 88976    |\n",
      "----------------------------------\n",
      "Episode reward: 67.864371\n",
      "Episode reward: 46.921289\n",
      "Episode reward: 44.699061\n",
      "Episode reward: 64.737201\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6708     |\n",
      "|    fps              | 3126     |\n",
      "|    time_elapsed     | 113      |\n",
      "|    total_timesteps  | 356233   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.366    |\n",
      "|    n_updates        | 89033    |\n",
      "----------------------------------\n",
      "Episode reward: 46.739143\n",
      "Episode reward: 42.890835\n",
      "Episode reward: 90.418967\n",
      "Episode reward: 60.891149\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6712     |\n",
      "|    fps              | 3126     |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 356478   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.202    |\n",
      "|    n_updates        | 89094    |\n",
      "----------------------------------\n",
      "Episode reward: 40.9099\n",
      "Episode reward: 45.772639\n",
      "Episode reward: 47.797062\n",
      "Episode reward: 56.919013\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6716     |\n",
      "|    fps              | 3126     |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 356670   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.281    |\n",
      "|    n_updates        | 89142    |\n",
      "----------------------------------\n",
      "Episode reward: 61.870249\n",
      "Episode reward: 35.926563\n",
      "Episode reward: 47.892561\n",
      "Episode reward: 65.885298\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6720     |\n",
      "|    fps              | 3126     |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 356882   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 89195    |\n",
      "----------------------------------\n",
      "Episode reward: 57.891095\n",
      "Episode reward: 87.71097\n",
      "Episode reward: 52.864114\n",
      "Episode reward: 86.880196\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6724     |\n",
      "|    fps              | 3125     |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 357172   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.431    |\n",
      "|    n_updates        | 89267    |\n",
      "----------------------------------\n",
      "Episode reward: 102.631121\n",
      "Episode reward: 40.908917\n",
      "Episode reward: 46.901006\n",
      "Episode reward: 48.927189\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6728     |\n",
      "|    fps              | 3125     |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 357414   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.414    |\n",
      "|    n_updates        | 89328    |\n",
      "----------------------------------\n",
      "Episode reward: 84.797897\n",
      "Episode reward: 73.02537\n",
      "Episode reward: 63.912859\n",
      "Episode reward: 68.082438\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6732     |\n",
      "|    fps              | 3125     |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 357708   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.007    |\n",
      "|    n_updates        | 89401    |\n",
      "----------------------------------\n",
      "Episode reward: 47.919832\n",
      "Episode reward: 149.508077\n",
      "Episode reward: 47.924925\n",
      "Episode reward: 73.672875\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.7     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6736     |\n",
      "|    fps              | 3125     |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 358031   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0205   |\n",
      "|    n_updates        | 89482    |\n",
      "----------------------------------\n",
      "Episode reward: 50.331908\n",
      "Episode reward: 36.948266\n",
      "Episode reward: 50.898069\n",
      "Episode reward: 32.78086\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.1     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6740     |\n",
      "|    fps              | 3124     |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 358203   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 89525    |\n",
      "----------------------------------\n",
      "Episode reward: 92.528875\n",
      "Episode reward: 42.774396\n",
      "Episode reward: 35.958207\n",
      "Episode reward: 80.422217\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 63.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6744     |\n",
      "|    fps              | 3124     |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 358457   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 89589    |\n",
      "----------------------------------\n",
      "Episode reward: 73.822669\n",
      "Episode reward: 59.71248\n",
      "Episode reward: 51.65599\n",
      "Episode reward: 56.330694\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6748     |\n",
      "|    fps              | 3124     |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 358702   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 89650    |\n",
      "----------------------------------\n",
      "Episode reward: 33.749769\n",
      "Episode reward: 38.919961\n",
      "Episode reward: 42.935223\n",
      "Episode reward: 57.066352\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6752     |\n",
      "|    fps              | 3124     |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 358876   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0205   |\n",
      "|    n_updates        | 89693    |\n",
      "----------------------------------\n",
      "Episode reward: 78.53025\n",
      "Episode reward: 54.803303\n",
      "Episode reward: 38.882471\n",
      "Episode reward: 84.811556\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6756     |\n",
      "|    fps              | 3124     |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 359134   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00825  |\n",
      "|    n_updates        | 89758    |\n",
      "----------------------------------\n",
      "Episode reward: 40.894059\n",
      "Episode reward: 66.738799\n",
      "Episode reward: 36.934245\n",
      "Episode reward: 38.808985\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6760     |\n",
      "|    fps              | 3124     |\n",
      "|    time_elapsed     | 114      |\n",
      "|    total_timesteps  | 359318   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00487  |\n",
      "|    n_updates        | 89804    |\n",
      "----------------------------------\n",
      "Episode reward: 44.926952\n",
      "Episode reward: 44.754829\n",
      "Episode reward: 49.860202\n",
      "Episode reward: 44.949191\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6764     |\n",
      "|    fps              | 3124     |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 359503   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00687  |\n",
      "|    n_updates        | 89850    |\n",
      "----------------------------------\n",
      "Episode reward: 41.946959\n",
      "Episode reward: 50.653713\n",
      "Episode reward: 113.869762\n",
      "Episode reward: 63.546126\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6768     |\n",
      "|    fps              | 3123     |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 359775   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.221    |\n",
      "|    n_updates        | 89918    |\n",
      "----------------------------------\n",
      "Episode reward: 113.120336\n",
      "Episode reward: 89.632347\n",
      "Episode reward: 58.470332\n",
      "Episode reward: 72.658066\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6772     |\n",
      "|    fps              | 3123     |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 360111   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.124    |\n",
      "|    n_updates        | 90002    |\n",
      "----------------------------------\n",
      "Episode reward: 57.869417\n",
      "Episode reward: 61.645606\n",
      "Episode reward: 52.888497\n",
      "Episode reward: 46.844799\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6776     |\n",
      "|    fps              | 3123     |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 360331   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 90057    |\n",
      "----------------------------------\n",
      "Episode reward: 79.892685\n",
      "Episode reward: 41.946654\n",
      "Episode reward: 66.754092\n",
      "Episode reward: 122.803064\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6780     |\n",
      "|    fps              | 3123     |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 360650   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00898  |\n",
      "|    n_updates        | 90137    |\n",
      "----------------------------------\n",
      "Episode reward: 87.524198\n",
      "Episode reward: 83.442996\n",
      "Episode reward: 42.79466\n",
      "Episode reward: 91.391086\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6784     |\n",
      "|    fps              | 3124     |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 360961   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 90215    |\n",
      "----------------------------------\n",
      "Episode reward: 36.941974\n",
      "Episode reward: 45.924891\n",
      "Episode reward: 55.613403\n",
      "Episode reward: 48.937387\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6788     |\n",
      "|    fps              | 3123     |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 361149   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.239    |\n",
      "|    n_updates        | 90262    |\n",
      "----------------------------------\n",
      "Episode reward: 57.892548\n",
      "Episode reward: 42.793153\n",
      "Episode reward: 85.858979\n",
      "Episode reward: 47.169577\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6792     |\n",
      "|    fps              | 3123     |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 361384   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0087   |\n",
      "|    n_updates        | 90320    |\n",
      "----------------------------------\n",
      "Episode reward: 52.815192\n",
      "Episode reward: 61.671324\n",
      "Episode reward: 56.27936\n",
      "Episode reward: 63.599841\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6796     |\n",
      "|    fps              | 3123     |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 361620   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00876  |\n",
      "|    n_updates        | 90379    |\n",
      "----------------------------------\n",
      "Episode reward: 58.600877\n",
      "Episode reward: 48.698028\n",
      "Episode reward: 52.842197\n",
      "Episode reward: 49.919887\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6800     |\n",
      "|    fps              | 3123     |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 361831   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.307    |\n",
      "|    n_updates        | 90432    |\n",
      "----------------------------------\n",
      "Episode reward: 62.909741\n",
      "Episode reward: 56.640796\n",
      "Episode reward: 43.715044\n",
      "Episode reward: 53.818185\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6804     |\n",
      "|    fps              | 3122     |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 362049   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.196    |\n",
      "|    n_updates        | 90487    |\n",
      "----------------------------------\n",
      "Episode reward: 94.726603\n",
      "Episode reward: 42.807009\n",
      "Episode reward: 69.669888\n",
      "Episode reward: 34.96202\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6808     |\n",
      "|    fps              | 3122     |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 362292   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.257    |\n",
      "|    n_updates        | 90547    |\n",
      "----------------------------------\n",
      "Episode reward: 44.490096\n",
      "Episode reward: 44.888939\n",
      "Episode reward: 69.455135\n",
      "Episode reward: 47.421313\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6812     |\n",
      "|    fps              | 3122     |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 362500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 90599    |\n",
      "----------------------------------\n",
      "Episode reward: 49.918747\n",
      "Episode reward: 53.924479\n",
      "Episode reward: 50.49894\n",
      "Episode reward: 82.166774\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6816     |\n",
      "|    fps              | 3122     |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 362740   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.371    |\n",
      "|    n_updates        | 90659    |\n",
      "----------------------------------\n",
      "Episode reward: 59.845095\n",
      "Episode reward: 38.903929\n",
      "Episode reward: 44.753675\n",
      "Episode reward: 51.918689\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6820     |\n",
      "|    fps              | 3122     |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 362936   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.111    |\n",
      "|    n_updates        | 90708    |\n",
      "----------------------------------\n",
      "Episode reward: 46.834481\n",
      "Episode reward: 106.634366\n",
      "Episode reward: 86.557083\n",
      "Episode reward: 34.912319\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6824     |\n",
      "|    fps              | 3122     |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 363213   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.692    |\n",
      "|    n_updates        | 90778    |\n",
      "----------------------------------\n",
      "Episode reward: 71.227505\n",
      "Episode reward: 46.919991\n",
      "Episode reward: 42.860775\n",
      "Episode reward: 45.937003\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6828     |\n",
      "|    fps              | 3121     |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 363422   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.163    |\n",
      "|    n_updates        | 90830    |\n",
      "----------------------------------\n",
      "Episode reward: 83.970899\n",
      "Episode reward: 38.803913\n",
      "Episode reward: 33.917655\n",
      "Episode reward: 94.292156\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6832     |\n",
      "|    fps              | 3121     |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 363675   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 90893    |\n",
      "----------------------------------\n",
      "Episode reward: 32.725688\n",
      "Episode reward: 45.914758\n",
      "Episode reward: 43.904434\n",
      "Episode reward: 56.919523\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6836     |\n",
      "|    fps              | 3122     |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 363855   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.018    |\n",
      "|    n_updates        | 90938    |\n",
      "----------------------------------\n",
      "Episode reward: 56.783557\n",
      "Episode reward: 58.024365\n",
      "Episode reward: 45.935046\n",
      "Episode reward: 41.913447\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6840     |\n",
      "|    fps              | 3121     |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 364059   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 90989    |\n",
      "----------------------------------\n",
      "Episode reward: 115.880491\n",
      "Episode reward: 38.937059\n",
      "Episode reward: 37.929026\n",
      "Episode reward: 55.928747\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6844     |\n",
      "|    fps              | 3122     |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 364310   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.261    |\n",
      "|    n_updates        | 91052    |\n",
      "----------------------------------\n",
      "Episode reward: 44.889341\n",
      "Episode reward: 80.415974\n",
      "Episode reward: 80.139084\n",
      "Episode reward: 54.597073\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6848     |\n",
      "|    fps              | 3122     |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 364575   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.552    |\n",
      "|    n_updates        | 91118    |\n",
      "----------------------------------\n",
      "Episode reward: 35.94744\n",
      "Episode reward: 53.731926\n",
      "Episode reward: 62.316289\n",
      "Episode reward: 88.628541\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6852     |\n",
      "|    fps              | 3121     |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 364817   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00754  |\n",
      "|    n_updates        | 91179    |\n",
      "----------------------------------\n",
      "Episode reward: 78.517859\n",
      "Episode reward: 65.830404\n",
      "Episode reward: 37.942954\n",
      "Episode reward: 59.706848\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6856     |\n",
      "|    fps              | 3121     |\n",
      "|    time_elapsed     | 116      |\n",
      "|    total_timesteps  | 365060   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 91239    |\n",
      "----------------------------------\n",
      "Episode reward: 46.883994\n",
      "Episode reward: 85.328295\n",
      "Episode reward: 37.751989\n",
      "Episode reward: 108.533221\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6860     |\n",
      "|    fps              | 3121     |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 365340   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00747  |\n",
      "|    n_updates        | 91309    |\n",
      "----------------------------------\n",
      "Episode reward: 62.562299\n",
      "Episode reward: 44.919963\n",
      "Episode reward: 47.909777\n",
      "Episode reward: 91.47786\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6864     |\n",
      "|    fps              | 3120     |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 365588   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00858  |\n",
      "|    n_updates        | 91371    |\n",
      "----------------------------------\n",
      "Episode reward: 35.93266\n",
      "Episode reward: 57.656607\n",
      "Episode reward: 49.921794\n",
      "Episode reward: 42.805068\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6868     |\n",
      "|    fps              | 3120     |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 365775   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 91418    |\n",
      "----------------------------------\n",
      "Episode reward: 36.754263\n",
      "Episode reward: 41.869974\n",
      "Episode reward: 85.06441\n",
      "Episode reward: 63.067364\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6872     |\n",
      "|    fps              | 3120     |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 366005   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 91476    |\n",
      "----------------------------------\n",
      "Episode reward: 54.356899\n",
      "Episode reward: 31.947211\n",
      "Episode reward: 67.76461\n",
      "Episode reward: 63.562877\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6876     |\n",
      "|    fps              | 3119     |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 366224   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00845  |\n",
      "|    n_updates        | 91530    |\n",
      "----------------------------------\n",
      "Episode reward: 108.969638\n",
      "Episode reward: 52.899773\n",
      "Episode reward: 40.754388\n",
      "Episode reward: 63.861923\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6880     |\n",
      "|    fps              | 3119     |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 366498   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.352    |\n",
      "|    n_updates        | 91599    |\n",
      "----------------------------------\n",
      "Episode reward: 56.646569\n",
      "Episode reward: 32.945844\n",
      "Episode reward: 53.655993\n",
      "Episode reward: 62.804403\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6884     |\n",
      "|    fps              | 3120     |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 366705   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00828  |\n",
      "|    n_updates        | 91651    |\n",
      "----------------------------------\n",
      "Episode reward: 34.643263\n",
      "Episode reward: 90.839756\n",
      "Episode reward: 68.897653\n",
      "Episode reward: 43.950204\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6888     |\n",
      "|    fps              | 3119     |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 366950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0065   |\n",
      "|    n_updates        | 91712    |\n",
      "----------------------------------\n",
      "Episode reward: 43.679193\n",
      "Episode reward: 61.906916\n",
      "Episode reward: 48.914995\n",
      "Episode reward: 42.605654\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6892     |\n",
      "|    fps              | 3119     |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 367148   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00544  |\n",
      "|    n_updates        | 91761    |\n",
      "----------------------------------\n",
      "Episode reward: 42.861104\n",
      "Episode reward: 47.852877\n",
      "Episode reward: 72.663619\n",
      "Episode reward: 47.941821\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6896     |\n",
      "|    fps              | 3118     |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 367360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0311   |\n",
      "|    n_updates        | 91814    |\n",
      "----------------------------------\n",
      "Episode reward: 43.89904\n",
      "Episode reward: 49.920236\n",
      "Episode reward: 77.22934\n",
      "Episode reward: 54.745026\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6900     |\n",
      "|    fps              | 3118     |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 367587   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0203   |\n",
      "|    n_updates        | 91871    |\n",
      "----------------------------------\n",
      "Episode reward: 34.59153\n",
      "Episode reward: 55.479003\n",
      "Episode reward: 81.119666\n",
      "Episode reward: 89.795905\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6904     |\n",
      "|    fps              | 3117     |\n",
      "|    time_elapsed     | 117      |\n",
      "|    total_timesteps  | 367851   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0184   |\n",
      "|    n_updates        | 91937    |\n",
      "----------------------------------\n",
      "Episode reward: 37.929219\n",
      "Episode reward: 95.990592\n",
      "Episode reward: 53.60735\n",
      "Episode reward: 51.833755\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6908     |\n",
      "|    fps              | 3117     |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 368093   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.443    |\n",
      "|    n_updates        | 91998    |\n",
      "----------------------------------\n",
      "Episode reward: 64.850301\n",
      "Episode reward: 42.918259\n",
      "Episode reward: 79.735052\n",
      "Episode reward: 63.842081\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6912     |\n",
      "|    fps              | 3117     |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 368345   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 92061    |\n",
      "----------------------------------\n",
      "Episode reward: 58.761376\n",
      "Episode reward: 31.947897\n",
      "Episode reward: 76.349115\n",
      "Episode reward: 67.64893\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6916     |\n",
      "|    fps              | 3117     |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 368583   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.312    |\n",
      "|    n_updates        | 92120    |\n",
      "----------------------------------\n",
      "Episode reward: 52.886569\n",
      "Episode reward: 77.813714\n",
      "Episode reward: 53.879349\n",
      "Episode reward: 52.903302\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6920     |\n",
      "|    fps              | 3116     |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 368821   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.274    |\n",
      "|    n_updates        | 92180    |\n",
      "----------------------------------\n",
      "Episode reward: 47.819364\n",
      "Episode reward: 115.465564\n",
      "Episode reward: 42.774141\n",
      "Episode reward: 65.361663\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6924     |\n",
      "|    fps              | 3116     |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 369100   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00384  |\n",
      "|    n_updates        | 92249    |\n",
      "----------------------------------\n",
      "Episode reward: 85.615292\n",
      "Episode reward: 55.883485\n",
      "Episode reward: 69.828585\n",
      "Episode reward: 80.606397\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6928     |\n",
      "|    fps              | 3116     |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 369398   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 92324    |\n",
      "----------------------------------\n",
      "Episode reward: 61.872938\n",
      "Episode reward: 54.898054\n",
      "Episode reward: 50.932534\n",
      "Episode reward: 33.95453\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6932     |\n",
      "|    fps              | 3116     |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 369600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00505  |\n",
      "|    n_updates        | 92374    |\n",
      "----------------------------------\n",
      "Episode reward: 45.856419\n",
      "Episode reward: 49.692103\n",
      "Episode reward: 89.742448\n",
      "Episode reward: 66.875471\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6936     |\n",
      "|    fps              | 3116     |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 369853   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.232    |\n",
      "|    n_updates        | 92438    |\n",
      "----------------------------------\n",
      "Episode reward: 47.843317\n",
      "Episode reward: 69.566548\n",
      "Episode reward: 43.486925\n",
      "Episode reward: 38.938979\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6940     |\n",
      "|    fps              | 3115     |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 370054   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.245    |\n",
      "|    n_updates        | 92488    |\n",
      "----------------------------------\n",
      "Episode reward: 33.94537\n",
      "Episode reward: 34.780244\n",
      "Episode reward: 45.382647\n",
      "Episode reward: 65.111811\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6944     |\n",
      "|    fps              | 3115     |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 370235   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0228   |\n",
      "|    n_updates        | 92533    |\n",
      "----------------------------------\n",
      "Episode reward: 99.959628\n",
      "Episode reward: 35.865255\n",
      "Episode reward: 62.829535\n",
      "Episode reward: 41.895032\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6948     |\n",
      "|    fps              | 3115     |\n",
      "|    time_elapsed     | 118      |\n",
      "|    total_timesteps  | 370479   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00776  |\n",
      "|    n_updates        | 92594    |\n",
      "----------------------------------\n",
      "Episode reward: 68.645882\n",
      "Episode reward: 54.927283\n",
      "Episode reward: 41.888227\n",
      "Episode reward: 62.842602\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6952     |\n",
      "|    fps              | 3115     |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 370708   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0272   |\n",
      "|    n_updates        | 92651    |\n",
      "----------------------------------\n",
      "Episode reward: 40.888393\n",
      "Episode reward: 56.781876\n",
      "Episode reward: 41.846\n",
      "Episode reward: 57.897484\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6956     |\n",
      "|    fps              | 3114     |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 370906   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 92701    |\n",
      "----------------------------------\n",
      "Episode reward: 61.643562\n",
      "Episode reward: 82.76094\n",
      "Episode reward: 59.931763\n",
      "Episode reward: 44.89526\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6960     |\n",
      "|    fps              | 3113     |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 371157   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.274    |\n",
      "|    n_updates        | 92764    |\n",
      "----------------------------------\n",
      "Episode reward: 49.909207\n",
      "Episode reward: 52.763234\n",
      "Episode reward: 62.715355\n",
      "Episode reward: 37.676048\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6964     |\n",
      "|    fps              | 3113     |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 371361   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0193   |\n",
      "|    n_updates        | 92815    |\n",
      "----------------------------------\n",
      "Episode reward: 41.812846\n",
      "Episode reward: 40.926209\n",
      "Episode reward: 52.76444\n",
      "Episode reward: 63.837039\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6968     |\n",
      "|    fps              | 3113     |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 371561   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.222    |\n",
      "|    n_updates        | 92865    |\n",
      "----------------------------------\n",
      "Episode reward: 49.389622\n",
      "Episode reward: 40.938609\n",
      "Episode reward: 76.222427\n",
      "Episode reward: 63.83619\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6972     |\n",
      "|    fps              | 3113     |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 371796   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0364   |\n",
      "|    n_updates        | 92923    |\n",
      "----------------------------------\n",
      "Episode reward: 43.946667\n",
      "Episode reward: 92.239006\n",
      "Episode reward: 39.919177\n",
      "Episode reward: 59.510741\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6976     |\n",
      "|    fps              | 3112     |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 372033   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.215    |\n",
      "|    n_updates        | 92983    |\n",
      "----------------------------------\n",
      "Episode reward: 47.717174\n",
      "Episode reward: 75.770412\n",
      "Episode reward: 50.929177\n",
      "Episode reward: 62.824593\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6980     |\n",
      "|    fps              | 3112     |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 372271   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.317    |\n",
      "|    n_updates        | 93042    |\n",
      "----------------------------------\n",
      "Episode reward: 56.890871\n",
      "Episode reward: 36.724225\n",
      "Episode reward: 71.801114\n",
      "Episode reward: 57.455167\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6984     |\n",
      "|    fps              | 3112     |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 372495   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 93098    |\n",
      "----------------------------------\n",
      "Episode reward: 83.441481\n",
      "Episode reward: 39.940993\n",
      "Episode reward: 41.943555\n",
      "Episode reward: 47.789226\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6988     |\n",
      "|    fps              | 3112     |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 372710   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.179    |\n",
      "|    n_updates        | 93152    |\n",
      "----------------------------------\n",
      "Episode reward: 105.318875\n",
      "Episode reward: 40.862564\n",
      "Episode reward: 39.861064\n",
      "Episode reward: 36.945162\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6992     |\n",
      "|    fps              | 3112     |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 372934   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00759  |\n",
      "|    n_updates        | 93208    |\n",
      "----------------------------------\n",
      "Episode reward: 55.914272\n",
      "Episode reward: 62.791611\n",
      "Episode reward: 54.670213\n",
      "Episode reward: 60.820657\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 6996     |\n",
      "|    fps              | 3111     |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 373169   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00445  |\n",
      "|    n_updates        | 93267    |\n",
      "----------------------------------\n",
      "Episode reward: 67.111816\n",
      "Episode reward: 44.815788\n",
      "Episode reward: 36.938456\n",
      "Episode reward: 36.865465\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7000     |\n",
      "|    fps              | 3111     |\n",
      "|    time_elapsed     | 119      |\n",
      "|    total_timesteps  | 373359   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.473    |\n",
      "|    n_updates        | 93314    |\n",
      "----------------------------------\n",
      "Episode reward: 45.932184\n",
      "Episode reward: 43.854685\n",
      "Episode reward: 64.862642\n",
      "Episode reward: 48.729231\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7004     |\n",
      "|    fps              | 3111     |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 373563   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00902  |\n",
      "|    n_updates        | 93365    |\n",
      "----------------------------------\n",
      "Episode reward: 36.884568\n",
      "Episode reward: 59.239175\n",
      "Episode reward: 55.891585\n",
      "Episode reward: 77.740878\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7008     |\n",
      "|    fps              | 3111     |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 373794   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0207   |\n",
      "|    n_updates        | 93423    |\n",
      "----------------------------------\n",
      "Episode reward: 47.894059\n",
      "Episode reward: 51.804744\n",
      "Episode reward: 53.832589\n",
      "Episode reward: 47.897848\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7012     |\n",
      "|    fps              | 3111     |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 373996   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.26     |\n",
      "|    n_updates        | 93473    |\n",
      "----------------------------------\n",
      "Episode reward: 45.857769\n",
      "Episode reward: 53.546218\n",
      "Episode reward: 44.878123\n",
      "Episode reward: 82.343532\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7016     |\n",
      "|    fps              | 3111     |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 374225   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.276    |\n",
      "|    n_updates        | 93531    |\n",
      "----------------------------------\n",
      "Episode reward: 47.918962\n",
      "Episode reward: 65.502762\n",
      "Episode reward: 82.906845\n",
      "Episode reward: 62.900896\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7020     |\n",
      "|    fps              | 3110     |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 374491   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 93597    |\n",
      "----------------------------------\n",
      "Episode reward: 55.685443\n",
      "Episode reward: 55.795871\n",
      "Episode reward: 58.862899\n",
      "Episode reward: 77.888578\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7024     |\n",
      "|    fps              | 3110     |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 374743   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0281   |\n",
      "|    n_updates        | 93660    |\n",
      "----------------------------------\n",
      "Episode reward: 59.840755\n",
      "Episode reward: 58.608167\n",
      "Episode reward: 46.919684\n",
      "Episode reward: 89.379492\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7028     |\n",
      "|    fps              | 3109     |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 374999   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0082   |\n",
      "|    n_updates        | 93724    |\n",
      "----------------------------------\n",
      "Episode reward: 72.841854\n",
      "Episode reward: 68.753449\n",
      "Episode reward: 82.745857\n",
      "Episode reward: 125.912083\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7032     |\n",
      "|    fps              | 3109     |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 375360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.251    |\n",
      "|    n_updates        | 93814    |\n",
      "----------------------------------\n",
      "Episode reward: 52.872784\n",
      "Episode reward: 86.491643\n",
      "Episode reward: 109.855017\n",
      "Episode reward: 53.68378\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7036     |\n",
      "|    fps              | 3108     |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 375666   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 93891    |\n",
      "----------------------------------\n",
      "Episode reward: 53.871001\n",
      "Episode reward: 61.638346\n",
      "Episode reward: 50.747141\n",
      "Episode reward: 49.859695\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7040     |\n",
      "|    fps              | 3108     |\n",
      "|    time_elapsed     | 120      |\n",
      "|    total_timesteps  | 375883   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.216    |\n",
      "|    n_updates        | 93945    |\n",
      "----------------------------------\n",
      "Episode reward: 70.77768\n",
      "Episode reward: 113.505497\n",
      "Episode reward: 54.687185\n",
      "Episode reward: 62.127925\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7044     |\n",
      "|    fps              | 3108     |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 376197   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.68     |\n",
      "|    n_updates        | 94024    |\n",
      "----------------------------------\n",
      "Episode reward: 51.919034\n",
      "Episode reward: 80.360427\n",
      "Episode reward: 79.555142\n",
      "Episode reward: 46.695556\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7048     |\n",
      "|    fps              | 3107     |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 376460   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00798  |\n",
      "|    n_updates        | 94089    |\n",
      "----------------------------------\n",
      "Episode reward: 62.906722\n",
      "Episode reward: 40.920022\n",
      "Episode reward: 58.777346\n",
      "Episode reward: 37.82803\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7052     |\n",
      "|    fps              | 3107     |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 376663   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.903    |\n",
      "|    n_updates        | 94140    |\n",
      "----------------------------------\n",
      "Episode reward: 39.857175\n",
      "Episode reward: 42.477159\n",
      "Episode reward: 42.904854\n",
      "Episode reward: 55.859957\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7056     |\n",
      "|    fps              | 3107     |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 376845   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.224    |\n",
      "|    n_updates        | 94186    |\n",
      "----------------------------------\n",
      "Episode reward: 55.852974\n",
      "Episode reward: 45.925983\n",
      "Episode reward: 56.760517\n",
      "Episode reward: 40.94105\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7060     |\n",
      "|    fps              | 3107     |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 377045   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 94236    |\n",
      "----------------------------------\n",
      "Episode reward: 56.553643\n",
      "Episode reward: 41.867734\n",
      "Episode reward: 41.944597\n",
      "Episode reward: 41.890195\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7064     |\n",
      "|    fps              | 3106     |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 377228   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.269    |\n",
      "|    n_updates        | 94281    |\n",
      "----------------------------------\n",
      "Episode reward: 51.846657\n",
      "Episode reward: 40.847463\n",
      "Episode reward: 35.836138\n",
      "Episode reward: 45.751605\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7068     |\n",
      "|    fps              | 3106     |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 377403   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 94325    |\n",
      "----------------------------------\n",
      "Episode reward: 44.932452\n",
      "Episode reward: 44.670721\n",
      "Episode reward: 68.789429\n",
      "Episode reward: 58.796383\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7072     |\n",
      "|    fps              | 3106     |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 377621   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.275    |\n",
      "|    n_updates        | 94380    |\n",
      "----------------------------------\n",
      "Episode reward: 66.807095\n",
      "Episode reward: 68.584053\n",
      "Episode reward: 71.634542\n",
      "Episode reward: 47.732555\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7076     |\n",
      "|    fps              | 3106     |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 377877   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 94444    |\n",
      "----------------------------------\n",
      "Episode reward: 42.920691\n",
      "Episode reward: 47.930394\n",
      "Episode reward: 54.67481\n",
      "Episode reward: 48.884633\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7080     |\n",
      "|    fps              | 3106     |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 378072   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 94492    |\n",
      "----------------------------------\n",
      "Episode reward: 95.685927\n",
      "Episode reward: 102.689352\n",
      "Episode reward: 44.697529\n",
      "Episode reward: 51.923778\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7084     |\n",
      "|    fps              | 3105     |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 378370   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0313   |\n",
      "|    n_updates        | 94567    |\n",
      "----------------------------------\n",
      "Episode reward: 56.370253\n",
      "Episode reward: 52.812176\n",
      "Episode reward: 65.558361\n",
      "Episode reward: 50.855889\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7088     |\n",
      "|    fps              | 3105     |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 378597   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00651  |\n",
      "|    n_updates        | 94624    |\n",
      "----------------------------------\n",
      "Episode reward: 69.11252\n",
      "Episode reward: 79.767265\n",
      "Episode reward: 73.608436\n",
      "Episode reward: 52.684037\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7092     |\n",
      "|    fps              | 3104     |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total_timesteps  | 378875   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 94693    |\n",
      "----------------------------------\n",
      "Episode reward: 73.190245\n",
      "Episode reward: 78.744663\n",
      "Episode reward: 73.287727\n",
      "Episode reward: 39.753726\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7096     |\n",
      "|    fps              | 3103     |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total_timesteps  | 379142   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0339   |\n",
      "|    n_updates        | 94760    |\n",
      "----------------------------------\n",
      "Episode reward: 56.550746\n",
      "Episode reward: 49.837691\n",
      "Episode reward: 60.895323\n",
      "Episode reward: 64.687116\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7100     |\n",
      "|    fps              | 3103     |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total_timesteps  | 379376   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 94818    |\n",
      "----------------------------------\n",
      "Episode reward: 69.55704\n",
      "Episode reward: 42.947896\n",
      "Episode reward: 62.827825\n",
      "Episode reward: 37.829946\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7104     |\n",
      "|    fps              | 3102     |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total_timesteps  | 379590   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00777  |\n",
      "|    n_updates        | 94872    |\n",
      "----------------------------------\n",
      "Episode reward: 46.899909\n",
      "Episode reward: 76.223864\n",
      "Episode reward: 51.796055\n",
      "Episode reward: 43.858294\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7108     |\n",
      "|    fps              | 3101     |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total_timesteps  | 379810   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.191    |\n",
      "|    n_updates        | 94927    |\n",
      "----------------------------------\n",
      "Episode reward: 64.861252\n",
      "Episode reward: 35.948341\n",
      "Episode reward: 40.927718\n",
      "Episode reward: 64.625924\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7112     |\n",
      "|    fps              | 3101     |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total_timesteps  | 380017   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.142    |\n",
      "|    n_updates        | 94979    |\n",
      "----------------------------------\n",
      "Episode reward: 69.917464\n",
      "Episode reward: 46.906903\n",
      "Episode reward: 53.742046\n",
      "Episode reward: 41.920898\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7116     |\n",
      "|    fps              | 3100     |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total_timesteps  | 380230   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0202   |\n",
      "|    n_updates        | 95032    |\n",
      "----------------------------------\n",
      "Episode reward: 51.924795\n",
      "Episode reward: 43.912926\n",
      "Episode reward: 78.775938\n",
      "Episode reward: 67.998547\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7120     |\n",
      "|    fps              | 3099     |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total_timesteps  | 380477   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0376   |\n",
      "|    n_updates        | 95094    |\n",
      "----------------------------------\n",
      "Episode reward: 54.853674\n",
      "Episode reward: 51.752956\n",
      "Episode reward: 50.892954\n",
      "Episode reward: 110.397329\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7124     |\n",
      "|    fps              | 3099     |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total_timesteps  | 380747   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.595    |\n",
      "|    n_updates        | 95161    |\n",
      "----------------------------------\n",
      "Episode reward: 54.665479\n",
      "Episode reward: 93.607657\n",
      "Episode reward: 46.887901\n",
      "Episode reward: 36.940285\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7128     |\n",
      "|    fps              | 3098     |\n",
      "|    time_elapsed     | 122      |\n",
      "|    total_timesteps  | 380980   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 95219    |\n",
      "----------------------------------\n",
      "Episode reward: 95.2248\n",
      "Episode reward: 37.635006\n",
      "Episode reward: 47.723166\n",
      "Episode reward: 64.314262\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7132     |\n",
      "|    fps              | 3096     |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 381227   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.172    |\n",
      "|    n_updates        | 95281    |\n",
      "----------------------------------\n",
      "Episode reward: 62.864614\n",
      "Episode reward: 56.596441\n",
      "Episode reward: 33.921543\n",
      "Episode reward: 38.771152\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7136     |\n",
      "|    fps              | 3097     |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 381421   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.452    |\n",
      "|    n_updates        | 95330    |\n",
      "----------------------------------\n",
      "Episode reward: 44.496025\n",
      "Episode reward: 46.874119\n",
      "Episode reward: 55.815265\n",
      "Episode reward: 59.887387\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7140     |\n",
      "|    fps              | 3097     |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 381629   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.59     |\n",
      "|    n_updates        | 95382    |\n",
      "----------------------------------\n",
      "Episode reward: 48.918844\n",
      "Episode reward: 63.185015\n",
      "Episode reward: 53.73834\n",
      "Episode reward: 55.915938\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7144     |\n",
      "|    fps              | 3097     |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 381852   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0571   |\n",
      "|    n_updates        | 95437    |\n",
      "----------------------------------\n",
      "Episode reward: 62.43414\n",
      "Episode reward: 85.715118\n",
      "Episode reward: 52.919031\n",
      "Episode reward: 44.863919\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7148     |\n",
      "|    fps              | 3097     |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 382099   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.321    |\n",
      "|    n_updates        | 95499    |\n",
      "----------------------------------\n",
      "Episode reward: 65.839411\n",
      "Episode reward: 55.903016\n",
      "Episode reward: 43.896889\n",
      "Episode reward: 42.863612\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7152     |\n",
      "|    fps              | 3096     |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 382308   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 95551    |\n",
      "----------------------------------\n",
      "Episode reward: 72.799222\n",
      "Episode reward: 66.014552\n",
      "Episode reward: 53.904775\n",
      "Episode reward: 118.268116\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7156     |\n",
      "|    fps              | 3096     |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 382635   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.326    |\n",
      "|    n_updates        | 95633    |\n",
      "----------------------------------\n",
      "Episode reward: 45.810416\n",
      "Episode reward: 32.942465\n",
      "Episode reward: 62.768496\n",
      "Episode reward: 73.210456\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7160     |\n",
      "|    fps              | 3096     |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 382851   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.131    |\n",
      "|    n_updates        | 95687    |\n",
      "----------------------------------\n",
      "Episode reward: 72.764438\n",
      "Episode reward: 83.375038\n",
      "Episode reward: 49.812673\n",
      "Episode reward: 59.855622\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7164     |\n",
      "|    fps              | 3096     |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 383118   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.496    |\n",
      "|    n_updates        | 95754    |\n",
      "----------------------------------\n",
      "Episode reward: 69.444687\n",
      "Episode reward: 84.762534\n",
      "Episode reward: 76.870054\n",
      "Episode reward: 41.915071\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7168     |\n",
      "|    fps              | 3096     |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 383395   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.325    |\n",
      "|    n_updates        | 95823    |\n",
      "----------------------------------\n",
      "Episode reward: 41.942489\n",
      "Episode reward: 48.757267\n",
      "Episode reward: 53.882538\n",
      "Episode reward: 106.922494\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7172     |\n",
      "|    fps              | 3095     |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 383651   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 95887    |\n",
      "----------------------------------\n",
      "Episode reward: 56.883168\n",
      "Episode reward: 37.892899\n",
      "Episode reward: 57.255248\n",
      "Episode reward: 80.664018\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7176     |\n",
      "|    fps              | 3094     |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 383885   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.339    |\n",
      "|    n_updates        | 95946    |\n",
      "----------------------------------\n",
      "Episode reward: 63.889105\n",
      "Episode reward: 39.94599\n",
      "Episode reward: 55.797409\n",
      "Episode reward: 35.855956\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7180     |\n",
      "|    fps              | 3094     |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 384081   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00814  |\n",
      "|    n_updates        | 95995    |\n",
      "----------------------------------\n",
      "Episode reward: 52.832035\n",
      "Episode reward: 97.706265\n",
      "Episode reward: 59.645147\n",
      "Episode reward: 47.90709\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7184     |\n",
      "|    fps              | 3094     |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 384342   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.344    |\n",
      "|    n_updates        | 96060    |\n",
      "----------------------------------\n",
      "Episode reward: 53.63548\n",
      "Episode reward: 87.733216\n",
      "Episode reward: 82.641446\n",
      "Episode reward: 48.55723\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7188     |\n",
      "|    fps              | 3094     |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 384616   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 96128    |\n",
      "----------------------------------\n",
      "Episode reward: 52.235446\n",
      "Episode reward: 61.649207\n",
      "Episode reward: 54.848969\n",
      "Episode reward: 87.658634\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7192     |\n",
      "|    fps              | 3094     |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 384874   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00889  |\n",
      "|    n_updates        | 96193    |\n",
      "----------------------------------\n",
      "Episode reward: 56.988084\n",
      "Episode reward: 62.860365\n",
      "Episode reward: 68.736663\n",
      "Episode reward: 50.906263\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7196     |\n",
      "|    fps              | 3094     |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 385115   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.347    |\n",
      "|    n_updates        | 96253    |\n",
      "----------------------------------\n",
      "Episode reward: 49.764786\n",
      "Episode reward: 66.675294\n",
      "Episode reward: 89.183477\n",
      "Episode reward: 47.899794\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7200     |\n",
      "|    fps              | 3093     |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 385370   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.581    |\n",
      "|    n_updates        | 96317    |\n",
      "----------------------------------\n",
      "Episode reward: 38.852619\n",
      "Episode reward: 72.434017\n",
      "Episode reward: 45.853205\n",
      "Episode reward: 50.928281\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7204     |\n",
      "|    fps              | 3093     |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 385581   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00694  |\n",
      "|    n_updates        | 96370    |\n",
      "----------------------------------\n",
      "Episode reward: 37.705187\n",
      "Episode reward: 45.848532\n",
      "Episode reward: 50.885853\n",
      "Episode reward: 59.731106\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7208     |\n",
      "|    fps              | 3093     |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 385776   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.181    |\n",
      "|    n_updates        | 96418    |\n",
      "----------------------------------\n",
      "Episode reward: 49.736011\n",
      "Episode reward: 51.466712\n",
      "Episode reward: 58.489124\n",
      "Episode reward: 101.373\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7212     |\n",
      "|    fps              | 3092     |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 386042   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 96485    |\n",
      "----------------------------------\n",
      "Episode reward: 77.629666\n",
      "Episode reward: 69.761369\n",
      "Episode reward: 81.632953\n",
      "Episode reward: 49.885811\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7216     |\n",
      "|    fps              | 3092     |\n",
      "|    time_elapsed     | 124      |\n",
      "|    total_timesteps  | 386323   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.256    |\n",
      "|    n_updates        | 96555    |\n",
      "----------------------------------\n",
      "Episode reward: 57.632072\n",
      "Episode reward: 39.955625\n",
      "Episode reward: 59.837343\n",
      "Episode reward: 42.829282\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7220     |\n",
      "|    fps              | 3092     |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total_timesteps  | 386524   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.091    |\n",
      "|    n_updates        | 96605    |\n",
      "----------------------------------\n",
      "Episode reward: 46.889224\n",
      "Episode reward: 49.800576\n",
      "Episode reward: 65.85662\n",
      "Episode reward: 66.787818\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7224     |\n",
      "|    fps              | 3091     |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total_timesteps  | 386754   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.302    |\n",
      "|    n_updates        | 96663    |\n",
      "----------------------------------\n",
      "Episode reward: 53.908949\n",
      "Episode reward: 42.911536\n",
      "Episode reward: 81.26848\n",
      "Episode reward: 45.930443\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7228     |\n",
      "|    fps              | 3091     |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total_timesteps  | 386981   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.324    |\n",
      "|    n_updates        | 96720    |\n",
      "----------------------------------\n",
      "Episode reward: 78.481251\n",
      "Episode reward: 98.496001\n",
      "Episode reward: 43.938325\n",
      "Episode reward: 60.223757\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7232     |\n",
      "|    fps              | 3091     |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total_timesteps  | 387266   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.223    |\n",
      "|    n_updates        | 96791    |\n",
      "----------------------------------\n",
      "Episode reward: 58.222242\n",
      "Episode reward: 49.707229\n",
      "Episode reward: 35.837372\n",
      "Episode reward: 77.451837\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7236     |\n",
      "|    fps              | 3090     |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total_timesteps  | 387490   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.821    |\n",
      "|    n_updates        | 96847    |\n",
      "----------------------------------\n",
      "Episode reward: 43.845138\n",
      "Episode reward: 67.827674\n",
      "Episode reward: 65.706743\n",
      "Episode reward: 73.020741\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7240     |\n",
      "|    fps              | 3089     |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total_timesteps  | 387743   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.36     |\n",
      "|    n_updates        | 96910    |\n",
      "----------------------------------\n",
      "Episode reward: 54.676979\n",
      "Episode reward: 84.521887\n",
      "Episode reward: 43.937111\n",
      "Episode reward: 90.622399\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7244     |\n",
      "|    fps              | 3089     |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total_timesteps  | 388020   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00376  |\n",
      "|    n_updates        | 96979    |\n",
      "----------------------------------\n",
      "Episode reward: 50.162677\n",
      "Episode reward: 64.827096\n",
      "Episode reward: 59.87071\n",
      "Episode reward: 60.810697\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7248     |\n",
      "|    fps              | 3089     |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total_timesteps  | 388257   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 97039    |\n",
      "----------------------------------\n",
      "Episode reward: 43.920522\n",
      "Episode reward: 44.895887\n",
      "Episode reward: 57.659924\n",
      "Episode reward: 86.798164\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7252     |\n",
      "|    fps              | 3088     |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total_timesteps  | 388491   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 97097    |\n",
      "----------------------------------\n",
      "Episode reward: 48.751547\n",
      "Episode reward: 58.87806\n",
      "Episode reward: 97.851803\n",
      "Episode reward: 48.620457\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7256     |\n",
      "|    fps              | 3088     |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total_timesteps  | 388748   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.247    |\n",
      "|    n_updates        | 97161    |\n",
      "----------------------------------\n",
      "Episode reward: 61.463336\n",
      "Episode reward: 90.603865\n",
      "Episode reward: 40.90983\n",
      "Episode reward: 81.700652\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7260     |\n",
      "|    fps              | 3088     |\n",
      "|    time_elapsed     | 125      |\n",
      "|    total_timesteps  | 389024   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 97230    |\n",
      "----------------------------------\n",
      "Episode reward: 57.086506\n",
      "Episode reward: 68.742226\n",
      "Episode reward: 46.561934\n",
      "Episode reward: 54.461873\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7264     |\n",
      "|    fps              | 3089     |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 389256   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.018    |\n",
      "|    n_updates        | 97288    |\n",
      "----------------------------------\n",
      "Episode reward: 58.889181\n",
      "Episode reward: 61.81227\n",
      "Episode reward: 42.861502\n",
      "Episode reward: 70.342881\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7268     |\n",
      "|    fps              | 3089     |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 389491   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.25     |\n",
      "|    n_updates        | 97347    |\n",
      "----------------------------------\n",
      "Episode reward: 75.016959\n",
      "Episode reward: 37.745998\n",
      "Episode reward: 54.870552\n",
      "Episode reward: 60.501335\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7272     |\n",
      "|    fps              | 3089     |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 389721   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 97405    |\n",
      "----------------------------------\n",
      "Episode reward: 42.92978\n",
      "Episode reward: 59.670961\n",
      "Episode reward: 45.797135\n",
      "Episode reward: 55.91386\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7276     |\n",
      "|    fps              | 3089     |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 389927   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.379    |\n",
      "|    n_updates        | 97456    |\n",
      "----------------------------------\n",
      "Episode reward: 53.887623\n",
      "Episode reward: 47.528723\n",
      "Episode reward: 44.879701\n",
      "Episode reward: 46.582778\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7280     |\n",
      "|    fps              | 3089     |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 390121   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.521    |\n",
      "|    n_updates        | 97505    |\n",
      "----------------------------------\n",
      "Episode reward: 63.876703\n",
      "Episode reward: 90.873319\n",
      "Episode reward: 50.790603\n",
      "Episode reward: 48.894825\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7284     |\n",
      "|    fps              | 3088     |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 390377   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0184   |\n",
      "|    n_updates        | 97569    |\n",
      "----------------------------------\n",
      "Episode reward: 64.653651\n",
      "Episode reward: 73.551403\n",
      "Episode reward: 33.887282\n",
      "Episode reward: 51.885019\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7288     |\n",
      "|    fps              | 3088     |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 390603   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.258    |\n",
      "|    n_updates        | 97625    |\n",
      "----------------------------------\n",
      "Episode reward: 48.920892\n",
      "Episode reward: 47.767614\n",
      "Episode reward: 42.887759\n",
      "Episode reward: 111.351926\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7292     |\n",
      "|    fps              | 3088     |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 390865   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00967  |\n",
      "|    n_updates        | 97691    |\n",
      "----------------------------------\n",
      "Episode reward: 32.931553\n",
      "Episode reward: 38.921417\n",
      "Episode reward: 74.235099\n",
      "Episode reward: 42.916194\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7296     |\n",
      "|    fps              | 3088     |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 391057   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00954  |\n",
      "|    n_updates        | 97739    |\n",
      "----------------------------------\n",
      "Episode reward: 55.777018\n",
      "Episode reward: 53.884294\n",
      "Episode reward: 98.14865\n",
      "Episode reward: 60.654962\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7300     |\n",
      "|    fps              | 3088     |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 391338   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.209    |\n",
      "|    n_updates        | 97809    |\n",
      "----------------------------------\n",
      "Episode reward: 68.326911\n",
      "Episode reward: 57.750642\n",
      "Episode reward: 53.829114\n",
      "Episode reward: 45.721662\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7304     |\n",
      "|    fps              | 3088     |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 391565   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.282    |\n",
      "|    n_updates        | 97866    |\n",
      "----------------------------------\n",
      "Episode reward: 46.794681\n",
      "Episode reward: 50.913517\n",
      "Episode reward: 54.788626\n",
      "Episode reward: 40.927692\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7308     |\n",
      "|    fps              | 3088     |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 391759   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 97914    |\n",
      "----------------------------------\n",
      "Episode reward: 58.315264\n",
      "Episode reward: 77.749128\n",
      "Episode reward: 92.876228\n",
      "Episode reward: 48.880243\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7312     |\n",
      "|    fps              | 3087     |\n",
      "|    time_elapsed     | 126      |\n",
      "|    total_timesteps  | 392043   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0196   |\n",
      "|    n_updates        | 97985    |\n",
      "----------------------------------\n",
      "Episode reward: 53.853795\n",
      "Episode reward: 71.703931\n",
      "Episode reward: 33.73278\n",
      "Episode reward: 60.870562\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7316     |\n",
      "|    fps              | 3087     |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 392264   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 98040    |\n",
      "----------------------------------\n",
      "Episode reward: 36.949099\n",
      "Episode reward: 75.970319\n",
      "Episode reward: 46.475569\n",
      "Episode reward: 46.870648\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7320     |\n",
      "|    fps              | 3087     |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 392472   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0377   |\n",
      "|    n_updates        | 98092    |\n",
      "----------------------------------\n",
      "Episode reward: 40.621146\n",
      "Episode reward: 82.561239\n",
      "Episode reward: 44.779016\n",
      "Episode reward: 82.340897\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7324     |\n",
      "|    fps              | 3087     |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 392725   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 98156    |\n",
      "----------------------------------\n",
      "Episode reward: 52.628323\n",
      "Episode reward: 54.800224\n",
      "Episode reward: 44.879132\n",
      "Episode reward: 51.743972\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7328     |\n",
      "|    fps              | 3086     |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 392930   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.263    |\n",
      "|    n_updates        | 98207    |\n",
      "----------------------------------\n",
      "Episode reward: 79.208925\n",
      "Episode reward: 44.937327\n",
      "Episode reward: 95.594508\n",
      "Episode reward: 61.5978\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7332     |\n",
      "|    fps              | 3085     |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 393222   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 98280    |\n",
      "----------------------------------\n",
      "Episode reward: 80.034966\n",
      "Episode reward: 50.903987\n",
      "Episode reward: 39.929991\n",
      "Episode reward: 43.915394\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7336     |\n",
      "|    fps              | 3085     |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 393438   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.506    |\n",
      "|    n_updates        | 98334    |\n",
      "----------------------------------\n",
      "Episode reward: 49.888601\n",
      "Episode reward: 65.348804\n",
      "Episode reward: 52.888456\n",
      "Episode reward: 78.047659\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7340     |\n",
      "|    fps              | 3085     |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 393687   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00887  |\n",
      "|    n_updates        | 98396    |\n",
      "----------------------------------\n",
      "Episode reward: 59.910019\n",
      "Episode reward: 50.820393\n",
      "Episode reward: 65.335683\n",
      "Episode reward: 36.915814\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7344     |\n",
      "|    fps              | 3085     |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 393901   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 98450    |\n",
      "----------------------------------\n",
      "Episode reward: 53.728474\n",
      "Episode reward: 34.853247\n",
      "Episode reward: 64.918338\n",
      "Episode reward: 63.356067\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7348     |\n",
      "|    fps              | 3084     |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 394121   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 98505    |\n",
      "----------------------------------\n",
      "Episode reward: 109.937574\n",
      "Episode reward: 42.92972\n",
      "Episode reward: 66.766076\n",
      "Episode reward: 58.456354\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7352     |\n",
      "|    fps              | 3084     |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 394401   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00505  |\n",
      "|    n_updates        | 98575    |\n",
      "----------------------------------\n",
      "Episode reward: 36.938765\n",
      "Episode reward: 53.807163\n",
      "Episode reward: 87.685562\n",
      "Episode reward: 52.97245\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7356     |\n",
      "|    fps              | 3084     |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 394635   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.416    |\n",
      "|    n_updates        | 98633    |\n",
      "----------------------------------\n",
      "Episode reward: 103.447239\n",
      "Episode reward: 80.114325\n",
      "Episode reward: 100.931786\n",
      "Episode reward: 47.922482\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7360     |\n",
      "|    fps              | 3084     |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total_timesteps  | 394983   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.253    |\n",
      "|    n_updates        | 98720    |\n",
      "----------------------------------\n",
      "Episode reward: 53.905539\n",
      "Episode reward: 56.796503\n",
      "Episode reward: 41.930911\n",
      "Episode reward: 50.749842\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7364     |\n",
      "|    fps              | 3084     |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total_timesteps  | 395187   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 98771    |\n",
      "----------------------------------\n",
      "Episode reward: 90.081744\n",
      "Episode reward: 58.613256\n",
      "Episode reward: 73.620632\n",
      "Episode reward: 112.285162\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7368     |\n",
      "|    fps              | 3083     |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total_timesteps  | 395525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0058   |\n",
      "|    n_updates        | 98856    |\n",
      "----------------------------------\n",
      "Episode reward: 39.915678\n",
      "Episode reward: 79.814144\n",
      "Episode reward: 78.634085\n",
      "Episode reward: 60.703951\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7372     |\n",
      "|    fps              | 3083     |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total_timesteps  | 395785   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.69     |\n",
      "|    n_updates        | 98921    |\n",
      "----------------------------------\n",
      "Episode reward: 37.8908\n",
      "Episode reward: 45.943666\n",
      "Episode reward: 41.936583\n",
      "Episode reward: 34.762002\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7376     |\n",
      "|    fps              | 3083     |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total_timesteps  | 395946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0384   |\n",
      "|    n_updates        | 98961    |\n",
      "----------------------------------\n",
      "Episode reward: 39.793379\n",
      "Episode reward: 50.60293\n",
      "Episode reward: 52.911517\n",
      "Episode reward: 44.68909\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7380     |\n",
      "|    fps              | 3083     |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total_timesteps  | 396135   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 99008    |\n",
      "----------------------------------\n",
      "Episode reward: 41.917468\n",
      "Episode reward: 71.853418\n",
      "Episode reward: 35.952289\n",
      "Episode reward: 60.230001\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7384     |\n",
      "|    fps              | 3082     |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total_timesteps  | 396346   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0294   |\n",
      "|    n_updates        | 99061    |\n",
      "----------------------------------\n",
      "Episode reward: 64.207663\n",
      "Episode reward: 63.493806\n",
      "Episode reward: 94.393054\n",
      "Episode reward: 61.894985\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7388     |\n",
      "|    fps              | 3082     |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total_timesteps  | 396632   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00985  |\n",
      "|    n_updates        | 99132    |\n",
      "----------------------------------\n",
      "Episode reward: 45.892795\n",
      "Episode reward: 88.224875\n",
      "Episode reward: 55.856824\n",
      "Episode reward: 44.773214\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7392     |\n",
      "|    fps              | 3082     |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total_timesteps  | 396868   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00713  |\n",
      "|    n_updates        | 99191    |\n",
      "----------------------------------\n",
      "Episode reward: 90.675236\n",
      "Episode reward: 53.839784\n",
      "Episode reward: 53.804126\n",
      "Episode reward: 45.666055\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7396     |\n",
      "|    fps              | 3082     |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total_timesteps  | 397114   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.443    |\n",
      "|    n_updates        | 99253    |\n",
      "----------------------------------\n",
      "Episode reward: 66.159153\n",
      "Episode reward: 90.720084\n",
      "Episode reward: 71.251467\n",
      "Episode reward: 47.448129\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7400     |\n",
      "|    fps              | 3081     |\n",
      "|    time_elapsed     | 128      |\n",
      "|    total_timesteps  | 397392   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.505    |\n",
      "|    n_updates        | 99322    |\n",
      "----------------------------------\n",
      "Episode reward: 40.92931\n",
      "Episode reward: 63.892821\n",
      "Episode reward: 50.627785\n",
      "Episode reward: 134.736589\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7404     |\n",
      "|    fps              | 3081     |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total_timesteps  | 397710   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.659    |\n",
      "|    n_updates        | 99402    |\n",
      "----------------------------------\n",
      "Episode reward: 68.748142\n",
      "Episode reward: 56.458029\n",
      "Episode reward: 81.509841\n",
      "Episode reward: 71.221797\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7408     |\n",
      "|    fps              | 3081     |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total_timesteps  | 397994   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.198    |\n",
      "|    n_updates        | 99473    |\n",
      "----------------------------------\n",
      "Episode reward: 60.745888\n",
      "Episode reward: 42.926926\n",
      "Episode reward: 86.102884\n",
      "Episode reward: 65.740569\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7412     |\n",
      "|    fps              | 3080     |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total_timesteps  | 398262   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.365    |\n",
      "|    n_updates        | 99540    |\n",
      "----------------------------------\n",
      "Episode reward: 46.928553\n",
      "Episode reward: 101.895972\n",
      "Episode reward: 49.927913\n",
      "Episode reward: 61.85309\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.6     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7416     |\n",
      "|    fps              | 3080     |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total_timesteps  | 398525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.175    |\n",
      "|    n_updates        | 99606    |\n",
      "----------------------------------\n",
      "Episode reward: 34.904909\n",
      "Episode reward: 62.426945\n",
      "Episode reward: 64.675277\n",
      "Episode reward: 54.789824\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7420     |\n",
      "|    fps              | 3080     |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total_timesteps  | 398743   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.234    |\n",
      "|    n_updates        | 99660    |\n",
      "----------------------------------\n",
      "Episode reward: 101.246367\n",
      "Episode reward: 54.202436\n",
      "Episode reward: 44.771816\n",
      "Episode reward: 47.77151\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7424     |\n",
      "|    fps              | 3080     |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total_timesteps  | 398993   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0563   |\n",
      "|    n_updates        | 99723    |\n",
      "----------------------------------\n",
      "Episode reward: 47.933137\n",
      "Episode reward: 76.802661\n",
      "Episode reward: 46.848365\n",
      "Episode reward: 56.786098\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7428     |\n",
      "|    fps              | 3080     |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total_timesteps  | 399222   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.663    |\n",
      "|    n_updates        | 99780    |\n",
      "----------------------------------\n",
      "Episode reward: 93.246934\n",
      "Episode reward: 55.848737\n",
      "Episode reward: 54.903784\n",
      "Episode reward: 66.370354\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7432     |\n",
      "|    fps              | 3080     |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total_timesteps  | 399494   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00823  |\n",
      "|    n_updates        | 99848    |\n",
      "----------------------------------\n",
      "Episode reward: 42.911926\n",
      "Episode reward: 48.687583\n",
      "Episode reward: 60.653689\n",
      "Episode reward: 35.945598\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7436     |\n",
      "|    fps              | 3079     |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total_timesteps  | 399683   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 99895    |\n",
      "----------------------------------\n",
      "Episode reward: 49.890518\n",
      "Episode reward: 100.656902\n",
      "Episode reward: 49.921893\n",
      "Episode reward: 86.710711\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7440     |\n",
      "|    fps              | 3079     |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total_timesteps  | 399971   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 99967    |\n",
      "----------------------------------\n",
      "Episode reward: 66.713233\n",
      "Episode reward: 45.897686\n",
      "Episode reward: 50.882217\n",
      "Episode reward: 48.849439\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7444     |\n",
      "|    fps              | 3079     |\n",
      "|    time_elapsed     | 129      |\n",
      "|    total_timesteps  | 400184   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.329    |\n",
      "|    n_updates        | 100020   |\n",
      "----------------------------------\n",
      "Episode reward: 40.915879\n",
      "Episode reward: 41.804868\n",
      "Episode reward: 40.870089\n",
      "Episode reward: 59.876244\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7448     |\n",
      "|    fps              | 3079     |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total_timesteps  | 400368   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0243   |\n",
      "|    n_updates        | 100066   |\n",
      "----------------------------------\n",
      "Episode reward: 39.851642\n",
      "Episode reward: 45.864983\n",
      "Episode reward: 70.868411\n",
      "Episode reward: 74.539734\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7452     |\n",
      "|    fps              | 3079     |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total_timesteps  | 400600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0202   |\n",
      "|    n_updates        | 100124   |\n",
      "----------------------------------\n",
      "Episode reward: 51.451091\n",
      "Episode reward: 47.915843\n",
      "Episode reward: 49.911692\n",
      "Episode reward: 51.562216\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7456     |\n",
      "|    fps              | 3079     |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total_timesteps  | 400802   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00822  |\n",
      "|    n_updates        | 100175   |\n",
      "----------------------------------\n",
      "Episode reward: 62.498517\n",
      "Episode reward: 102.456701\n",
      "Episode reward: 38.922562\n",
      "Episode reward: 57.27735\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7460     |\n",
      "|    fps              | 3078     |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total_timesteps  | 401070   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.236    |\n",
      "|    n_updates        | 100242   |\n",
      "----------------------------------\n",
      "Episode reward: 43.607568\n",
      "Episode reward: 40.932423\n",
      "Episode reward: 41.852725\n",
      "Episode reward: 60.769034\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7464     |\n",
      "|    fps              | 3077     |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total_timesteps  | 401258   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1        |\n",
      "|    n_updates        | 100289   |\n",
      "----------------------------------\n",
      "Episode reward: 63.721671\n",
      "Episode reward: 42.67759\n",
      "Episode reward: 54.88827\n",
      "Episode reward: 39.748161\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7468     |\n",
      "|    fps              | 3077     |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total_timesteps  | 401460   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.335    |\n",
      "|    n_updates        | 100339   |\n",
      "----------------------------------\n",
      "Episode reward: 62.806324\n",
      "Episode reward: 59.879172\n",
      "Episode reward: 41.814596\n",
      "Episode reward: 53.833021\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7472     |\n",
      "|    fps              | 3077     |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total_timesteps  | 401680   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.349    |\n",
      "|    n_updates        | 100394   |\n",
      "----------------------------------\n",
      "Episode reward: 48.783853\n",
      "Episode reward: 77.422256\n",
      "Episode reward: 45.530014\n",
      "Episode reward: 64.769587\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7476     |\n",
      "|    fps              | 3076     |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total_timesteps  | 401920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.446    |\n",
      "|    n_updates        | 100454   |\n",
      "----------------------------------\n",
      "Episode reward: 74.156042\n",
      "Episode reward: 47.866034\n",
      "Episode reward: 79.509471\n",
      "Episode reward: 64.429355\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7480     |\n",
      "|    fps              | 3076     |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total_timesteps  | 402189   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.424    |\n",
      "|    n_updates        | 100522   |\n",
      "----------------------------------\n",
      "Episode reward: 67.876621\n",
      "Episode reward: 46.923296\n",
      "Episode reward: 122.6052\n",
      "Episode reward: 54.75612\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7484     |\n",
      "|    fps              | 3076     |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total_timesteps  | 402509   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.024    |\n",
      "|    n_updates        | 100602   |\n",
      "----------------------------------\n",
      "Episode reward: 78.711461\n",
      "Episode reward: 48.891126\n",
      "Episode reward: 47.83433\n",
      "Episode reward: 52.851835\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7488     |\n",
      "|    fps              | 3076     |\n",
      "|    time_elapsed     | 130      |\n",
      "|    total_timesteps  | 402743   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.273    |\n",
      "|    n_updates        | 100660   |\n",
      "----------------------------------\n",
      "Episode reward: 54.788816\n",
      "Episode reward: 56.557026\n",
      "Episode reward: 67.167671\n",
      "Episode reward: 70.174722\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7492     |\n",
      "|    fps              | 3076     |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total_timesteps  | 402995   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.358    |\n",
      "|    n_updates        | 100723   |\n",
      "----------------------------------\n",
      "Episode reward: 54.768542\n",
      "Episode reward: 68.831466\n",
      "Episode reward: 65.712126\n",
      "Episode reward: 53.777964\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7496     |\n",
      "|    fps              | 3076     |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total_timesteps  | 403240   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.258    |\n",
      "|    n_updates        | 100784   |\n",
      "----------------------------------\n",
      "Episode reward: 51.815181\n",
      "Episode reward: 36.707915\n",
      "Episode reward: 52.89977\n",
      "Episode reward: 83.148256\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7500     |\n",
      "|    fps              | 3076     |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total_timesteps  | 403467   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 100841   |\n",
      "----------------------------------\n",
      "Episode reward: 74.63297\n",
      "Episode reward: 36.938681\n",
      "Episode reward: 55.908922\n",
      "Episode reward: 88.268063\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7504     |\n",
      "|    fps              | 3076     |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total_timesteps  | 403724   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.173    |\n",
      "|    n_updates        | 100905   |\n",
      "----------------------------------\n",
      "Episode reward: 33.953895\n",
      "Episode reward: 61.379949\n",
      "Episode reward: 58.510244\n",
      "Episode reward: 44.739611\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7508     |\n",
      "|    fps              | 3076     |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total_timesteps  | 403925   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00657  |\n",
      "|    n_updates        | 100956   |\n",
      "----------------------------------\n",
      "Episode reward: 72.715413\n",
      "Episode reward: 60.792934\n",
      "Episode reward: 48.886285\n",
      "Episode reward: 70.033085\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7512     |\n",
      "|    fps              | 3076     |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total_timesteps  | 404179   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0108   |\n",
      "|    n_updates        | 101019   |\n",
      "----------------------------------\n",
      "Episode reward: 76.987141\n",
      "Episode reward: 80.556774\n",
      "Episode reward: 68.136803\n",
      "Episode reward: 59.87253\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7516     |\n",
      "|    fps              | 3075     |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total_timesteps  | 404468   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00441  |\n",
      "|    n_updates        | 101091   |\n",
      "----------------------------------\n",
      "Episode reward: 56.898678\n",
      "Episode reward: 47.572254\n",
      "Episode reward: 58.674647\n",
      "Episode reward: 64.834165\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7520     |\n",
      "|    fps              | 3075     |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total_timesteps  | 404698   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.544    |\n",
      "|    n_updates        | 101149   |\n",
      "----------------------------------\n",
      "Episode reward: 64.642764\n",
      "Episode reward: 38.936436\n",
      "Episode reward: 86.631988\n",
      "Episode reward: 54.812934\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7524     |\n",
      "|    fps              | 3074     |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total_timesteps  | 404946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.68     |\n",
      "|    n_updates        | 101211   |\n",
      "----------------------------------\n",
      "Episode reward: 67.841515\n",
      "Episode reward: 47.863558\n",
      "Episode reward: 58.817079\n",
      "Episode reward: 58.868092\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7528     |\n",
      "|    fps              | 3074     |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total_timesteps  | 405180   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00634  |\n",
      "|    n_updates        | 101269   |\n",
      "----------------------------------\n",
      "Episode reward: 45.408617\n",
      "Episode reward: 51.906657\n",
      "Episode reward: 41.699342\n",
      "Episode reward: 84.077634\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7532     |\n",
      "|    fps              | 3073     |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total_timesteps  | 405405   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 101326   |\n",
      "----------------------------------\n",
      "Episode reward: 62.505929\n",
      "Episode reward: 31.941737\n",
      "Episode reward: 59.647466\n",
      "Episode reward: 59.856895\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7536     |\n",
      "|    fps              | 3073     |\n",
      "|    time_elapsed     | 131      |\n",
      "|    total_timesteps  | 405620   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00661  |\n",
      "|    n_updates        | 101379   |\n",
      "----------------------------------\n",
      "Episode reward: 57.919248\n",
      "Episode reward: 39.907579\n",
      "Episode reward: 76.22688\n",
      "Episode reward: 76.449076\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7540     |\n",
      "|    fps              | 3073     |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total_timesteps  | 405873   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.4      |\n",
      "|    n_updates        | 101443   |\n",
      "----------------------------------\n",
      "Episode reward: 101.642634\n",
      "Episode reward: 44.674514\n",
      "Episode reward: 49.736993\n",
      "Episode reward: 42.810936\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7544     |\n",
      "|    fps              | 3072     |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total_timesteps  | 406113   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0248   |\n",
      "|    n_updates        | 101503   |\n",
      "----------------------------------\n",
      "Episode reward: 48.89687\n",
      "Episode reward: 61.728389\n",
      "Episode reward: 54.652101\n",
      "Episode reward: 33.947329\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7548     |\n",
      "|    fps              | 3072     |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total_timesteps  | 406313   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.299    |\n",
      "|    n_updates        | 101553   |\n",
      "----------------------------------\n",
      "Episode reward: 121.744985\n",
      "Episode reward: 42.930455\n",
      "Episode reward: 51.718222\n",
      "Episode reward: 91.766644\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7552     |\n",
      "|    fps              | 3072     |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total_timesteps  | 406630   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.642    |\n",
      "|    n_updates        | 101632   |\n",
      "----------------------------------\n",
      "Episode reward: 32.954335\n",
      "Episode reward: 74.970664\n",
      "Episode reward: 46.720416\n",
      "Episode reward: 60.236146\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7556     |\n",
      "|    fps              | 3072     |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total_timesteps  | 406848   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.164    |\n",
      "|    n_updates        | 101686   |\n",
      "----------------------------------\n",
      "Episode reward: 94.251654\n",
      "Episode reward: 71.757545\n",
      "Episode reward: 82.836614\n",
      "Episode reward: 109.434961\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7560     |\n",
      "|    fps              | 3072     |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total_timesteps  | 407216   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 101778   |\n",
      "----------------------------------\n",
      "Episode reward: 72.621708\n",
      "Episode reward: 38.923208\n",
      "Episode reward: 57.903932\n",
      "Episode reward: 70.769273\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7564     |\n",
      "|    fps              | 3072     |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total_timesteps  | 407458   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00621  |\n",
      "|    n_updates        | 101839   |\n",
      "----------------------------------\n",
      "Episode reward: 47.771425\n",
      "Episode reward: 49.915221\n",
      "Episode reward: 65.567435\n",
      "Episode reward: 64.88697\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7568     |\n",
      "|    fps              | 3072     |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total_timesteps  | 407687   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 101896   |\n",
      "----------------------------------\n",
      "Episode reward: 50.923642\n",
      "Episode reward: 108.018465\n",
      "Episode reward: 90.832744\n",
      "Episode reward: 55.828089\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7572     |\n",
      "|    fps              | 3072     |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total_timesteps  | 408008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.265    |\n",
      "|    n_updates        | 101976   |\n",
      "----------------------------------\n",
      "Episode reward: 53.920655\n",
      "Episode reward: 59.829825\n",
      "Episode reward: 55.709416\n",
      "Episode reward: 58.863522\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7576     |\n",
      "|    fps              | 3072     |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total_timesteps  | 408237   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0245   |\n",
      "|    n_updates        | 102034   |\n",
      "----------------------------------\n",
      "Episode reward: 51.889817\n",
      "Episode reward: 81.742692\n",
      "Episode reward: 92.504286\n",
      "Episode reward: 55.269369\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7580     |\n",
      "|    fps              | 3072     |\n",
      "|    time_elapsed     | 132      |\n",
      "|    total_timesteps  | 408521   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.257    |\n",
      "|    n_updates        | 102105   |\n",
      "----------------------------------\n",
      "Episode reward: 56.898055\n",
      "Episode reward: 79.63115\n",
      "Episode reward: 98.762127\n",
      "Episode reward: 57.851699\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7584     |\n",
      "|    fps              | 3072     |\n",
      "|    time_elapsed     | 133      |\n",
      "|    total_timesteps  | 408819   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 102179   |\n",
      "----------------------------------\n",
      "Episode reward: 47.933735\n",
      "Episode reward: 76.98864\n",
      "Episode reward: 125.701843\n",
      "Episode reward: 92.319882\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7588     |\n",
      "|    fps              | 3072     |\n",
      "|    time_elapsed     | 133      |\n",
      "|    total_timesteps  | 409175   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.198    |\n",
      "|    n_updates        | 102268   |\n",
      "----------------------------------\n",
      "Episode reward: 58.089749\n",
      "Episode reward: 42.417846\n",
      "Episode reward: 58.435709\n",
      "Episode reward: 75.140769\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7592     |\n",
      "|    fps              | 3072     |\n",
      "|    time_elapsed     | 133      |\n",
      "|    total_timesteps  | 409413   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00969  |\n",
      "|    n_updates        | 102328   |\n",
      "----------------------------------\n",
      "Episode reward: 67.838075\n",
      "Episode reward: 40.944235\n",
      "Episode reward: 59.618896\n",
      "Episode reward: 45.888005\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7596     |\n",
      "|    fps              | 3072     |\n",
      "|    time_elapsed     | 133      |\n",
      "|    total_timesteps  | 409628   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.07     |\n",
      "|    n_updates        | 102381   |\n",
      "----------------------------------\n",
      "Episode reward: 61.801737\n",
      "Episode reward: 39.884247\n",
      "Episode reward: 79.354002\n",
      "Episode reward: 64.649007\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.1     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7600     |\n",
      "|    fps              | 3071     |\n",
      "|    time_elapsed     | 133      |\n",
      "|    total_timesteps  | 409878   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00399  |\n",
      "|    n_updates        | 102444   |\n",
      "----------------------------------\n",
      "Episode reward: 40.870628\n",
      "Episode reward: 74.611344\n",
      "Episode reward: 52.915475\n",
      "Episode reward: 63.697769\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7604     |\n",
      "|    fps              | 3071     |\n",
      "|    time_elapsed     | 133      |\n",
      "|    total_timesteps  | 410111   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0427   |\n",
      "|    n_updates        | 102502   |\n",
      "----------------------------------\n",
      "Episode reward: 67.844534\n",
      "Episode reward: 49.666219\n",
      "Episode reward: 56.929163\n",
      "Episode reward: 97.965872\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.7     |\n",
      "|    ep_rew_mean      | 63.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7608     |\n",
      "|    fps              | 3071     |\n",
      "|    time_elapsed     | 133      |\n",
      "|    total_timesteps  | 410397   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 102574   |\n",
      "----------------------------------\n",
      "Episode reward: 59.295083\n",
      "Episode reward: 41.709306\n",
      "Episode reward: 61.867998\n",
      "Episode reward: 67.651338\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7612     |\n",
      "|    fps              | 3070     |\n",
      "|    time_elapsed     | 133      |\n",
      "|    total_timesteps  | 410629   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 102632   |\n",
      "----------------------------------\n",
      "Episode reward: 44.937961\n",
      "Episode reward: 51.920052\n",
      "Episode reward: 83.783632\n",
      "Episode reward: 40.877666\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7616     |\n",
      "|    fps              | 3070     |\n",
      "|    time_elapsed     | 133      |\n",
      "|    total_timesteps  | 410851   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.332    |\n",
      "|    n_updates        | 102687   |\n",
      "----------------------------------\n",
      "Episode reward: 57.882283\n",
      "Episode reward: 66.734522\n",
      "Episode reward: 56.49363\n",
      "Episode reward: 53.795317\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7620     |\n",
      "|    fps              | 3069     |\n",
      "|    time_elapsed     | 133      |\n",
      "|    total_timesteps  | 411087   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0265   |\n",
      "|    n_updates        | 102746   |\n",
      "----------------------------------\n",
      "Episode reward: 61.847442\n",
      "Episode reward: 62.864898\n",
      "Episode reward: 68.679351\n",
      "Episode reward: 74.779244\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.1     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7624     |\n",
      "|    fps              | 3069     |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 411356   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.406    |\n",
      "|    n_updates        | 102813   |\n",
      "----------------------------------\n",
      "Episode reward: 72.446643\n",
      "Episode reward: 94.308188\n",
      "Episode reward: 55.780302\n",
      "Episode reward: 62.592248\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 63.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7628     |\n",
      "|    fps              | 3069     |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 411643   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.68     |\n",
      "|    n_updates        | 102885   |\n",
      "----------------------------------\n",
      "Episode reward: 85.778079\n",
      "Episode reward: 59.854706\n",
      "Episode reward: 79.093094\n",
      "Episode reward: 72.462235\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.4     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7632     |\n",
      "|    fps              | 3069     |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 411944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 102960   |\n",
      "----------------------------------\n",
      "Episode reward: 40.806841\n",
      "Episode reward: 42.863695\n",
      "Episode reward: 55.802445\n",
      "Episode reward: 73.524748\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.4     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7636     |\n",
      "|    fps              | 3069     |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 412160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0378   |\n",
      "|    n_updates        | 103014   |\n",
      "----------------------------------\n",
      "Episode reward: 50.608691\n",
      "Episode reward: 51.909244\n",
      "Episode reward: 55.910286\n",
      "Episode reward: 70.637852\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.2     |\n",
      "|    ep_rew_mean      | 64.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7640     |\n",
      "|    fps              | 3068     |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 412390   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 103072   |\n",
      "----------------------------------\n",
      "Episode reward: 80.356795\n",
      "Episode reward: 51.894831\n",
      "Episode reward: 83.886682\n",
      "Episode reward: 69.828679\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.7     |\n",
      "|    ep_rew_mean      | 64.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7644     |\n",
      "|    fps              | 3068     |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 412685   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0193   |\n",
      "|    n_updates        | 103146   |\n",
      "----------------------------------\n",
      "Episode reward: 40.889842\n",
      "Episode reward: 52.87417\n",
      "Episode reward: 49.670304\n",
      "Episode reward: 63.604726\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.8     |\n",
      "|    ep_rew_mean      | 64.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7648     |\n",
      "|    fps              | 3068     |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 412894   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 103198   |\n",
      "----------------------------------\n",
      "Episode reward: 63.410417\n",
      "Episode reward: 52.692655\n",
      "Episode reward: 56.712422\n",
      "Episode reward: 70.200175\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.1     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7652     |\n",
      "|    fps              | 3067     |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 413139   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 103259   |\n",
      "----------------------------------\n",
      "Episode reward: 102.144952\n",
      "Episode reward: 67.762844\n",
      "Episode reward: 74.747764\n",
      "Episode reward: 59.876745\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66       |\n",
      "|    ep_rew_mean      | 65       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7656     |\n",
      "|    fps              | 3067     |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 413446   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.386    |\n",
      "|    n_updates        | 103336   |\n",
      "----------------------------------\n",
      "Episode reward: 58.83955\n",
      "Episode reward: 36.951546\n",
      "Episode reward: 98.689352\n",
      "Episode reward: 46.492836\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.7     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7660     |\n",
      "|    fps              | 3067     |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 413688   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 103396   |\n",
      "----------------------------------\n",
      "Episode reward: 48.891064\n",
      "Episode reward: 61.837365\n",
      "Episode reward: 69.601986\n",
      "Episode reward: 63.534257\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7664     |\n",
      "|    fps              | 3067     |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 413933   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0077   |\n",
      "|    n_updates        | 103458   |\n",
      "----------------------------------\n",
      "Episode reward: 40.908105\n",
      "Episode reward: 74.766571\n",
      "Episode reward: 43.905046\n",
      "Episode reward: 50.816929\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 63.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7668     |\n",
      "|    fps              | 3067     |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 414144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 103510   |\n",
      "----------------------------------\n",
      "Episode reward: 50.783637\n",
      "Episode reward: 46.794761\n",
      "Episode reward: 57.612359\n",
      "Episode reward: 49.572521\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7672     |\n",
      "|    fps              | 3067     |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 414350   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 103562   |\n",
      "----------------------------------\n",
      "Episode reward: 79.803244\n",
      "Episode reward: 41.898899\n",
      "Episode reward: 68.830889\n",
      "Episode reward: 98.207002\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7676     |\n",
      "|    fps              | 3066     |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 414652   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00944  |\n",
      "|    n_updates        | 103637   |\n",
      "----------------------------------\n",
      "Episode reward: 69.562817\n",
      "Episode reward: 93.636816\n",
      "Episode reward: 47.893848\n",
      "Episode reward: 62.858326\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.1     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7680     |\n",
      "|    fps              | 3066     |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 414927   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.464    |\n",
      "|    n_updates        | 103706   |\n",
      "----------------------------------\n",
      "Episode reward: 68.721692\n",
      "Episode reward: 74.171039\n",
      "Episode reward: 70.812597\n",
      "Episode reward: 37.84698\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7684     |\n",
      "|    fps              | 3066     |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 415181   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.45     |\n",
      "|    n_updates        | 103770   |\n",
      "----------------------------------\n",
      "Episode reward: 93.340532\n",
      "Episode reward: 43.943557\n",
      "Episode reward: 54.343979\n",
      "Episode reward: 90.759922\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7688     |\n",
      "|    fps              | 3066     |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 415468   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 103841   |\n",
      "----------------------------------\n",
      "Episode reward: 61.655567\n",
      "Episode reward: 40.934823\n",
      "Episode reward: 49.567596\n",
      "Episode reward: 80.792181\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7692     |\n",
      "|    fps              | 3066     |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 415703   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 103900   |\n",
      "----------------------------------\n",
      "Episode reward: 71.805833\n",
      "Episode reward: 40.93253\n",
      "Episode reward: 102.704914\n",
      "Episode reward: 78.765953\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7696     |\n",
      "|    fps              | 3066     |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 416013   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00789  |\n",
      "|    n_updates        | 103978   |\n",
      "----------------------------------\n",
      "Episode reward: 55.901163\n",
      "Episode reward: 91.219171\n",
      "Episode reward: 53.273295\n",
      "Episode reward: 52.41162\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7700     |\n",
      "|    fps              | 3066     |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 416268   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00849  |\n",
      "|    n_updates        | 104041   |\n",
      "----------------------------------\n",
      "Episode reward: 48.887962\n",
      "Episode reward: 82.521524\n",
      "Episode reward: 79.393973\n",
      "Episode reward: 35.940606\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.1     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7704     |\n",
      "|    fps              | 3065     |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 416517   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.257    |\n",
      "|    n_updates        | 104104   |\n",
      "----------------------------------\n",
      "Episode reward: 53.801094\n",
      "Episode reward: 69.823555\n",
      "Episode reward: 65.745324\n",
      "Episode reward: 48.553398\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7708     |\n",
      "|    fps              | 3064     |\n",
      "|    time_elapsed     | 135      |\n",
      "|    total_timesteps  | 416756   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00914  |\n",
      "|    n_updates        | 104163   |\n",
      "----------------------------------\n",
      "Episode reward: 53.653516\n",
      "Episode reward: 81.936113\n",
      "Episode reward: 76.684353\n",
      "Episode reward: 53.761576\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7712     |\n",
      "|    fps              | 3064     |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 417024   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.508    |\n",
      "|    n_updates        | 104230   |\n",
      "----------------------------------\n",
      "Episode reward: 44.892371\n",
      "Episode reward: 46.847259\n",
      "Episode reward: 46.856764\n",
      "Episode reward: 43.872891\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7716     |\n",
      "|    fps              | 3064     |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 417207   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.269    |\n",
      "|    n_updates        | 104276   |\n",
      "----------------------------------\n",
      "Episode reward: 52.384464\n",
      "Episode reward: 46.823513\n",
      "Episode reward: 41.867129\n",
      "Episode reward: 37.935706\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7720     |\n",
      "|    fps              | 3063     |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 417387   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0183   |\n",
      "|    n_updates        | 104321   |\n",
      "----------------------------------\n",
      "Episode reward: 49.916613\n",
      "Episode reward: 92.225184\n",
      "Episode reward: 67.698237\n",
      "Episode reward: 53.392743\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7724     |\n",
      "|    fps              | 3063     |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 417654   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.518    |\n",
      "|    n_updates        | 104388   |\n",
      "----------------------------------\n",
      "Episode reward: 67.818828\n",
      "Episode reward: 45.760604\n",
      "Episode reward: 66.28688\n",
      "Episode reward: 51.823639\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7728     |\n",
      "|    fps              | 3062     |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 417887   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 104446   |\n",
      "----------------------------------\n",
      "Episode reward: 37.823838\n",
      "Episode reward: 42.725753\n",
      "Episode reward: 45.743833\n",
      "Episode reward: 80.214074\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7732     |\n",
      "|    fps              | 3062     |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 418095   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 104498   |\n",
      "----------------------------------\n",
      "Episode reward: 77.793342\n",
      "Episode reward: 36.788268\n",
      "Episode reward: 72.698839\n",
      "Episode reward: 71.209427\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7736     |\n",
      "|    fps              | 3062     |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 418357   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0191   |\n",
      "|    n_updates        | 104564   |\n",
      "----------------------------------\n",
      "Episode reward: 61.640661\n",
      "Episode reward: 51.624972\n",
      "Episode reward: 43.803031\n",
      "Episode reward: 60.884447\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7740     |\n",
      "|    fps              | 3062     |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 418576   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 104618   |\n",
      "----------------------------------\n",
      "Episode reward: 122.658472\n",
      "Episode reward: 44.898701\n",
      "Episode reward: 72.186743\n",
      "Episode reward: 52.900189\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7744     |\n",
      "|    fps              | 3062     |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 418878   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0266   |\n",
      "|    n_updates        | 104694   |\n",
      "----------------------------------\n",
      "Episode reward: 37.862452\n",
      "Episode reward: 46.896154\n",
      "Episode reward: 79.449429\n",
      "Episode reward: 40.777866\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7748     |\n",
      "|    fps              | 3062     |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 419085   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.43     |\n",
      "|    n_updates        | 104746   |\n",
      "----------------------------------\n",
      "Episode reward: 59.811203\n",
      "Episode reward: 63.563592\n",
      "Episode reward: 70.862288\n",
      "Episode reward: 90.864349\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7752     |\n",
      "|    fps              | 3061     |\n",
      "|    time_elapsed     | 136      |\n",
      "|    total_timesteps  | 419374   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00917  |\n",
      "|    n_updates        | 104818   |\n",
      "----------------------------------\n",
      "Episode reward: 59.31428\n",
      "Episode reward: 40.90755\n",
      "Episode reward: 44.851691\n",
      "Episode reward: 62.787816\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7756     |\n",
      "|    fps              | 3062     |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total_timesteps  | 419583   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00828  |\n",
      "|    n_updates        | 104870   |\n",
      "----------------------------------\n",
      "Episode reward: 33.898579\n",
      "Episode reward: 42.62491\n",
      "Episode reward: 47.896802\n",
      "Episode reward: 51.628092\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7760     |\n",
      "|    fps              | 3062     |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total_timesteps  | 419760   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.019    |\n",
      "|    n_updates        | 104914   |\n",
      "----------------------------------\n",
      "Episode reward: 61.653192\n",
      "Episode reward: 68.410049\n",
      "Episode reward: 61.440644\n",
      "Episode reward: 39.573676\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7764     |\n",
      "|    fps              | 3062     |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total_timesteps  | 419993   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.633    |\n",
      "|    n_updates        | 104973   |\n",
      "----------------------------------\n",
      "Episode reward: 45.399196\n",
      "Episode reward: 48.885161\n",
      "Episode reward: 77.691841\n",
      "Episode reward: 36.788942\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7768     |\n",
      "|    fps              | 3062     |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total_timesteps  | 420203   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.138    |\n",
      "|    n_updates        | 105025   |\n",
      "----------------------------------\n",
      "Episode reward: 74.425117\n",
      "Episode reward: 40.934678\n",
      "Episode reward: 37.887039\n",
      "Episode reward: 40.804734\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7772     |\n",
      "|    fps              | 3062     |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total_timesteps  | 420398   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.01     |\n",
      "|    n_updates        | 105074   |\n",
      "----------------------------------\n",
      "Episode reward: 66.643866\n",
      "Episode reward: 59.861012\n",
      "Episode reward: 65.799364\n",
      "Episode reward: 60.213399\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7776     |\n",
      "|    fps              | 3062     |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total_timesteps  | 420652   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0209   |\n",
      "|    n_updates        | 105137   |\n",
      "----------------------------------\n",
      "Episode reward: 56.441504\n",
      "Episode reward: 62.492021\n",
      "Episode reward: 82.797901\n",
      "Episode reward: 88.876237\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7780     |\n",
      "|    fps              | 3062     |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total_timesteps  | 420945   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.037    |\n",
      "|    n_updates        | 105211   |\n",
      "----------------------------------\n",
      "Episode reward: 64.688193\n",
      "Episode reward: 65.887061\n",
      "Episode reward: 78.796563\n",
      "Episode reward: 44.819901\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7784     |\n",
      "|    fps              | 3062     |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total_timesteps  | 421200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.362    |\n",
      "|    n_updates        | 105274   |\n",
      "----------------------------------\n",
      "Episode reward: 36.947776\n",
      "Episode reward: 79.809379\n",
      "Episode reward: 49.255182\n",
      "Episode reward: 51.910768\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7788     |\n",
      "|    fps              | 3062     |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total_timesteps  | 421419   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0081   |\n",
      "|    n_updates        | 105329   |\n",
      "----------------------------------\n",
      "Episode reward: 67.873341\n",
      "Episode reward: 59.892462\n",
      "Episode reward: 66.079444\n",
      "Episode reward: 44.846049\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7792     |\n",
      "|    fps              | 3062     |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total_timesteps  | 421659   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.508    |\n",
      "|    n_updates        | 105389   |\n",
      "----------------------------------\n",
      "Episode reward: 38.876237\n",
      "Episode reward: 98.805098\n",
      "Episode reward: 76.106451\n",
      "Episode reward: 72.172182\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7796     |\n",
      "|    fps              | 3062     |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total_timesteps  | 421949   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.352    |\n",
      "|    n_updates        | 105462   |\n",
      "----------------------------------\n",
      "Episode reward: 66.329348\n",
      "Episode reward: 61.914935\n",
      "Episode reward: 34.86843\n",
      "Episode reward: 78.885527\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7800     |\n",
      "|    fps              | 3061     |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total_timesteps  | 422193   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.031    |\n",
      "|    n_updates        | 105523   |\n",
      "----------------------------------\n",
      "Episode reward: 53.574925\n",
      "Episode reward: 66.714304\n",
      "Episode reward: 88.620252\n",
      "Episode reward: 52.154926\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7804     |\n",
      "|    fps              | 3061     |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 422462   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0253   |\n",
      "|    n_updates        | 105590   |\n",
      "----------------------------------\n",
      "Episode reward: 45.727659\n",
      "Episode reward: 110.265671\n",
      "Episode reward: 49.898469\n",
      "Episode reward: 79.630034\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7808     |\n",
      "|    fps              | 3060     |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 422751   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.552    |\n",
      "|    n_updates        | 105662   |\n",
      "----------------------------------\n",
      "Episode reward: 33.779938\n",
      "Episode reward: 67.026733\n",
      "Episode reward: 72.597746\n",
      "Episode reward: 51.665768\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7812     |\n",
      "|    fps              | 3060     |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 422980   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00785  |\n",
      "|    n_updates        | 105719   |\n",
      "----------------------------------\n",
      "Episode reward: 43.894674\n",
      "Episode reward: 48.693341\n",
      "Episode reward: 77.414142\n",
      "Episode reward: 67.517619\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7816     |\n",
      "|    fps              | 3060     |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 423223   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0863   |\n",
      "|    n_updates        | 105780   |\n",
      "----------------------------------\n",
      "Episode reward: 86.338728\n",
      "Episode reward: 39.876021\n",
      "Episode reward: 40.934502\n",
      "Episode reward: 73.495795\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7820     |\n",
      "|    fps              | 3060     |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 423465   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0103   |\n",
      "|    n_updates        | 105841   |\n",
      "----------------------------------\n",
      "Episode reward: 66.774084\n",
      "Episode reward: 29.897889\n",
      "Episode reward: 57.258756\n",
      "Episode reward: 53.874374\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7824     |\n",
      "|    fps              | 3060     |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 423674   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.519    |\n",
      "|    n_updates        | 105893   |\n",
      "----------------------------------\n",
      "Episode reward: 38.956773\n",
      "Episode reward: 42.776033\n",
      "Episode reward: 53.576935\n",
      "Episode reward: 55.598274\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7828     |\n",
      "|    fps              | 3060     |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 423866   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 105941   |\n",
      "----------------------------------\n",
      "Episode reward: 39.703436\n",
      "Episode reward: 52.921548\n",
      "Episode reward: 45.841698\n",
      "Episode reward: 48.744904\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7832     |\n",
      "|    fps              | 3060     |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 424054   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.945    |\n",
      "|    n_updates        | 105988   |\n",
      "----------------------------------\n",
      "Episode reward: 44.888572\n",
      "Episode reward: 31.940808\n",
      "Episode reward: 50.876148\n",
      "Episode reward: 50.891317\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7836     |\n",
      "|    fps              | 3060     |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 424233   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 106033   |\n",
      "----------------------------------\n",
      "Episode reward: 90.349335\n",
      "Episode reward: 66.556557\n",
      "Episode reward: 46.83388\n",
      "Episode reward: 79.394112\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7840     |\n",
      "|    fps              | 3060     |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 424542   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.611    |\n",
      "|    n_updates        | 106110   |\n",
      "----------------------------------\n",
      "Episode reward: 56.81487\n",
      "Episode reward: 46.748217\n",
      "Episode reward: 46.912382\n",
      "Episode reward: 60.705163\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7844     |\n",
      "|    fps              | 3060     |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 424754   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 106163   |\n",
      "----------------------------------\n",
      "Episode reward: 37.9325\n",
      "Episode reward: 48.879542\n",
      "Episode reward: 99.246759\n",
      "Episode reward: 33.94158\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7848     |\n",
      "|    fps              | 3060     |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 424975   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.779    |\n",
      "|    n_updates        | 106218   |\n",
      "----------------------------------\n",
      "Episode reward: 52.610919\n",
      "Episode reward: 81.992649\n",
      "Episode reward: 78.821385\n",
      "Episode reward: 63.881799\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7852     |\n",
      "|    fps              | 3060     |\n",
      "|    time_elapsed     | 138      |\n",
      "|    total_timesteps  | 425254   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00711  |\n",
      "|    n_updates        | 106288   |\n",
      "----------------------------------\n",
      "Episode reward: 81.804885\n",
      "Episode reward: 56.892441\n",
      "Episode reward: 95.582354\n",
      "Episode reward: 75.831484\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7856     |\n",
      "|    fps              | 3059     |\n",
      "|    time_elapsed     | 139      |\n",
      "|    total_timesteps  | 425565   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.378    |\n",
      "|    n_updates        | 106366   |\n",
      "----------------------------------\n",
      "Episode reward: 48.879073\n",
      "Episode reward: 57.714786\n",
      "Episode reward: 41.867254\n",
      "Episode reward: 86.895273\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7860     |\n",
      "|    fps              | 3059     |\n",
      "|    time_elapsed     | 139      |\n",
      "|    total_timesteps  | 425802   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00728  |\n",
      "|    n_updates        | 106425   |\n",
      "----------------------------------\n",
      "Episode reward: 68.456399\n",
      "Episode reward: 48.892828\n",
      "Episode reward: 44.906305\n",
      "Episode reward: 57.627539\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7864     |\n",
      "|    fps              | 3059     |\n",
      "|    time_elapsed     | 139      |\n",
      "|    total_timesteps  | 426023   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 106480   |\n",
      "----------------------------------\n",
      "Episode reward: 55.894134\n",
      "Episode reward: 64.48715\n",
      "Episode reward: 41.873797\n",
      "Episode reward: 63.830406\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7868     |\n",
      "|    fps              | 3059     |\n",
      "|    time_elapsed     | 139      |\n",
      "|    total_timesteps  | 426250   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0205   |\n",
      "|    n_updates        | 106537   |\n",
      "----------------------------------\n",
      "Episode reward: 65.730988\n",
      "Episode reward: 59.744918\n",
      "Episode reward: 37.957354\n",
      "Episode reward: 39.957844\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7872     |\n",
      "|    fps              | 3059     |\n",
      "|    time_elapsed     | 139      |\n",
      "|    total_timesteps  | 426454   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00397  |\n",
      "|    n_updates        | 106588   |\n",
      "----------------------------------\n",
      "Episode reward: 43.903401\n",
      "Episode reward: 61.396232\n",
      "Episode reward: 59.480555\n",
      "Episode reward: 47.945519\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7876     |\n",
      "|    fps              | 3059     |\n",
      "|    time_elapsed     | 139      |\n",
      "|    total_timesteps  | 426668   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.184    |\n",
      "|    n_updates        | 106641   |\n",
      "----------------------------------\n",
      "Episode reward: 81.310746\n",
      "Episode reward: 116.43474\n",
      "Episode reward: 44.751814\n",
      "Episode reward: 52.923238\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7880     |\n",
      "|    fps              | 3059     |\n",
      "|    time_elapsed     | 139      |\n",
      "|    total_timesteps  | 426973   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.021    |\n",
      "|    n_updates        | 106718   |\n",
      "----------------------------------\n",
      "Episode reward: 40.848018\n",
      "Episode reward: 86.4225\n",
      "Episode reward: 44.869311\n",
      "Episode reward: 79.599302\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7884     |\n",
      "|    fps              | 3059     |\n",
      "|    time_elapsed     | 139      |\n",
      "|    total_timesteps  | 427226   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.438    |\n",
      "|    n_updates        | 106781   |\n",
      "----------------------------------\n",
      "Episode reward: 76.583122\n",
      "Episode reward: 86.443495\n",
      "Episode reward: 45.940288\n",
      "Episode reward: 38.954448\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7888     |\n",
      "|    fps              | 3058     |\n",
      "|    time_elapsed     | 139      |\n",
      "|    total_timesteps  | 427483   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 106845   |\n",
      "----------------------------------\n",
      "Episode reward: 65.142818\n",
      "Episode reward: 60.864821\n",
      "Episode reward: 62.725693\n",
      "Episode reward: 41.898906\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7892     |\n",
      "|    fps              | 3058     |\n",
      "|    time_elapsed     | 139      |\n",
      "|    total_timesteps  | 427715   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 106903   |\n",
      "----------------------------------\n",
      "Episode reward: 47.622063\n",
      "Episode reward: 43.895876\n",
      "Episode reward: 74.581752\n",
      "Episode reward: 31.961701\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7896     |\n",
      "|    fps              | 3058     |\n",
      "|    time_elapsed     | 139      |\n",
      "|    total_timesteps  | 427915   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00995  |\n",
      "|    n_updates        | 106953   |\n",
      "----------------------------------\n",
      "Episode reward: 74.772987\n",
      "Episode reward: 68.404884\n",
      "Episode reward: 59.909608\n",
      "Episode reward: 147.080194\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7900     |\n",
      "|    fps              | 3058     |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total_timesteps  | 428268   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 107041   |\n",
      "----------------------------------\n",
      "Episode reward: 44.700742\n",
      "Episode reward: 45.883568\n",
      "Episode reward: 62.064392\n",
      "Episode reward: 32.908915\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7904     |\n",
      "|    fps              | 3058     |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total_timesteps  | 428455   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.39     |\n",
      "|    n_updates        | 107088   |\n",
      "----------------------------------\n",
      "Episode reward: 56.887819\n",
      "Episode reward: 54.910691\n",
      "Episode reward: 67.856496\n",
      "Episode reward: 52.755949\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7908     |\n",
      "|    fps              | 3057     |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total_timesteps  | 428688   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.348    |\n",
      "|    n_updates        | 107146   |\n",
      "----------------------------------\n",
      "Episode reward: 44.826059\n",
      "Episode reward: 65.755699\n",
      "Episode reward: 52.810402\n",
      "Episode reward: 47.737986\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7912     |\n",
      "|    fps              | 3057     |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total_timesteps  | 428900   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 107199   |\n",
      "----------------------------------\n",
      "Episode reward: 36.787922\n",
      "Episode reward: 44.932867\n",
      "Episode reward: 42.883058\n",
      "Episode reward: 55.627329\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7916     |\n",
      "|    fps              | 3056     |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total_timesteps  | 429081   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 107245   |\n",
      "----------------------------------\n",
      "Episode reward: 97.135986\n",
      "Episode reward: 50.360604\n",
      "Episode reward: 58.926038\n",
      "Episode reward: 74.648068\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7920     |\n",
      "|    fps              | 3056     |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total_timesteps  | 429365   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.236    |\n",
      "|    n_updates        | 107316   |\n",
      "----------------------------------\n",
      "Episode reward: 61.599837\n",
      "Episode reward: 76.671564\n",
      "Episode reward: 44.891762\n",
      "Episode reward: 62.793812\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7924     |\n",
      "|    fps              | 3056     |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total_timesteps  | 429612   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00996  |\n",
      "|    n_updates        | 107377   |\n",
      "----------------------------------\n",
      "Episode reward: 62.353904\n",
      "Episode reward: 126.420941\n",
      "Episode reward: 65.523992\n",
      "Episode reward: 100.242118\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7928     |\n",
      "|    fps              | 3056     |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total_timesteps  | 429969   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 107467   |\n",
      "----------------------------------\n",
      "Episode reward: 49.876322\n",
      "Episode reward: 56.839885\n",
      "Episode reward: 64.144738\n",
      "Episode reward: 32.910685\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7932     |\n",
      "|    fps              | 3056     |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total_timesteps  | 430174   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.037    |\n",
      "|    n_updates        | 107518   |\n",
      "----------------------------------\n",
      "Episode reward: 31.953168\n",
      "Episode reward: 83.512776\n",
      "Episode reward: 62.748947\n",
      "Episode reward: 53.824838\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7936     |\n",
      "|    fps              | 3055     |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total_timesteps  | 430410   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 107577   |\n",
      "----------------------------------\n",
      "Episode reward: 71.559345\n",
      "Episode reward: 48.864225\n",
      "Episode reward: 54.676631\n",
      "Episode reward: 70.672738\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7940     |\n",
      "|    fps              | 3055     |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total_timesteps  | 430657   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0363   |\n",
      "|    n_updates        | 107639   |\n",
      "----------------------------------\n",
      "Episode reward: 89.57177\n",
      "Episode reward: 57.902659\n",
      "Episode reward: 81.272805\n",
      "Episode reward: 30.94914\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7944     |\n",
      "|    fps              | 3055     |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total_timesteps  | 430921   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 107705   |\n",
      "----------------------------------\n",
      "Episode reward: 65.869458\n",
      "Episode reward: 46.916587\n",
      "Episode reward: 45.862626\n",
      "Episode reward: 70.840864\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7948     |\n",
      "|    fps              | 3055     |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total_timesteps  | 431154   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 107763   |\n",
      "----------------------------------\n",
      "Episode reward: 45.633133\n",
      "Episode reward: 65.744944\n",
      "Episode reward: 42.932415\n",
      "Episode reward: 65.884361\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7952     |\n",
      "|    fps              | 3055     |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total_timesteps  | 431375   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0203   |\n",
      "|    n_updates        | 107818   |\n",
      "----------------------------------\n",
      "Episode reward: 87.665356\n",
      "Episode reward: 85.797426\n",
      "Episode reward: 49.567988\n",
      "Episode reward: 55.639625\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7956     |\n",
      "|    fps              | 3055     |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total_timesteps  | 431655   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 107888   |\n",
      "----------------------------------\n",
      "Episode reward: 55.691225\n",
      "Episode reward: 51.926717\n",
      "Episode reward: 110.216049\n",
      "Episode reward: 50.754253\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7960     |\n",
      "|    fps              | 3054     |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total_timesteps  | 431939   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0233   |\n",
      "|    n_updates        | 107959   |\n",
      "----------------------------------\n",
      "Episode reward: 73.726826\n",
      "Episode reward: 51.502785\n",
      "Episode reward: 70.769693\n",
      "Episode reward: 43.806529\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7964     |\n",
      "|    fps              | 3054     |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total_timesteps  | 432180   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 108019   |\n",
      "----------------------------------\n",
      "Episode reward: 30.943171\n",
      "Episode reward: 117.366498\n",
      "Episode reward: 57.869546\n",
      "Episode reward: 40.841656\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7968     |\n",
      "|    fps              | 3054     |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total_timesteps  | 432428   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 108081   |\n",
      "----------------------------------\n",
      "Episode reward: 73.719413\n",
      "Episode reward: 41.75924\n",
      "Episode reward: 58.89315\n",
      "Episode reward: 47.812925\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7972     |\n",
      "|    fps              | 3054     |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total_timesteps  | 432651   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.023    |\n",
      "|    n_updates        | 108137   |\n",
      "----------------------------------\n",
      "Episode reward: 78.008045\n",
      "Episode reward: 37.944873\n",
      "Episode reward: 48.91543\n",
      "Episode reward: 64.467006\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7976     |\n",
      "|    fps              | 3054     |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total_timesteps  | 432882   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 108195   |\n",
      "----------------------------------\n",
      "Episode reward: 52.90991\n",
      "Episode reward: 60.788699\n",
      "Episode reward: 77.707905\n",
      "Episode reward: 35.745663\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7980     |\n",
      "|    fps              | 3053     |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total_timesteps  | 433110   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.309    |\n",
      "|    n_updates        | 108252   |\n",
      "----------------------------------\n",
      "Episode reward: 43.704062\n",
      "Episode reward: 78.793161\n",
      "Episode reward: 102.305956\n",
      "Episode reward: 39.820333\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7984     |\n",
      "|    fps              | 3053     |\n",
      "|    time_elapsed     | 141      |\n",
      "|    total_timesteps  | 433377   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00811  |\n",
      "|    n_updates        | 108319   |\n",
      "----------------------------------\n",
      "Episode reward: 59.876278\n",
      "Episode reward: 54.960718\n",
      "Episode reward: 65.165904\n",
      "Episode reward: 39.936449\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7988     |\n",
      "|    fps              | 3053     |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 433599   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0145   |\n",
      "|    n_updates        | 108374   |\n",
      "----------------------------------\n",
      "Episode reward: 51.55812\n",
      "Episode reward: 86.135211\n",
      "Episode reward: 62.535068\n",
      "Episode reward: 49.668963\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7992     |\n",
      "|    fps              | 3053     |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 433855   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0358   |\n",
      "|    n_updates        | 108438   |\n",
      "----------------------------------\n",
      "Episode reward: 59.913594\n",
      "Episode reward: 51.811947\n",
      "Episode reward: 73.709802\n",
      "Episode reward: 41.815983\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 7996     |\n",
      "|    fps              | 3053     |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 434085   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 108496   |\n",
      "----------------------------------\n",
      "Episode reward: 76.504068\n",
      "Episode reward: 54.788763\n",
      "Episode reward: 55.793158\n",
      "Episode reward: 34.908817\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8000     |\n",
      "|    fps              | 3053     |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 434308   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.522    |\n",
      "|    n_updates        | 108551   |\n",
      "----------------------------------\n",
      "Episode reward: 65.806945\n",
      "Episode reward: 43.889451\n",
      "Episode reward: 47.83215\n",
      "Episode reward: 47.742711\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8004     |\n",
      "|    fps              | 3053     |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 434514   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0493   |\n",
      "|    n_updates        | 108603   |\n",
      "----------------------------------\n",
      "Episode reward: 63.995049\n",
      "Episode reward: 58.670246\n",
      "Episode reward: 63.474025\n",
      "Episode reward: 86.191733\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8008     |\n",
      "|    fps              | 3053     |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 434791   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0213   |\n",
      "|    n_updates        | 108672   |\n",
      "----------------------------------\n",
      "Episode reward: 89.604091\n",
      "Episode reward: 54.810953\n",
      "Episode reward: 51.772337\n",
      "Episode reward: 43.945259\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8012     |\n",
      "|    fps              | 3053     |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 435035   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.02     |\n",
      "|    n_updates        | 108733   |\n",
      "----------------------------------\n",
      "Episode reward: 51.671769\n",
      "Episode reward: 74.733474\n",
      "Episode reward: 44.904822\n",
      "Episode reward: 62.689926\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8016     |\n",
      "|    fps              | 3052     |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 435270   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.364    |\n",
      "|    n_updates        | 108792   |\n",
      "----------------------------------\n",
      "Episode reward: 50.924828\n",
      "Episode reward: 31.859743\n",
      "Episode reward: 95.770136\n",
      "Episode reward: 54.832959\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8020     |\n",
      "|    fps              | 3052     |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 435504   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 108850   |\n",
      "----------------------------------\n",
      "Episode reward: 42.952595\n",
      "Episode reward: 38.89098\n",
      "Episode reward: 51.860595\n",
      "Episode reward: 53.66606\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8024     |\n",
      "|    fps              | 3052     |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 435692   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.182    |\n",
      "|    n_updates        | 108897   |\n",
      "----------------------------------\n",
      "Episode reward: 42.92281\n",
      "Episode reward: 99.174921\n",
      "Episode reward: 64.720744\n",
      "Episode reward: 52.875514\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8028     |\n",
      "|    fps              | 3051     |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 435954   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.44     |\n",
      "|    n_updates        | 108963   |\n",
      "----------------------------------\n",
      "Episode reward: 47.883946\n",
      "Episode reward: 46.691906\n",
      "Episode reward: 38.947702\n",
      "Episode reward: 59.699484\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8032     |\n",
      "|    fps              | 3051     |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 436148   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0253   |\n",
      "|    n_updates        | 109011   |\n",
      "----------------------------------\n",
      "Episode reward: 52.766274\n",
      "Episode reward: 71.426994\n",
      "Episode reward: 54.873152\n",
      "Episode reward: 68.815519\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8036     |\n",
      "|    fps              | 3051     |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total_timesteps  | 436398   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 109074   |\n",
      "----------------------------------\n",
      "Episode reward: 46.488174\n",
      "Episode reward: 57.908718\n",
      "Episode reward: 54.713143\n",
      "Episode reward: 78.017745\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8040     |\n",
      "|    fps              | 3051     |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total_timesteps  | 436637   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0283   |\n",
      "|    n_updates        | 109134   |\n",
      "----------------------------------\n",
      "Episode reward: 36.881954\n",
      "Episode reward: 60.88777\n",
      "Episode reward: 59.29043\n",
      "Episode reward: 43.922068\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8044     |\n",
      "|    fps              | 3051     |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total_timesteps  | 436839   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00808  |\n",
      "|    n_updates        | 109184   |\n",
      "----------------------------------\n",
      "Episode reward: 53.71018\n",
      "Episode reward: 63.843906\n",
      "Episode reward: 54.362729\n",
      "Episode reward: 35.89034\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8048     |\n",
      "|    fps              | 3051     |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total_timesteps  | 437048   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.332    |\n",
      "|    n_updates        | 109236   |\n",
      "----------------------------------\n",
      "Episode reward: 43.877261\n",
      "Episode reward: 75.823001\n",
      "Episode reward: 106.165359\n",
      "Episode reward: 55.886158\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8052     |\n",
      "|    fps              | 3050     |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total_timesteps  | 437337   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.963    |\n",
      "|    n_updates        | 109309   |\n",
      "----------------------------------\n",
      "Episode reward: 72.244903\n",
      "Episode reward: 84.234084\n",
      "Episode reward: 56.751163\n",
      "Episode reward: 47.798843\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8056     |\n",
      "|    fps              | 3049     |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total_timesteps  | 437603   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 109375   |\n",
      "----------------------------------\n",
      "Episode reward: 49.669642\n",
      "Episode reward: 39.786992\n",
      "Episode reward: 40.915676\n",
      "Episode reward: 56.871533\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8060     |\n",
      "|    fps              | 3049     |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total_timesteps  | 437791   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.372    |\n",
      "|    n_updates        | 109422   |\n",
      "----------------------------------\n",
      "Episode reward: 59.898656\n",
      "Episode reward: 74.378949\n",
      "Episode reward: 68.096241\n",
      "Episode reward: 31.724284\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8064     |\n",
      "|    fps              | 3049     |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total_timesteps  | 438032   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 109482   |\n",
      "----------------------------------\n",
      "Episode reward: 51.844696\n",
      "Episode reward: 71.544157\n",
      "Episode reward: 64.557205\n",
      "Episode reward: 55.906663\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8068     |\n",
      "|    fps              | 3049     |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total_timesteps  | 438277   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.33     |\n",
      "|    n_updates        | 109544   |\n",
      "----------------------------------\n",
      "Episode reward: 74.956099\n",
      "Episode reward: 42.583124\n",
      "Episode reward: 99.494639\n",
      "Episode reward: 93.381291\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8072     |\n",
      "|    fps              | 3048     |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total_timesteps  | 438605   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00642  |\n",
      "|    n_updates        | 109626   |\n",
      "----------------------------------\n",
      "Episode reward: 50.681817\n",
      "Episode reward: 56.500411\n",
      "Episode reward: 74.654656\n",
      "Episode reward: 42.865739\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8076     |\n",
      "|    fps              | 3048     |\n",
      "|    time_elapsed     | 143      |\n",
      "|    total_timesteps  | 438831   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00927  |\n",
      "|    n_updates        | 109682   |\n",
      "----------------------------------\n",
      "Episode reward: 55.907298\n",
      "Episode reward: 98.743602\n",
      "Episode reward: 48.852186\n",
      "Episode reward: 42.907005\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8080     |\n",
      "|    fps              | 3048     |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 439079   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.367    |\n",
      "|    n_updates        | 109744   |\n",
      "----------------------------------\n",
      "Episode reward: 42.918886\n",
      "Episode reward: 47.90004\n",
      "Episode reward: 39.924852\n",
      "Episode reward: 63.847293\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8084     |\n",
      "|    fps              | 3047     |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 439274   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.172    |\n",
      "|    n_updates        | 109793   |\n",
      "----------------------------------\n",
      "Episode reward: 39.883069\n",
      "Episode reward: 52.791457\n",
      "Episode reward: 44.904137\n",
      "Episode reward: 98.209786\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8088     |\n",
      "|    fps              | 3047     |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 439511   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.261    |\n",
      "|    n_updates        | 109852   |\n",
      "----------------------------------\n",
      "Episode reward: 35.952087\n",
      "Episode reward: 36.930184\n",
      "Episode reward: 85.601936\n",
      "Episode reward: 90.269654\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8092     |\n",
      "|    fps              | 3047     |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 439764   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.362    |\n",
      "|    n_updates        | 109915   |\n",
      "----------------------------------\n",
      "Episode reward: 54.866527\n",
      "Episode reward: 102.508968\n",
      "Episode reward: 71.113763\n",
      "Episode reward: 85.712906\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8096     |\n",
      "|    fps              | 3047     |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 440083   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0261   |\n",
      "|    n_updates        | 109995   |\n",
      "----------------------------------\n",
      "Episode reward: 68.872421\n",
      "Episode reward: 50.91351\n",
      "Episode reward: 35.86481\n",
      "Episode reward: 49.932906\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8100     |\n",
      "|    fps              | 3047     |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 440289   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.24     |\n",
      "|    n_updates        | 110047   |\n",
      "----------------------------------\n",
      "Episode reward: 33.951103\n",
      "Episode reward: 40.887379\n",
      "Episode reward: 58.886161\n",
      "Episode reward: 43.729712\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8104     |\n",
      "|    fps              | 3047     |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 440467   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0245   |\n",
      "|    n_updates        | 110091   |\n",
      "----------------------------------\n",
      "Episode reward: 63.892044\n",
      "Episode reward: 78.614378\n",
      "Episode reward: 54.909031\n",
      "Episode reward: 49.930798\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8108     |\n",
      "|    fps              | 3046     |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 440719   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.149    |\n",
      "|    n_updates        | 110154   |\n",
      "----------------------------------\n",
      "Episode reward: 76.806678\n",
      "Episode reward: 33.949169\n",
      "Episode reward: 38.883752\n",
      "Episode reward: 38.792675\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8112     |\n",
      "|    fps              | 3046     |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 440908   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.396    |\n",
      "|    n_updates        | 110201   |\n",
      "----------------------------------\n",
      "Episode reward: 68.780724\n",
      "Episode reward: 94.777388\n",
      "Episode reward: 103.842523\n",
      "Episode reward: 57.907692\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8116     |\n",
      "|    fps              | 3045     |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 441243   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00913  |\n",
      "|    n_updates        | 110285   |\n",
      "----------------------------------\n",
      "Episode reward: 44.925789\n",
      "Episode reward: 72.627997\n",
      "Episode reward: 57.623649\n",
      "Episode reward: 57.749843\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8120     |\n",
      "|    fps              | 3044     |\n",
      "|    time_elapsed     | 144      |\n",
      "|    total_timesteps  | 441481   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00701  |\n",
      "|    n_updates        | 110345   |\n",
      "----------------------------------\n",
      "Episode reward: 48.314909\n",
      "Episode reward: 33.890564\n",
      "Episode reward: 58.541003\n",
      "Episode reward: 80.720387\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8124     |\n",
      "|    fps              | 3044     |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total_timesteps  | 441704   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.407    |\n",
      "|    n_updates        | 110400   |\n",
      "----------------------------------\n",
      "Episode reward: 60.264551\n",
      "Episode reward: 67.770212\n",
      "Episode reward: 57.290557\n",
      "Episode reward: 58.904173\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8128     |\n",
      "|    fps              | 3044     |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total_timesteps  | 441950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 110462   |\n",
      "----------------------------------\n",
      "Episode reward: 70.762928\n",
      "Episode reward: 65.837788\n",
      "Episode reward: 72.122031\n",
      "Episode reward: 53.922629\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8132     |\n",
      "|    fps              | 3044     |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total_timesteps  | 442214   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 110528   |\n",
      "----------------------------------\n",
      "Episode reward: 52.899044\n",
      "Episode reward: 62.652936\n",
      "Episode reward: 46.890795\n",
      "Episode reward: 58.677874\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8136     |\n",
      "|    fps              | 3043     |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total_timesteps  | 442437   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0265   |\n",
      "|    n_updates        | 110584   |\n",
      "----------------------------------\n",
      "Episode reward: 49.782821\n",
      "Episode reward: 56.892009\n",
      "Episode reward: 80.633097\n",
      "Episode reward: 51.883444\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8140     |\n",
      "|    fps              | 3043     |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total_timesteps  | 442677   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.892    |\n",
      "|    n_updates        | 110644   |\n",
      "----------------------------------\n",
      "Episode reward: 54.749371\n",
      "Episode reward: 85.377762\n",
      "Episode reward: 45.835785\n",
      "Episode reward: 43.872279\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8144     |\n",
      "|    fps              | 3043     |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total_timesteps  | 442914   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 110703   |\n",
      "----------------------------------\n",
      "Episode reward: 65.601059\n",
      "Episode reward: 48.617522\n",
      "Episode reward: 48.741892\n",
      "Episode reward: 83.488755\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8148     |\n",
      "|    fps              | 3043     |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total_timesteps  | 443162   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.426    |\n",
      "|    n_updates        | 110765   |\n",
      "----------------------------------\n",
      "Episode reward: 54.68187\n",
      "Episode reward: 58.878603\n",
      "Episode reward: 68.836306\n",
      "Episode reward: 62.759733\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8152     |\n",
      "|    fps              | 3042     |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total_timesteps  | 443408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.322    |\n",
      "|    n_updates        | 110826   |\n",
      "----------------------------------\n",
      "Episode reward: 48.880013\n",
      "Episode reward: 38.876895\n",
      "Episode reward: 65.579259\n",
      "Episode reward: 95.590923\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8156     |\n",
      "|    fps              | 3042     |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total_timesteps  | 443660   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0602   |\n",
      "|    n_updates        | 110889   |\n",
      "----------------------------------\n",
      "Episode reward: 51.37973\n",
      "Episode reward: 39.917953\n",
      "Episode reward: 54.090426\n",
      "Episode reward: 45.924289\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8160     |\n",
      "|    fps              | 3042     |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total_timesteps  | 443853   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.019    |\n",
      "|    n_updates        | 110938   |\n",
      "----------------------------------\n",
      "Episode reward: 52.921393\n",
      "Episode reward: 47.898022\n",
      "Episode reward: 66.830095\n",
      "Episode reward: 66.787111\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8164     |\n",
      "|    fps              | 3042     |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total_timesteps  | 444088   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.77     |\n",
      "|    n_updates        | 110996   |\n",
      "----------------------------------\n",
      "Episode reward: 34.612698\n",
      "Episode reward: 60.827978\n",
      "Episode reward: 52.686184\n",
      "Episode reward: 67.518562\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8168     |\n",
      "|    fps              | 3042     |\n",
      "|    time_elapsed     | 146      |\n",
      "|    total_timesteps  | 444305   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.246    |\n",
      "|    n_updates        | 111051   |\n",
      "----------------------------------\n",
      "Episode reward: 53.302825\n",
      "Episode reward: 55.890671\n",
      "Episode reward: 54.613082\n",
      "Episode reward: 82.410521\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8172     |\n",
      "|    fps              | 3041     |\n",
      "|    time_elapsed     | 146      |\n",
      "|    total_timesteps  | 444553   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0184   |\n",
      "|    n_updates        | 111113   |\n",
      "----------------------------------\n",
      "Episode reward: 64.177021\n",
      "Episode reward: 38.891477\n",
      "Episode reward: 65.8037\n",
      "Episode reward: 31.939055\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8176     |\n",
      "|    fps              | 3041     |\n",
      "|    time_elapsed     | 146      |\n",
      "|    total_timesteps  | 444755   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.266    |\n",
      "|    n_updates        | 111163   |\n",
      "----------------------------------\n",
      "Episode reward: 56.723309\n",
      "Episode reward: 109.450063\n",
      "Episode reward: 39.840563\n",
      "Episode reward: 87.128575\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8180     |\n",
      "|    fps              | 3041     |\n",
      "|    time_elapsed     | 146      |\n",
      "|    total_timesteps  | 445053   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 111238   |\n",
      "----------------------------------\n",
      "Episode reward: 38.838575\n",
      "Episode reward: 82.661807\n",
      "Episode reward: 40.717132\n",
      "Episode reward: 47.939078\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8184     |\n",
      "|    fps              | 3041     |\n",
      "|    time_elapsed     | 146      |\n",
      "|    total_timesteps  | 445264   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0132   |\n",
      "|    n_updates        | 111290   |\n",
      "----------------------------------\n",
      "Episode reward: 81.631287\n",
      "Episode reward: 57.721419\n",
      "Episode reward: 64.869087\n",
      "Episode reward: 36.874819\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8188     |\n",
      "|    fps              | 3041     |\n",
      "|    time_elapsed     | 146      |\n",
      "|    total_timesteps  | 445507   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0791   |\n",
      "|    n_updates        | 111351   |\n",
      "----------------------------------\n",
      "Episode reward: 45.412548\n",
      "Episode reward: 76.735587\n",
      "Episode reward: 39.89087\n",
      "Episode reward: 62.882943\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8192     |\n",
      "|    fps              | 3041     |\n",
      "|    time_elapsed     | 146      |\n",
      "|    total_timesteps  | 445738   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0292   |\n",
      "|    n_updates        | 111409   |\n",
      "----------------------------------\n",
      "Episode reward: 63.990876\n",
      "Episode reward: 65.851466\n",
      "Episode reward: 70.451621\n",
      "Episode reward: 45.871643\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8196     |\n",
      "|    fps              | 3040     |\n",
      "|    time_elapsed     | 146      |\n",
      "|    total_timesteps  | 445987   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 111471   |\n",
      "----------------------------------\n",
      "Episode reward: 82.687862\n",
      "Episode reward: 76.829905\n",
      "Episode reward: 57.874115\n",
      "Episode reward: 41.913585\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8200     |\n",
      "|    fps              | 3040     |\n",
      "|    time_elapsed     | 146      |\n",
      "|    total_timesteps  | 446250   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.349    |\n",
      "|    n_updates        | 111537   |\n",
      "----------------------------------\n",
      "Episode reward: 61.715525\n",
      "Episode reward: 80.802881\n",
      "Episode reward: 103.581474\n",
      "Episode reward: 51.859327\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8204     |\n",
      "|    fps              | 3040     |\n",
      "|    time_elapsed     | 146      |\n",
      "|    total_timesteps  | 446549   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0284   |\n",
      "|    n_updates        | 111612   |\n",
      "----------------------------------\n",
      "Episode reward: 36.841625\n",
      "Episode reward: 37.938802\n",
      "Episode reward: 52.896435\n",
      "Episode reward: 68.577589\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8208     |\n",
      "|    fps              | 3040     |\n",
      "|    time_elapsed     | 146      |\n",
      "|    total_timesteps  | 446746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.604    |\n",
      "|    n_updates        | 111661   |\n",
      "----------------------------------\n",
      "Episode reward: 42.850411\n",
      "Episode reward: 35.934023\n",
      "Episode reward: 56.921109\n",
      "Episode reward: 39.831339\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8212     |\n",
      "|    fps              | 3040     |\n",
      "|    time_elapsed     | 146      |\n",
      "|    total_timesteps  | 446922   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.381    |\n",
      "|    n_updates        | 111705   |\n",
      "----------------------------------\n",
      "Episode reward: 43.894564\n",
      "Episode reward: 81.044104\n",
      "Episode reward: 75.052096\n",
      "Episode reward: 73.47603\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8216     |\n",
      "|    fps              | 3040     |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total_timesteps  | 447200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.382    |\n",
      "|    n_updates        | 111774   |\n",
      "----------------------------------\n",
      "Episode reward: 39.852314\n",
      "Episode reward: 37.884733\n",
      "Episode reward: 60.710282\n",
      "Episode reward: 61.797751\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8220     |\n",
      "|    fps              | 3039     |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total_timesteps  | 447401   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0195   |\n",
      "|    n_updates        | 111825   |\n",
      "----------------------------------\n",
      "Episode reward: 49.652188\n",
      "Episode reward: 83.523456\n",
      "Episode reward: 70.016581\n",
      "Episode reward: 36.812732\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8224     |\n",
      "|    fps              | 3039     |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total_timesteps  | 447648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0237   |\n",
      "|    n_updates        | 111886   |\n",
      "----------------------------------\n",
      "Episode reward: 45.896434\n",
      "Episode reward: 54.778858\n",
      "Episode reward: 58.713644\n",
      "Episode reward: 66.738672\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8228     |\n",
      "|    fps              | 3039     |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total_timesteps  | 447875   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.653    |\n",
      "|    n_updates        | 111943   |\n",
      "----------------------------------\n",
      "Episode reward: 46.394422\n",
      "Episode reward: 72.627537\n",
      "Episode reward: 74.634066\n",
      "Episode reward: 83.210446\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8232     |\n",
      "|    fps              | 3039     |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total_timesteps  | 448156   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 112013   |\n",
      "----------------------------------\n",
      "Episode reward: 78.94814\n",
      "Episode reward: 49.689706\n",
      "Episode reward: 55.331547\n",
      "Episode reward: 86.557786\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8236     |\n",
      "|    fps              | 3038     |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total_timesteps  | 448429   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 112082   |\n",
      "----------------------------------\n",
      "Episode reward: 65.414332\n",
      "Episode reward: 133.38989\n",
      "Episode reward: 77.542773\n",
      "Episode reward: 102.334863\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8240     |\n",
      "|    fps              | 3038     |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total_timesteps  | 448820   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.531    |\n",
      "|    n_updates        | 112179   |\n",
      "----------------------------------\n",
      "Episode reward: 73.832108\n",
      "Episode reward: 55.79169\n",
      "Episode reward: 48.381691\n",
      "Episode reward: 62.845939\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8244     |\n",
      "|    fps              | 3038     |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total_timesteps  | 449064   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.424    |\n",
      "|    n_updates        | 112240   |\n",
      "----------------------------------\n",
      "Episode reward: 37.857835\n",
      "Episode reward: 50.70075\n",
      "Episode reward: 67.290857\n",
      "Episode reward: 41.949818\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8248     |\n",
      "|    fps              | 3038     |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total_timesteps  | 449263   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 112290   |\n",
      "----------------------------------\n",
      "Episode reward: 43.565341\n",
      "Episode reward: 37.918613\n",
      "Episode reward: 52.849577\n",
      "Episode reward: 73.747891\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8252     |\n",
      "|    fps              | 3038     |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total_timesteps  | 449472   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.418    |\n",
      "|    n_updates        | 112342   |\n",
      "----------------------------------\n",
      "Episode reward: 40.904557\n",
      "Episode reward: 50.671978\n",
      "Episode reward: 37.784141\n",
      "Episode reward: 37.957571\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8256     |\n",
      "|    fps              | 3037     |\n",
      "|    time_elapsed     | 148      |\n",
      "|    total_timesteps  | 449640   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 112384   |\n",
      "----------------------------------\n",
      "Episode reward: 69.649946\n",
      "Episode reward: 44.903992\n",
      "Episode reward: 56.316562\n",
      "Episode reward: 68.944944\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8260     |\n",
      "|    fps              | 3037     |\n",
      "|    time_elapsed     | 148      |\n",
      "|    total_timesteps  | 449883   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.85     |\n",
      "|    n_updates        | 112445   |\n",
      "----------------------------------\n",
      "Episode reward: 95.869806\n",
      "Episode reward: 40.743302\n",
      "Episode reward: 61.551707\n",
      "Episode reward: 48.855066\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8264     |\n",
      "|    fps              | 3037     |\n",
      "|    time_elapsed     | 148      |\n",
      "|    total_timesteps  | 450133   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.232    |\n",
      "|    n_updates        | 112508   |\n",
      "----------------------------------\n",
      "Episode reward: 47.886822\n",
      "Episode reward: 68.184085\n",
      "Episode reward: 65.106672\n",
      "Episode reward: 63.788494\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8268     |\n",
      "|    fps              | 3037     |\n",
      "|    time_elapsed     | 148      |\n",
      "|    total_timesteps  | 450380   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.432    |\n",
      "|    n_updates        | 112569   |\n",
      "----------------------------------\n",
      "Episode reward: 60.70839\n",
      "Episode reward: 40.92268\n",
      "Episode reward: 84.699185\n",
      "Episode reward: 87.368068\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8272     |\n",
      "|    fps              | 3037     |\n",
      "|    time_elapsed     | 148      |\n",
      "|    total_timesteps  | 450656   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0218   |\n",
      "|    n_updates        | 112638   |\n",
      "----------------------------------\n",
      "Episode reward: 46.906725\n",
      "Episode reward: 81.748832\n",
      "Episode reward: 46.881839\n",
      "Episode reward: 60.800868\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8276     |\n",
      "|    fps              | 3037     |\n",
      "|    time_elapsed     | 148      |\n",
      "|    total_timesteps  | 450893   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0229   |\n",
      "|    n_updates        | 112698   |\n",
      "----------------------------------\n",
      "Episode reward: 65.750299\n",
      "Episode reward: 84.990596\n",
      "Episode reward: 57.629983\n",
      "Episode reward: 110.123003\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8280     |\n",
      "|    fps              | 3037     |\n",
      "|    time_elapsed     | 148      |\n",
      "|    total_timesteps  | 451214   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0209   |\n",
      "|    n_updates        | 112778   |\n",
      "----------------------------------\n",
      "Episode reward: 86.208577\n",
      "Episode reward: 89.900602\n",
      "Episode reward: 46.716941\n",
      "Episode reward: 59.468318\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8284     |\n",
      "|    fps              | 3037     |\n",
      "|    time_elapsed     | 148      |\n",
      "|    total_timesteps  | 451500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 112849   |\n",
      "----------------------------------\n",
      "Episode reward: 88.668858\n",
      "Episode reward: 52.867924\n",
      "Episode reward: 35.69446\n",
      "Episode reward: 48.51775\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8288     |\n",
      "|    fps              | 3037     |\n",
      "|    time_elapsed     | 148      |\n",
      "|    total_timesteps  | 451728   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.164    |\n",
      "|    n_updates        | 112906   |\n",
      "----------------------------------\n",
      "Episode reward: 67.799197\n",
      "Episode reward: 67.893699\n",
      "Episode reward: 49.924828\n",
      "Episode reward: 59.804685\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8292     |\n",
      "|    fps              | 3037     |\n",
      "|    time_elapsed     | 148      |\n",
      "|    total_timesteps  | 451975   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00948  |\n",
      "|    n_updates        | 112968   |\n",
      "----------------------------------\n",
      "Episode reward: 60.338111\n",
      "Episode reward: 48.743099\n",
      "Episode reward: 53.592446\n",
      "Episode reward: 64.376919\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8296     |\n",
      "|    fps              | 3036     |\n",
      "|    time_elapsed     | 148      |\n",
      "|    total_timesteps  | 452204   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0234   |\n",
      "|    n_updates        | 113025   |\n",
      "----------------------------------\n",
      "Episode reward: 126.935435\n",
      "Episode reward: 36.957055\n",
      "Episode reward: 47.877127\n",
      "Episode reward: 43.850258\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8300     |\n",
      "|    fps              | 3037     |\n",
      "|    time_elapsed     | 148      |\n",
      "|    total_timesteps  | 452473   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 113093   |\n",
      "----------------------------------\n",
      "Episode reward: 55.500233\n",
      "Episode reward: 134.955139\n",
      "Episode reward: 60.730506\n",
      "Episode reward: 46.921327\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8304     |\n",
      "|    fps              | 3037     |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total_timesteps  | 452775   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0327   |\n",
      "|    n_updates        | 113168   |\n",
      "----------------------------------\n",
      "Episode reward: 84.395732\n",
      "Episode reward: 55.893327\n",
      "Episode reward: 37.956307\n",
      "Episode reward: 62.359439\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8308     |\n",
      "|    fps              | 3037     |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total_timesteps  | 453017   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.529    |\n",
      "|    n_updates        | 113229   |\n",
      "----------------------------------\n",
      "Episode reward: 54.890759\n",
      "Episode reward: 45.875673\n",
      "Episode reward: 65.862621\n",
      "Episode reward: 57.844104\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8312     |\n",
      "|    fps              | 3036     |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total_timesteps  | 453242   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.464    |\n",
      "|    n_updates        | 113285   |\n",
      "----------------------------------\n",
      "Episode reward: 117.642098\n",
      "Episode reward: 56.879402\n",
      "Episode reward: 43.840869\n",
      "Episode reward: 42.928732\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8316     |\n",
      "|    fps              | 3036     |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total_timesteps  | 453507   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 113351   |\n",
      "----------------------------------\n",
      "Episode reward: 97.906046\n",
      "Episode reward: 61.683014\n",
      "Episode reward: 80.44716\n",
      "Episode reward: 41.755533\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8320     |\n",
      "|    fps              | 3035     |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total_timesteps  | 453795   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0309   |\n",
      "|    n_updates        | 113423   |\n",
      "----------------------------------\n",
      "Episode reward: 46.931222\n",
      "Episode reward: 87.220896\n",
      "Episode reward: 67.637178\n",
      "Episode reward: 67.594196\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8324     |\n",
      "|    fps              | 3035     |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total_timesteps  | 454066   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.442    |\n",
      "|    n_updates        | 113491   |\n",
      "----------------------------------\n",
      "Episode reward: 42.884433\n",
      "Episode reward: 50.765281\n",
      "Episode reward: 53.885524\n",
      "Episode reward: 33.861763\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8328     |\n",
      "|    fps              | 3035     |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total_timesteps  | 454248   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0457   |\n",
      "|    n_updates        | 113536   |\n",
      "----------------------------------\n",
      "Episode reward: 64.872116\n",
      "Episode reward: 78.800771\n",
      "Episode reward: 63.216043\n",
      "Episode reward: 65.838834\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8332     |\n",
      "|    fps              | 3035     |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total_timesteps  | 454524   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 113605   |\n",
      "----------------------------------\n",
      "Episode reward: 68.945052\n",
      "Episode reward: 58.436292\n",
      "Episode reward: 70.943288\n",
      "Episode reward: 44.913826\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8336     |\n",
      "|    fps              | 3034     |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total_timesteps  | 454771   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.2      |\n",
      "|    n_updates        | 113667   |\n",
      "----------------------------------\n",
      "Episode reward: 35.948273\n",
      "Episode reward: 120.183259\n",
      "Episode reward: 81.806085\n",
      "Episode reward: 49.899775\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8340     |\n",
      "|    fps              | 3034     |\n",
      "|    time_elapsed     | 149      |\n",
      "|    total_timesteps  | 455060   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0211   |\n",
      "|    n_updates        | 113739   |\n",
      "----------------------------------\n",
      "Episode reward: 34.733267\n",
      "Episode reward: 37.898533\n",
      "Episode reward: 49.522054\n",
      "Episode reward: 28.921393\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8344     |\n",
      "|    fps              | 3034     |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 455212   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.47     |\n",
      "|    n_updates        | 113777   |\n",
      "----------------------------------\n",
      "Episode reward: 95.257573\n",
      "Episode reward: 59.871705\n",
      "Episode reward: 81.23737\n",
      "Episode reward: 38.700002\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8348     |\n",
      "|    fps              | 3034     |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 455489   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.794    |\n",
      "|    n_updates        | 113847   |\n",
      "----------------------------------\n",
      "Episode reward: 56.847522\n",
      "Episode reward: 55.758319\n",
      "Episode reward: 66.8648\n",
      "Episode reward: 42.441676\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8352     |\n",
      "|    fps              | 3034     |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 455712   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.398    |\n",
      "|    n_updates        | 113902   |\n",
      "----------------------------------\n",
      "Episode reward: 49.713954\n",
      "Episode reward: 89.64771\n",
      "Episode reward: 44.85683\n",
      "Episode reward: 89.849933\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8356     |\n",
      "|    fps              | 3034     |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 456005   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00778  |\n",
      "|    n_updates        | 113976   |\n",
      "----------------------------------\n",
      "Episode reward: 79.393716\n",
      "Episode reward: 71.872976\n",
      "Episode reward: 61.857463\n",
      "Episode reward: 38.634117\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8360     |\n",
      "|    fps              | 3034     |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 456258   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.913    |\n",
      "|    n_updates        | 114039   |\n",
      "----------------------------------\n",
      "Episode reward: 45.858543\n",
      "Episode reward: 66.663383\n",
      "Episode reward: 66.507334\n",
      "Episode reward: 83.69497\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8364     |\n",
      "|    fps              | 3034     |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 456522   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00889  |\n",
      "|    n_updates        | 114105   |\n",
      "----------------------------------\n",
      "Episode reward: 110.648674\n",
      "Episode reward: 42.953879\n",
      "Episode reward: 68.803091\n",
      "Episode reward: 35.911373\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8368     |\n",
      "|    fps              | 3034     |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 456781   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0115   |\n",
      "|    n_updates        | 114170   |\n",
      "----------------------------------\n",
      "Episode reward: 55.691966\n",
      "Episode reward: 44.855146\n",
      "Episode reward: 36.852121\n",
      "Episode reward: 40.942139\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8372     |\n",
      "|    fps              | 3033     |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 456960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 114214   |\n",
      "----------------------------------\n",
      "Episode reward: 48.880433\n",
      "Episode reward: 47.836057\n",
      "Episode reward: 44.704979\n",
      "Episode reward: 79.432357\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8376     |\n",
      "|    fps              | 3033     |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 457182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0113   |\n",
      "|    n_updates        | 114270   |\n",
      "----------------------------------\n",
      "Episode reward: 48.910713\n",
      "Episode reward: 66.767327\n",
      "Episode reward: 60.834063\n",
      "Episode reward: 56.849582\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8380     |\n",
      "|    fps              | 3034     |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 457418   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.454    |\n",
      "|    n_updates        | 114329   |\n",
      "----------------------------------\n",
      "Episode reward: 40.940477\n",
      "Episode reward: 37.655561\n",
      "Episode reward: 67.794131\n",
      "Episode reward: 49.905037\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8384     |\n",
      "|    fps              | 3033     |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 457615   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.38     |\n",
      "|    n_updates        | 114378   |\n",
      "----------------------------------\n",
      "Episode reward: 90.659001\n",
      "Episode reward: 51.729869\n",
      "Episode reward: 76.806095\n",
      "Episode reward: 63.833419\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8388     |\n",
      "|    fps              | 3032     |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 457899   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 114449   |\n",
      "----------------------------------\n",
      "Episode reward: 70.822638\n",
      "Episode reward: 69.666226\n",
      "Episode reward: 39.926377\n",
      "Episode reward: 64.124246\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8392     |\n",
      "|    fps              | 3032     |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 458145   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00879  |\n",
      "|    n_updates        | 114511   |\n",
      "----------------------------------\n",
      "Episode reward: 66.865791\n",
      "Episode reward: 54.653326\n",
      "Episode reward: 43.854573\n",
      "Episode reward: 55.688253\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8396     |\n",
      "|    fps              | 3032     |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 458367   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 114566   |\n",
      "----------------------------------\n",
      "Episode reward: 42.952468\n",
      "Episode reward: 56.80114\n",
      "Episode reward: 48.854371\n",
      "Episode reward: 60.795249\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8400     |\n",
      "|    fps              | 3031     |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 458577   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 114619   |\n",
      "----------------------------------\n",
      "Episode reward: 44.833945\n",
      "Episode reward: 57.863786\n",
      "Episode reward: 81.625333\n",
      "Episode reward: 41.875752\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8404     |\n",
      "|    fps              | 3032     |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 458804   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.524    |\n",
      "|    n_updates        | 114675   |\n",
      "----------------------------------\n",
      "Episode reward: 78.782962\n",
      "Episode reward: 45.880715\n",
      "Episode reward: 36.813256\n",
      "Episode reward: 39.665397\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8408     |\n",
      "|    fps              | 3031     |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 459006   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.407    |\n",
      "|    n_updates        | 114726   |\n",
      "----------------------------------\n",
      "Episode reward: 55.903162\n",
      "Episode reward: 48.904774\n",
      "Episode reward: 34.94411\n",
      "Episode reward: 80.468338\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8412     |\n",
      "|    fps              | 3031     |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 459227   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 114781   |\n",
      "----------------------------------\n",
      "Episode reward: 79.809221\n",
      "Episode reward: 59.618911\n",
      "Episode reward: 49.860112\n",
      "Episode reward: 47.83264\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8416     |\n",
      "|    fps              | 3031     |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 459465   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.388    |\n",
      "|    n_updates        | 114841   |\n",
      "----------------------------------\n",
      "Episode reward: 71.810187\n",
      "Episode reward: 59.395072\n",
      "Episode reward: 40.849097\n",
      "Episode reward: 36.951329\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8420     |\n",
      "|    fps              | 3031     |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 459675   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0122   |\n",
      "|    n_updates        | 114893   |\n",
      "----------------------------------\n",
      "Episode reward: 48.834924\n",
      "Episode reward: 48.905523\n",
      "Episode reward: 83.497471\n",
      "Episode reward: 43.866205\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8424     |\n",
      "|    fps              | 3030     |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 459901   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0185   |\n",
      "|    n_updates        | 114950   |\n",
      "----------------------------------\n",
      "Episode reward: 69.684177\n",
      "Episode reward: 43.889125\n",
      "Episode reward: 46.934802\n",
      "Episode reward: 57.864397\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8428     |\n",
      "|    fps              | 3030     |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 460120   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 115004   |\n",
      "----------------------------------\n",
      "Episode reward: 79.496181\n",
      "Episode reward: 41.730526\n",
      "Episode reward: 56.674988\n",
      "Episode reward: 82.590526\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8432     |\n",
      "|    fps              | 3030     |\n",
      "|    time_elapsed     | 151      |\n",
      "|    total_timesteps  | 460383   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0312   |\n",
      "|    n_updates        | 115070   |\n",
      "----------------------------------\n",
      "Episode reward: 117.456554\n",
      "Episode reward: 50.876571\n",
      "Episode reward: 52.807572\n",
      "Episode reward: 47.921568\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8436     |\n",
      "|    fps              | 3030     |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total_timesteps  | 460674   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 115143   |\n",
      "----------------------------------\n",
      "Episode reward: 54.664869\n",
      "Episode reward: 40.429596\n",
      "Episode reward: 44.611545\n",
      "Episode reward: 41.951636\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8440     |\n",
      "|    fps              | 3030     |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total_timesteps  | 460857   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0343   |\n",
      "|    n_updates        | 115189   |\n",
      "----------------------------------\n",
      "Episode reward: 37.910759\n",
      "Episode reward: 47.812678\n",
      "Episode reward: 83.749041\n",
      "Episode reward: 46.92316\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8444     |\n",
      "|    fps              | 3030     |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total_timesteps  | 461092   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 115247   |\n",
      "----------------------------------\n",
      "Episode reward: 37.936141\n",
      "Episode reward: 57.864177\n",
      "Episode reward: 39.887775\n",
      "Episode reward: 44.909702\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8448     |\n",
      "|    fps              | 3029     |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total_timesteps  | 461273   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0285   |\n",
      "|    n_updates        | 115293   |\n",
      "----------------------------------\n",
      "Episode reward: 55.627475\n",
      "Episode reward: 35.94611\n",
      "Episode reward: 45.894312\n",
      "Episode reward: 33.89396\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8452     |\n",
      "|    fps              | 3029     |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total_timesteps  | 461445   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.557    |\n",
      "|    n_updates        | 115336   |\n",
      "----------------------------------\n",
      "Episode reward: 49.914164\n",
      "Episode reward: 51.912054\n",
      "Episode reward: 57.807234\n",
      "Episode reward: 36.675598\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8456     |\n",
      "|    fps              | 3029     |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total_timesteps  | 461642   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.489    |\n",
      "|    n_updates        | 115385   |\n",
      "----------------------------------\n",
      "Episode reward: 54.896209\n",
      "Episode reward: 50.041579\n",
      "Episode reward: 34.945647\n",
      "Episode reward: 66.85974\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8460     |\n",
      "|    fps              | 3028     |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total_timesteps  | 461850   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 115437   |\n",
      "----------------------------------\n",
      "Episode reward: 66.862753\n",
      "Episode reward: 59.717687\n",
      "Episode reward: 46.865634\n",
      "Episode reward: 38.892705\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8464     |\n",
      "|    fps              | 3028     |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total_timesteps  | 462063   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0091   |\n",
      "|    n_updates        | 115490   |\n",
      "----------------------------------\n",
      "Episode reward: 81.783233\n",
      "Episode reward: 54.805569\n",
      "Episode reward: 39.94063\n",
      "Episode reward: 26.955609\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8468     |\n",
      "|    fps              | 3028     |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total_timesteps  | 462269   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.708    |\n",
      "|    n_updates        | 115542   |\n",
      "----------------------------------\n",
      "Episode reward: 51.709915\n",
      "Episode reward: 76.40859\n",
      "Episode reward: 38.930729\n",
      "Episode reward: 47.913284\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8472     |\n",
      "|    fps              | 3027     |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total_timesteps  | 462485   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00843  |\n",
      "|    n_updates        | 115596   |\n",
      "----------------------------------\n",
      "Episode reward: 58.379603\n",
      "Episode reward: 51.673231\n",
      "Episode reward: 109.67215\n",
      "Episode reward: 52.779003\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8476     |\n",
      "|    fps              | 3027     |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total_timesteps  | 462770   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.144    |\n",
      "|    n_updates        | 115667   |\n",
      "----------------------------------\n",
      "Episode reward: 67.745626\n",
      "Episode reward: 48.841842\n",
      "Episode reward: 40.905731\n",
      "Episode reward: 53.782945\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8480     |\n",
      "|    fps              | 3027     |\n",
      "|    time_elapsed     | 152      |\n",
      "|    total_timesteps  | 462983   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0392   |\n",
      "|    n_updates        | 115720   |\n",
      "----------------------------------\n",
      "Episode reward: 64.778101\n",
      "Episode reward: 48.917279\n",
      "Episode reward: 82.928364\n",
      "Episode reward: 58.443144\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8484     |\n",
      "|    fps              | 3027     |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 463245   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 115786   |\n",
      "----------------------------------\n",
      "Episode reward: 44.925744\n",
      "Episode reward: 34.879684\n",
      "Episode reward: 68.497543\n",
      "Episode reward: 77.269107\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8488     |\n",
      "|    fps              | 3027     |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 463473   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.249    |\n",
      "|    n_updates        | 115843   |\n",
      "----------------------------------\n",
      "Episode reward: 40.899122\n",
      "Episode reward: 36.896609\n",
      "Episode reward: 62.773544\n",
      "Episode reward: 84.629369\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8492     |\n",
      "|    fps              | 3027     |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 463703   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 115900   |\n",
      "----------------------------------\n",
      "Episode reward: 35.716881\n",
      "Episode reward: 34.943697\n",
      "Episode reward: 75.800981\n",
      "Episode reward: 58.906785\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8496     |\n",
      "|    fps              | 3027     |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 463909   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.604    |\n",
      "|    n_updates        | 115952   |\n",
      "----------------------------------\n",
      "Episode reward: 77.789622\n",
      "Episode reward: 38.877298\n",
      "Episode reward: 40.909769\n",
      "Episode reward: 41.78958\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8500     |\n",
      "|    fps              | 3027     |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 464109   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 116002   |\n",
      "----------------------------------\n",
      "Episode reward: 45.698271\n",
      "Episode reward: 49.722128\n",
      "Episode reward: 57.733576\n",
      "Episode reward: 64.589607\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 54.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8504     |\n",
      "|    fps              | 3027     |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 464328   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.335    |\n",
      "|    n_updates        | 116056   |\n",
      "----------------------------------\n",
      "Episode reward: 62.537444\n",
      "Episode reward: 55.843582\n",
      "Episode reward: 55.811043\n",
      "Episode reward: 48.89511\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.5     |\n",
      "|    ep_rew_mean      | 54.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8508     |\n",
      "|    fps              | 3026     |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 464552   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.221    |\n",
      "|    n_updates        | 116112   |\n",
      "----------------------------------\n",
      "Episode reward: 31.882137\n",
      "Episode reward: 66.305602\n",
      "Episode reward: 27.878326\n",
      "Episode reward: 53.53788\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8512     |\n",
      "|    fps              | 3026     |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 464733   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0191   |\n",
      "|    n_updates        | 116158   |\n",
      "----------------------------------\n",
      "Episode reward: 94.698819\n",
      "Episode reward: 39.933985\n",
      "Episode reward: 74.723823\n",
      "Episode reward: 60.845543\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8516     |\n",
      "|    fps              | 3026     |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 465006   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.681    |\n",
      "|    n_updates        | 116226   |\n",
      "----------------------------------\n",
      "Episode reward: 36.743119\n",
      "Episode reward: 42.914722\n",
      "Episode reward: 65.40434\n",
      "Episode reward: 60.529793\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8520     |\n",
      "|    fps              | 3026     |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 465213   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 116278   |\n",
      "----------------------------------\n",
      "Episode reward: 43.822595\n",
      "Episode reward: 57.529072\n",
      "Episode reward: 40.734999\n",
      "Episode reward: 60.552168\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8524     |\n",
      "|    fps              | 3026     |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 465417   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 116329   |\n",
      "----------------------------------\n",
      "Episode reward: 53.317107\n",
      "Episode reward: 44.862495\n",
      "Episode reward: 73.780716\n",
      "Episode reward: 53.691169\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 54.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8528     |\n",
      "|    fps              | 3026     |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 465645   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 116386   |\n",
      "----------------------------------\n",
      "Episode reward: 31.948538\n",
      "Episode reward: 73.766526\n",
      "Episode reward: 46.835366\n",
      "Episode reward: 73.553721\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.9     |\n",
      "|    ep_rew_mean      | 54       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8532     |\n",
      "|    fps              | 3025     |\n",
      "|    time_elapsed     | 153      |\n",
      "|    total_timesteps  | 465872   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.661    |\n",
      "|    n_updates        | 116442   |\n",
      "----------------------------------\n",
      "Episode reward: 54.718664\n",
      "Episode reward: 39.924471\n",
      "Episode reward: 43.721947\n",
      "Episode reward: 74.66857\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.1     |\n",
      "|    ep_rew_mean      | 53.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8536     |\n",
      "|    fps              | 3025     |\n",
      "|    time_elapsed     | 154      |\n",
      "|    total_timesteps  | 466086   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00981  |\n",
      "|    n_updates        | 116496   |\n",
      "----------------------------------\n",
      "Episode reward: 45.890335\n",
      "Episode reward: 62.07328\n",
      "Episode reward: 43.942225\n",
      "Episode reward: 31.850409\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54.1     |\n",
      "|    ep_rew_mean      | 53.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8540     |\n",
      "|    fps              | 3025     |\n",
      "|    time_elapsed     | 154      |\n",
      "|    total_timesteps  | 466271   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 116542   |\n",
      "----------------------------------\n",
      "Episode reward: 80.728862\n",
      "Episode reward: 53.736584\n",
      "Episode reward: 42.614096\n",
      "Episode reward: 43.918758\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 54       |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8544     |\n",
      "|    fps              | 3024     |\n",
      "|    time_elapsed     | 154      |\n",
      "|    total_timesteps  | 466493   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 116598   |\n",
      "----------------------------------\n",
      "Episode reward: 40.91972\n",
      "Episode reward: 35.890595\n",
      "Episode reward: 41.952852\n",
      "Episode reward: 47.804323\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.9     |\n",
      "|    ep_rew_mean      | 53.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8548     |\n",
      "|    fps              | 3024     |\n",
      "|    time_elapsed     | 154      |\n",
      "|    total_timesteps  | 466660   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0139   |\n",
      "|    n_updates        | 116639   |\n",
      "----------------------------------\n",
      "Episode reward: 60.880161\n",
      "Episode reward: 83.124946\n",
      "Episode reward: 73.274376\n",
      "Episode reward: 70.715871\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.1     |\n",
      "|    ep_rew_mean      | 54.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8552     |\n",
      "|    fps              | 3024     |\n",
      "|    time_elapsed     | 154      |\n",
      "|    total_timesteps  | 466951   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.407    |\n",
      "|    n_updates        | 116712   |\n",
      "----------------------------------\n",
      "Episode reward: 52.885577\n",
      "Episode reward: 32.934265\n",
      "Episode reward: 76.766451\n",
      "Episode reward: 85.178409\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8556     |\n",
      "|    fps              | 3024     |\n",
      "|    time_elapsed     | 154      |\n",
      "|    total_timesteps  | 467201   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 116775   |\n",
      "----------------------------------\n",
      "Episode reward: 66.099177\n",
      "Episode reward: 43.892012\n",
      "Episode reward: 68.839979\n",
      "Episode reward: 107.176904\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8560     |\n",
      "|    fps              | 3024     |\n",
      "|    time_elapsed     | 154      |\n",
      "|    total_timesteps  | 467497   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 116849   |\n",
      "----------------------------------\n",
      "Episode reward: 54.864886\n",
      "Episode reward: 47.904396\n",
      "Episode reward: 76.763919\n",
      "Episode reward: 36.910338\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8564     |\n",
      "|    fps              | 3023     |\n",
      "|    time_elapsed     | 154      |\n",
      "|    total_timesteps  | 467714   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0196   |\n",
      "|    n_updates        | 116903   |\n",
      "----------------------------------\n",
      "Episode reward: 49.907284\n",
      "Episode reward: 65.659992\n",
      "Episode reward: 63.612026\n",
      "Episode reward: 103.734791\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8568     |\n",
      "|    fps              | 3023     |\n",
      "|    time_elapsed     | 154      |\n",
      "|    total_timesteps  | 468001   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0336   |\n",
      "|    n_updates        | 116975   |\n",
      "----------------------------------\n",
      "Episode reward: 63.93934\n",
      "Episode reward: 42.742521\n",
      "Episode reward: 58.757797\n",
      "Episode reward: 42.493803\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8572     |\n",
      "|    fps              | 3023     |\n",
      "|    time_elapsed     | 154      |\n",
      "|    total_timesteps  | 468211   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 117027   |\n",
      "----------------------------------\n",
      "Episode reward: 42.834903\n",
      "Episode reward: 75.422274\n",
      "Episode reward: 55.758148\n",
      "Episode reward: 57.681492\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8576     |\n",
      "|    fps              | 3022     |\n",
      "|    time_elapsed     | 154      |\n",
      "|    total_timesteps  | 468444   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 117085   |\n",
      "----------------------------------\n",
      "Episode reward: 43.737775\n",
      "Episode reward: 52.776794\n",
      "Episode reward: 52.884407\n",
      "Episode reward: 67.828594\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8580     |\n",
      "|    fps              | 3022     |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total_timesteps  | 468662   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.945    |\n",
      "|    n_updates        | 117140   |\n",
      "----------------------------------\n",
      "Episode reward: 87.284522\n",
      "Episode reward: 107.394916\n",
      "Episode reward: 43.918941\n",
      "Episode reward: 32.752875\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8584     |\n",
      "|    fps              | 3021     |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total_timesteps  | 468935   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0226   |\n",
      "|    n_updates        | 117208   |\n",
      "----------------------------------\n",
      "Episode reward: 38.920107\n",
      "Episode reward: 65.169661\n",
      "Episode reward: 36.940531\n",
      "Episode reward: 60.987087\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8588     |\n",
      "|    fps              | 3021     |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total_timesteps  | 469140   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 117259   |\n",
      "----------------------------------\n",
      "Episode reward: 47.909532\n",
      "Episode reward: 45.929168\n",
      "Episode reward: 87.760691\n",
      "Episode reward: 35.889115\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8592     |\n",
      "|    fps              | 3021     |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total_timesteps  | 469358   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.587    |\n",
      "|    n_updates        | 117314   |\n",
      "----------------------------------\n",
      "Episode reward: 59.738372\n",
      "Episode reward: 55.843777\n",
      "Episode reward: 43.882492\n",
      "Episode reward: 42.663019\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8596     |\n",
      "|    fps              | 3021     |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total_timesteps  | 469561   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.983    |\n",
      "|    n_updates        | 117365   |\n",
      "----------------------------------\n",
      "Episode reward: 74.376455\n",
      "Episode reward: 34.95002\n",
      "Episode reward: 84.417998\n",
      "Episode reward: 42.824726\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8600     |\n",
      "|    fps              | 3021     |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total_timesteps  | 469801   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.811    |\n",
      "|    n_updates        | 117425   |\n",
      "----------------------------------\n",
      "Episode reward: 41.922339\n",
      "Episode reward: 52.863355\n",
      "Episode reward: 68.444468\n",
      "Episode reward: 72.663765\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8604     |\n",
      "|    fps              | 3021     |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total_timesteps  | 470040   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 117484   |\n",
      "----------------------------------\n",
      "Episode reward: 58.704907\n",
      "Episode reward: 47.874434\n",
      "Episode reward: 63.867247\n",
      "Episode reward: 52.661094\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8608     |\n",
      "|    fps              | 3021     |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total_timesteps  | 470264   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.54     |\n",
      "|    n_updates        | 117540   |\n",
      "----------------------------------\n",
      "Episode reward: 67.2676\n",
      "Episode reward: 58.887754\n",
      "Episode reward: 96.438762\n",
      "Episode reward: 38.835385\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8612     |\n",
      "|    fps              | 3020     |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total_timesteps  | 470528   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0244   |\n",
      "|    n_updates        | 117606   |\n",
      "----------------------------------\n",
      "Episode reward: 91.140179\n",
      "Episode reward: 83.793279\n",
      "Episode reward: 50.900975\n",
      "Episode reward: 108.967963\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8616     |\n",
      "|    fps              | 3020     |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total_timesteps  | 470872   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.416    |\n",
      "|    n_updates        | 117692   |\n",
      "----------------------------------\n",
      "Episode reward: 35.939413\n",
      "Episode reward: 80.905431\n",
      "Episode reward: 61.814569\n",
      "Episode reward: 41.916696\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8620     |\n",
      "|    fps              | 3020     |\n",
      "|    time_elapsed     | 155      |\n",
      "|    total_timesteps  | 471096   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 117748   |\n",
      "----------------------------------\n",
      "Episode reward: 58.872287\n",
      "Episode reward: 88.378713\n",
      "Episode reward: 31.740966\n",
      "Episode reward: 52.769073\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8624     |\n",
      "|    fps              | 3019     |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 471329   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0242   |\n",
      "|    n_updates        | 117807   |\n",
      "----------------------------------\n",
      "Episode reward: 69.028066\n",
      "Episode reward: 72.131963\n",
      "Episode reward: 60.851505\n",
      "Episode reward: 53.849322\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8628     |\n",
      "|    fps              | 3019     |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 471588   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.873    |\n",
      "|    n_updates        | 117871   |\n",
      "----------------------------------\n",
      "Episode reward: 64.33558\n",
      "Episode reward: 62.547342\n",
      "Episode reward: 55.788497\n",
      "Episode reward: 39.929625\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8632     |\n",
      "|    fps              | 3019     |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 471812   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.627    |\n",
      "|    n_updates        | 117927   |\n",
      "----------------------------------\n",
      "Episode reward: 69.594471\n",
      "Episode reward: 58.532813\n",
      "Episode reward: 91.509677\n",
      "Episode reward: 53.869894\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8636     |\n",
      "|    fps              | 3019     |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 472087   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00908  |\n",
      "|    n_updates        | 117996   |\n",
      "----------------------------------\n",
      "Episode reward: 42.90461\n",
      "Episode reward: 39.88853\n",
      "Episode reward: 45.815339\n",
      "Episode reward: 86.815896\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8640     |\n",
      "|    fps              | 3019     |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 472303   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.878    |\n",
      "|    n_updates        | 118050   |\n",
      "----------------------------------\n",
      "Episode reward: 41.857384\n",
      "Episode reward: 76.734427\n",
      "Episode reward: 61.820666\n",
      "Episode reward: 58.202527\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8644     |\n",
      "|    fps              | 3019     |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 472546   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.286    |\n",
      "|    n_updates        | 118111   |\n",
      "----------------------------------\n",
      "Episode reward: 55.793484\n",
      "Episode reward: 68.64589\n",
      "Episode reward: 36.509614\n",
      "Episode reward: 54.924513\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8648     |\n",
      "|    fps              | 3019     |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 472763   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 118165   |\n",
      "----------------------------------\n",
      "Episode reward: 54.646808\n",
      "Episode reward: 71.111967\n",
      "Episode reward: 44.922628\n",
      "Episode reward: 36.93633\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8652     |\n",
      "|    fps              | 3019     |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 472976   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.531    |\n",
      "|    n_updates        | 118218   |\n",
      "----------------------------------\n",
      "Episode reward: 55.763365\n",
      "Episode reward: 56.680755\n",
      "Episode reward: 48.494664\n",
      "Episode reward: 53.98213\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8656     |\n",
      "|    fps              | 3018     |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 473193   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 118273   |\n",
      "----------------------------------\n",
      "Episode reward: 31.952271\n",
      "Episode reward: 44.843061\n",
      "Episode reward: 37.878934\n",
      "Episode reward: 44.911739\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8660     |\n",
      "|    fps              | 3018     |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 473353   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.278    |\n",
      "|    n_updates        | 118313   |\n",
      "----------------------------------\n",
      "Episode reward: 63.851794\n",
      "Episode reward: 54.277475\n",
      "Episode reward: 32.958319\n",
      "Episode reward: 46.840927\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8664     |\n",
      "|    fps              | 3018     |\n",
      "|    time_elapsed     | 156      |\n",
      "|    total_timesteps  | 473552   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0101   |\n",
      "|    n_updates        | 118362   |\n",
      "----------------------------------\n",
      "Episode reward: 47.907317\n",
      "Episode reward: 57.795165\n",
      "Episode reward: 61.750709\n",
      "Episode reward: 115.504881\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8668     |\n",
      "|    fps              | 3017     |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total_timesteps  | 473836   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.579    |\n",
      "|    n_updates        | 118433   |\n",
      "----------------------------------\n",
      "Episode reward: 54.73331\n",
      "Episode reward: 32.870608\n",
      "Episode reward: 72.170829\n",
      "Episode reward: 56.962875\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8672     |\n",
      "|    fps              | 3017     |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total_timesteps  | 474055   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.379    |\n",
      "|    n_updates        | 118488   |\n",
      "----------------------------------\n",
      "Episode reward: 61.5336\n",
      "Episode reward: 75.552738\n",
      "Episode reward: 56.869988\n",
      "Episode reward: 35.942845\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8676     |\n",
      "|    fps              | 3017     |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total_timesteps  | 474286   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.637    |\n",
      "|    n_updates        | 118546   |\n",
      "----------------------------------\n",
      "Episode reward: 54.684539\n",
      "Episode reward: 107.23031\n",
      "Episode reward: 43.731322\n",
      "Episode reward: 40.905046\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8680     |\n",
      "|    fps              | 3016     |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total_timesteps  | 474534   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.26     |\n",
      "|    n_updates        | 118608   |\n",
      "----------------------------------\n",
      "Episode reward: 70.809679\n",
      "Episode reward: 50.934218\n",
      "Episode reward: 141.196345\n",
      "Episode reward: 45.886937\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8684     |\n",
      "|    fps              | 3017     |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total_timesteps  | 474857   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.444    |\n",
      "|    n_updates        | 118689   |\n",
      "----------------------------------\n",
      "Episode reward: 46.470999\n",
      "Episode reward: 36.934734\n",
      "Episode reward: 75.027721\n",
      "Episode reward: 51.63376\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8688     |\n",
      "|    fps              | 3017     |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total_timesteps  | 475069   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.05     |\n",
      "|    n_updates        | 118742   |\n",
      "----------------------------------\n",
      "Episode reward: 35.903904\n",
      "Episode reward: 125.217334\n",
      "Episode reward: 66.989659\n",
      "Episode reward: 51.911028\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8692     |\n",
      "|    fps              | 3017     |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total_timesteps  | 475359   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0121   |\n",
      "|    n_updates        | 118814   |\n",
      "----------------------------------\n",
      "Episode reward: 58.373562\n",
      "Episode reward: 50.86051\n",
      "Episode reward: 36.838821\n",
      "Episode reward: 56.884558\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8696     |\n",
      "|    fps              | 3017     |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total_timesteps  | 475563   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 118865   |\n",
      "----------------------------------\n",
      "Episode reward: 37.913362\n",
      "Episode reward: 53.930143\n",
      "Episode reward: 61.827328\n",
      "Episode reward: 42.915624\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8700     |\n",
      "|    fps              | 3016     |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total_timesteps  | 475760   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 118914   |\n",
      "----------------------------------\n",
      "Episode reward: 57.616995\n",
      "Episode reward: 38.783533\n",
      "Episode reward: 60.700326\n",
      "Episode reward: 54.850671\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8704     |\n",
      "|    fps              | 3016     |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total_timesteps  | 475973   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00765  |\n",
      "|    n_updates        | 118968   |\n",
      "----------------------------------\n",
      "Episode reward: 34.92634\n",
      "Episode reward: 47.791108\n",
      "Episode reward: 37.706583\n",
      "Episode reward: 73.029847\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8708     |\n",
      "|    fps              | 3016     |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total_timesteps  | 476170   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 119017   |\n",
      "----------------------------------\n",
      "Episode reward: 54.537685\n",
      "Episode reward: 64.728497\n",
      "Episode reward: 79.642361\n",
      "Episode reward: 64.887848\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8712     |\n",
      "|    fps              | 3017     |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total_timesteps  | 476435   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0222   |\n",
      "|    n_updates        | 119083   |\n",
      "----------------------------------\n",
      "Episode reward: 62.802133\n",
      "Episode reward: 47.812255\n",
      "Episode reward: 38.848393\n",
      "Episode reward: 37.75408\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8716     |\n",
      "|    fps              | 3016     |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total_timesteps  | 476623   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0239   |\n",
      "|    n_updates        | 119130   |\n",
      "----------------------------------\n",
      "Episode reward: 47.576811\n",
      "Episode reward: 62.838293\n",
      "Episode reward: 35.923414\n",
      "Episode reward: 65.73376\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8720     |\n",
      "|    fps              | 3016     |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 476836   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 119183   |\n",
      "----------------------------------\n",
      "Episode reward: 39.915074\n",
      "Episode reward: 61.706817\n",
      "Episode reward: 39.907454\n",
      "Episode reward: 66.822271\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8724     |\n",
      "|    fps              | 3016     |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 477045   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.417    |\n",
      "|    n_updates        | 119236   |\n",
      "----------------------------------\n",
      "Episode reward: 107.104879\n",
      "Episode reward: 37.915184\n",
      "Episode reward: 51.878251\n",
      "Episode reward: 76.815533\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8728     |\n",
      "|    fps              | 3016     |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 477320   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 119304   |\n",
      "----------------------------------\n",
      "Episode reward: 36.912851\n",
      "Episode reward: 47.845956\n",
      "Episode reward: 77.174068\n",
      "Episode reward: 57.831882\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8732     |\n",
      "|    fps              | 3016     |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 477544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0255   |\n",
      "|    n_updates        | 119360   |\n",
      "----------------------------------\n",
      "Episode reward: 97.941108\n",
      "Episode reward: 88.002091\n",
      "Episode reward: 117.568013\n",
      "Episode reward: 46.907856\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8736     |\n",
      "|    fps              | 3015     |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 477903   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 119450   |\n",
      "----------------------------------\n",
      "Episode reward: 42.801592\n",
      "Episode reward: 44.905086\n",
      "Episode reward: 87.450182\n",
      "Episode reward: 43.819563\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8740     |\n",
      "|    fps              | 3015     |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 478132   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0119   |\n",
      "|    n_updates        | 119507   |\n",
      "----------------------------------\n",
      "Episode reward: 74.253752\n",
      "Episode reward: 28.896841\n",
      "Episode reward: 36.784873\n",
      "Episode reward: 33.935168\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8744     |\n",
      "|    fps              | 3015     |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 478307   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0244   |\n",
      "|    n_updates        | 119551   |\n",
      "----------------------------------\n",
      "Episode reward: 120.514246\n",
      "Episode reward: 46.867735\n",
      "Episode reward: 69.354643\n",
      "Episode reward: 80.31213\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8748     |\n",
      "|    fps              | 3015     |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 478636   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.407    |\n",
      "|    n_updates        | 119633   |\n",
      "----------------------------------\n",
      "Episode reward: 36.933413\n",
      "Episode reward: 48.872448\n",
      "Episode reward: 46.92903\n",
      "Episode reward: 53.863613\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8752     |\n",
      "|    fps              | 3015     |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 478823   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.62     |\n",
      "|    n_updates        | 119680   |\n",
      "----------------------------------\n",
      "Episode reward: 56.752358\n",
      "Episode reward: 45.472769\n",
      "Episode reward: 48.680238\n",
      "Episode reward: 44.92742\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8756     |\n",
      "|    fps              | 3015     |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 479020   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.42     |\n",
      "|    n_updates        | 119729   |\n",
      "----------------------------------\n",
      "Episode reward: 68.868159\n",
      "Episode reward: 47.605208\n",
      "Episode reward: 52.90541\n",
      "Episode reward: 46.671933\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8760     |\n",
      "|    fps              | 3015     |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 479237   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.993    |\n",
      "|    n_updates        | 119784   |\n",
      "----------------------------------\n",
      "Episode reward: 47.843998\n",
      "Episode reward: 53.872186\n",
      "Episode reward: 65.801039\n",
      "Episode reward: 32.8225\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8764     |\n",
      "|    fps              | 3015     |\n",
      "|    time_elapsed     | 158      |\n",
      "|    total_timesteps  | 479438   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 119834   |\n",
      "----------------------------------\n",
      "Episode reward: 48.880554\n",
      "Episode reward: 59.929099\n",
      "Episode reward: 74.800657\n",
      "Episode reward: 85.16712\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8768     |\n",
      "|    fps              | 3015     |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total_timesteps  | 479708   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.52     |\n",
      "|    n_updates        | 119901   |\n",
      "----------------------------------\n",
      "Episode reward: 45.935893\n",
      "Episode reward: 67.847581\n",
      "Episode reward: 45.831708\n",
      "Episode reward: 50.790773\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8772     |\n",
      "|    fps              | 3015     |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total_timesteps  | 479920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.866    |\n",
      "|    n_updates        | 119954   |\n",
      "----------------------------------\n",
      "Episode reward: 69.832648\n",
      "Episode reward: 59.632579\n",
      "Episode reward: 38.883098\n",
      "Episode reward: 61.806629\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8776     |\n",
      "|    fps              | 3014     |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total_timesteps  | 480151   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.557    |\n",
      "|    n_updates        | 120012   |\n",
      "----------------------------------\n",
      "Episode reward: 44.757283\n",
      "Episode reward: 71.434095\n",
      "Episode reward: 49.702208\n",
      "Episode reward: 29.923126\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8780     |\n",
      "|    fps              | 3014     |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total_timesteps  | 480348   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 120061   |\n",
      "----------------------------------\n",
      "Episode reward: 36.942517\n",
      "Episode reward: 46.241272\n",
      "Episode reward: 67.172513\n",
      "Episode reward: 51.543309\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8784     |\n",
      "|    fps              | 3014     |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total_timesteps  | 480552   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0273   |\n",
      "|    n_updates        | 120112   |\n",
      "----------------------------------\n",
      "Episode reward: 102.242945\n",
      "Episode reward: 85.798871\n",
      "Episode reward: 33.869047\n",
      "Episode reward: 55.359354\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8788     |\n",
      "|    fps              | 3013     |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total_timesteps  | 480835   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.304    |\n",
      "|    n_updates        | 120183   |\n",
      "----------------------------------\n",
      "Episode reward: 51.759842\n",
      "Episode reward: 53.881596\n",
      "Episode reward: 84.457946\n",
      "Episode reward: 117.376618\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8792     |\n",
      "|    fps              | 3013     |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total_timesteps  | 481148   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 120261   |\n",
      "----------------------------------\n",
      "Episode reward: 56.876804\n",
      "Episode reward: 91.013768\n",
      "Episode reward: 28.803917\n",
      "Episode reward: 73.79484\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8796     |\n",
      "|    fps              | 3012     |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total_timesteps  | 481400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.738    |\n",
      "|    n_updates        | 120324   |\n",
      "----------------------------------\n",
      "Episode reward: 78.796405\n",
      "Episode reward: 38.93773\n",
      "Episode reward: 49.94014\n",
      "Episode reward: 52.645133\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8800     |\n",
      "|    fps              | 3012     |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total_timesteps  | 481622   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.022    |\n",
      "|    n_updates        | 120380   |\n",
      "----------------------------------\n",
      "Episode reward: 64.439729\n",
      "Episode reward: 55.652177\n",
      "Episode reward: 41.821761\n",
      "Episode reward: 75.068878\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8804     |\n",
      "|    fps              | 3011     |\n",
      "|    time_elapsed     | 159      |\n",
      "|    total_timesteps  | 481862   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 120440   |\n",
      "----------------------------------\n",
      "Episode reward: 36.617546\n",
      "Episode reward: 35.820167\n",
      "Episode reward: 47.878004\n",
      "Episode reward: 52.573575\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8808     |\n",
      "|    fps              | 3011     |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 482036   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 120483   |\n",
      "----------------------------------\n",
      "Episode reward: 28.750146\n",
      "Episode reward: 51.818915\n",
      "Episode reward: 66.687806\n",
      "Episode reward: 29.766152\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8812     |\n",
      "|    fps              | 3011     |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 482214   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.817    |\n",
      "|    n_updates        | 120528   |\n",
      "----------------------------------\n",
      "Episode reward: 35.693322\n",
      "Episode reward: 28.953234\n",
      "Episode reward: 64.865355\n",
      "Episode reward: 76.668033\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8816     |\n",
      "|    fps              | 3011     |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 482421   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0289   |\n",
      "|    n_updates        | 120580   |\n",
      "----------------------------------\n",
      "Episode reward: 29.907305\n",
      "Episode reward: 42.813731\n",
      "Episode reward: 35.786713\n",
      "Episode reward: 52.557188\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8820     |\n",
      "|    fps              | 3011     |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 482583   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0229   |\n",
      "|    n_updates        | 120620   |\n",
      "----------------------------------\n",
      "Episode reward: 26.879116\n",
      "Episode reward: 33.680463\n",
      "Episode reward: 90.967443\n",
      "Episode reward: 43.908511\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8824     |\n",
      "|    fps              | 3011     |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 482780   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 120669   |\n",
      "----------------------------------\n",
      "Episode reward: 55.833282\n",
      "Episode reward: 49.879975\n",
      "Episode reward: 38.777507\n",
      "Episode reward: 71.685975\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8828     |\n",
      "|    fps              | 3011     |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 482997   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.435    |\n",
      "|    n_updates        | 120724   |\n",
      "----------------------------------\n",
      "Episode reward: 35.86872\n",
      "Episode reward: 60.19764\n",
      "Episode reward: 59.509997\n",
      "Episode reward: 111.523716\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8832     |\n",
      "|    fps              | 3010     |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 483270   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 120792   |\n",
      "----------------------------------\n",
      "Episode reward: 56.339072\n",
      "Episode reward: 45.842577\n",
      "Episode reward: 39.88596\n",
      "Episode reward: 36.852816\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.5     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8836     |\n",
      "|    fps              | 3011     |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 483450   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 120837   |\n",
      "----------------------------------\n",
      "Episode reward: 53.009378\n",
      "Episode reward: 30.486276\n",
      "Episode reward: 53.864734\n",
      "Episode reward: 66.244374\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.2     |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8840     |\n",
      "|    fps              | 3010     |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 483656   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00988  |\n",
      "|    n_updates        | 120888   |\n",
      "----------------------------------\n",
      "Episode reward: 35.910497\n",
      "Episode reward: 54.739397\n",
      "Episode reward: 43.657069\n",
      "Episode reward: 65.325806\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.5     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8844     |\n",
      "|    fps              | 3010     |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 483857   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.758    |\n",
      "|    n_updates        | 120939   |\n",
      "----------------------------------\n",
      "Episode reward: 37.875173\n",
      "Episode reward: 48.270268\n",
      "Episode reward: 42.472224\n",
      "Episode reward: 41.77571\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 53.9     |\n",
      "|    ep_rew_mean      | 53.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8848     |\n",
      "|    fps              | 3010     |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 484029   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11     |\n",
      "|    n_updates        | 120982   |\n",
      "----------------------------------\n",
      "Episode reward: 61.797267\n",
      "Episode reward: 70.12998\n",
      "Episode reward: 62.592007\n",
      "Episode reward: 129.889032\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8852     |\n",
      "|    fps              | 3010     |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 484356   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0118   |\n",
      "|    n_updates        | 121063   |\n",
      "----------------------------------\n",
      "Episode reward: 61.735054\n",
      "Episode reward: 86.138547\n",
      "Episode reward: 58.845318\n",
      "Episode reward: 72.158573\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8856     |\n",
      "|    fps              | 3010     |\n",
      "|    time_elapsed     | 160      |\n",
      "|    total_timesteps  | 484637   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 121134   |\n",
      "----------------------------------\n",
      "Episode reward: 47.914567\n",
      "Episode reward: 39.665064\n",
      "Episode reward: 76.913446\n",
      "Episode reward: 48.835694\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8860     |\n",
      "|    fps              | 3010     |\n",
      "|    time_elapsed     | 161      |\n",
      "|    total_timesteps  | 484854   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0232   |\n",
      "|    n_updates        | 121188   |\n",
      "----------------------------------\n",
      "Episode reward: 31.925129\n",
      "Episode reward: 34.781893\n",
      "Episode reward: 38.835864\n",
      "Episode reward: 35.853194\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8864     |\n",
      "|    fps              | 3010     |\n",
      "|    time_elapsed     | 161      |\n",
      "|    total_timesteps  | 484996   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 121223   |\n",
      "----------------------------------\n",
      "Episode reward: 66.648743\n",
      "Episode reward: 77.483316\n",
      "Episode reward: 42.899389\n",
      "Episode reward: 88.496749\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8868     |\n",
      "|    fps              | 3009     |\n",
      "|    time_elapsed     | 161      |\n",
      "|    total_timesteps  | 485284   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.786    |\n",
      "|    n_updates        | 121295   |\n",
      "----------------------------------\n",
      "Episode reward: 58.833172\n",
      "Episode reward: 54.812036\n",
      "Episode reward: 31.96054\n",
      "Episode reward: 62.769583\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8872     |\n",
      "|    fps              | 3009     |\n",
      "|    time_elapsed     | 161      |\n",
      "|    total_timesteps  | 485493   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0183   |\n",
      "|    n_updates        | 121348   |\n",
      "----------------------------------\n",
      "Episode reward: 42.851256\n",
      "Episode reward: 80.523774\n",
      "Episode reward: 39.832835\n",
      "Episode reward: 45.894381\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.5     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8876     |\n",
      "|    fps              | 3009     |\n",
      "|    time_elapsed     | 161      |\n",
      "|    total_timesteps  | 485706   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.564    |\n",
      "|    n_updates        | 121401   |\n",
      "----------------------------------\n",
      "Episode reward: 33.869568\n",
      "Episode reward: 55.123379\n",
      "Episode reward: 55.686438\n",
      "Episode reward: 42.473156\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.5     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8880     |\n",
      "|    fps              | 3009     |\n",
      "|    time_elapsed     | 161      |\n",
      "|    total_timesteps  | 485895   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.334    |\n",
      "|    n_updates        | 121448   |\n",
      "----------------------------------\n",
      "Episode reward: 42.775847\n",
      "Episode reward: 95.782593\n",
      "Episode reward: 61.229511\n",
      "Episode reward: 72.816476\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8884     |\n",
      "|    fps              | 3009     |\n",
      "|    time_elapsed     | 161      |\n",
      "|    total_timesteps  | 486176   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0213   |\n",
      "|    n_updates        | 121518   |\n",
      "----------------------------------\n",
      "Episode reward: 60.872226\n",
      "Episode reward: 133.25555\n",
      "Episode reward: 27.863387\n",
      "Episode reward: 53.552316\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8888     |\n",
      "|    fps              | 3008     |\n",
      "|    time_elapsed     | 161      |\n",
      "|    total_timesteps  | 486453   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.662    |\n",
      "|    n_updates        | 121588   |\n",
      "----------------------------------\n",
      "Episode reward: 98.624508\n",
      "Episode reward: 28.926336\n",
      "Episode reward: 38.748152\n",
      "Episode reward: 106.85043\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8892     |\n",
      "|    fps              | 3008     |\n",
      "|    time_elapsed     | 161      |\n",
      "|    total_timesteps  | 486728   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.573    |\n",
      "|    n_updates        | 121656   |\n",
      "----------------------------------\n",
      "Episode reward: 58.881685\n",
      "Episode reward: 50.756682\n",
      "Episode reward: 78.474072\n",
      "Episode reward: 63.795837\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8896     |\n",
      "|    fps              | 3008     |\n",
      "|    time_elapsed     | 161      |\n",
      "|    total_timesteps  | 486982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 121720   |\n",
      "----------------------------------\n",
      "Episode reward: 83.748985\n",
      "Episode reward: 51.924267\n",
      "Episode reward: 73.395025\n",
      "Episode reward: 61.395089\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8900     |\n",
      "|    fps              | 3008     |\n",
      "|    time_elapsed     | 161      |\n",
      "|    total_timesteps  | 487254   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0248   |\n",
      "|    n_updates        | 121788   |\n",
      "----------------------------------\n",
      "Episode reward: 79.082573\n",
      "Episode reward: 47.489898\n",
      "Episode reward: 40.822659\n",
      "Episode reward: 53.863675\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8904     |\n",
      "|    fps              | 3008     |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total_timesteps  | 487477   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.531    |\n",
      "|    n_updates        | 121844   |\n",
      "----------------------------------\n",
      "Episode reward: 44.440754\n",
      "Episode reward: 111.212553\n",
      "Episode reward: 140.463385\n",
      "Episode reward: 37.936232\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8908     |\n",
      "|    fps              | 3008     |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total_timesteps  | 487813   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0129   |\n",
      "|    n_updates        | 121928   |\n",
      "----------------------------------\n",
      "Episode reward: 73.843678\n",
      "Episode reward: 26.92493\n",
      "Episode reward: 41.798262\n",
      "Episode reward: 54.549646\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8912     |\n",
      "|    fps              | 3008     |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total_timesteps  | 488011   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.348    |\n",
      "|    n_updates        | 121977   |\n",
      "----------------------------------\n",
      "Episode reward: 70.314556\n",
      "Episode reward: 39.925121\n",
      "Episode reward: 35.74615\n",
      "Episode reward: 72.860927\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8916     |\n",
      "|    fps              | 3008     |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total_timesteps  | 488232   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.557    |\n",
      "|    n_updates        | 122032   |\n",
      "----------------------------------\n",
      "Episode reward: 35.913472\n",
      "Episode reward: 52.82242\n",
      "Episode reward: 69.689765\n",
      "Episode reward: 54.8823\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8920     |\n",
      "|    fps              | 3008     |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total_timesteps  | 488447   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 122086   |\n",
      "----------------------------------\n",
      "Episode reward: 42.840342\n",
      "Episode reward: 36.798369\n",
      "Episode reward: 40.82034\n",
      "Episode reward: 50.869824\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8924     |\n",
      "|    fps              | 3007     |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total_timesteps  | 488619   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00995  |\n",
      "|    n_updates        | 122129   |\n",
      "----------------------------------\n",
      "Episode reward: 43.910288\n",
      "Episode reward: 48.558173\n",
      "Episode reward: 38.95911\n",
      "Episode reward: 31.803368\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8928     |\n",
      "|    fps              | 3007     |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total_timesteps  | 488783   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 122170   |\n",
      "----------------------------------\n",
      "Episode reward: 37.862229\n",
      "Episode reward: 40.897927\n",
      "Episode reward: 62.769903\n",
      "Episode reward: 78.563074\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8932     |\n",
      "|    fps              | 3007     |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total_timesteps  | 489005   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 122226   |\n",
      "----------------------------------\n",
      "Episode reward: 44.839441\n",
      "Episode reward: 38.592615\n",
      "Episode reward: 42.695276\n",
      "Episode reward: 81.447216\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8936     |\n",
      "|    fps              | 3007     |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total_timesteps  | 489214   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.01     |\n",
      "|    n_updates        | 122278   |\n",
      "----------------------------------\n",
      "Episode reward: 54.76426\n",
      "Episode reward: 34.950229\n",
      "Episode reward: 37.897368\n",
      "Episode reward: 73.788062\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8940     |\n",
      "|    fps              | 3007     |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total_timesteps  | 489416   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.63     |\n",
      "|    n_updates        | 122328   |\n",
      "----------------------------------\n",
      "Episode reward: 69.54429\n",
      "Episode reward: 46.892722\n",
      "Episode reward: 38.826075\n",
      "Episode reward: 59.831473\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8944     |\n",
      "|    fps              | 3007     |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total_timesteps  | 489632   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0227   |\n",
      "|    n_updates        | 122382   |\n",
      "----------------------------------\n",
      "Episode reward: 55.664189\n",
      "Episode reward: 43.678586\n",
      "Episode reward: 57.529894\n",
      "Episode reward: 54.894282\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8948     |\n",
      "|    fps              | 3006     |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total_timesteps  | 489845   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 122436   |\n",
      "----------------------------------\n",
      "Episode reward: 86.239493\n",
      "Episode reward: 73.844475\n",
      "Episode reward: 54.805777\n",
      "Episode reward: 57.863926\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8952     |\n",
      "|    fps              | 3006     |\n",
      "|    time_elapsed     | 162      |\n",
      "|    total_timesteps  | 490127   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.37     |\n",
      "|    n_updates        | 122506   |\n",
      "----------------------------------\n",
      "Episode reward: 33.874854\n",
      "Episode reward: 67.425794\n",
      "Episode reward: 69.023289\n",
      "Episode reward: 50.374265\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8956     |\n",
      "|    fps              | 3006     |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 490350   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.623    |\n",
      "|    n_updates        | 122562   |\n",
      "----------------------------------\n",
      "Episode reward: 61.783542\n",
      "Episode reward: 82.654686\n",
      "Episode reward: 39.914562\n",
      "Episode reward: 49.90965\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8960     |\n",
      "|    fps              | 3006     |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 490585   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0283   |\n",
      "|    n_updates        | 122621   |\n",
      "----------------------------------\n",
      "Episode reward: 28.898543\n",
      "Episode reward: 96.335562\n",
      "Episode reward: 67.198011\n",
      "Episode reward: 59.715883\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8964     |\n",
      "|    fps              | 3006     |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 490858   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.024    |\n",
      "|    n_updates        | 122689   |\n",
      "----------------------------------\n",
      "Episode reward: 84.406703\n",
      "Episode reward: 31.863584\n",
      "Episode reward: 55.835363\n",
      "Episode reward: 45.905974\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8968     |\n",
      "|    fps              | 3006     |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 491078   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0209   |\n",
      "|    n_updates        | 122744   |\n",
      "----------------------------------\n",
      "Episode reward: 65.816684\n",
      "Episode reward: 46.891672\n",
      "Episode reward: 63.505074\n",
      "Episode reward: 71.798212\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8972     |\n",
      "|    fps              | 3006     |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 491328   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.521    |\n",
      "|    n_updates        | 122806   |\n",
      "----------------------------------\n",
      "Episode reward: 87.512666\n",
      "Episode reward: 47.468304\n",
      "Episode reward: 55.930232\n",
      "Episode reward: 34.902926\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8976     |\n",
      "|    fps              | 3005     |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 491572   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0208   |\n",
      "|    n_updates        | 122867   |\n",
      "----------------------------------\n",
      "Episode reward: 65.512772\n",
      "Episode reward: 92.46202\n",
      "Episode reward: 40.937951\n",
      "Episode reward: 67.858577\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8980     |\n",
      "|    fps              | 3005     |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 491841   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0364   |\n",
      "|    n_updates        | 122935   |\n",
      "----------------------------------\n",
      "Episode reward: 34.846583\n",
      "Episode reward: 86.53503\n",
      "Episode reward: 42.881999\n",
      "Episode reward: 47.916249\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8984     |\n",
      "|    fps              | 3005     |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 492055   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0376   |\n",
      "|    n_updates        | 122988   |\n",
      "----------------------------------\n",
      "Episode reward: 38.897299\n",
      "Episode reward: 56.66709\n",
      "Episode reward: 66.238379\n",
      "Episode reward: 37.821779\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8988     |\n",
      "|    fps              | 3005     |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 492256   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 123038   |\n",
      "----------------------------------\n",
      "Episode reward: 91.636848\n",
      "Episode reward: 40.808757\n",
      "Episode reward: 28.821889\n",
      "Episode reward: 77.037317\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8992     |\n",
      "|    fps              | 3005     |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 492502   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.355    |\n",
      "|    n_updates        | 123100   |\n",
      "----------------------------------\n",
      "Episode reward: 49.853802\n",
      "Episode reward: 56.530378\n",
      "Episode reward: 41.891374\n",
      "Episode reward: 39.939518\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 8996     |\n",
      "|    fps              | 3004     |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 492691   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0149   |\n",
      "|    n_updates        | 123147   |\n",
      "----------------------------------\n",
      "Episode reward: 90.576172\n",
      "Episode reward: 91.056342\n",
      "Episode reward: 42.737837\n",
      "Episode reward: 92.292674\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9000     |\n",
      "|    fps              | 3004     |\n",
      "|    time_elapsed     | 164      |\n",
      "|    total_timesteps  | 493046   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1        |\n",
      "|    n_updates        | 123236   |\n",
      "----------------------------------\n",
      "Episode reward: 27.935106\n",
      "Episode reward: 64.67981\n",
      "Episode reward: 84.028872\n",
      "Episode reward: 41.835877\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9004     |\n",
      "|    fps              | 3004     |\n",
      "|    time_elapsed     | 164      |\n",
      "|    total_timesteps  | 493266   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 123291   |\n",
      "----------------------------------\n",
      "Episode reward: 46.922608\n",
      "Episode reward: 89.508912\n",
      "Episode reward: 37.946248\n",
      "Episode reward: 48.689764\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9008     |\n",
      "|    fps              | 3004     |\n",
      "|    time_elapsed     | 164      |\n",
      "|    total_timesteps  | 493490   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.984    |\n",
      "|    n_updates        | 123347   |\n",
      "----------------------------------\n",
      "Episode reward: 30.792506\n",
      "Episode reward: 41.929477\n",
      "Episode reward: 69.061536\n",
      "Episode reward: 67.849708\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9012     |\n",
      "|    fps              | 3004     |\n",
      "|    time_elapsed     | 164      |\n",
      "|    total_timesteps  | 493701   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0394   |\n",
      "|    n_updates        | 123400   |\n",
      "----------------------------------\n",
      "Episode reward: 36.956128\n",
      "Episode reward: 51.606157\n",
      "Episode reward: 111.183684\n",
      "Episode reward: 48.923065\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9016     |\n",
      "|    fps              | 3004     |\n",
      "|    time_elapsed     | 164      |\n",
      "|    total_timesteps  | 493967   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.07     |\n",
      "|    n_updates        | 123466   |\n",
      "----------------------------------\n",
      "Episode reward: 83.492082\n",
      "Episode reward: 49.738756\n",
      "Episode reward: 37.833877\n",
      "Episode reward: 33.847196\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9020     |\n",
      "|    fps              | 3004     |\n",
      "|    time_elapsed     | 164      |\n",
      "|    total_timesteps  | 494174   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.335    |\n",
      "|    n_updates        | 123518   |\n",
      "----------------------------------\n",
      "Episode reward: 56.894666\n",
      "Episode reward: 26.816166\n",
      "Episode reward: 49.783157\n",
      "Episode reward: 65.46029\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9024     |\n",
      "|    fps              | 3003     |\n",
      "|    time_elapsed     | 164      |\n",
      "|    total_timesteps  | 494375   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.604    |\n",
      "|    n_updates        | 123568   |\n",
      "----------------------------------\n",
      "Episode reward: 49.844676\n",
      "Episode reward: 50.900007\n",
      "Episode reward: 77.322679\n",
      "Episode reward: 113.621254\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9028     |\n",
      "|    fps              | 3003     |\n",
      "|    time_elapsed     | 164      |\n",
      "|    total_timesteps  | 494689   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 123647   |\n",
      "----------------------------------\n",
      "Episode reward: 58.789221\n",
      "Episode reward: 46.852261\n",
      "Episode reward: 38.669576\n",
      "Episode reward: 63.727972\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9032     |\n",
      "|    fps              | 3003     |\n",
      "|    time_elapsed     | 164      |\n",
      "|    total_timesteps  | 494898   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.913    |\n",
      "|    n_updates        | 123699   |\n",
      "----------------------------------\n",
      "Episode reward: 53.369145\n",
      "Episode reward: 74.7893\n",
      "Episode reward: 49.470924\n",
      "Episode reward: 54.550963\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9036     |\n",
      "|    fps              | 3003     |\n",
      "|    time_elapsed     | 164      |\n",
      "|    total_timesteps  | 495132   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.69     |\n",
      "|    n_updates        | 123757   |\n",
      "----------------------------------\n",
      "Episode reward: 57.525651\n",
      "Episode reward: 51.880491\n",
      "Episode reward: 29.775183\n",
      "Episode reward: 57.725508\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9040     |\n",
      "|    fps              | 3002     |\n",
      "|    time_elapsed     | 164      |\n",
      "|    total_timesteps  | 495330   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 123807   |\n",
      "----------------------------------\n",
      "Episode reward: 70.614968\n",
      "Episode reward: 55.863024\n",
      "Episode reward: 43.876025\n",
      "Episode reward: 86.698438\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9044     |\n",
      "|    fps              | 3002     |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total_timesteps  | 495588   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.16     |\n",
      "|    n_updates        | 123871   |\n",
      "----------------------------------\n",
      "Episode reward: 44.823786\n",
      "Episode reward: 28.647171\n",
      "Episode reward: 65.818717\n",
      "Episode reward: 52.636176\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9048     |\n",
      "|    fps              | 3002     |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total_timesteps  | 495782   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.975    |\n",
      "|    n_updates        | 123920   |\n",
      "----------------------------------\n",
      "Episode reward: 95.03651\n",
      "Episode reward: 44.875273\n",
      "Episode reward: 60.957107\n",
      "Episode reward: 33.944862\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9052     |\n",
      "|    fps              | 3002     |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total_timesteps  | 496020   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.05     |\n",
      "|    n_updates        | 123979   |\n",
      "----------------------------------\n",
      "Episode reward: 57.844914\n",
      "Episode reward: 43.802663\n",
      "Episode reward: 42.915401\n",
      "Episode reward: 28.889313\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9056     |\n",
      "|    fps              | 3001     |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total_timesteps  | 496194   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.313    |\n",
      "|    n_updates        | 124023   |\n",
      "----------------------------------\n",
      "Episode reward: 65.031744\n",
      "Episode reward: 35.722041\n",
      "Episode reward: 48.617349\n",
      "Episode reward: 39.86552\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9060     |\n",
      "|    fps              | 3001     |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total_timesteps  | 496385   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.867    |\n",
      "|    n_updates        | 124071   |\n",
      "----------------------------------\n",
      "Episode reward: 30.783035\n",
      "Episode reward: 41.943416\n",
      "Episode reward: 49.874709\n",
      "Episode reward: 78.645073\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9064     |\n",
      "|    fps              | 3001     |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total_timesteps  | 496600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.47     |\n",
      "|    n_updates        | 124124   |\n",
      "----------------------------------\n",
      "Episode reward: 70.530729\n",
      "Episode reward: 73.473384\n",
      "Episode reward: 93.203075\n",
      "Episode reward: 52.856858\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9068     |\n",
      "|    fps              | 3000     |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total_timesteps  | 496899   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.229    |\n",
      "|    n_updates        | 124199   |\n",
      "----------------------------------\n",
      "Episode reward: 61.086745\n",
      "Episode reward: 36.951225\n",
      "Episode reward: 58.833059\n",
      "Episode reward: 55.325943\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9072     |\n",
      "|    fps              | 3000     |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total_timesteps  | 497113   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.611    |\n",
      "|    n_updates        | 124253   |\n",
      "----------------------------------\n",
      "Episode reward: 44.921539\n",
      "Episode reward: 56.790236\n",
      "Episode reward: 37.945844\n",
      "Episode reward: 96.359722\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9076     |\n",
      "|    fps              | 3000     |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total_timesteps  | 497356   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.767    |\n",
      "|    n_updates        | 124313   |\n",
      "----------------------------------\n",
      "Episode reward: 40.916119\n",
      "Episode reward: 48.220528\n",
      "Episode reward: 37.86534\n",
      "Episode reward: 28.937982\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9080     |\n",
      "|    fps              | 3000     |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total_timesteps  | 497513   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.72     |\n",
      "|    n_updates        | 124353   |\n",
      "----------------------------------\n",
      "Episode reward: 47.906438\n",
      "Episode reward: 62.830797\n",
      "Episode reward: 38.853719\n",
      "Episode reward: 54.921639\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9084     |\n",
      "|    fps              | 3000     |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total_timesteps  | 497718   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 124404   |\n",
      "----------------------------------\n",
      "Episode reward: 55.376675\n",
      "Episode reward: 44.908957\n",
      "Episode reward: 46.754403\n",
      "Episode reward: 43.903769\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9088     |\n",
      "|    fps              | 3000     |\n",
      "|    time_elapsed     | 165      |\n",
      "|    total_timesteps  | 497910   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0229   |\n",
      "|    n_updates        | 124452   |\n",
      "----------------------------------\n",
      "Episode reward: 69.628114\n",
      "Episode reward: 35.912791\n",
      "Episode reward: 37.843335\n",
      "Episode reward: 50.910833\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9092     |\n",
      "|    fps              | 3000     |\n",
      "|    time_elapsed     | 166      |\n",
      "|    total_timesteps  | 498105   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.62     |\n",
      "|    n_updates        | 124501   |\n",
      "----------------------------------\n",
      "Episode reward: 60.706445\n",
      "Episode reward: 41.941348\n",
      "Episode reward: 70.720476\n",
      "Episode reward: 88.714952\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9096     |\n",
      "|    fps              | 2999     |\n",
      "|    time_elapsed     | 166      |\n",
      "|    total_timesteps  | 498376   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0185   |\n",
      "|    n_updates        | 124568   |\n",
      "----------------------------------\n",
      "Episode reward: 87.197074\n",
      "Episode reward: 85.732576\n",
      "Episode reward: 49.937388\n",
      "Episode reward: 32.828254\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9100     |\n",
      "|    fps              | 2999     |\n",
      "|    time_elapsed     | 166      |\n",
      "|    total_timesteps  | 498638   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.02     |\n",
      "|    n_updates        | 124634   |\n",
      "----------------------------------\n",
      "Episode reward: 46.518406\n",
      "Episode reward: 128.325345\n",
      "Episode reward: 60.879315\n",
      "Episode reward: 88.545018\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9104     |\n",
      "|    fps              | 2999     |\n",
      "|    time_elapsed     | 166      |\n",
      "|    total_timesteps  | 498964   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0158   |\n",
      "|    n_updates        | 124715   |\n",
      "----------------------------------\n",
      "Episode reward: 93.318414\n",
      "Episode reward: 50.816697\n",
      "Episode reward: 59.868297\n",
      "Episode reward: 34.580761\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9108     |\n",
      "|    fps              | 2999     |\n",
      "|    time_elapsed     | 166      |\n",
      "|    total_timesteps  | 499224   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 124780   |\n",
      "----------------------------------\n",
      "Episode reward: 38.882806\n",
      "Episode reward: 46.883244\n",
      "Episode reward: 95.912302\n",
      "Episode reward: 73.782629\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9112     |\n",
      "|    fps              | 2998     |\n",
      "|    time_elapsed     | 166      |\n",
      "|    total_timesteps  | 499501   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.289    |\n",
      "|    n_updates        | 124850   |\n",
      "----------------------------------\n",
      "Episode reward: 27.904036\n",
      "Episode reward: 42.48651\n",
      "Episode reward: 53.646931\n",
      "Episode reward: 42.827398\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9116     |\n",
      "|    fps              | 2999     |\n",
      "|    time_elapsed     | 166      |\n",
      "|    total_timesteps  | 499669   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0173   |\n",
      "|    n_updates        | 124892   |\n",
      "----------------------------------\n",
      "Episode reward: 47.913866\n",
      "Episode reward: 35.925826\n",
      "Episode reward: 72.761767\n",
      "Episode reward: 75.333133\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9120     |\n",
      "|    fps              | 2999     |\n",
      "|    time_elapsed     | 166      |\n",
      "|    total_timesteps  | 499903   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0127   |\n",
      "|    n_updates        | 124950   |\n",
      "----------------------------------\n",
      "Episode reward: 41.917118\n",
      "Episode reward: 47.737791\n",
      "Episode reward: 83.652654\n",
      "Episode reward: 50.755455\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9124     |\n",
      "|    fps              | 2998     |\n",
      "|    time_elapsed     | 166      |\n",
      "|    total_timesteps  | 500128   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 125006   |\n",
      "----------------------------------\n",
      "Episode reward: 49.461516\n",
      "Episode reward: 38.909751\n",
      "Episode reward: 131.235069\n",
      "Episode reward: 55.402955\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9128     |\n",
      "|    fps              | 2998     |\n",
      "|    time_elapsed     | 166      |\n",
      "|    total_timesteps  | 500409   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.807    |\n",
      "|    n_updates        | 125077   |\n",
      "----------------------------------\n",
      "Episode reward: 34.933844\n",
      "Episode reward: 99.278997\n",
      "Episode reward: 61.868433\n",
      "Episode reward: 81.663657\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9132     |\n",
      "|    fps              | 2998     |\n",
      "|    time_elapsed     | 166      |\n",
      "|    total_timesteps  | 500696   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0237   |\n",
      "|    n_updates        | 125148   |\n",
      "----------------------------------\n",
      "Episode reward: 65.850187\n",
      "Episode reward: 41.538642\n",
      "Episode reward: 31.94253\n",
      "Episode reward: 45.466802\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9136     |\n",
      "|    fps              | 2998     |\n",
      "|    time_elapsed     | 167      |\n",
      "|    total_timesteps  | 500882   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0221   |\n",
      "|    n_updates        | 125195   |\n",
      "----------------------------------\n",
      "Episode reward: 72.760921\n",
      "Episode reward: 23.823814\n",
      "Episode reward: 55.812185\n",
      "Episode reward: 33.90587\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9140     |\n",
      "|    fps              | 2998     |\n",
      "|    time_elapsed     | 167      |\n",
      "|    total_timesteps  | 501071   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0288   |\n",
      "|    n_updates        | 125242   |\n",
      "----------------------------------\n",
      "Episode reward: 36.285033\n",
      "Episode reward: 41.856314\n",
      "Episode reward: 50.896989\n",
      "Episode reward: 57.68229\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9144     |\n",
      "|    fps              | 2998     |\n",
      "|    time_elapsed     | 167      |\n",
      "|    total_timesteps  | 501259   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.651    |\n",
      "|    n_updates        | 125289   |\n",
      "----------------------------------\n",
      "Episode reward: 54.601299\n",
      "Episode reward: 49.850758\n",
      "Episode reward: 109.063765\n",
      "Episode reward: 44.504863\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9148     |\n",
      "|    fps              | 2997     |\n",
      "|    time_elapsed     | 167      |\n",
      "|    total_timesteps  | 501520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.698    |\n",
      "|    n_updates        | 125354   |\n",
      "----------------------------------\n",
      "Episode reward: 57.735627\n",
      "Episode reward: 58.423749\n",
      "Episode reward: 45.911023\n",
      "Episode reward: 33.933902\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9152     |\n",
      "|    fps              | 2997     |\n",
      "|    time_elapsed     | 167      |\n",
      "|    total_timesteps  | 501717   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.58     |\n",
      "|    n_updates        | 125404   |\n",
      "----------------------------------\n",
      "Episode reward: 45.904505\n",
      "Episode reward: 55.854739\n",
      "Episode reward: 40.894591\n",
      "Episode reward: 35.932968\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9156     |\n",
      "|    fps              | 2997     |\n",
      "|    time_elapsed     | 167      |\n",
      "|    total_timesteps  | 501896   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0305   |\n",
      "|    n_updates        | 125448   |\n",
      "----------------------------------\n",
      "Episode reward: 88.711048\n",
      "Episode reward: 39.789247\n",
      "Episode reward: 43.9345\n",
      "Episode reward: 43.817116\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9160     |\n",
      "|    fps              | 2997     |\n",
      "|    time_elapsed     | 167      |\n",
      "|    total_timesteps  | 502113   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.036    |\n",
      "|    n_updates        | 125503   |\n",
      "----------------------------------\n",
      "Episode reward: 59.885118\n",
      "Episode reward: 82.198961\n",
      "Episode reward: 43.920023\n",
      "Episode reward: 24.918222\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9164     |\n",
      "|    fps              | 2997     |\n",
      "|    time_elapsed     | 167      |\n",
      "|    total_timesteps  | 502326   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.031    |\n",
      "|    n_updates        | 125556   |\n",
      "----------------------------------\n",
      "Episode reward: 42.798451\n",
      "Episode reward: 58.318977\n",
      "Episode reward: 62.844947\n",
      "Episode reward: 46.840476\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9168     |\n",
      "|    fps              | 2997     |\n",
      "|    time_elapsed     | 167      |\n",
      "|    total_timesteps  | 502538   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.739    |\n",
      "|    n_updates        | 125609   |\n",
      "----------------------------------\n",
      "Episode reward: 63.853313\n",
      "Episode reward: 30.816722\n",
      "Episode reward: 62.144254\n",
      "Episode reward: 49.545536\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9172     |\n",
      "|    fps              | 2996     |\n",
      "|    time_elapsed     | 167      |\n",
      "|    total_timesteps  | 502746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0269   |\n",
      "|    n_updates        | 125661   |\n",
      "----------------------------------\n",
      "Episode reward: 74.84751\n",
      "Episode reward: 43.858871\n",
      "Episode reward: 33.940332\n",
      "Episode reward: 27.940553\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 54.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9176     |\n",
      "|    fps              | 2996     |\n",
      "|    time_elapsed     | 167      |\n",
      "|    total_timesteps  | 502927   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.747    |\n",
      "|    n_updates        | 125706   |\n",
      "----------------------------------\n",
      "Episode reward: 66.606177\n",
      "Episode reward: 30.823592\n",
      "Episode reward: 50.845645\n",
      "Episode reward: 118.172423\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9180     |\n",
      "|    fps              | 2996     |\n",
      "|    time_elapsed     | 167      |\n",
      "|    total_timesteps  | 503215   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.97     |\n",
      "|    n_updates        | 125778   |\n",
      "----------------------------------\n",
      "Episode reward: 64.716286\n",
      "Episode reward: 42.853476\n",
      "Episode reward: 76.335226\n",
      "Episode reward: 57.80487\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9184     |\n",
      "|    fps              | 2996     |\n",
      "|    time_elapsed     | 168      |\n",
      "|    total_timesteps  | 503459   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 125839   |\n",
      "----------------------------------\n",
      "Episode reward: 65.698857\n",
      "Episode reward: 48.800882\n",
      "Episode reward: 48.863599\n",
      "Episode reward: 51.80404\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9188     |\n",
      "|    fps              | 2995     |\n",
      "|    time_elapsed     | 168      |\n",
      "|    total_timesteps  | 503675   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 125893   |\n",
      "----------------------------------\n",
      "Episode reward: 63.250202\n",
      "Episode reward: 59.825574\n",
      "Episode reward: 93.561383\n",
      "Episode reward: 54.885495\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9192     |\n",
      "|    fps              | 2995     |\n",
      "|    time_elapsed     | 168      |\n",
      "|    total_timesteps  | 503968   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0255   |\n",
      "|    n_updates        | 125966   |\n",
      "----------------------------------\n",
      "Episode reward: 53.608898\n",
      "Episode reward: 53.670912\n",
      "Episode reward: 45.902199\n",
      "Episode reward: 48.940088\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9196     |\n",
      "|    fps              | 2995     |\n",
      "|    time_elapsed     | 168      |\n",
      "|    total_timesteps  | 504171   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.63     |\n",
      "|    n_updates        | 126017   |\n",
      "----------------------------------\n",
      "Episode reward: 70.418218\n",
      "Episode reward: 85.371759\n",
      "Episode reward: 40.469413\n",
      "Episode reward: 72.705289\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9200     |\n",
      "|    fps              | 2995     |\n",
      "|    time_elapsed     | 168      |\n",
      "|    total_timesteps  | 504444   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0235   |\n",
      "|    n_updates        | 126085   |\n",
      "----------------------------------\n",
      "Episode reward: 78.641651\n",
      "Episode reward: 57.348943\n",
      "Episode reward: 64.849044\n",
      "Episode reward: 29.929367\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9204     |\n",
      "|    fps              | 2995     |\n",
      "|    time_elapsed     | 168      |\n",
      "|    total_timesteps  | 504676   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0454   |\n",
      "|    n_updates        | 126143   |\n",
      "----------------------------------\n",
      "Episode reward: 52.802457\n",
      "Episode reward: 32.693881\n",
      "Episode reward: 88.973989\n",
      "Episode reward: 33.936133\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9208     |\n",
      "|    fps              | 2994     |\n",
      "|    time_elapsed     | 168      |\n",
      "|    total_timesteps  | 504904   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.367    |\n",
      "|    n_updates        | 126200   |\n",
      "----------------------------------\n",
      "Episode reward: 46.862779\n",
      "Episode reward: 57.866824\n",
      "Episode reward: 47.567926\n",
      "Episode reward: 34.919763\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 54.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9212     |\n",
      "|    fps              | 2994     |\n",
      "|    time_elapsed     | 168      |\n",
      "|    total_timesteps  | 505092   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 126247   |\n",
      "----------------------------------\n",
      "Episode reward: 42.644646\n",
      "Episode reward: 50.838812\n",
      "Episode reward: 44.670271\n",
      "Episode reward: 55.915941\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9216     |\n",
      "|    fps              | 2994     |\n",
      "|    time_elapsed     | 168      |\n",
      "|    total_timesteps  | 505287   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.17     |\n",
      "|    n_updates        | 126296   |\n",
      "----------------------------------\n",
      "Episode reward: 79.510328\n",
      "Episode reward: 71.123568\n",
      "Episode reward: 93.734086\n",
      "Episode reward: 30.845142\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9220     |\n",
      "|    fps              | 2994     |\n",
      "|    time_elapsed     | 168      |\n",
      "|    total_timesteps  | 505573   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 126368   |\n",
      "----------------------------------\n",
      "Episode reward: 65.766106\n",
      "Episode reward: 50.827167\n",
      "Episode reward: 52.708548\n",
      "Episode reward: 64.206177\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9224     |\n",
      "|    fps              | 2993     |\n",
      "|    time_elapsed     | 168      |\n",
      "|    total_timesteps  | 505809   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0205   |\n",
      "|    n_updates        | 126427   |\n",
      "----------------------------------\n",
      "Episode reward: 57.839499\n",
      "Episode reward: 60.849656\n",
      "Episode reward: 81.558114\n",
      "Episode reward: 70.752195\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9228     |\n",
      "|    fps              | 2993     |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 506082   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.764    |\n",
      "|    n_updates        | 126495   |\n",
      "----------------------------------\n",
      "Episode reward: 72.568213\n",
      "Episode reward: 47.92884\n",
      "Episode reward: 46.940815\n",
      "Episode reward: 43.883969\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9232     |\n",
      "|    fps              | 2993     |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 506294   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.709    |\n",
      "|    n_updates        | 126548   |\n",
      "----------------------------------\n",
      "Episode reward: 89.725096\n",
      "Episode reward: 34.937625\n",
      "Episode reward: 42.886208\n",
      "Episode reward: 35.505706\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9236     |\n",
      "|    fps              | 2993     |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 506498   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00906  |\n",
      "|    n_updates        | 126599   |\n",
      "----------------------------------\n",
      "Episode reward: 70.623576\n",
      "Episode reward: 54.874007\n",
      "Episode reward: 36.668401\n",
      "Episode reward: 81.126245\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9240     |\n",
      "|    fps              | 2993     |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 506743   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0413   |\n",
      "|    n_updates        | 126660   |\n",
      "----------------------------------\n",
      "Episode reward: 54.498724\n",
      "Episode reward: 36.913436\n",
      "Episode reward: 95.407963\n",
      "Episode reward: 63.972802\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9244     |\n",
      "|    fps              | 2992     |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 506999   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 126724   |\n",
      "----------------------------------\n",
      "Episode reward: 50.479071\n",
      "Episode reward: 67.916255\n",
      "Episode reward: 98.125305\n",
      "Episode reward: 99.018022\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9248     |\n",
      "|    fps              | 2992     |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 507334   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 126808   |\n",
      "----------------------------------\n",
      "Episode reward: 41.883733\n",
      "Episode reward: 71.436535\n",
      "Episode reward: 30.816926\n",
      "Episode reward: 77.802215\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9252     |\n",
      "|    fps              | 2991     |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 507557   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0106   |\n",
      "|    n_updates        | 126864   |\n",
      "----------------------------------\n",
      "Episode reward: 45.858528\n",
      "Episode reward: 54.866247\n",
      "Episode reward: 44.858\n",
      "Episode reward: 51.876561\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9256     |\n",
      "|    fps              | 2991     |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 507755   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 126913   |\n",
      "----------------------------------\n",
      "Episode reward: 39.916577\n",
      "Episode reward: 46.896225\n",
      "Episode reward: 40.91416\n",
      "Episode reward: 35.88978\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9260     |\n",
      "|    fps              | 2991     |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 507919   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.034    |\n",
      "|    n_updates        | 126954   |\n",
      "----------------------------------\n",
      "Episode reward: 68.749788\n",
      "Episode reward: 35.844746\n",
      "Episode reward: 31.901118\n",
      "Episode reward: 48.923069\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9264     |\n",
      "|    fps              | 2991     |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 508105   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.628    |\n",
      "|    n_updates        | 127001   |\n",
      "----------------------------------\n",
      "Episode reward: 61.685452\n",
      "Episode reward: 94.920269\n",
      "Episode reward: 80.280451\n",
      "Episode reward: 34.795741\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9268     |\n",
      "|    fps              | 2991     |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 508393   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0264   |\n",
      "|    n_updates        | 127073   |\n",
      "----------------------------------\n",
      "Episode reward: 30.915173\n",
      "Episode reward: 107.693513\n",
      "Episode reward: 38.47632\n",
      "Episode reward: 67.853724\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9272     |\n",
      "|    fps              | 2991     |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 508645   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.051    |\n",
      "|    n_updates        | 127136   |\n",
      "----------------------------------\n",
      "Episode reward: 41.759431\n",
      "Episode reward: 51.777222\n",
      "Episode reward: 63.487852\n",
      "Episode reward: 99.467646\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9276     |\n",
      "|    fps              | 2991     |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 508908   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.53     |\n",
      "|    n_updates        | 127201   |\n",
      "----------------------------------\n",
      "Episode reward: 35.446323\n",
      "Episode reward: 47.880254\n",
      "Episode reward: 61.358882\n",
      "Episode reward: 38.935861\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9280     |\n",
      "|    fps              | 2991     |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 509093   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.167    |\n",
      "|    n_updates        | 127248   |\n",
      "----------------------------------\n",
      "Episode reward: 65.803395\n",
      "Episode reward: 57.844307\n",
      "Episode reward: 42.539556\n",
      "Episode reward: 29.904992\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9284     |\n",
      "|    fps              | 2990     |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 509291   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0351   |\n",
      "|    n_updates        | 127297   |\n",
      "----------------------------------\n",
      "Episode reward: 100.938645\n",
      "Episode reward: 92.684797\n",
      "Episode reward: 30.87907\n",
      "Episode reward: 36.934463\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9288     |\n",
      "|    fps              | 2990     |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 509554   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0734   |\n",
      "|    n_updates        | 127363   |\n",
      "----------------------------------\n",
      "Episode reward: 38.913917\n",
      "Episode reward: 55.7085\n",
      "Episode reward: 36.941415\n",
      "Episode reward: 52.760416\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9292     |\n",
      "|    fps              | 2990     |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 509739   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 127409   |\n",
      "----------------------------------\n",
      "Episode reward: 56.097314\n",
      "Episode reward: 33.869235\n",
      "Episode reward: 39.944336\n",
      "Episode reward: 78.665411\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9296     |\n",
      "|    fps              | 2990     |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 509949   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.168    |\n",
      "|    n_updates        | 127462   |\n",
      "----------------------------------\n",
      "Episode reward: 88.217262\n",
      "Episode reward: 53.79843\n",
      "Episode reward: 60.844394\n",
      "Episode reward: 68.579193\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9300     |\n",
      "|    fps              | 2989     |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 510225   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.365    |\n",
      "|    n_updates        | 127531   |\n",
      "----------------------------------\n",
      "Episode reward: 66.679894\n",
      "Episode reward: 102.028965\n",
      "Episode reward: 55.174437\n",
      "Episode reward: 49.805511\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9304     |\n",
      "|    fps              | 2989     |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 510501   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.344    |\n",
      "|    n_updates        | 127600   |\n",
      "----------------------------------\n",
      "Episode reward: 37.949515\n",
      "Episode reward: 72.456331\n",
      "Episode reward: 45.944783\n",
      "Episode reward: 58.396961\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9308     |\n",
      "|    fps              | 2989     |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 510718   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.539    |\n",
      "|    n_updates        | 127654   |\n",
      "----------------------------------\n",
      "Episode reward: 69.708394\n",
      "Episode reward: 29.828401\n",
      "Episode reward: 51.128726\n",
      "Episode reward: 42.9074\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9312     |\n",
      "|    fps              | 2989     |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 510913   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.535    |\n",
      "|    n_updates        | 127703   |\n",
      "----------------------------------\n",
      "Episode reward: 77.814391\n",
      "Episode reward: 29.936127\n",
      "Episode reward: 44.752218\n",
      "Episode reward: 36.683498\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9316     |\n",
      "|    fps              | 2989     |\n",
      "|    time_elapsed     | 170      |\n",
      "|    total_timesteps  | 511104   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 127750   |\n",
      "----------------------------------\n",
      "Episode reward: 42.87291\n",
      "Episode reward: 56.761215\n",
      "Episode reward: 47.690131\n",
      "Episode reward: 39.846751\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9320     |\n",
      "|    fps              | 2989     |\n",
      "|    time_elapsed     | 171      |\n",
      "|    total_timesteps  | 511292   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0249   |\n",
      "|    n_updates        | 127797   |\n",
      "----------------------------------\n",
      "Episode reward: 53.763409\n",
      "Episode reward: 103.485282\n",
      "Episode reward: 56.720128\n",
      "Episode reward: 51.855664\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9324     |\n",
      "|    fps              | 2988     |\n",
      "|    time_elapsed     | 171      |\n",
      "|    total_timesteps  | 511559   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0239   |\n",
      "|    n_updates        | 127864   |\n",
      "----------------------------------\n",
      "Episode reward: 49.445256\n",
      "Episode reward: 35.924449\n",
      "Episode reward: 74.845367\n",
      "Episode reward: 41.609895\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9328     |\n",
      "|    fps              | 2988     |\n",
      "|    time_elapsed     | 171      |\n",
      "|    total_timesteps  | 511762   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11     |\n",
      "|    n_updates        | 127915   |\n",
      "----------------------------------\n",
      "Episode reward: 41.905238\n",
      "Episode reward: 40.747321\n",
      "Episode reward: 64.801714\n",
      "Episode reward: 31.803809\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9332     |\n",
      "|    fps              | 2988     |\n",
      "|    time_elapsed     | 171      |\n",
      "|    total_timesteps  | 511942   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 127960   |\n",
      "----------------------------------\n",
      "Episode reward: 79.500301\n",
      "Episode reward: 86.486207\n",
      "Episode reward: 63.814671\n",
      "Episode reward: 40.886429\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9336     |\n",
      "|    fps              | 2988     |\n",
      "|    time_elapsed     | 171      |\n",
      "|    total_timesteps  | 512215   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0331   |\n",
      "|    n_updates        | 128028   |\n",
      "----------------------------------\n",
      "Episode reward: 70.860767\n",
      "Episode reward: 30.922126\n",
      "Episode reward: 141.382478\n",
      "Episode reward: 80.598224\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9340     |\n",
      "|    fps              | 2988     |\n",
      "|    time_elapsed     | 171      |\n",
      "|    total_timesteps  | 512543   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0277   |\n",
      "|    n_updates        | 128110   |\n",
      "----------------------------------\n",
      "Episode reward: 32.928582\n",
      "Episode reward: 49.930353\n",
      "Episode reward: 34.961761\n",
      "Episode reward: 64.572488\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9344     |\n",
      "|    fps              | 2988     |\n",
      "|    time_elapsed     | 171      |\n",
      "|    total_timesteps  | 512726   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0336   |\n",
      "|    n_updates        | 128156   |\n",
      "----------------------------------\n",
      "Episode reward: 63.768017\n",
      "Episode reward: 31.719604\n",
      "Episode reward: 45.707953\n",
      "Episode reward: 50.914154\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.9     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9348     |\n",
      "|    fps              | 2988     |\n",
      "|    time_elapsed     | 171      |\n",
      "|    total_timesteps  | 512919   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 128204   |\n",
      "----------------------------------\n",
      "Episode reward: 65.722831\n",
      "Episode reward: 59.457888\n",
      "Episode reward: 54.889506\n",
      "Episode reward: 32.931017\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 55.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9352     |\n",
      "|    fps              | 2987     |\n",
      "|    time_elapsed     | 171      |\n",
      "|    total_timesteps  | 513133   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 128258   |\n",
      "----------------------------------\n",
      "Episode reward: 70.808761\n",
      "Episode reward: 72.205854\n",
      "Episode reward: 47.396763\n",
      "Episode reward: 59.369622\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9356     |\n",
      "|    fps              | 2987     |\n",
      "|    time_elapsed     | 171      |\n",
      "|    total_timesteps  | 513385   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.518    |\n",
      "|    n_updates        | 128321   |\n",
      "----------------------------------\n",
      "Episode reward: 80.783195\n",
      "Episode reward: 105.544269\n",
      "Episode reward: 34.908409\n",
      "Episode reward: 54.039178\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9360     |\n",
      "|    fps              | 2987     |\n",
      "|    time_elapsed     | 171      |\n",
      "|    total_timesteps  | 513664   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.021    |\n",
      "|    n_updates        | 128390   |\n",
      "----------------------------------\n",
      "Episode reward: 53.472047\n",
      "Episode reward: 76.615485\n",
      "Episode reward: 80.398511\n",
      "Episode reward: 43.943318\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9364     |\n",
      "|    fps              | 2987     |\n",
      "|    time_elapsed     | 172      |\n",
      "|    total_timesteps  | 513920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0219   |\n",
      "|    n_updates        | 128454   |\n",
      "----------------------------------\n",
      "Episode reward: 82.497573\n",
      "Episode reward: 103.056523\n",
      "Episode reward: 44.839202\n",
      "Episode reward: 71.747386\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9368     |\n",
      "|    fps              | 2987     |\n",
      "|    time_elapsed     | 172      |\n",
      "|    total_timesteps  | 514225   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0344   |\n",
      "|    n_updates        | 128531   |\n",
      "----------------------------------\n",
      "Episode reward: 42.936675\n",
      "Episode reward: 51.615956\n",
      "Episode reward: 36.859777\n",
      "Episode reward: 52.808177\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9372     |\n",
      "|    fps              | 2987     |\n",
      "|    time_elapsed     | 172      |\n",
      "|    total_timesteps  | 514410   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0131   |\n",
      "|    n_updates        | 128577   |\n",
      "----------------------------------\n",
      "Episode reward: 44.941891\n",
      "Episode reward: 40.863668\n",
      "Episode reward: 63.793508\n",
      "Episode reward: 44.933678\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9376     |\n",
      "|    fps              | 2987     |\n",
      "|    time_elapsed     | 172      |\n",
      "|    total_timesteps  | 514605   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0255   |\n",
      "|    n_updates        | 128626   |\n",
      "----------------------------------\n",
      "Episode reward: 83.536741\n",
      "Episode reward: 43.882763\n",
      "Episode reward: 78.605703\n",
      "Episode reward: 86.633862\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9380     |\n",
      "|    fps              | 2986     |\n",
      "|    time_elapsed     | 172      |\n",
      "|    total_timesteps  | 514899   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.41     |\n",
      "|    n_updates        | 128699   |\n",
      "----------------------------------\n",
      "Episode reward: 43.912261\n",
      "Episode reward: 41.91643\n",
      "Episode reward: 47.449393\n",
      "Episode reward: 69.494176\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9384     |\n",
      "|    fps              | 2986     |\n",
      "|    time_elapsed     | 172      |\n",
      "|    total_timesteps  | 515103   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 128750   |\n",
      "----------------------------------\n",
      "Episode reward: 50.806899\n",
      "Episode reward: 37.871192\n",
      "Episode reward: 67.725674\n",
      "Episode reward: 104.893665\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9388     |\n",
      "|    fps              | 2986     |\n",
      "|    time_elapsed     | 172      |\n",
      "|    total_timesteps  | 515385   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.04     |\n",
      "|    n_updates        | 128821   |\n",
      "----------------------------------\n",
      "Episode reward: 53.110208\n",
      "Episode reward: 91.25526\n",
      "Episode reward: 48.833097\n",
      "Episode reward: 73.212433\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9392     |\n",
      "|    fps              | 2985     |\n",
      "|    time_elapsed     | 172      |\n",
      "|    total_timesteps  | 515655   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0206   |\n",
      "|    n_updates        | 128888   |\n",
      "----------------------------------\n",
      "Episode reward: 53.583037\n",
      "Episode reward: 49.869361\n",
      "Episode reward: 49.829828\n",
      "Episode reward: 39.937879\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9396     |\n",
      "|    fps              | 2985     |\n",
      "|    time_elapsed     | 172      |\n",
      "|    total_timesteps  | 515849   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.461    |\n",
      "|    n_updates        | 128937   |\n",
      "----------------------------------\n",
      "Episode reward: 52.79005\n",
      "Episode reward: 97.638843\n",
      "Episode reward: 116.757827\n",
      "Episode reward: 53.862658\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9400     |\n",
      "|    fps              | 2985     |\n",
      "|    time_elapsed     | 172      |\n",
      "|    total_timesteps  | 516175   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 129018   |\n",
      "----------------------------------\n",
      "Episode reward: 47.924141\n",
      "Episode reward: 69.71411\n",
      "Episode reward: 63.57981\n",
      "Episode reward: 36.806033\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9404     |\n",
      "|    fps              | 2985     |\n",
      "|    time_elapsed     | 172      |\n",
      "|    total_timesteps  | 516394   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.727    |\n",
      "|    n_updates        | 129073   |\n",
      "----------------------------------\n",
      "Episode reward: 44.890015\n",
      "Episode reward: 60.884096\n",
      "Episode reward: 54.911187\n",
      "Episode reward: 60.103629\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9408     |\n",
      "|    fps              | 2985     |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 516616   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.31     |\n",
      "|    n_updates        | 129128   |\n",
      "----------------------------------\n",
      "Episode reward: 101.552869\n",
      "Episode reward: 61.694764\n",
      "Episode reward: 72.690682\n",
      "Episode reward: 80.607112\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9412     |\n",
      "|    fps              | 2985     |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 516939   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.26     |\n",
      "|    n_updates        | 129209   |\n",
      "----------------------------------\n",
      "Episode reward: 90.625646\n",
      "Episode reward: 41.907562\n",
      "Episode reward: 51.88367\n",
      "Episode reward: 33.844648\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9416     |\n",
      "|    fps              | 2985     |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 517158   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0125   |\n",
      "|    n_updates        | 129264   |\n",
      "----------------------------------\n",
      "Episode reward: 32.530861\n",
      "Episode reward: 104.612556\n",
      "Episode reward: 40.851515\n",
      "Episode reward: 30.667492\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9420     |\n",
      "|    fps              | 2985     |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 517389   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.318    |\n",
      "|    n_updates        | 129322   |\n",
      "----------------------------------\n",
      "Episode reward: 58.191738\n",
      "Episode reward: 58.833264\n",
      "Episode reward: 48.724299\n",
      "Episode reward: 44.649244\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9424     |\n",
      "|    fps              | 2985     |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 517601   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0165   |\n",
      "|    n_updates        | 129375   |\n",
      "----------------------------------\n",
      "Episode reward: 68.702643\n",
      "Episode reward: 52.82718\n",
      "Episode reward: 44.89839\n",
      "Episode reward: 85.727361\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9428     |\n",
      "|    fps              | 2985     |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 517854   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.45     |\n",
      "|    n_updates        | 129438   |\n",
      "----------------------------------\n",
      "Episode reward: 47.903979\n",
      "Episode reward: 48.776389\n",
      "Episode reward: 86.579881\n",
      "Episode reward: 81.038022\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9432     |\n",
      "|    fps              | 2985     |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 518140   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 129509   |\n",
      "----------------------------------\n",
      "Episode reward: 36.674864\n",
      "Episode reward: 55.514825\n",
      "Episode reward: 101.701127\n",
      "Episode reward: 55.246997\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9436     |\n",
      "|    fps              | 2985     |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 518407   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.01     |\n",
      "|    n_updates        | 129576   |\n",
      "----------------------------------\n",
      "Episode reward: 44.763234\n",
      "Episode reward: 41.954036\n",
      "Episode reward: 90.848421\n",
      "Episode reward: 35.450671\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9440     |\n",
      "|    fps              | 2985     |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 518624   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 129630   |\n",
      "----------------------------------\n",
      "Episode reward: 59.587371\n",
      "Episode reward: 92.068105\n",
      "Episode reward: 31.898103\n",
      "Episode reward: 34.867586\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9444     |\n",
      "|    fps              | 2985     |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 518848   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 129686   |\n",
      "----------------------------------\n",
      "Episode reward: 38.940753\n",
      "Episode reward: 59.865184\n",
      "Episode reward: 77.526557\n",
      "Episode reward: 54.885658\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9448     |\n",
      "|    fps              | 2985     |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 519080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00748  |\n",
      "|    n_updates        | 129744   |\n",
      "----------------------------------\n",
      "Episode reward: 70.852466\n",
      "Episode reward: 39.906244\n",
      "Episode reward: 63.757407\n",
      "Episode reward: 39.853768\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9452     |\n",
      "|    fps              | 2984     |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 519296   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 129798   |\n",
      "----------------------------------\n",
      "Episode reward: 79.009135\n",
      "Episode reward: 95.101529\n",
      "Episode reward: 58.717455\n",
      "Episode reward: 29.932575\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9456     |\n",
      "|    fps              | 2984     |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 519562   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.799    |\n",
      "|    n_updates        | 129865   |\n",
      "----------------------------------\n",
      "Episode reward: 33.889931\n",
      "Episode reward: 84.47537\n",
      "Episode reward: 33.864426\n",
      "Episode reward: 42.92713\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9460     |\n",
      "|    fps              | 2984     |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 519759   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.027    |\n",
      "|    n_updates        | 129914   |\n",
      "----------------------------------\n",
      "Episode reward: 82.593343\n",
      "Episode reward: 44.830551\n",
      "Episode reward: 62.348627\n",
      "Episode reward: 68.668553\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9464     |\n",
      "|    fps              | 2984     |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 520019   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.123    |\n",
      "|    n_updates        | 129979   |\n",
      "----------------------------------\n",
      "Episode reward: 79.251028\n",
      "Episode reward: 51.826576\n",
      "Episode reward: 58.813631\n",
      "Episode reward: 73.761434\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9468     |\n",
      "|    fps              | 2984     |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 520285   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.02     |\n",
      "|    n_updates        | 130046   |\n",
      "----------------------------------\n",
      "Episode reward: 78.465916\n",
      "Episode reward: 41.453017\n",
      "Episode reward: 53.711763\n",
      "Episode reward: 75.751711\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9472     |\n",
      "|    fps              | 2984     |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 520536   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.048    |\n",
      "|    n_updates        | 130108   |\n",
      "----------------------------------\n",
      "Episode reward: 54.79179\n",
      "Episode reward: 77.830228\n",
      "Episode reward: 36.612347\n",
      "Episode reward: 64.876315\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9476     |\n",
      "|    fps              | 2984     |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 520771   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.912    |\n",
      "|    n_updates        | 130167   |\n",
      "----------------------------------\n",
      "Episode reward: 63.340066\n",
      "Episode reward: 45.904938\n",
      "Episode reward: 72.406838\n",
      "Episode reward: 43.936494\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9480     |\n",
      "|    fps              | 2984     |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 520998   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.026    |\n",
      "|    n_updates        | 130224   |\n",
      "----------------------------------\n",
      "Episode reward: 60.435\n",
      "Episode reward: 45.910167\n",
      "Episode reward: 85.375366\n",
      "Episode reward: 52.804951\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9484     |\n",
      "|    fps              | 2983     |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 521245   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0329   |\n",
      "|    n_updates        | 130286   |\n",
      "----------------------------------\n",
      "Episode reward: 36.384219\n",
      "Episode reward: 40.951153\n",
      "Episode reward: 40.89066\n",
      "Episode reward: 35.91977\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9488     |\n",
      "|    fps              | 2983     |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 521400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.19     |\n",
      "|    n_updates        | 130324   |\n",
      "----------------------------------\n",
      "Episode reward: 60.552711\n",
      "Episode reward: 43.546444\n",
      "Episode reward: 53.810577\n",
      "Episode reward: 55.809539\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9492     |\n",
      "|    fps              | 2983     |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 521615   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.348    |\n",
      "|    n_updates        | 130378   |\n",
      "----------------------------------\n",
      "Episode reward: 35.848596\n",
      "Episode reward: 73.46677\n",
      "Episode reward: 45.901604\n",
      "Episode reward: 49.792798\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9496     |\n",
      "|    fps              | 2982     |\n",
      "|    time_elapsed     | 174      |\n",
      "|    total_timesteps  | 521821   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0338   |\n",
      "|    n_updates        | 130430   |\n",
      "----------------------------------\n",
      "Episode reward: 60.613534\n",
      "Episode reward: 46.929044\n",
      "Episode reward: 42.946594\n",
      "Episode reward: 55.777443\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9500     |\n",
      "|    fps              | 2982     |\n",
      "|    time_elapsed     | 175      |\n",
      "|    total_timesteps  | 522028   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.86     |\n",
      "|    n_updates        | 130481   |\n",
      "----------------------------------\n",
      "Episode reward: 104.666377\n",
      "Episode reward: 30.76274\n",
      "Episode reward: 76.732801\n",
      "Episode reward: 29.507276\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9504     |\n",
      "|    fps              | 2982     |\n",
      "|    time_elapsed     | 175      |\n",
      "|    total_timesteps  | 522288   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0291   |\n",
      "|    n_updates        | 130546   |\n",
      "----------------------------------\n",
      "Episode reward: 29.719221\n",
      "Episode reward: 55.775341\n",
      "Episode reward: 35.897562\n",
      "Episode reward: 143.509993\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9508     |\n",
      "|    fps              | 2981     |\n",
      "|    time_elapsed     | 175      |\n",
      "|    total_timesteps  | 522570   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.63     |\n",
      "|    n_updates        | 130617   |\n",
      "----------------------------------\n",
      "Episode reward: 97.606756\n",
      "Episode reward: 40.905229\n",
      "Episode reward: 37.869789\n",
      "Episode reward: 50.609138\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9512     |\n",
      "|    fps              | 2981     |\n",
      "|    time_elapsed     | 175      |\n",
      "|    total_timesteps  | 522798   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.754    |\n",
      "|    n_updates        | 130674   |\n",
      "----------------------------------\n",
      "Episode reward: 116.589864\n",
      "Episode reward: 71.754901\n",
      "Episode reward: 44.592455\n",
      "Episode reward: 47.676097\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9516     |\n",
      "|    fps              | 2981     |\n",
      "|    time_elapsed     | 175      |\n",
      "|    total_timesteps  | 523084   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.759    |\n",
      "|    n_updates        | 130745   |\n",
      "----------------------------------\n",
      "Episode reward: 55.658082\n",
      "Episode reward: 60.818542\n",
      "Episode reward: 45.560663\n",
      "Episode reward: 51.728482\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9520     |\n",
      "|    fps              | 2980     |\n",
      "|    time_elapsed     | 175      |\n",
      "|    total_timesteps  | 523299   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.04     |\n",
      "|    n_updates        | 130799   |\n",
      "----------------------------------\n",
      "Episode reward: 102.977173\n",
      "Episode reward: 42.745405\n",
      "Episode reward: 92.905368\n",
      "Episode reward: 63.795044\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9524     |\n",
      "|    fps              | 2980     |\n",
      "|    time_elapsed     | 175      |\n",
      "|    total_timesteps  | 523611   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.325    |\n",
      "|    n_updates        | 130877   |\n",
      "----------------------------------\n",
      "Episode reward: 35.9599\n",
      "Episode reward: 83.104401\n",
      "Episode reward: 32.815739\n",
      "Episode reward: 69.550657\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9528     |\n",
      "|    fps              | 2980     |\n",
      "|    time_elapsed     | 175      |\n",
      "|    total_timesteps  | 523835   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0195   |\n",
      "|    n_updates        | 130933   |\n",
      "----------------------------------\n",
      "Episode reward: 59.091667\n",
      "Episode reward: 47.894596\n",
      "Episode reward: 33.779988\n",
      "Episode reward: 41.917452\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9532     |\n",
      "|    fps              | 2980     |\n",
      "|    time_elapsed     | 175      |\n",
      "|    total_timesteps  | 524019   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.623    |\n",
      "|    n_updates        | 130979   |\n",
      "----------------------------------\n",
      "Episode reward: 50.907634\n",
      "Episode reward: 25.852061\n",
      "Episode reward: 80.500307\n",
      "Episode reward: 46.727396\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9536     |\n",
      "|    fps              | 2980     |\n",
      "|    time_elapsed     | 175      |\n",
      "|    total_timesteps  | 524227   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 131031   |\n",
      "----------------------------------\n",
      "Episode reward: 63.771462\n",
      "Episode reward: 59.843698\n",
      "Episode reward: 29.801172\n",
      "Episode reward: 40.921985\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9540     |\n",
      "|    fps              | 2980     |\n",
      "|    time_elapsed     | 175      |\n",
      "|    total_timesteps  | 524422   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0263   |\n",
      "|    n_updates        | 131080   |\n",
      "----------------------------------\n",
      "Episode reward: 56.820917\n",
      "Episode reward: 105.837148\n",
      "Episode reward: 38.549718\n",
      "Episode reward: 84.540217\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9544     |\n",
      "|    fps              | 2980     |\n",
      "|    time_elapsed     | 176      |\n",
      "|    total_timesteps  | 524728   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.549    |\n",
      "|    n_updates        | 131156   |\n",
      "----------------------------------\n",
      "Episode reward: 54.779658\n",
      "Episode reward: 50.921152\n",
      "Episode reward: 38.942874\n",
      "Episode reward: 62.394302\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9548     |\n",
      "|    fps              | 2979     |\n",
      "|    time_elapsed     | 176      |\n",
      "|    total_timesteps  | 524936   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0267   |\n",
      "|    n_updates        | 131208   |\n",
      "----------------------------------\n",
      "Episode reward: 118.827551\n",
      "Episode reward: 66.313627\n",
      "Episode reward: 46.648856\n",
      "Episode reward: 31.9354\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9552     |\n",
      "|    fps              | 2979     |\n",
      "|    time_elapsed     | 176      |\n",
      "|    total_timesteps  | 525216   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.291    |\n",
      "|    n_updates        | 131278   |\n",
      "----------------------------------\n",
      "Episode reward: 53.916134\n",
      "Episode reward: 63.73218\n",
      "Episode reward: 75.952923\n",
      "Episode reward: 62.843393\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9556     |\n",
      "|    fps              | 2979     |\n",
      "|    time_elapsed     | 176      |\n",
      "|    total_timesteps  | 525483   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 131345   |\n",
      "----------------------------------\n",
      "Episode reward: 37.822673\n",
      "Episode reward: 79.856945\n",
      "Episode reward: 45.803869\n",
      "Episode reward: 32.879927\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9560     |\n",
      "|    fps              | 2979     |\n",
      "|    time_elapsed     | 176      |\n",
      "|    total_timesteps  | 525681   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 131395   |\n",
      "----------------------------------\n",
      "Episode reward: 70.741649\n",
      "Episode reward: 54.817534\n",
      "Episode reward: 63.26849\n",
      "Episode reward: 61.160871\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9564     |\n",
      "|    fps              | 2979     |\n",
      "|    time_elapsed     | 176      |\n",
      "|    total_timesteps  | 525934   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.803    |\n",
      "|    n_updates        | 131458   |\n",
      "----------------------------------\n",
      "Episode reward: 64.041155\n",
      "Episode reward: 41.811094\n",
      "Episode reward: 37.750226\n",
      "Episode reward: 55.848889\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9568     |\n",
      "|    fps              | 2979     |\n",
      "|    time_elapsed     | 176      |\n",
      "|    total_timesteps  | 526135   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 131508   |\n",
      "----------------------------------\n",
      "Episode reward: 83.529663\n",
      "Episode reward: 33.87386\n",
      "Episode reward: 48.35472\n",
      "Episode reward: 71.833943\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9572     |\n",
      "|    fps              | 2979     |\n",
      "|    time_elapsed     | 176      |\n",
      "|    total_timesteps  | 526383   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 131570   |\n",
      "----------------------------------\n",
      "Episode reward: 58.715964\n",
      "Episode reward: 80.708408\n",
      "Episode reward: 91.488323\n",
      "Episode reward: 55.85821\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9576     |\n",
      "|    fps              | 2979     |\n",
      "|    time_elapsed     | 176      |\n",
      "|    total_timesteps  | 526672   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0241   |\n",
      "|    n_updates        | 131642   |\n",
      "----------------------------------\n",
      "Episode reward: 59.871736\n",
      "Episode reward: 33.732518\n",
      "Episode reward: 41.773139\n",
      "Episode reward: 58.481201\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9580     |\n",
      "|    fps              | 2978     |\n",
      "|    time_elapsed     | 176      |\n",
      "|    total_timesteps  | 526867   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0221   |\n",
      "|    n_updates        | 131691   |\n",
      "----------------------------------\n",
      "Episode reward: 37.746851\n",
      "Episode reward: 52.896593\n",
      "Episode reward: 42.841739\n",
      "Episode reward: 69.30077\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9584     |\n",
      "|    fps              | 2978     |\n",
      "|    time_elapsed     | 176      |\n",
      "|    total_timesteps  | 527074   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.895    |\n",
      "|    n_updates        | 131743   |\n",
      "----------------------------------\n",
      "Episode reward: 60.731322\n",
      "Episode reward: 41.888339\n",
      "Episode reward: 67.806001\n",
      "Episode reward: 82.793243\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9588     |\n",
      "|    fps              | 2978     |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total_timesteps  | 527328   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 131806   |\n",
      "----------------------------------\n",
      "Episode reward: 65.715808\n",
      "Episode reward: 49.619947\n",
      "Episode reward: 92.136945\n",
      "Episode reward: 90.189306\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9592     |\n",
      "|    fps              | 2978     |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total_timesteps  | 527648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.61     |\n",
      "|    n_updates        | 131886   |\n",
      "----------------------------------\n",
      "Episode reward: 77.780193\n",
      "Episode reward: 29.821454\n",
      "Episode reward: 32.922256\n",
      "Episode reward: 43.881356\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9596     |\n",
      "|    fps              | 2978     |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total_timesteps  | 527833   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 131933   |\n",
      "----------------------------------\n",
      "Episode reward: 39.651966\n",
      "Episode reward: 69.500875\n",
      "Episode reward: 50.854213\n",
      "Episode reward: 53.639891\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9600     |\n",
      "|    fps              | 2978     |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total_timesteps  | 528048   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00898  |\n",
      "|    n_updates        | 131986   |\n",
      "----------------------------------\n",
      "Episode reward: 33.478341\n",
      "Episode reward: 53.853783\n",
      "Episode reward: 61.810035\n",
      "Episode reward: 45.729489\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9604     |\n",
      "|    fps              | 2978     |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total_timesteps  | 528244   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.01     |\n",
      "|    n_updates        | 132035   |\n",
      "----------------------------------\n",
      "Episode reward: 62.69782\n",
      "Episode reward: 68.782137\n",
      "Episode reward: 48.676364\n",
      "Episode reward: 102.305384\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9608     |\n",
      "|    fps              | 2978     |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total_timesteps  | 528535   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.65     |\n",
      "|    n_updates        | 132108   |\n",
      "----------------------------------\n",
      "Episode reward: 51.857747\n",
      "Episode reward: 42.608996\n",
      "Episode reward: 40.79994\n",
      "Episode reward: 60.94095\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9612     |\n",
      "|    fps              | 2977     |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total_timesteps  | 528733   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.023    |\n",
      "|    n_updates        | 132158   |\n",
      "----------------------------------\n",
      "Episode reward: 155.3438\n",
      "Episode reward: 30.937217\n",
      "Episode reward: 35.937439\n",
      "Episode reward: 51.843516\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9616     |\n",
      "|    fps              | 2977     |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total_timesteps  | 529009   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0332   |\n",
      "|    n_updates        | 132227   |\n",
      "----------------------------------\n",
      "Episode reward: 64.708053\n",
      "Episode reward: 37.829085\n",
      "Episode reward: 65.712799\n",
      "Episode reward: 56.848084\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9620     |\n",
      "|    fps              | 2976     |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total_timesteps  | 529237   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0306   |\n",
      "|    n_updates        | 132284   |\n",
      "----------------------------------\n",
      "Episode reward: 76.06783\n",
      "Episode reward: 41.862813\n",
      "Episode reward: 59.645516\n",
      "Episode reward: 49.446446\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9624     |\n",
      "|    fps              | 2976     |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total_timesteps  | 529466   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 132341   |\n",
      "----------------------------------\n",
      "Episode reward: 45.761631\n",
      "Episode reward: 40.481324\n",
      "Episode reward: 57.367647\n",
      "Episode reward: 78.804396\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9628     |\n",
      "|    fps              | 2976     |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total_timesteps  | 529690   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 132397   |\n",
      "----------------------------------\n",
      "Episode reward: 32.73661\n",
      "Episode reward: 41.955341\n",
      "Episode reward: 49.91286\n",
      "Episode reward: 124.419499\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9632     |\n",
      "|    fps              | 2975     |\n",
      "|    time_elapsed     | 178      |\n",
      "|    total_timesteps  | 529943   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 132460   |\n",
      "----------------------------------\n",
      "Episode reward: 82.337036\n",
      "Episode reward: 25.919415\n",
      "Episode reward: 88.739385\n",
      "Episode reward: 58.289841\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9636     |\n",
      "|    fps              | 2975     |\n",
      "|    time_elapsed     | 178      |\n",
      "|    total_timesteps  | 530201   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0225   |\n",
      "|    n_updates        | 132525   |\n",
      "----------------------------------\n",
      "Episode reward: 48.888985\n",
      "Episode reward: 40.480149\n",
      "Episode reward: 92.948055\n",
      "Episode reward: 28.847723\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9640     |\n",
      "|    fps              | 2975     |\n",
      "|    time_elapsed     | 178      |\n",
      "|    total_timesteps  | 530418   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.16     |\n",
      "|    n_updates        | 132579   |\n",
      "----------------------------------\n",
      "Episode reward: 42.874811\n",
      "Episode reward: 65.659258\n",
      "Episode reward: 88.725783\n",
      "Episode reward: 49.590553\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9644     |\n",
      "|    fps              | 2975     |\n",
      "|    time_elapsed     | 178      |\n",
      "|    total_timesteps  | 530666   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0318   |\n",
      "|    n_updates        | 132641   |\n",
      "----------------------------------\n",
      "Episode reward: 38.771207\n",
      "Episode reward: 100.59822\n",
      "Episode reward: 93.888017\n",
      "Episode reward: 58.032727\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9648     |\n",
      "|    fps              | 2974     |\n",
      "|    time_elapsed     | 178      |\n",
      "|    total_timesteps  | 530961   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.6      |\n",
      "|    n_updates        | 132715   |\n",
      "----------------------------------\n",
      "Episode reward: 54.837583\n",
      "Episode reward: 30.547437\n",
      "Episode reward: 60.655548\n",
      "Episode reward: 36.490637\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9652     |\n",
      "|    fps              | 2974     |\n",
      "|    time_elapsed     | 178      |\n",
      "|    total_timesteps  | 531145   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0243   |\n",
      "|    n_updates        | 132761   |\n",
      "----------------------------------\n",
      "Episode reward: 34.485695\n",
      "Episode reward: 29.928708\n",
      "Episode reward: 52.417742\n",
      "Episode reward: 41.784113\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9656     |\n",
      "|    fps              | 2974     |\n",
      "|    time_elapsed     | 178      |\n",
      "|    total_timesteps  | 531305   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0142   |\n",
      "|    n_updates        | 132801   |\n",
      "----------------------------------\n",
      "Episode reward: 80.107131\n",
      "Episode reward: 54.850371\n",
      "Episode reward: 78.366049\n",
      "Episode reward: 47.89461\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9660     |\n",
      "|    fps              | 2974     |\n",
      "|    time_elapsed     | 178      |\n",
      "|    total_timesteps  | 531568   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0394   |\n",
      "|    n_updates        | 132866   |\n",
      "----------------------------------\n",
      "Episode reward: 44.935627\n",
      "Episode reward: 39.8944\n",
      "Episode reward: 61.828171\n",
      "Episode reward: 33.700393\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9664     |\n",
      "|    fps              | 2974     |\n",
      "|    time_elapsed     | 178      |\n",
      "|    total_timesteps  | 531749   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.997    |\n",
      "|    n_updates        | 132912   |\n",
      "----------------------------------\n",
      "Episode reward: 42.791231\n",
      "Episode reward: 63.621885\n",
      "Episode reward: 33.443809\n",
      "Episode reward: 156.465793\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9668     |\n",
      "|    fps              | 2974     |\n",
      "|    time_elapsed     | 178      |\n",
      "|    total_timesteps  | 532054   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.974    |\n",
      "|    n_updates        | 132988   |\n",
      "----------------------------------\n",
      "Episode reward: 36.658078\n",
      "Episode reward: 50.385518\n",
      "Episode reward: 75.723035\n",
      "Episode reward: 46.615772\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9672     |\n",
      "|    fps              | 2974     |\n",
      "|    time_elapsed     | 178      |\n",
      "|    total_timesteps  | 532265   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0253   |\n",
      "|    n_updates        | 133041   |\n",
      "----------------------------------\n",
      "Episode reward: 46.744027\n",
      "Episode reward: 42.913048\n",
      "Episode reward: 51.689521\n",
      "Episode reward: 63.79174\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9676     |\n",
      "|    fps              | 2974     |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total_timesteps  | 532471   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.58     |\n",
      "|    n_updates        | 133092   |\n",
      "----------------------------------\n",
      "Episode reward: 58.738954\n",
      "Episode reward: 50.718883\n",
      "Episode reward: 80.507559\n",
      "Episode reward: 39.850713\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9680     |\n",
      "|    fps              | 2973     |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total_timesteps  | 532703   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 133150   |\n",
      "----------------------------------\n",
      "Episode reward: 93.278561\n",
      "Episode reward: 55.433672\n",
      "Episode reward: 36.858607\n",
      "Episode reward: 38.883492\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9684     |\n",
      "|    fps              | 2973     |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total_timesteps  | 532937   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0208   |\n",
      "|    n_updates        | 133209   |\n",
      "----------------------------------\n",
      "Episode reward: 41.804398\n",
      "Episode reward: 77.823197\n",
      "Episode reward: 51.867446\n",
      "Episode reward: 95.397373\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9688     |\n",
      "|    fps              | 2973     |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total_timesteps  | 533216   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0284   |\n",
      "|    n_updates        | 133278   |\n",
      "----------------------------------\n",
      "Episode reward: 43.886365\n",
      "Episode reward: 59.846262\n",
      "Episode reward: 37.874918\n",
      "Episode reward: 32.933152\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9692     |\n",
      "|    fps              | 2973     |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total_timesteps  | 533391   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0313   |\n",
      "|    n_updates        | 133322   |\n",
      "----------------------------------\n",
      "Episode reward: 59.834185\n",
      "Episode reward: 50.891996\n",
      "Episode reward: 44.927702\n",
      "Episode reward: 39.729606\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9696     |\n",
      "|    fps              | 2972     |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total_timesteps  | 533587   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0336   |\n",
      "|    n_updates        | 133371   |\n",
      "----------------------------------\n",
      "Episode reward: 34.77491\n",
      "Episode reward: 90.713619\n",
      "Episode reward: 43.852781\n",
      "Episode reward: 42.932599\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9700     |\n",
      "|    fps              | 2972     |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total_timesteps  | 533801   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0232   |\n",
      "|    n_updates        | 133425   |\n",
      "----------------------------------\n",
      "Episode reward: 34.835326\n",
      "Episode reward: 51.928835\n",
      "Episode reward: 82.650001\n",
      "Episode reward: 94.793612\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9704     |\n",
      "|    fps              | 2972     |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total_timesteps  | 534077   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0146   |\n",
      "|    n_updates        | 133494   |\n",
      "----------------------------------\n",
      "Episode reward: 44.894966\n",
      "Episode reward: 39.84411\n",
      "Episode reward: 31.934292\n",
      "Episode reward: 96.87653\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9708     |\n",
      "|    fps              | 2972     |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total_timesteps  | 534293   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0206   |\n",
      "|    n_updates        | 133548   |\n",
      "----------------------------------\n",
      "Episode reward: 28.658875\n",
      "Episode reward: 72.149873\n",
      "Episode reward: 44.843547\n",
      "Episode reward: 27.517635\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9712     |\n",
      "|    fps              | 2972     |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total_timesteps  | 534469   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.378    |\n",
      "|    n_updates        | 133592   |\n",
      "----------------------------------\n",
      "Episode reward: 46.835818\n",
      "Episode reward: 72.511845\n",
      "Episode reward: 74.771215\n",
      "Episode reward: 73.649908\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9716     |\n",
      "|    fps              | 2972     |\n",
      "|    time_elapsed     | 179      |\n",
      "|    total_timesteps  | 534740   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.05     |\n",
      "|    n_updates        | 133659   |\n",
      "----------------------------------\n",
      "Episode reward: 46.883643\n",
      "Episode reward: 74.745259\n",
      "Episode reward: 87.053792\n",
      "Episode reward: 52.731337\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9720     |\n",
      "|    fps              | 2971     |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total_timesteps  | 535003   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.839    |\n",
      "|    n_updates        | 133725   |\n",
      "----------------------------------\n",
      "Episode reward: 49.790588\n",
      "Episode reward: 41.794576\n",
      "Episode reward: 37.919376\n",
      "Episode reward: 47.64735\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9724     |\n",
      "|    fps              | 2971     |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total_timesteps  | 535181   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0492   |\n",
      "|    n_updates        | 133770   |\n",
      "----------------------------------\n",
      "Episode reward: 52.812676\n",
      "Episode reward: 33.740817\n",
      "Episode reward: 78.430232\n",
      "Episode reward: 32.853035\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9728     |\n",
      "|    fps              | 2971     |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total_timesteps  | 535382   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.68     |\n",
      "|    n_updates        | 133820   |\n",
      "----------------------------------\n",
      "Episode reward: 58.491837\n",
      "Episode reward: 74.721164\n",
      "Episode reward: 37.872006\n",
      "Episode reward: 71.747582\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9732     |\n",
      "|    fps              | 2971     |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total_timesteps  | 535628   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0217   |\n",
      "|    n_updates        | 133881   |\n",
      "----------------------------------\n",
      "Episode reward: 49.570736\n",
      "Episode reward: 42.736229\n",
      "Episode reward: 86.220796\n",
      "Episode reward: 44.886089\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9736     |\n",
      "|    fps              | 2971     |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total_timesteps  | 535853   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.019    |\n",
      "|    n_updates        | 133938   |\n",
      "----------------------------------\n",
      "Episode reward: 48.447912\n",
      "Episode reward: 29.778744\n",
      "Episode reward: 76.776899\n",
      "Episode reward: 44.827473\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 55.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9740     |\n",
      "|    fps              | 2970     |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total_timesteps  | 536054   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0215   |\n",
      "|    n_updates        | 133988   |\n",
      "----------------------------------\n",
      "Episode reward: 31.931431\n",
      "Episode reward: 32.631947\n",
      "Episode reward: 112.405992\n",
      "Episode reward: 33.739318\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56       |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9744     |\n",
      "|    fps              | 2970     |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total_timesteps  | 536267   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0138   |\n",
      "|    n_updates        | 134041   |\n",
      "----------------------------------\n",
      "Episode reward: 64.370192\n",
      "Episode reward: 27.866839\n",
      "Episode reward: 55.844334\n",
      "Episode reward: 109.463273\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9748     |\n",
      "|    fps              | 2970     |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total_timesteps  | 536540   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0887   |\n",
      "|    n_updates        | 134109   |\n",
      "----------------------------------\n",
      "Episode reward: 42.753871\n",
      "Episode reward: 85.942824\n",
      "Episode reward: 101.47903\n",
      "Episode reward: 47.92466\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9752     |\n",
      "|    fps              | 2970     |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total_timesteps  | 536825   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0171   |\n",
      "|    n_updates        | 134181   |\n",
      "----------------------------------\n",
      "Episode reward: 46.886159\n",
      "Episode reward: 57.824287\n",
      "Episode reward: 72.741178\n",
      "Episode reward: 33.93289\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9756     |\n",
      "|    fps              | 2970     |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total_timesteps  | 537037   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.07     |\n",
      "|    n_updates        | 134234   |\n",
      "----------------------------------\n",
      "Episode reward: 75.793255\n",
      "Episode reward: 57.683332\n",
      "Episode reward: 92.188772\n",
      "Episode reward: 33.882482\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9760     |\n",
      "|    fps              | 2970     |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total_timesteps  | 537304   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.963    |\n",
      "|    n_updates        | 134300   |\n",
      "----------------------------------\n",
      "Episode reward: 49.852306\n",
      "Episode reward: 41.738946\n",
      "Episode reward: 29.800511\n",
      "Episode reward: 61.700778\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9764     |\n",
      "|    fps              | 2970     |\n",
      "|    time_elapsed     | 180      |\n",
      "|    total_timesteps  | 537488   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0435   |\n",
      "|    n_updates        | 134346   |\n",
      "----------------------------------\n",
      "Episode reward: 28.923224\n",
      "Episode reward: 85.225314\n",
      "Episode reward: 38.910972\n",
      "Episode reward: 46.688787\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9768     |\n",
      "|    fps              | 2970     |\n",
      "|    time_elapsed     | 181      |\n",
      "|    total_timesteps  | 537697   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0283   |\n",
      "|    n_updates        | 134399   |\n",
      "----------------------------------\n",
      "Episode reward: 57.756255\n",
      "Episode reward: 43.856702\n",
      "Episode reward: 65.684878\n",
      "Episode reward: 144.262461\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9772     |\n",
      "|    fps              | 2970     |\n",
      "|    time_elapsed     | 181      |\n",
      "|    total_timesteps  | 538014   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.346    |\n",
      "|    n_updates        | 134478   |\n",
      "----------------------------------\n",
      "Episode reward: 34.850496\n",
      "Episode reward: 36.876254\n",
      "Episode reward: 48.601754\n",
      "Episode reward: 33.659032\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9776     |\n",
      "|    fps              | 2970     |\n",
      "|    time_elapsed     | 181      |\n",
      "|    total_timesteps  | 538169   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 134517   |\n",
      "----------------------------------\n",
      "Episode reward: 65.614292\n",
      "Episode reward: 65.807211\n",
      "Episode reward: 99.294269\n",
      "Episode reward: 149.235392\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9780     |\n",
      "|    fps              | 2970     |\n",
      "|    time_elapsed     | 181      |\n",
      "|    total_timesteps  | 538554   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0542   |\n",
      "|    n_updates        | 134613   |\n",
      "----------------------------------\n",
      "Episode reward: 86.544367\n",
      "Episode reward: 116.490445\n",
      "Episode reward: 40.517448\n",
      "Episode reward: 80.237891\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9784     |\n",
      "|    fps              | 2969     |\n",
      "|    time_elapsed     | 181      |\n",
      "|    total_timesteps  | 538915   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.51     |\n",
      "|    n_updates        | 134703   |\n",
      "----------------------------------\n",
      "Episode reward: 88.692174\n",
      "Episode reward: 103.703605\n",
      "Episode reward: 40.826854\n",
      "Episode reward: 45.864181\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9788     |\n",
      "|    fps              | 2969     |\n",
      "|    time_elapsed     | 181      |\n",
      "|    total_timesteps  | 539206   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0155   |\n",
      "|    n_updates        | 134776   |\n",
      "----------------------------------\n",
      "Episode reward: 82.319482\n",
      "Episode reward: 38.538671\n",
      "Episode reward: 61.833273\n",
      "Episode reward: 59.725693\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9792     |\n",
      "|    fps              | 2969     |\n",
      "|    time_elapsed     | 181      |\n",
      "|    total_timesteps  | 539455   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.12     |\n",
      "|    n_updates        | 134838   |\n",
      "----------------------------------\n",
      "Episode reward: 83.769333\n",
      "Episode reward: 30.532646\n",
      "Episode reward: 40.857583\n",
      "Episode reward: 41.924907\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9796     |\n",
      "|    fps              | 2969     |\n",
      "|    time_elapsed     | 181      |\n",
      "|    total_timesteps  | 539653   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.949    |\n",
      "|    n_updates        | 134888   |\n",
      "----------------------------------\n",
      "Episode reward: 64.188439\n",
      "Episode reward: 116.027305\n",
      "Episode reward: 31.550956\n",
      "Episode reward: 68.646513\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9800     |\n",
      "|    fps              | 2968     |\n",
      "|    time_elapsed     | 181      |\n",
      "|    total_timesteps  | 539948   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0256   |\n",
      "|    n_updates        | 134961   |\n",
      "----------------------------------\n",
      "Episode reward: 71.762944\n",
      "Episode reward: 32.947823\n",
      "Episode reward: 106.660297\n",
      "Episode reward: 73.841054\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9804     |\n",
      "|    fps              | 2968     |\n",
      "|    time_elapsed     | 181      |\n",
      "|    total_timesteps  | 540234   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0478   |\n",
      "|    n_updates        | 135033   |\n",
      "----------------------------------\n",
      "Episode reward: 38.825726\n",
      "Episode reward: 117.183626\n",
      "Episode reward: 53.636676\n",
      "Episode reward: 55.422454\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9808     |\n",
      "|    fps              | 2968     |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 540503   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.847    |\n",
      "|    n_updates        | 135100   |\n",
      "----------------------------------\n",
      "Episode reward: 33.925834\n",
      "Episode reward: 91.150802\n",
      "Episode reward: 82.783505\n",
      "Episode reward: 74.270411\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9812     |\n",
      "|    fps              | 2968     |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 540787   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 135171   |\n",
      "----------------------------------\n",
      "Episode reward: 67.49805\n",
      "Episode reward: 46.934101\n",
      "Episode reward: 82.518372\n",
      "Episode reward: 49.89068\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9816     |\n",
      "|    fps              | 2968     |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 541038   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.36     |\n",
      "|    n_updates        | 135234   |\n",
      "----------------------------------\n",
      "Episode reward: 82.9785\n",
      "Episode reward: 59.231718\n",
      "Episode reward: 31.959941\n",
      "Episode reward: 35.746354\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9820     |\n",
      "|    fps              | 2968     |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 541250   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0195   |\n",
      "|    n_updates        | 135287   |\n",
      "----------------------------------\n",
      "Episode reward: 85.593184\n",
      "Episode reward: 61.785205\n",
      "Episode reward: 90.309295\n",
      "Episode reward: 39.724247\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9824     |\n",
      "|    fps              | 2968     |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 541531   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.968    |\n",
      "|    n_updates        | 135357   |\n",
      "----------------------------------\n",
      "Episode reward: 85.564188\n",
      "Episode reward: 88.719905\n",
      "Episode reward: 42.861962\n",
      "Episode reward: 52.742701\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9828     |\n",
      "|    fps              | 2968     |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 541803   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0449   |\n",
      "|    n_updates        | 135425   |\n",
      "----------------------------------\n",
      "Episode reward: 40.559855\n",
      "Episode reward: 90.470127\n",
      "Episode reward: 72.625351\n",
      "Episode reward: 63.753734\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9832     |\n",
      "|    fps              | 2968     |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 542074   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0291   |\n",
      "|    n_updates        | 135493   |\n",
      "----------------------------------\n",
      "Episode reward: 60.732995\n",
      "Episode reward: 53.877589\n",
      "Episode reward: 28.812171\n",
      "Episode reward: 27.76901\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9836     |\n",
      "|    fps              | 2968     |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 542246   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.755    |\n",
      "|    n_updates        | 135536   |\n",
      "----------------------------------\n",
      "Episode reward: 29.924898\n",
      "Episode reward: 100.444967\n",
      "Episode reward: 68.459773\n",
      "Episode reward: 44.815386\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9840     |\n",
      "|    fps              | 2968     |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 542495   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.15     |\n",
      "|    n_updates        | 135598   |\n",
      "----------------------------------\n",
      "Episode reward: 33.826059\n",
      "Episode reward: 36.940407\n",
      "Episode reward: 55.789551\n",
      "Episode reward: 60.272801\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9844     |\n",
      "|    fps              | 2967     |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 542683   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0319   |\n",
      "|    n_updates        | 135645   |\n",
      "----------------------------------\n",
      "Episode reward: 53.854522\n",
      "Episode reward: 44.581636\n",
      "Episode reward: 59.811054\n",
      "Episode reward: 42.598504\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9848     |\n",
      "|    fps              | 2967     |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 542885   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 135696   |\n",
      "----------------------------------\n",
      "Episode reward: 46.287665\n",
      "Episode reward: 54.731323\n",
      "Episode reward: 29.855053\n",
      "Episode reward: 58.742118\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9852     |\n",
      "|    fps              | 2967     |\n",
      "|    time_elapsed     | 182      |\n",
      "|    total_timesteps  | 543076   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0133   |\n",
      "|    n_updates        | 135743   |\n",
      "----------------------------------\n",
      "Episode reward: 101.588311\n",
      "Episode reward: 105.310108\n",
      "Episode reward: 58.828364\n",
      "Episode reward: 76.89637\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9856     |\n",
      "|    fps              | 2967     |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total_timesteps  | 543433   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.02     |\n",
      "|    n_updates        | 135833   |\n",
      "----------------------------------\n",
      "Episode reward: 59.751895\n",
      "Episode reward: 42.892012\n",
      "Episode reward: 57.765909\n",
      "Episode reward: 38.302456\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9860     |\n",
      "|    fps              | 2967     |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total_timesteps  | 543633   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 135883   |\n",
      "----------------------------------\n",
      "Episode reward: 28.952116\n",
      "Episode reward: 88.555033\n",
      "Episode reward: 35.77047\n",
      "Episode reward: 47.899146\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9864     |\n",
      "|    fps              | 2967     |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total_timesteps  | 543836   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0311   |\n",
      "|    n_updates        | 135933   |\n",
      "----------------------------------\n",
      "Episode reward: 54.738512\n",
      "Episode reward: 49.87033\n",
      "Episode reward: 47.720742\n",
      "Episode reward: 38.938807\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9868     |\n",
      "|    fps              | 2967     |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total_timesteps  | 544028   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.974    |\n",
      "|    n_updates        | 135981   |\n",
      "----------------------------------\n",
      "Episode reward: 63.771128\n",
      "Episode reward: 77.237386\n",
      "Episode reward: 99.050008\n",
      "Episode reward: 41.907485\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9872     |\n",
      "|    fps              | 2967     |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total_timesteps  | 544313   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0317   |\n",
      "|    n_updates        | 136053   |\n",
      "----------------------------------\n",
      "Episode reward: 57.738931\n",
      "Episode reward: 34.861843\n",
      "Episode reward: 34.90119\n",
      "Episode reward: 89.392709\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9876     |\n",
      "|    fps              | 2966     |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total_timesteps  | 544532   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.52     |\n",
      "|    n_updates        | 136107   |\n",
      "----------------------------------\n",
      "Episode reward: 41.867213\n",
      "Episode reward: 68.745586\n",
      "Episode reward: 58.852315\n",
      "Episode reward: 114.464198\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9880     |\n",
      "|    fps              | 2966     |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total_timesteps  | 544826   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 136181   |\n",
      "----------------------------------\n",
      "Episode reward: 62.546996\n",
      "Episode reward: 84.345844\n",
      "Episode reward: 62.777624\n",
      "Episode reward: 36.911507\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9884     |\n",
      "|    fps              | 2966     |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total_timesteps  | 545075   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.69     |\n",
      "|    n_updates        | 136243   |\n",
      "----------------------------------\n",
      "Episode reward: 39.909344\n",
      "Episode reward: 70.091583\n",
      "Episode reward: 66.160027\n",
      "Episode reward: 46.698614\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9888     |\n",
      "|    fps              | 2965     |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total_timesteps  | 545303   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.872    |\n",
      "|    n_updates        | 136300   |\n",
      "----------------------------------\n",
      "Episode reward: 50.648358\n",
      "Episode reward: 61.849455\n",
      "Episode reward: 43.608524\n",
      "Episode reward: 60.715337\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9892     |\n",
      "|    fps              | 2965     |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total_timesteps  | 545521   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0277   |\n",
      "|    n_updates        | 136355   |\n",
      "----------------------------------\n",
      "Episode reward: 61.17798\n",
      "Episode reward: 95.860561\n",
      "Episode reward: 37.948825\n",
      "Episode reward: 29.930677\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9896     |\n",
      "|    fps              | 2965     |\n",
      "|    time_elapsed     | 184      |\n",
      "|    total_timesteps  | 545752   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0265   |\n",
      "|    n_updates        | 136412   |\n",
      "----------------------------------\n",
      "Episode reward: 66.603424\n",
      "Episode reward: 38.694972\n",
      "Episode reward: 25.869026\n",
      "Episode reward: 64.162352\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9900     |\n",
      "|    fps              | 2965     |\n",
      "|    time_elapsed     | 184      |\n",
      "|    total_timesteps  | 545949   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.55     |\n",
      "|    n_updates        | 136462   |\n",
      "----------------------------------\n",
      "Episode reward: 91.840667\n",
      "Episode reward: 69.764428\n",
      "Episode reward: 48.717736\n",
      "Episode reward: 56.6526\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9904     |\n",
      "|    fps              | 2965     |\n",
      "|    time_elapsed     | 184      |\n",
      "|    total_timesteps  | 546218   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.62     |\n",
      "|    n_updates        | 136529   |\n",
      "----------------------------------\n",
      "Episode reward: 86.473788\n",
      "Episode reward: 66.519952\n",
      "Episode reward: 60.816265\n",
      "Episode reward: 41.835733\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9908     |\n",
      "|    fps              | 2965     |\n",
      "|    time_elapsed     | 184      |\n",
      "|    total_timesteps  | 546475   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.403    |\n",
      "|    n_updates        | 136593   |\n",
      "----------------------------------\n",
      "Episode reward: 66.829845\n",
      "Episode reward: 48.277327\n",
      "Episode reward: 43.650462\n",
      "Episode reward: 33.936577\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9912     |\n",
      "|    fps              | 2965     |\n",
      "|    time_elapsed     | 184      |\n",
      "|    total_timesteps  | 546669   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.809    |\n",
      "|    n_updates        | 136642   |\n",
      "----------------------------------\n",
      "Episode reward: 35.937962\n",
      "Episode reward: 92.602933\n",
      "Episode reward: 28.912129\n",
      "Episode reward: 131.372817\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9916     |\n",
      "|    fps              | 2965     |\n",
      "|    time_elapsed     | 184      |\n",
      "|    total_timesteps  | 546972   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.92     |\n",
      "|    n_updates        | 136717   |\n",
      "----------------------------------\n",
      "Episode reward: 88.629628\n",
      "Episode reward: 69.640654\n",
      "Episode reward: 43.807682\n",
      "Episode reward: 76.610962\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9920     |\n",
      "|    fps              | 2965     |\n",
      "|    time_elapsed     | 184      |\n",
      "|    total_timesteps  | 547257   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0504   |\n",
      "|    n_updates        | 136789   |\n",
      "----------------------------------\n",
      "Episode reward: 53.688035\n",
      "Episode reward: 66.847588\n",
      "Episode reward: 82.640339\n",
      "Episode reward: 90.121043\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9924     |\n",
      "|    fps              | 2964     |\n",
      "|    time_elapsed     | 184      |\n",
      "|    total_timesteps  | 547577   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.828    |\n",
      "|    n_updates        | 136869   |\n",
      "----------------------------------\n",
      "Episode reward: 46.812704\n",
      "Episode reward: 81.450043\n",
      "Episode reward: 44.917867\n",
      "Episode reward: 78.368027\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9928     |\n",
      "|    fps              | 2964     |\n",
      "|    time_elapsed     | 184      |\n",
      "|    total_timesteps  | 547831   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.48     |\n",
      "|    n_updates        | 136932   |\n",
      "----------------------------------\n",
      "Episode reward: 54.368218\n",
      "Episode reward: 47.821787\n",
      "Episode reward: 28.800353\n",
      "Episode reward: 65.51206\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9932     |\n",
      "|    fps              | 2964     |\n",
      "|    time_elapsed     | 184      |\n",
      "|    total_timesteps  | 548029   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.832    |\n",
      "|    n_updates        | 136982   |\n",
      "----------------------------------\n",
      "Episode reward: 35.694777\n",
      "Episode reward: 56.586786\n",
      "Episode reward: 30.577623\n",
      "Episode reward: 25.913701\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9936     |\n",
      "|    fps              | 2964     |\n",
      "|    time_elapsed     | 184      |\n",
      "|    total_timesteps  | 548179   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0164   |\n",
      "|    n_updates        | 137019   |\n",
      "----------------------------------\n",
      "Episode reward: 55.857526\n",
      "Episode reward: 69.399709\n",
      "Episode reward: 54.556174\n",
      "Episode reward: 27.851197\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9940     |\n",
      "|    fps              | 2964     |\n",
      "|    time_elapsed     | 184      |\n",
      "|    total_timesteps  | 548391   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0228   |\n",
      "|    n_updates        | 137072   |\n",
      "----------------------------------\n",
      "Episode reward: 76.658147\n",
      "Episode reward: 57.818049\n",
      "Episode reward: 109.478809\n",
      "Episode reward: 52.884438\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9944     |\n",
      "|    fps              | 2964     |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total_timesteps  | 548705   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.265    |\n",
      "|    n_updates        | 137151   |\n",
      "----------------------------------\n",
      "Episode reward: 57.869391\n",
      "Episode reward: 105.680952\n",
      "Episode reward: 91.029458\n",
      "Episode reward: 39.537721\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9948     |\n",
      "|    fps              | 2964     |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total_timesteps  | 549001   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0185   |\n",
      "|    n_updates        | 137225   |\n",
      "----------------------------------\n",
      "Episode reward: 54.474403\n",
      "Episode reward: 65.99986\n",
      "Episode reward: 57.435885\n",
      "Episode reward: 31.933033\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9952     |\n",
      "|    fps              | 2964     |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total_timesteps  | 549213   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0316   |\n",
      "|    n_updates        | 137278   |\n",
      "----------------------------------\n",
      "Episode reward: 80.742639\n",
      "Episode reward: 38.855813\n",
      "Episode reward: 109.565316\n",
      "Episode reward: 37.819973\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9956     |\n",
      "|    fps              | 2964     |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total_timesteps  | 549481   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.389    |\n",
      "|    n_updates        | 137345   |\n",
      "----------------------------------\n",
      "Episode reward: 48.90596\n",
      "Episode reward: 75.910039\n",
      "Episode reward: 61.760038\n",
      "Episode reward: 30.650747\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9960     |\n",
      "|    fps              | 2963     |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total_timesteps  | 549709   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0307   |\n",
      "|    n_updates        | 137402   |\n",
      "----------------------------------\n",
      "Episode reward: 32.902769\n",
      "Episode reward: 61.715421\n",
      "Episode reward: 35.54813\n",
      "Episode reward: 31.548273\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9964     |\n",
      "|    fps              | 2963     |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total_timesteps  | 549872   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0202   |\n",
      "|    n_updates        | 137442   |\n",
      "----------------------------------\n",
      "Episode reward: 55.965986\n",
      "Episode reward: 47.843243\n",
      "Episode reward: 33.936643\n",
      "Episode reward: 70.727227\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9968     |\n",
      "|    fps              | 2963     |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total_timesteps  | 550082   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0731   |\n",
      "|    n_updates        | 137495   |\n",
      "----------------------------------\n",
      "Episode reward: 48.586187\n",
      "Episode reward: 73.629724\n",
      "Episode reward: 27.869132\n",
      "Episode reward: 81.675783\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9972     |\n",
      "|    fps              | 2963     |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total_timesteps  | 550318   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.86     |\n",
      "|    n_updates        | 137554   |\n",
      "----------------------------------\n",
      "Episode reward: 75.964042\n",
      "Episode reward: 40.931188\n",
      "Episode reward: 80.21909\n",
      "Episode reward: 32.882706\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9976     |\n",
      "|    fps              | 2963     |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total_timesteps  | 550550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0365   |\n",
      "|    n_updates        | 137612   |\n",
      "----------------------------------\n",
      "Episode reward: 30.862825\n",
      "Episode reward: 39.630052\n",
      "Episode reward: 49.713913\n",
      "Episode reward: 100.927462\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9980     |\n",
      "|    fps              | 2963     |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total_timesteps  | 550773   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0278   |\n",
      "|    n_updates        | 137668   |\n",
      "----------------------------------\n",
      "Episode reward: 57.504057\n",
      "Episode reward: 31.792009\n",
      "Episode reward: 70.431609\n",
      "Episode reward: 34.955286\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9984     |\n",
      "|    fps              | 2963     |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total_timesteps  | 550969   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0721   |\n",
      "|    n_updates        | 137717   |\n",
      "----------------------------------\n",
      "Episode reward: 53.609836\n",
      "Episode reward: 70.30424\n",
      "Episode reward: 89.35166\n",
      "Episode reward: 44.784135\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9988     |\n",
      "|    fps              | 2962     |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 551230   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0315   |\n",
      "|    n_updates        | 137782   |\n",
      "----------------------------------\n",
      "Episode reward: 36.592568\n",
      "Episode reward: 65.67385\n",
      "Episode reward: 111.822875\n",
      "Episode reward: 33.785725\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9992     |\n",
      "|    fps              | 2962     |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 551483   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.88     |\n",
      "|    n_updates        | 137845   |\n",
      "----------------------------------\n",
      "Episode reward: 45.899308\n",
      "Episode reward: 72.403617\n",
      "Episode reward: 36.670605\n",
      "Episode reward: 93.649638\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 9996     |\n",
      "|    fps              | 2962     |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 551735   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0316   |\n",
      "|    n_updates        | 137908   |\n",
      "----------------------------------\n",
      "Episode reward: 32.950933\n",
      "Episode reward: 34.850239\n",
      "Episode reward: 54.724554\n",
      "Episode reward: 46.879589\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10000    |\n",
      "|    fps              | 2962     |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 551905   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0221   |\n",
      "|    n_updates        | 137951   |\n",
      "----------------------------------\n",
      "Episode reward: 92.764242\n",
      "Episode reward: 44.850875\n",
      "Episode reward: 42.590804\n",
      "Episode reward: 57.759715\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10004    |\n",
      "|    fps              | 2962     |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 552170   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0336   |\n",
      "|    n_updates        | 138017   |\n",
      "----------------------------------\n",
      "Episode reward: 78.438703\n",
      "Episode reward: 33.893021\n",
      "Episode reward: 37.92578\n",
      "Episode reward: 27.804545\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10008    |\n",
      "|    fps              | 2961     |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 552349   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0239   |\n",
      "|    n_updates        | 138062   |\n",
      "----------------------------------\n",
      "Episode reward: 84.495155\n",
      "Episode reward: 52.745024\n",
      "Episode reward: 29.929007\n",
      "Episode reward: 92.240075\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10012    |\n",
      "|    fps              | 2961     |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 552614   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0583   |\n",
      "|    n_updates        | 138128   |\n",
      "----------------------------------\n",
      "Episode reward: 32.727132\n",
      "Episode reward: 51.814862\n",
      "Episode reward: 95.141015\n",
      "Episode reward: 63.714836\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10016    |\n",
      "|    fps              | 2961     |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 552865   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0254   |\n",
      "|    n_updates        | 138191   |\n",
      "----------------------------------\n",
      "Episode reward: 53.791713\n",
      "Episode reward: 62.744278\n",
      "Episode reward: 57.726864\n",
      "Episode reward: 39.833152\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10020    |\n",
      "|    fps              | 2961     |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 553080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0353   |\n",
      "|    n_updates        | 138244   |\n",
      "----------------------------------\n",
      "Episode reward: 61.26844\n",
      "Episode reward: 32.880807\n",
      "Episode reward: 37.938135\n",
      "Episode reward: 115.098347\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10024    |\n",
      "|    fps              | 2961     |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 553353   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.033    |\n",
      "|    n_updates        | 138313   |\n",
      "----------------------------------\n",
      "Episode reward: 52.675523\n",
      "Episode reward: 104.532626\n",
      "Episode reward: 32.920522\n",
      "Episode reward: 94.76057\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10028    |\n",
      "|    fps              | 2960     |\n",
      "|    time_elapsed     | 186      |\n",
      "|    total_timesteps  | 553644   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0194   |\n",
      "|    n_updates        | 138385   |\n",
      "----------------------------------\n",
      "Episode reward: 42.701284\n",
      "Episode reward: 24.632349\n",
      "Episode reward: 79.749161\n",
      "Episode reward: 51.807317\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10032    |\n",
      "|    fps              | 2960     |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total_timesteps  | 553844   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.487    |\n",
      "|    n_updates        | 138435   |\n",
      "----------------------------------\n",
      "Episode reward: 45.639124\n",
      "Episode reward: 56.632576\n",
      "Episode reward: 68.351819\n",
      "Episode reward: 31.859875\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10036    |\n",
      "|    fps              | 2960     |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total_timesteps  | 554048   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0423   |\n",
      "|    n_updates        | 138486   |\n",
      "----------------------------------\n",
      "Episode reward: 39.869135\n",
      "Episode reward: 71.095875\n",
      "Episode reward: 50.881421\n",
      "Episode reward: 54.657303\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10040    |\n",
      "|    fps              | 2960     |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total_timesteps  | 554266   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 138541   |\n",
      "----------------------------------\n",
      "Episode reward: 57.826302\n",
      "Episode reward: 72.634103\n",
      "Episode reward: 48.472321\n",
      "Episode reward: 32.891563\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10044    |\n",
      "|    fps              | 2960     |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total_timesteps  | 554479   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 138594   |\n",
      "----------------------------------\n",
      "Episode reward: 75.457224\n",
      "Episode reward: 69.774738\n",
      "Episode reward: 38.77513\n",
      "Episode reward: 65.156228\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10048    |\n",
      "|    fps              | 2960     |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total_timesteps  | 554730   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0239   |\n",
      "|    n_updates        | 138657   |\n",
      "----------------------------------\n",
      "Episode reward: 59.667682\n",
      "Episode reward: 42.815872\n",
      "Episode reward: 30.676623\n",
      "Episode reward: 45.847563\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10052    |\n",
      "|    fps              | 2960     |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total_timesteps  | 554910   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.329    |\n",
      "|    n_updates        | 138702   |\n",
      "----------------------------------\n",
      "Episode reward: 38.785066\n",
      "Episode reward: 100.288461\n",
      "Episode reward: 40.712533\n",
      "Episode reward: 75.637153\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10056    |\n",
      "|    fps              | 2960     |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total_timesteps  | 555169   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0156   |\n",
      "|    n_updates        | 138767   |\n",
      "----------------------------------\n",
      "Episode reward: 33.937582\n",
      "Episode reward: 35.757931\n",
      "Episode reward: 82.541502\n",
      "Episode reward: 49.914205\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.6     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10060    |\n",
      "|    fps              | 2960     |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total_timesteps  | 555372   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.353    |\n",
      "|    n_updates        | 138817   |\n",
      "----------------------------------\n",
      "Episode reward: 94.165478\n",
      "Episode reward: 53.887447\n",
      "Episode reward: 38.91648\n",
      "Episode reward: 75.781242\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10064    |\n",
      "|    fps              | 2960     |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total_timesteps  | 555636   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 138883   |\n",
      "----------------------------------\n",
      "Episode reward: 53.82992\n",
      "Episode reward: 62.210414\n",
      "Episode reward: 47.82915\n",
      "Episode reward: 41.730084\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10068    |\n",
      "|    fps              | 2959     |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total_timesteps  | 555845   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0261   |\n",
      "|    n_updates        | 138936   |\n",
      "----------------------------------\n",
      "Episode reward: 96.051889\n",
      "Episode reward: 93.559094\n",
      "Episode reward: 54.821278\n",
      "Episode reward: 49.556238\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10072    |\n",
      "|    fps              | 2959     |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total_timesteps  | 556148   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.669    |\n",
      "|    n_updates        | 139011   |\n",
      "----------------------------------\n",
      "Episode reward: 117.035296\n",
      "Episode reward: 62.566632\n",
      "Episode reward: 52.801229\n",
      "Episode reward: 49.918563\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10076    |\n",
      "|    fps              | 2959     |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total_timesteps  | 556457   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0104   |\n",
      "|    n_updates        | 139089   |\n",
      "----------------------------------\n",
      "Episode reward: 35.911728\n",
      "Episode reward: 58.074106\n",
      "Episode reward: 100.297704\n",
      "Episode reward: 71.078358\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10080    |\n",
      "|    fps              | 2959     |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total_timesteps  | 556749   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0154   |\n",
      "|    n_updates        | 139162   |\n",
      "----------------------------------\n",
      "Episode reward: 35.694966\n",
      "Episode reward: 92.019905\n",
      "Episode reward: 56.909865\n",
      "Episode reward: 80.669775\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10084    |\n",
      "|    fps              | 2959     |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total_timesteps  | 557020   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0181   |\n",
      "|    n_updates        | 139229   |\n",
      "----------------------------------\n",
      "Episode reward: 34.851062\n",
      "Episode reward: 82.090163\n",
      "Episode reward: 108.64202\n",
      "Episode reward: 58.646211\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10088    |\n",
      "|    fps              | 2959     |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total_timesteps  | 557324   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.455    |\n",
      "|    n_updates        | 139305   |\n",
      "----------------------------------\n",
      "Episode reward: 61.885493\n",
      "Episode reward: 55.846937\n",
      "Episode reward: 40.662602\n",
      "Episode reward: 60.775681\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10092    |\n",
      "|    fps              | 2959     |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total_timesteps  | 557545   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0393   |\n",
      "|    n_updates        | 139361   |\n",
      "----------------------------------\n",
      "Episode reward: 56.735346\n",
      "Episode reward: 47.73697\n",
      "Episode reward: 49.828282\n",
      "Episode reward: 52.500728\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10096    |\n",
      "|    fps              | 2959     |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total_timesteps  | 557753   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0325   |\n",
      "|    n_updates        | 139413   |\n",
      "----------------------------------\n",
      "Episode reward: 38.910532\n",
      "Episode reward: 60.797441\n",
      "Episode reward: 47.889551\n",
      "Episode reward: 59.661346\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10100    |\n",
      "|    fps              | 2959     |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total_timesteps  | 557962   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0256   |\n",
      "|    n_updates        | 139465   |\n",
      "----------------------------------\n",
      "Episode reward: 120.855444\n",
      "Episode reward: 37.272663\n",
      "Episode reward: 79.564864\n",
      "Episode reward: 45.91493\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10104    |\n",
      "|    fps              | 2958     |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total_timesteps  | 558250   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0089   |\n",
      "|    n_updates        | 139537   |\n",
      "----------------------------------\n",
      "Episode reward: 87.175909\n",
      "Episode reward: 47.674131\n",
      "Episode reward: 56.06668\n",
      "Episode reward: 62.943138\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10108    |\n",
      "|    fps              | 2958     |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total_timesteps  | 558509   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0269   |\n",
      "|    n_updates        | 139602   |\n",
      "----------------------------------\n",
      "Episode reward: 90.299621\n",
      "Episode reward: 41.878016\n",
      "Episode reward: 86.441856\n",
      "Episode reward: 51.77718\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10112    |\n",
      "|    fps              | 2958     |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total_timesteps  | 558781   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.024    |\n",
      "|    n_updates        | 139670   |\n",
      "----------------------------------\n",
      "Episode reward: 31.644082\n",
      "Episode reward: 62.671384\n",
      "Episode reward: 23.810001\n",
      "Episode reward: 61.800141\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10116    |\n",
      "|    fps              | 2958     |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total_timesteps  | 558962   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0215   |\n",
      "|    n_updates        | 139715   |\n",
      "----------------------------------\n",
      "Episode reward: 49.691672\n",
      "Episode reward: 39.808386\n",
      "Episode reward: 42.869645\n",
      "Episode reward: 32.825876\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10120    |\n",
      "|    fps              | 2958     |\n",
      "|    time_elapsed     | 188      |\n",
      "|    total_timesteps  | 559128   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.613    |\n",
      "|    n_updates        | 139756   |\n",
      "----------------------------------\n",
      "Episode reward: 51.815713\n",
      "Episode reward: 74.76887\n",
      "Episode reward: 88.664297\n",
      "Episode reward: 42.883293\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10124    |\n",
      "|    fps              | 2958     |\n",
      "|    time_elapsed     | 189      |\n",
      "|    total_timesteps  | 559416   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.318    |\n",
      "|    n_updates        | 139828   |\n",
      "----------------------------------\n",
      "Episode reward: 114.314054\n",
      "Episode reward: 128.843819\n",
      "Episode reward: 27.689008\n",
      "Episode reward: 55.859128\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10128    |\n",
      "|    fps              | 2957     |\n",
      "|    time_elapsed     | 189      |\n",
      "|    total_timesteps  | 559748   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0263   |\n",
      "|    n_updates        | 139911   |\n",
      "----------------------------------\n",
      "Episode reward: 29.937243\n",
      "Episode reward: 63.678624\n",
      "Episode reward: 57.4908\n",
      "Episode reward: 40.824622\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10132    |\n",
      "|    fps              | 2957     |\n",
      "|    time_elapsed     | 189      |\n",
      "|    total_timesteps  | 559941   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0335   |\n",
      "|    n_updates        | 139960   |\n",
      "----------------------------------\n",
      "Episode reward: 108.326119\n",
      "Episode reward: 72.705596\n",
      "Episode reward: 67.042369\n",
      "Episode reward: 40.669473\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10136    |\n",
      "|    fps              | 2957     |\n",
      "|    time_elapsed     | 189      |\n",
      "|    total_timesteps  | 560239   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0386   |\n",
      "|    n_updates        | 140034   |\n",
      "----------------------------------\n",
      "Episode reward: 91.333782\n",
      "Episode reward: 37.856499\n",
      "Episode reward: 107.760278\n",
      "Episode reward: 64.610119\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10140    |\n",
      "|    fps              | 2957     |\n",
      "|    time_elapsed     | 189      |\n",
      "|    total_timesteps  | 560565   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0399   |\n",
      "|    n_updates        | 140116   |\n",
      "----------------------------------\n",
      "Episode reward: 56.886373\n",
      "Episode reward: 34.912195\n",
      "Episode reward: 27.926591\n",
      "Episode reward: 40.664145\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10144    |\n",
      "|    fps              | 2957     |\n",
      "|    time_elapsed     | 189      |\n",
      "|    total_timesteps  | 560726   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0419   |\n",
      "|    n_updates        | 140156   |\n",
      "----------------------------------\n",
      "Episode reward: 52.857424\n",
      "Episode reward: 52.80502\n",
      "Episode reward: 101.56073\n",
      "Episode reward: 60.828495\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10148    |\n",
      "|    fps              | 2956     |\n",
      "|    time_elapsed     | 189      |\n",
      "|    total_timesteps  | 560996   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.7      |\n",
      "|    n_updates        | 140223   |\n",
      "----------------------------------\n",
      "Episode reward: 35.785155\n",
      "Episode reward: 74.483007\n",
      "Episode reward: 41.446712\n",
      "Episode reward: 34.424701\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10152    |\n",
      "|    fps              | 2956     |\n",
      "|    time_elapsed     | 189      |\n",
      "|    total_timesteps  | 561184   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.937    |\n",
      "|    n_updates        | 140270   |\n",
      "----------------------------------\n",
      "Episode reward: 74.709401\n",
      "Episode reward: 70.267119\n",
      "Episode reward: 32.879198\n",
      "Episode reward: 56.819318\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10156    |\n",
      "|    fps              | 2956     |\n",
      "|    time_elapsed     | 189      |\n",
      "|    total_timesteps  | 561421   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.1      |\n",
      "|    n_updates        | 140330   |\n",
      "----------------------------------\n",
      "Episode reward: 127.944832\n",
      "Episode reward: 41.543076\n",
      "Episode reward: 50.59334\n",
      "Episode reward: 37.802194\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10160    |\n",
      "|    fps              | 2955     |\n",
      "|    time_elapsed     | 190      |\n",
      "|    total_timesteps  | 561691   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0252   |\n",
      "|    n_updates        | 140397   |\n",
      "----------------------------------\n",
      "Episode reward: 39.746007\n",
      "Episode reward: 83.220626\n",
      "Episode reward: 58.293417\n",
      "Episode reward: 63.806168\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10164    |\n",
      "|    fps              | 2955     |\n",
      "|    time_elapsed     | 190      |\n",
      "|    total_timesteps  | 561946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.08     |\n",
      "|    n_updates        | 140461   |\n",
      "----------------------------------\n",
      "Episode reward: 55.723867\n",
      "Episode reward: 50.879275\n",
      "Episode reward: 40.836049\n",
      "Episode reward: 54.46445\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10168    |\n",
      "|    fps              | 2955     |\n",
      "|    time_elapsed     | 190      |\n",
      "|    total_timesteps  | 562149   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0282   |\n",
      "|    n_updates        | 140512   |\n",
      "----------------------------------\n",
      "Episode reward: 45.822673\n",
      "Episode reward: 72.744055\n",
      "Episode reward: 31.883406\n",
      "Episode reward: 84.370702\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10172    |\n",
      "|    fps              | 2955     |\n",
      "|    time_elapsed     | 190      |\n",
      "|    total_timesteps  | 562385   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.366    |\n",
      "|    n_updates        | 140571   |\n",
      "----------------------------------\n",
      "Episode reward: 43.911714\n",
      "Episode reward: 67.796642\n",
      "Episode reward: 45.757007\n",
      "Episode reward: 74.696539\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10176    |\n",
      "|    fps              | 2955     |\n",
      "|    time_elapsed     | 190      |\n",
      "|    total_timesteps  | 562619   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.226    |\n",
      "|    n_updates        | 140629   |\n",
      "----------------------------------\n",
      "Episode reward: 26.885565\n",
      "Episode reward: 30.678469\n",
      "Episode reward: 58.828557\n",
      "Episode reward: 55.68219\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10180    |\n",
      "|    fps              | 2955     |\n",
      "|    time_elapsed     | 190      |\n",
      "|    total_timesteps  | 562792   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0282   |\n",
      "|    n_updates        | 140672   |\n",
      "----------------------------------\n",
      "Episode reward: 135.594108\n",
      "Episode reward: 47.895367\n",
      "Episode reward: 74.579804\n",
      "Episode reward: 27.876487\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10184    |\n",
      "|    fps              | 2954     |\n",
      "|    time_elapsed     | 190      |\n",
      "|    total_timesteps  | 563080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 140744   |\n",
      "----------------------------------\n",
      "Episode reward: 37.824707\n",
      "Episode reward: 59.088589\n",
      "Episode reward: 43.867337\n",
      "Episode reward: 31.658407\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10188    |\n",
      "|    fps              | 2954     |\n",
      "|    time_elapsed     | 190      |\n",
      "|    total_timesteps  | 563254   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0502   |\n",
      "|    n_updates        | 140788   |\n",
      "----------------------------------\n",
      "Episode reward: 52.804607\n",
      "Episode reward: 61.728904\n",
      "Episode reward: 95.747463\n",
      "Episode reward: 128.193701\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10192    |\n",
      "|    fps              | 2954     |\n",
      "|    time_elapsed     | 190      |\n",
      "|    total_timesteps  | 563598   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.02     |\n",
      "|    n_updates        | 140874   |\n",
      "----------------------------------\n",
      "Episode reward: 36.947368\n",
      "Episode reward: 36.817587\n",
      "Episode reward: 46.678547\n",
      "Episode reward: 104.618446\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10196    |\n",
      "|    fps              | 2954     |\n",
      "|    time_elapsed     | 190      |\n",
      "|    total_timesteps  | 563824   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0137   |\n",
      "|    n_updates        | 140930   |\n",
      "----------------------------------\n",
      "Episode reward: 65.479796\n",
      "Episode reward: 49.911116\n",
      "Episode reward: 84.167968\n",
      "Episode reward: 33.91776\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10200    |\n",
      "|    fps              | 2954     |\n",
      "|    time_elapsed     | 190      |\n",
      "|    total_timesteps  | 564062   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0203   |\n",
      "|    n_updates        | 140990   |\n",
      "----------------------------------\n",
      "Episode reward: 34.72773\n",
      "Episode reward: 29.869443\n",
      "Episode reward: 56.527231\n",
      "Episode reward: 36.742044\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10204    |\n",
      "|    fps              | 2953     |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total_timesteps  | 564221   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0235   |\n",
      "|    n_updates        | 141030   |\n",
      "----------------------------------\n",
      "Episode reward: 54.586617\n",
      "Episode reward: 36.884852\n",
      "Episode reward: 75.413673\n",
      "Episode reward: 35.812234\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10208    |\n",
      "|    fps              | 2953     |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total_timesteps  | 564425   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0476   |\n",
      "|    n_updates        | 141081   |\n",
      "----------------------------------\n",
      "Episode reward: 44.908921\n",
      "Episode reward: 47.785644\n",
      "Episode reward: 51.680139\n",
      "Episode reward: 73.524184\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10212    |\n",
      "|    fps              | 2953     |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total_timesteps  | 564644   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 141135   |\n",
      "----------------------------------\n",
      "Episode reward: 67.157498\n",
      "Episode reward: 102.574367\n",
      "Episode reward: 95.350309\n",
      "Episode reward: 40.912464\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10216    |\n",
      "|    fps              | 2953     |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total_timesteps  | 564959   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.022    |\n",
      "|    n_updates        | 141214   |\n",
      "----------------------------------\n",
      "Episode reward: 48.320836\n",
      "Episode reward: 51.876723\n",
      "Episode reward: 36.298806\n",
      "Episode reward: 48.726927\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10220    |\n",
      "|    fps              | 2953     |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total_timesteps  | 565146   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0308   |\n",
      "|    n_updates        | 141261   |\n",
      "----------------------------------\n",
      "Episode reward: 58.77813\n",
      "Episode reward: 82.065187\n",
      "Episode reward: 54.85701\n",
      "Episode reward: 107.834722\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10224    |\n",
      "|    fps              | 2952     |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total_timesteps  | 565453   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0242   |\n",
      "|    n_updates        | 141338   |\n",
      "----------------------------------\n",
      "Episode reward: 88.634762\n",
      "Episode reward: 56.786303\n",
      "Episode reward: 66.712449\n",
      "Episode reward: 45.425626\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10228    |\n",
      "|    fps              | 2952     |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total_timesteps  | 565712   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0297   |\n",
      "|    n_updates        | 141402   |\n",
      "----------------------------------\n",
      "Episode reward: 70.710451\n",
      "Episode reward: 46.487056\n",
      "Episode reward: 51.830109\n",
      "Episode reward: 86.883375\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10232    |\n",
      "|    fps              | 2952     |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total_timesteps  | 565983   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11     |\n",
      "|    n_updates        | 141470   |\n",
      "----------------------------------\n",
      "Episode reward: 53.830811\n",
      "Episode reward: 31.634643\n",
      "Episode reward: 39.944162\n",
      "Episode reward: 94.408027\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10236    |\n",
      "|    fps              | 2952     |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total_timesteps  | 566204   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0315   |\n",
      "|    n_updates        | 141525   |\n",
      "----------------------------------\n",
      "Episode reward: 49.873024\n",
      "Episode reward: 38.933259\n",
      "Episode reward: 38.916499\n",
      "Episode reward: 41.84333\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10240    |\n",
      "|    fps              | 2952     |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total_timesteps  | 566374   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0538   |\n",
      "|    n_updates        | 141568   |\n",
      "----------------------------------\n",
      "Episode reward: 86.605762\n",
      "Episode reward: 33.878857\n",
      "Episode reward: 38.742835\n",
      "Episode reward: 34.929107\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10244    |\n",
      "|    fps              | 2952     |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total_timesteps  | 566570   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0128   |\n",
      "|    n_updates        | 141617   |\n",
      "----------------------------------\n",
      "Episode reward: 32.768838\n",
      "Episode reward: 71.599305\n",
      "Episode reward: 39.417578\n",
      "Episode reward: 37.795384\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10248    |\n",
      "|    fps              | 2952     |\n",
      "|    time_elapsed     | 191      |\n",
      "|    total_timesteps  | 566753   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 141663   |\n",
      "----------------------------------\n",
      "Episode reward: 38.919783\n",
      "Episode reward: 84.568668\n",
      "Episode reward: 28.857551\n",
      "Episode reward: 25.881574\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10252    |\n",
      "|    fps              | 2952     |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total_timesteps  | 566932   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0334   |\n",
      "|    n_updates        | 141707   |\n",
      "----------------------------------\n",
      "Episode reward: 112.649173\n",
      "Episode reward: 88.32301\n",
      "Episode reward: 27.902745\n",
      "Episode reward: 57.946393\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10256    |\n",
      "|    fps              | 2952     |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total_timesteps  | 567228   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 141781   |\n",
      "----------------------------------\n",
      "Episode reward: 77.233414\n",
      "Episode reward: 43.775136\n",
      "Episode reward: 65.62998\n",
      "Episode reward: 30.927343\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10260    |\n",
      "|    fps              | 2952     |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total_timesteps  | 567447   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0397   |\n",
      "|    n_updates        | 141836   |\n",
      "----------------------------------\n",
      "Episode reward: 54.805301\n",
      "Episode reward: 45.868101\n",
      "Episode reward: 150.427425\n",
      "Episode reward: 49.918565\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10264    |\n",
      "|    fps              | 2952     |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total_timesteps  | 567749   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0515   |\n",
      "|    n_updates        | 141912   |\n",
      "----------------------------------\n",
      "Episode reward: 41.841683\n",
      "Episode reward: 97.314008\n",
      "Episode reward: 40.766691\n",
      "Episode reward: 49.814035\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10268    |\n",
      "|    fps              | 2952     |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total_timesteps  | 567988   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 141971   |\n",
      "----------------------------------\n",
      "Episode reward: 33.784205\n",
      "Episode reward: 55.769154\n",
      "Episode reward: 41.78185\n",
      "Episode reward: 77.561023\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10272    |\n",
      "|    fps              | 2951     |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total_timesteps  | 568198   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0372   |\n",
      "|    n_updates        | 142024   |\n",
      "----------------------------------\n",
      "Episode reward: 59.695412\n",
      "Episode reward: 122.174967\n",
      "Episode reward: 46.715357\n",
      "Episode reward: 61.934874\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10276    |\n",
      "|    fps              | 2951     |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total_timesteps  | 568494   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.029    |\n",
      "|    n_updates        | 142098   |\n",
      "----------------------------------\n",
      "Episode reward: 43.867698\n",
      "Episode reward: 36.950914\n",
      "Episode reward: 64.748152\n",
      "Episode reward: 93.462988\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10280    |\n",
      "|    fps              | 2950     |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total_timesteps  | 568747   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.991    |\n",
      "|    n_updates        | 142161   |\n",
      "----------------------------------\n",
      "Episode reward: 33.89972\n",
      "Episode reward: 27.830516\n",
      "Episode reward: 63.596551\n",
      "Episode reward: 55.862476\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10284    |\n",
      "|    fps              | 2950     |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total_timesteps  | 568929   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.668    |\n",
      "|    n_updates        | 142207   |\n",
      "----------------------------------\n",
      "Episode reward: 69.720188\n",
      "Episode reward: 52.893511\n",
      "Episode reward: 67.741912\n",
      "Episode reward: 54.841152\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10288    |\n",
      "|    fps              | 2950     |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total_timesteps  | 569175   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.634    |\n",
      "|    n_updates        | 142268   |\n",
      "----------------------------------\n",
      "Episode reward: 73.601627\n",
      "Episode reward: 38.603419\n",
      "Episode reward: 36.5858\n",
      "Episode reward: 49.368212\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10292    |\n",
      "|    fps              | 2950     |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total_timesteps  | 569375   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.925    |\n",
      "|    n_updates        | 142318   |\n",
      "----------------------------------\n",
      "Episode reward: 110.621132\n",
      "Episode reward: 46.901639\n",
      "Episode reward: 55.836133\n",
      "Episode reward: 95.444875\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10296    |\n",
      "|    fps              | 2950     |\n",
      "|    time_elapsed     | 193      |\n",
      "|    total_timesteps  | 569690   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.57     |\n",
      "|    n_updates        | 142397   |\n",
      "----------------------------------\n",
      "Episode reward: 49.742128\n",
      "Episode reward: 26.790331\n",
      "Episode reward: 51.839418\n",
      "Episode reward: 51.910884\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10300    |\n",
      "|    fps              | 2950     |\n",
      "|    time_elapsed     | 193      |\n",
      "|    total_timesteps  | 569871   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.04     |\n",
      "|    n_updates        | 142442   |\n",
      "----------------------------------\n",
      "Episode reward: 79.467001\n",
      "Episode reward: 79.013439\n",
      "Episode reward: 48.827163\n",
      "Episode reward: 82.742759\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10304    |\n",
      "|    fps              | 2950     |\n",
      "|    time_elapsed     | 193      |\n",
      "|    total_timesteps  | 570166   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.16     |\n",
      "|    n_updates        | 142516   |\n",
      "----------------------------------\n",
      "Episode reward: 32.829369\n",
      "Episode reward: 46.728558\n",
      "Episode reward: 79.667914\n",
      "Episode reward: 23.798513\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10308    |\n",
      "|    fps              | 2949     |\n",
      "|    time_elapsed     | 193      |\n",
      "|    total_timesteps  | 570350   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0463   |\n",
      "|    n_updates        | 142562   |\n",
      "----------------------------------\n",
      "Episode reward: 30.94447\n",
      "Episode reward: 41.891909\n",
      "Episode reward: 43.924031\n",
      "Episode reward: 51.702362\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10312    |\n",
      "|    fps              | 2949     |\n",
      "|    time_elapsed     | 193      |\n",
      "|    total_timesteps  | 570519   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.962    |\n",
      "|    n_updates        | 142604   |\n",
      "----------------------------------\n",
      "Episode reward: 28.698418\n",
      "Episode reward: 73.170512\n",
      "Episode reward: 42.948841\n",
      "Episode reward: 40.920925\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10316    |\n",
      "|    fps              | 2949     |\n",
      "|    time_elapsed     | 193      |\n",
      "|    total_timesteps  | 570706   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0126   |\n",
      "|    n_updates        | 142651   |\n",
      "----------------------------------\n",
      "Episode reward: 52.853117\n",
      "Episode reward: 71.736116\n",
      "Episode reward: 111.973354\n",
      "Episode reward: 50.757926\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10320    |\n",
      "|    fps              | 2948     |\n",
      "|    time_elapsed     | 193      |\n",
      "|    total_timesteps  | 570995   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0224   |\n",
      "|    n_updates        | 142723   |\n",
      "----------------------------------\n",
      "Episode reward: 62.294009\n",
      "Episode reward: 83.889797\n",
      "Episode reward: 94.570726\n",
      "Episode reward: 29.817579\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10324    |\n",
      "|    fps              | 2948     |\n",
      "|    time_elapsed     | 193      |\n",
      "|    total_timesteps  | 571268   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0364   |\n",
      "|    n_updates        | 142791   |\n",
      "----------------------------------\n",
      "Episode reward: 31.827627\n",
      "Episode reward: 44.453615\n",
      "Episode reward: 65.720437\n",
      "Episode reward: 83.647901\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.8     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10328    |\n",
      "|    fps              | 2948     |\n",
      "|    time_elapsed     | 193      |\n",
      "|    total_timesteps  | 571496   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.46     |\n",
      "|    n_updates        | 142848   |\n",
      "----------------------------------\n",
      "Episode reward: 78.731253\n",
      "Episode reward: 54.534185\n",
      "Episode reward: 49.855463\n",
      "Episode reward: 101.330741\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10332    |\n",
      "|    fps              | 2948     |\n",
      "|    time_elapsed     | 193      |\n",
      "|    total_timesteps  | 571803   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.826    |\n",
      "|    n_updates        | 142925   |\n",
      "----------------------------------\n",
      "Episode reward: 71.352228\n",
      "Episode reward: 50.799416\n",
      "Episode reward: 83.585604\n",
      "Episode reward: 109.767122\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10336    |\n",
      "|    fps              | 2948     |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total_timesteps  | 572123   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0341   |\n",
      "|    n_updates        | 143005   |\n",
      "----------------------------------\n",
      "Episode reward: 73.472483\n",
      "Episode reward: 96.990645\n",
      "Episode reward: 58.756846\n",
      "Episode reward: 52.545734\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10340    |\n",
      "|    fps              | 2948     |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total_timesteps  | 572407   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0369   |\n",
      "|    n_updates        | 143076   |\n",
      "----------------------------------\n",
      "Episode reward: 53.574477\n",
      "Episode reward: 72.045091\n",
      "Episode reward: 32.873754\n",
      "Episode reward: 56.734557\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10344    |\n",
      "|    fps              | 2948     |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total_timesteps  | 572625   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.331    |\n",
      "|    n_updates        | 143131   |\n",
      "----------------------------------\n",
      "Episode reward: 59.372256\n",
      "Episode reward: 89.630632\n",
      "Episode reward: 24.551815\n",
      "Episode reward: 33.820876\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10348    |\n",
      "|    fps              | 2948     |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total_timesteps  | 572834   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.34     |\n",
      "|    n_updates        | 143183   |\n",
      "----------------------------------\n",
      "Episode reward: 41.908831\n",
      "Episode reward: 60.805096\n",
      "Episode reward: 60.348535\n",
      "Episode reward: 36.855713\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10352    |\n",
      "|    fps              | 2947     |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total_timesteps  | 573035   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0234   |\n",
      "|    n_updates        | 143233   |\n",
      "----------------------------------\n",
      "Episode reward: 31.91483\n",
      "Episode reward: 72.731613\n",
      "Episode reward: 80.529622\n",
      "Episode reward: 55.747948\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10356    |\n",
      "|    fps              | 2947     |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total_timesteps  | 573281   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.356    |\n",
      "|    n_updates        | 143295   |\n",
      "----------------------------------\n",
      "Episode reward: 113.833479\n",
      "Episode reward: 57.440166\n",
      "Episode reward: 101.601764\n",
      "Episode reward: 46.90074\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10360    |\n",
      "|    fps              | 2947     |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total_timesteps  | 573606   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.038    |\n",
      "|    n_updates        | 143376   |\n",
      "----------------------------------\n",
      "Episode reward: 111.368343\n",
      "Episode reward: 53.753959\n",
      "Episode reward: 84.655967\n",
      "Episode reward: 41.926827\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10364    |\n",
      "|    fps              | 2946     |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total_timesteps  | 573902   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0227   |\n",
      "|    n_updates        | 143450   |\n",
      "----------------------------------\n",
      "Episode reward: 55.784451\n",
      "Episode reward: 35.640117\n",
      "Episode reward: 58.711746\n",
      "Episode reward: 41.704969\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10368    |\n",
      "|    fps              | 2946     |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total_timesteps  | 574095   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0259   |\n",
      "|    n_updates        | 143498   |\n",
      "----------------------------------\n",
      "Episode reward: 49.555734\n",
      "Episode reward: 57.840663\n",
      "Episode reward: 44.916313\n",
      "Episode reward: 42.791242\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10372    |\n",
      "|    fps              | 2946     |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total_timesteps  | 574291   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 143547   |\n",
      "----------------------------------\n",
      "Episode reward: 28.85193\n",
      "Episode reward: 46.820657\n",
      "Episode reward: 47.644906\n",
      "Episode reward: 33.679087\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10376    |\n",
      "|    fps              | 2946     |\n",
      "|    time_elapsed     | 194      |\n",
      "|    total_timesteps  | 574449   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0209   |\n",
      "|    n_updates        | 143587   |\n",
      "----------------------------------\n",
      "Episode reward: 44.864919\n",
      "Episode reward: 44.428229\n",
      "Episode reward: 53.790097\n",
      "Episode reward: 23.778774\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10380    |\n",
      "|    fps              | 2945     |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total_timesteps  | 574617   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0264   |\n",
      "|    n_updates        | 143629   |\n",
      "----------------------------------\n",
      "Episode reward: 39.9267\n",
      "Episode reward: 69.442741\n",
      "Episode reward: 45.838997\n",
      "Episode reward: 78.489937\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10384    |\n",
      "|    fps              | 2945     |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total_timesteps  | 574852   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.503    |\n",
      "|    n_updates        | 143687   |\n",
      "----------------------------------\n",
      "Episode reward: 83.422836\n",
      "Episode reward: 55.544577\n",
      "Episode reward: 27.926737\n",
      "Episode reward: 84.752084\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10388    |\n",
      "|    fps              | 2945     |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total_timesteps  | 575107   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0438   |\n",
      "|    n_updates        | 143751   |\n",
      "----------------------------------\n",
      "Episode reward: 81.532456\n",
      "Episode reward: 121.154294\n",
      "Episode reward: 47.092984\n",
      "Episode reward: 111.006987\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10392    |\n",
      "|    fps              | 2945     |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total_timesteps  | 575472   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0278   |\n",
      "|    n_updates        | 143842   |\n",
      "----------------------------------\n",
      "Episode reward: 35.74774\n",
      "Episode reward: 50.807361\n",
      "Episode reward: 46.550684\n",
      "Episode reward: 143.018373\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10396    |\n",
      "|    fps              | 2945     |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total_timesteps  | 575750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.029    |\n",
      "|    n_updates        | 143912   |\n",
      "----------------------------------\n",
      "Episode reward: 39.834022\n",
      "Episode reward: 64.67637\n",
      "Episode reward: 44.898094\n",
      "Episode reward: 82.776577\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10400    |\n",
      "|    fps              | 2944     |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total_timesteps  | 575985   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.603    |\n",
      "|    n_updates        | 143971   |\n",
      "----------------------------------\n",
      "Episode reward: 54.435712\n",
      "Episode reward: 48.877287\n",
      "Episode reward: 59.693291\n",
      "Episode reward: 46.68582\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10404    |\n",
      "|    fps              | 2944     |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total_timesteps  | 576196   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.02     |\n",
      "|    n_updates        | 144023   |\n",
      "----------------------------------\n",
      "Episode reward: 64.77934\n",
      "Episode reward: 89.590381\n",
      "Episode reward: 93.694127\n",
      "Episode reward: 45.720898\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10408    |\n",
      "|    fps              | 2944     |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total_timesteps  | 576499   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.09     |\n",
      "|    n_updates        | 144099   |\n",
      "----------------------------------\n",
      "Episode reward: 53.996047\n",
      "Episode reward: 40.130544\n",
      "Episode reward: 43.847971\n",
      "Episode reward: 60.849932\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10412    |\n",
      "|    fps              | 2944     |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total_timesteps  | 576700   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00965  |\n",
      "|    n_updates        | 144149   |\n",
      "----------------------------------\n",
      "Episode reward: 99.090069\n",
      "Episode reward: 58.778351\n",
      "Episode reward: 87.982573\n",
      "Episode reward: 26.927583\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 61.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10416    |\n",
      "|    fps              | 2944     |\n",
      "|    time_elapsed     | 195      |\n",
      "|    total_timesteps  | 576990   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0269   |\n",
      "|    n_updates        | 144222   |\n",
      "----------------------------------\n",
      "Episode reward: 49.539491\n",
      "Episode reward: 46.913199\n",
      "Episode reward: 90.691901\n",
      "Episode reward: 59.61099\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10420    |\n",
      "|    fps              | 2944     |\n",
      "|    time_elapsed     | 196      |\n",
      "|    total_timesteps  | 577238   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0342   |\n",
      "|    n_updates        | 144284   |\n",
      "----------------------------------\n",
      "Episode reward: 35.936803\n",
      "Episode reward: 28.925434\n",
      "Episode reward: 80.626217\n",
      "Episode reward: 29.906017\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10424    |\n",
      "|    fps              | 2944     |\n",
      "|    time_elapsed     | 196      |\n",
      "|    total_timesteps  | 577415   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.877    |\n",
      "|    n_updates        | 144328   |\n",
      "----------------------------------\n",
      "Episode reward: 43.888912\n",
      "Episode reward: 50.47502\n",
      "Episode reward: 60.478245\n",
      "Episode reward: 59.675135\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10428    |\n",
      "|    fps              | 2944     |\n",
      "|    time_elapsed     | 196      |\n",
      "|    total_timesteps  | 577631   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.849    |\n",
      "|    n_updates        | 144382   |\n",
      "----------------------------------\n",
      "Episode reward: 33.710618\n",
      "Episode reward: 49.875601\n",
      "Episode reward: 83.328225\n",
      "Episode reward: 59.673609\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10432    |\n",
      "|    fps              | 2943     |\n",
      "|    time_elapsed     | 196      |\n",
      "|    total_timesteps  | 577863   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.7      |\n",
      "|    n_updates        | 144440   |\n",
      "----------------------------------\n",
      "Episode reward: 46.876158\n",
      "Episode reward: 60.684542\n",
      "Episode reward: 49.806429\n",
      "Episode reward: 44.900588\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10436    |\n",
      "|    fps              | 2943     |\n",
      "|    time_elapsed     | 196      |\n",
      "|    total_timesteps  | 578067   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.267    |\n",
      "|    n_updates        | 144491   |\n",
      "----------------------------------\n",
      "Episode reward: 47.749352\n",
      "Episode reward: 51.654451\n",
      "Episode reward: 59.597254\n",
      "Episode reward: 48.614778\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10440    |\n",
      "|    fps              | 2944     |\n",
      "|    time_elapsed     | 196      |\n",
      "|    total_timesteps  | 578276   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0174   |\n",
      "|    n_updates        | 144543   |\n",
      "----------------------------------\n",
      "Episode reward: 25.81246\n",
      "Episode reward: 95.148878\n",
      "Episode reward: 36.800126\n",
      "Episode reward: 34.822292\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10444    |\n",
      "|    fps              | 2943     |\n",
      "|    time_elapsed     | 196      |\n",
      "|    total_timesteps  | 578488   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0467   |\n",
      "|    n_updates        | 144596   |\n",
      "----------------------------------\n",
      "Episode reward: 40.876766\n",
      "Episode reward: 47.874464\n",
      "Episode reward: 38.917512\n",
      "Episode reward: 61.349804\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10448    |\n",
      "|    fps              | 2943     |\n",
      "|    time_elapsed     | 196      |\n",
      "|    total_timesteps  | 578678   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0159   |\n",
      "|    n_updates        | 144644   |\n",
      "----------------------------------\n",
      "Episode reward: 79.374447\n",
      "Episode reward: 37.852867\n",
      "Episode reward: 40.703956\n",
      "Episode reward: 61.078678\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10452    |\n",
      "|    fps              | 2943     |\n",
      "|    time_elapsed     | 196      |\n",
      "|    total_timesteps  | 578899   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.909    |\n",
      "|    n_updates        | 144699   |\n",
      "----------------------------------\n",
      "Episode reward: 58.555401\n",
      "Episode reward: 81.646586\n",
      "Episode reward: 91.837558\n",
      "Episode reward: 78.405614\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10456    |\n",
      "|    fps              | 2943     |\n",
      "|    time_elapsed     | 196      |\n",
      "|    total_timesteps  | 579213   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.566    |\n",
      "|    n_updates        | 144778   |\n",
      "----------------------------------\n",
      "Episode reward: 74.63431\n",
      "Episode reward: 73.764444\n",
      "Episode reward: 60.733635\n",
      "Episode reward: 87.355959\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10460    |\n",
      "|    fps              | 2943     |\n",
      "|    time_elapsed     | 196      |\n",
      "|    total_timesteps  | 579515   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0372   |\n",
      "|    n_updates        | 144853   |\n",
      "----------------------------------\n",
      "Episode reward: 98.648224\n",
      "Episode reward: 41.934571\n",
      "Episode reward: 65.633955\n",
      "Episode reward: 43.915641\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10464    |\n",
      "|    fps              | 2943     |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 579787   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11     |\n",
      "|    n_updates        | 144921   |\n",
      "----------------------------------\n",
      "Episode reward: 72.066366\n",
      "Episode reward: 33.90665\n",
      "Episode reward: 41.925726\n",
      "Episode reward: 110.265759\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10468    |\n",
      "|    fps              | 2943     |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 580049   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 144987   |\n",
      "----------------------------------\n",
      "Episode reward: 56.656353\n",
      "Episode reward: 57.699318\n",
      "Episode reward: 32.759117\n",
      "Episode reward: 30.621158\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10472    |\n",
      "|    fps              | 2943     |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 580229   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0696   |\n",
      "|    n_updates        | 145032   |\n",
      "----------------------------------\n",
      "Episode reward: 33.841019\n",
      "Episode reward: 73.64279\n",
      "Episode reward: 101.367526\n",
      "Episode reward: 37.684683\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10476    |\n",
      "|    fps              | 2943     |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 580488   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0509   |\n",
      "|    n_updates        | 145096   |\n",
      "----------------------------------\n",
      "Episode reward: 62.689816\n",
      "Episode reward: 55.794732\n",
      "Episode reward: 82.624263\n",
      "Episode reward: 43.90665\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10480    |\n",
      "|    fps              | 2942     |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 580734   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0369   |\n",
      "|    n_updates        | 145158   |\n",
      "----------------------------------\n",
      "Episode reward: 39.874573\n",
      "Episode reward: 37.801223\n",
      "Episode reward: 29.873497\n",
      "Episode reward: 77.558738\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10484    |\n",
      "|    fps              | 2942     |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 580920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0441   |\n",
      "|    n_updates        | 145204   |\n",
      "----------------------------------\n",
      "Episode reward: 61.855622\n",
      "Episode reward: 39.427533\n",
      "Episode reward: 33.91602\n",
      "Episode reward: 83.902685\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10488    |\n",
      "|    fps              | 2942     |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 581142   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 145260   |\n",
      "----------------------------------\n",
      "Episode reward: 33.799237\n",
      "Episode reward: 42.857829\n",
      "Episode reward: 30.779833\n",
      "Episode reward: 68.681335\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10492    |\n",
      "|    fps              | 2942     |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 581319   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0237   |\n",
      "|    n_updates        | 145304   |\n",
      "----------------------------------\n",
      "Episode reward: 32.871892\n",
      "Episode reward: 34.811886\n",
      "Episode reward: 70.842416\n",
      "Episode reward: 31.931925\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10496    |\n",
      "|    fps              | 2942     |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 581491   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0311   |\n",
      "|    n_updates        | 145347   |\n",
      "----------------------------------\n",
      "Episode reward: 140.406262\n",
      "Episode reward: 54.732978\n",
      "Episode reward: 105.554709\n",
      "Episode reward: 79.656123\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10500    |\n",
      "|    fps              | 2941     |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 581878   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.03     |\n",
      "|    n_updates        | 145444   |\n",
      "----------------------------------\n",
      "Episode reward: 47.784934\n",
      "Episode reward: 34.926414\n",
      "Episode reward: 53.669314\n",
      "Episode reward: 31.828032\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10504    |\n",
      "|    fps              | 2941     |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 582047   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0227   |\n",
      "|    n_updates        | 145486   |\n",
      "----------------------------------\n",
      "Episode reward: 36.815414\n",
      "Episode reward: 41.911217\n",
      "Episode reward: 71.877425\n",
      "Episode reward: 48.86961\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10508    |\n",
      "|    fps              | 2941     |\n",
      "|    time_elapsed     | 197      |\n",
      "|    total_timesteps  | 582248   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0439   |\n",
      "|    n_updates        | 145536   |\n",
      "----------------------------------\n",
      "Episode reward: 68.58217\n",
      "Episode reward: 43.548412\n",
      "Episode reward: 64.991596\n",
      "Episode reward: 85.351239\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10512    |\n",
      "|    fps              | 2941     |\n",
      "|    time_elapsed     | 198      |\n",
      "|    total_timesteps  | 582514   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0427   |\n",
      "|    n_updates        | 145603   |\n",
      "----------------------------------\n",
      "Episode reward: 52.226559\n",
      "Episode reward: 104.603834\n",
      "Episode reward: 42.901795\n",
      "Episode reward: 82.516097\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10516    |\n",
      "|    fps              | 2941     |\n",
      "|    time_elapsed     | 198      |\n",
      "|    total_timesteps  | 582807   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.26     |\n",
      "|    n_updates        | 145676   |\n",
      "----------------------------------\n",
      "Episode reward: 65.802416\n",
      "Episode reward: 46.857742\n",
      "Episode reward: 80.946634\n",
      "Episode reward: 33.758257\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10520    |\n",
      "|    fps              | 2941     |\n",
      "|    time_elapsed     | 198      |\n",
      "|    total_timesteps  | 583037   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0277   |\n",
      "|    n_updates        | 145734   |\n",
      "----------------------------------\n",
      "Episode reward: 68.712176\n",
      "Episode reward: 74.460169\n",
      "Episode reward: 52.784102\n",
      "Episode reward: 51.829913\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10524    |\n",
      "|    fps              | 2940     |\n",
      "|    time_elapsed     | 198      |\n",
      "|    total_timesteps  | 583289   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.12     |\n",
      "|    n_updates        | 145797   |\n",
      "----------------------------------\n",
      "Episode reward: 80.609881\n",
      "Episode reward: 65.994917\n",
      "Episode reward: 41.594239\n",
      "Episode reward: 42.875019\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10528    |\n",
      "|    fps              | 2940     |\n",
      "|    time_elapsed     | 198      |\n",
      "|    total_timesteps  | 583522   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0427   |\n",
      "|    n_updates        | 145855   |\n",
      "----------------------------------\n",
      "Episode reward: 72.749015\n",
      "Episode reward: 39.893066\n",
      "Episode reward: 70.625298\n",
      "Episode reward: 68.515905\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10532    |\n",
      "|    fps              | 2940     |\n",
      "|    time_elapsed     | 198      |\n",
      "|    total_timesteps  | 583776   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.84     |\n",
      "|    n_updates        | 145918   |\n",
      "----------------------------------\n",
      "Episode reward: 91.863157\n",
      "Episode reward: 39.283942\n",
      "Episode reward: 42.88955\n",
      "Episode reward: 67.262255\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10536    |\n",
      "|    fps              | 2940     |\n",
      "|    time_elapsed     | 198      |\n",
      "|    total_timesteps  | 584020   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0299   |\n",
      "|    n_updates        | 145979   |\n",
      "----------------------------------\n",
      "Episode reward: 77.159875\n",
      "Episode reward: 67.557773\n",
      "Episode reward: 118.831094\n",
      "Episode reward: 76.14811\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10540    |\n",
      "|    fps              | 2940     |\n",
      "|    time_elapsed     | 198      |\n",
      "|    total_timesteps  | 584369   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.3      |\n",
      "|    n_updates        | 146067   |\n",
      "----------------------------------\n",
      "Episode reward: 38.922783\n",
      "Episode reward: 36.89523\n",
      "Episode reward: 54.871206\n",
      "Episode reward: 68.621048\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10544    |\n",
      "|    fps              | 2939     |\n",
      "|    time_elapsed     | 198      |\n",
      "|    total_timesteps  | 584569   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0222   |\n",
      "|    n_updates        | 146117   |\n",
      "----------------------------------\n",
      "Episode reward: 78.965396\n",
      "Episode reward: 42.663851\n",
      "Episode reward: 26.727845\n",
      "Episode reward: 29.851185\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10548    |\n",
      "|    fps              | 2939     |\n",
      "|    time_elapsed     | 198      |\n",
      "|    total_timesteps  | 584749   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0281   |\n",
      "|    n_updates        | 146162   |\n",
      "----------------------------------\n",
      "Episode reward: 58.11676\n",
      "Episode reward: 48.929929\n",
      "Episode reward: 67.795539\n",
      "Episode reward: 44.878251\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10552    |\n",
      "|    fps              | 2939     |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total_timesteps  | 584970   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.61     |\n",
      "|    n_updates        | 146217   |\n",
      "----------------------------------\n",
      "Episode reward: 36.460004\n",
      "Episode reward: 32.883778\n",
      "Episode reward: 48.896763\n",
      "Episode reward: 38.783994\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10556    |\n",
      "|    fps              | 2939     |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total_timesteps  | 585128   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0281   |\n",
      "|    n_updates        | 146256   |\n",
      "----------------------------------\n",
      "Episode reward: 57.741887\n",
      "Episode reward: 58.626727\n",
      "Episode reward: 52.742771\n",
      "Episode reward: 44.873593\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10560    |\n",
      "|    fps              | 2939     |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total_timesteps  | 585343   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.97     |\n",
      "|    n_updates        | 146310   |\n",
      "----------------------------------\n",
      "Episode reward: 34.818426\n",
      "Episode reward: 56.814028\n",
      "Episode reward: 44.853099\n",
      "Episode reward: 33.951393\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10564    |\n",
      "|    fps              | 2939     |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total_timesteps  | 585514   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.375    |\n",
      "|    n_updates        | 146353   |\n",
      "----------------------------------\n",
      "Episode reward: 52.861406\n",
      "Episode reward: 42.658802\n",
      "Episode reward: 103.239148\n",
      "Episode reward: 37.93826\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10568    |\n",
      "|    fps              | 2939     |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total_timesteps  | 585755   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 146413   |\n",
      "----------------------------------\n",
      "Episode reward: 56.715351\n",
      "Episode reward: 52.769202\n",
      "Episode reward: 72.003698\n",
      "Episode reward: 52.801162\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10572    |\n",
      "|    fps              | 2939     |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total_timesteps  | 585993   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0366   |\n",
      "|    n_updates        | 146473   |\n",
      "----------------------------------\n",
      "Episode reward: 50.851907\n",
      "Episode reward: 53.49789\n",
      "Episode reward: 83.447269\n",
      "Episode reward: 43.770667\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10576    |\n",
      "|    fps              | 2939     |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total_timesteps  | 586226   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.722    |\n",
      "|    n_updates        | 146531   |\n",
      "----------------------------------\n",
      "Episode reward: 118.103274\n",
      "Episode reward: 58.784608\n",
      "Episode reward: 44.649356\n",
      "Episode reward: 36.931565\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10580    |\n",
      "|    fps              | 2939     |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total_timesteps  | 586488   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0992   |\n",
      "|    n_updates        | 146596   |\n",
      "----------------------------------\n",
      "Episode reward: 48.502838\n",
      "Episode reward: 35.946143\n",
      "Episode reward: 71.189714\n",
      "Episode reward: 24.852255\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10584    |\n",
      "|    fps              | 2938     |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total_timesteps  | 586670   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0217   |\n",
      "|    n_updates        | 146642   |\n",
      "----------------------------------\n",
      "Episode reward: 75.613367\n",
      "Episode reward: 52.898975\n",
      "Episode reward: 64.201308\n",
      "Episode reward: 65.694511\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10588    |\n",
      "|    fps              | 2938     |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total_timesteps  | 586931   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 146707   |\n",
      "----------------------------------\n",
      "Episode reward: 45.243858\n",
      "Episode reward: 53.636848\n",
      "Episode reward: 135.88101\n",
      "Episode reward: 95.396677\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10592    |\n",
      "|    fps              | 2938     |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total_timesteps  | 587270   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.472    |\n",
      "|    n_updates        | 146792   |\n",
      "----------------------------------\n",
      "Episode reward: 80.763563\n",
      "Episode reward: 74.43287\n",
      "Episode reward: 56.896872\n",
      "Episode reward: 43.922001\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10596    |\n",
      "|    fps              | 2938     |\n",
      "|    time_elapsed     | 199      |\n",
      "|    total_timesteps  | 587527   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0224   |\n",
      "|    n_updates        | 146856   |\n",
      "----------------------------------\n",
      "Episode reward: 53.610328\n",
      "Episode reward: 31.815308\n",
      "Episode reward: 37.896069\n",
      "Episode reward: 109.702205\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10600    |\n",
      "|    fps              | 2938     |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total_timesteps  | 587763   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0265   |\n",
      "|    n_updates        | 146915   |\n",
      "----------------------------------\n",
      "Episode reward: 85.831609\n",
      "Episode reward: 44.83704\n",
      "Episode reward: 75.320653\n",
      "Episode reward: 84.441474\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10604    |\n",
      "|    fps              | 2938     |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total_timesteps  | 588061   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0225   |\n",
      "|    n_updates        | 146990   |\n",
      "----------------------------------\n",
      "Episode reward: 81.147228\n",
      "Episode reward: 47.55596\n",
      "Episode reward: 67.687628\n",
      "Episode reward: 101.645182\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10608    |\n",
      "|    fps              | 2938     |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total_timesteps  | 588390   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 147072   |\n",
      "----------------------------------\n",
      "Episode reward: 37.907249\n",
      "Episode reward: 38.750371\n",
      "Episode reward: 79.043906\n",
      "Episode reward: 26.910511\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10612    |\n",
      "|    fps              | 2937     |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total_timesteps  | 588574   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0217   |\n",
      "|    n_updates        | 147118   |\n",
      "----------------------------------\n",
      "Episode reward: 46.919406\n",
      "Episode reward: 101.828392\n",
      "Episode reward: 86.24973\n",
      "Episode reward: 50.790649\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10616    |\n",
      "|    fps              | 2937     |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total_timesteps  | 588862   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0245   |\n",
      "|    n_updates        | 147190   |\n",
      "----------------------------------\n",
      "Episode reward: 48.837062\n",
      "Episode reward: 49.608306\n",
      "Episode reward: 81.015871\n",
      "Episode reward: 88.969337\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10620    |\n",
      "|    fps              | 2937     |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total_timesteps  | 589156   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0198   |\n",
      "|    n_updates        | 147263   |\n",
      "----------------------------------\n",
      "Episode reward: 46.857635\n",
      "Episode reward: 54.376784\n",
      "Episode reward: 53.734688\n",
      "Episode reward: 26.887065\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10624    |\n",
      "|    fps              | 2937     |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total_timesteps  | 589339   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0297   |\n",
      "|    n_updates        | 147309   |\n",
      "----------------------------------\n",
      "Episode reward: 104.243288\n",
      "Episode reward: 45.663565\n",
      "Episode reward: 30.820668\n",
      "Episode reward: 74.972467\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10628    |\n",
      "|    fps              | 2937     |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total_timesteps  | 589597   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.27     |\n",
      "|    n_updates        | 147374   |\n",
      "----------------------------------\n",
      "Episode reward: 60.432271\n",
      "Episode reward: 66.630914\n",
      "Episode reward: 44.832057\n",
      "Episode reward: 57.779409\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10632    |\n",
      "|    fps              | 2937     |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total_timesteps  | 589829   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 147432   |\n",
      "----------------------------------\n",
      "Episode reward: 87.766344\n",
      "Episode reward: 78.648995\n",
      "Episode reward: 85.69589\n",
      "Episode reward: 62.115123\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10636    |\n",
      "|    fps              | 2936     |\n",
      "|    time_elapsed     | 200      |\n",
      "|    total_timesteps  | 590146   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.46     |\n",
      "|    n_updates        | 147511   |\n",
      "----------------------------------\n",
      "Episode reward: 57.78047\n",
      "Episode reward: 68.301323\n",
      "Episode reward: 83.168291\n",
      "Episode reward: 41.917177\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10640    |\n",
      "|    fps              | 2936     |\n",
      "|    time_elapsed     | 201      |\n",
      "|    total_timesteps  | 590399   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0436   |\n",
      "|    n_updates        | 147574   |\n",
      "----------------------------------\n",
      "Episode reward: 62.726569\n",
      "Episode reward: 92.066221\n",
      "Episode reward: 63.826521\n",
      "Episode reward: 84.741745\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10644    |\n",
      "|    fps              | 2936     |\n",
      "|    time_elapsed     | 201      |\n",
      "|    total_timesteps  | 590725   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 147656   |\n",
      "----------------------------------\n",
      "Episode reward: 60.769785\n",
      "Episode reward: 77.413488\n",
      "Episode reward: 83.03358\n",
      "Episode reward: 79.743936\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10648    |\n",
      "|    fps              | 2935     |\n",
      "|    time_elapsed     | 201      |\n",
      "|    total_timesteps  | 591031   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.427    |\n",
      "|    n_updates        | 147732   |\n",
      "----------------------------------\n",
      "Episode reward: 59.698162\n",
      "Episode reward: 82.59549\n",
      "Episode reward: 53.847147\n",
      "Episode reward: 40.763785\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10652    |\n",
      "|    fps              | 2935     |\n",
      "|    time_elapsed     | 201      |\n",
      "|    total_timesteps  | 591269   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.628    |\n",
      "|    n_updates        | 147792   |\n",
      "----------------------------------\n",
      "Episode reward: 50.913713\n",
      "Episode reward: 67.835786\n",
      "Episode reward: 28.75157\n",
      "Episode reward: 54.852126\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10656    |\n",
      "|    fps              | 2935     |\n",
      "|    time_elapsed     | 201      |\n",
      "|    total_timesteps  | 591473   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0166   |\n",
      "|    n_updates        | 147843   |\n",
      "----------------------------------\n",
      "Episode reward: 56.177985\n",
      "Episode reward: 60.323546\n",
      "Episode reward: 38.896122\n",
      "Episode reward: 63.737073\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10660    |\n",
      "|    fps              | 2934     |\n",
      "|    time_elapsed     | 201      |\n",
      "|    total_timesteps  | 591694   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1        |\n",
      "|    n_updates        | 147898   |\n",
      "----------------------------------\n",
      "Episode reward: 123.002337\n",
      "Episode reward: 39.49653\n",
      "Episode reward: 83.170567\n",
      "Episode reward: 73.641503\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65       |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10664    |\n",
      "|    fps              | 2934     |\n",
      "|    time_elapsed     | 201      |\n",
      "|    total_timesteps  | 592017   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0424   |\n",
      "|    n_updates        | 147979   |\n",
      "----------------------------------\n",
      "Episode reward: 85.028505\n",
      "Episode reward: 47.83839\n",
      "Episode reward: 50.871134\n",
      "Episode reward: 52.584226\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65       |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10668    |\n",
      "|    fps              | 2934     |\n",
      "|    time_elapsed     | 201      |\n",
      "|    total_timesteps  | 592255   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.666    |\n",
      "|    n_updates        | 148038   |\n",
      "----------------------------------\n",
      "Episode reward: 108.000624\n",
      "Episode reward: 51.690401\n",
      "Episode reward: 84.774964\n",
      "Episode reward: 29.824744\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.7     |\n",
      "|    ep_rew_mean      | 64       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10672    |\n",
      "|    fps              | 2934     |\n",
      "|    time_elapsed     | 201      |\n",
      "|    total_timesteps  | 592567   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0286   |\n",
      "|    n_updates        | 148116   |\n",
      "----------------------------------\n",
      "Episode reward: 68.609199\n",
      "Episode reward: 34.759882\n",
      "Episode reward: 49.393305\n",
      "Episode reward: 86.497069\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.8     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10676    |\n",
      "|    fps              | 2933     |\n",
      "|    time_elapsed     | 202      |\n",
      "|    total_timesteps  | 592811   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 148177   |\n",
      "----------------------------------\n",
      "Episode reward: 36.560164\n",
      "Episode reward: 80.424963\n",
      "Episode reward: 33.881859\n",
      "Episode reward: 49.823932\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.3     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10680    |\n",
      "|    fps              | 2933     |\n",
      "|    time_elapsed     | 202      |\n",
      "|    total_timesteps  | 593017   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.498    |\n",
      "|    n_updates        | 148229   |\n",
      "----------------------------------\n",
      "Episode reward: 113.382492\n",
      "Episode reward: 45.922069\n",
      "Episode reward: 53.885271\n",
      "Episode reward: 23.869909\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66       |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10684    |\n",
      "|    fps              | 2933     |\n",
      "|    time_elapsed     | 202      |\n",
      "|    total_timesteps  | 593269   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0293   |\n",
      "|    n_updates        | 148292   |\n",
      "----------------------------------\n",
      "Episode reward: 64.754705\n",
      "Episode reward: 65.72155\n",
      "Episode reward: 73.729723\n",
      "Episode reward: 42.846366\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.9     |\n",
      "|    ep_rew_mean      | 63.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10688    |\n",
      "|    fps              | 2933     |\n",
      "|    time_elapsed     | 202      |\n",
      "|    total_timesteps  | 593517   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.57     |\n",
      "|    n_updates        | 148354   |\n",
      "----------------------------------\n",
      "Episode reward: 85.64116\n",
      "Episode reward: 44.897737\n",
      "Episode reward: 64.589004\n",
      "Episode reward: 61.083391\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.1     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10692    |\n",
      "|    fps              | 2932     |\n",
      "|    time_elapsed     | 202      |\n",
      "|    total_timesteps  | 593776   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.287    |\n",
      "|    n_updates        | 148418   |\n",
      "----------------------------------\n",
      "Episode reward: 42.6917\n",
      "Episode reward: 68.689384\n",
      "Episode reward: 35.91861\n",
      "Episode reward: 85.650428\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.9     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10696    |\n",
      "|    fps              | 2932     |\n",
      "|    time_elapsed     | 202      |\n",
      "|    total_timesteps  | 594013   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0313   |\n",
      "|    n_updates        | 148478   |\n",
      "----------------------------------\n",
      "Episode reward: 34.752188\n",
      "Episode reward: 81.28243\n",
      "Episode reward: 41.878647\n",
      "Episode reward: 115.52002\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.5     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10700    |\n",
      "|    fps              | 2932     |\n",
      "|    time_elapsed     | 202      |\n",
      "|    total_timesteps  | 594317   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.38     |\n",
      "|    n_updates        | 148554   |\n",
      "----------------------------------\n",
      "Episode reward: 116.689761\n",
      "Episode reward: 66.79904\n",
      "Episode reward: 66.700511\n",
      "Episode reward: 91.890646\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.1     |\n",
      "|    ep_rew_mean      | 63.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10704    |\n",
      "|    fps              | 2932     |\n",
      "|    time_elapsed     | 202      |\n",
      "|    total_timesteps  | 594675   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0569   |\n",
      "|    n_updates        | 148643   |\n",
      "----------------------------------\n",
      "Episode reward: 98.15089\n",
      "Episode reward: 78.377751\n",
      "Episode reward: 31.758853\n",
      "Episode reward: 66.635513\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.6     |\n",
      "|    ep_rew_mean      | 63.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10708    |\n",
      "|    fps              | 2932     |\n",
      "|    time_elapsed     | 202      |\n",
      "|    total_timesteps  | 594952   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.549    |\n",
      "|    n_updates        | 148712   |\n",
      "----------------------------------\n",
      "Episode reward: 69.824751\n",
      "Episode reward: 68.774055\n",
      "Episode reward: 49.771703\n",
      "Episode reward: 77.342112\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.5     |\n",
      "|    ep_rew_mean      | 64.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10712    |\n",
      "|    fps              | 2932     |\n",
      "|    time_elapsed     | 202      |\n",
      "|    total_timesteps  | 595220   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.3      |\n",
      "|    n_updates        | 148779   |\n",
      "----------------------------------\n",
      "Episode reward: 64.418172\n",
      "Episode reward: 33.493361\n",
      "Episode reward: 70.579924\n",
      "Episode reward: 58.142687\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.9     |\n",
      "|    ep_rew_mean      | 63.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10716    |\n",
      "|    fps              | 2932     |\n",
      "|    time_elapsed     | 203      |\n",
      "|    total_timesteps  | 595450   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0236   |\n",
      "|    n_updates        | 148837   |\n",
      "----------------------------------\n",
      "Episode reward: 79.373896\n",
      "Episode reward: 68.087492\n",
      "Episode reward: 48.887764\n",
      "Episode reward: 41.846519\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.3     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10720    |\n",
      "|    fps              | 2932     |\n",
      "|    time_elapsed     | 203      |\n",
      "|    total_timesteps  | 595690   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0308   |\n",
      "|    n_updates        | 148897   |\n",
      "----------------------------------\n",
      "Episode reward: 73.690379\n",
      "Episode reward: 49.614197\n",
      "Episode reward: 50.07133\n",
      "Episode reward: 78.403948\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.1     |\n",
      "|    ep_rew_mean      | 64.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10724    |\n",
      "|    fps              | 2932     |\n",
      "|    time_elapsed     | 203      |\n",
      "|    total_timesteps  | 595948   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0335   |\n",
      "|    n_updates        | 148961   |\n",
      "----------------------------------\n",
      "Episode reward: 49.89806\n",
      "Episode reward: 92.038918\n",
      "Episode reward: 64.647702\n",
      "Episode reward: 63.890705\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.2     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10728    |\n",
      "|    fps              | 2932     |\n",
      "|    time_elapsed     | 203      |\n",
      "|    total_timesteps  | 596222   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0387   |\n",
      "|    n_updates        | 149030   |\n",
      "----------------------------------\n",
      "Episode reward: 50.803577\n",
      "Episode reward: 99.544096\n",
      "Episode reward: 99.546278\n",
      "Episode reward: 59.744833\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67       |\n",
      "|    ep_rew_mean      | 65.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10732    |\n",
      "|    fps              | 2931     |\n",
      "|    time_elapsed     | 203      |\n",
      "|    total_timesteps  | 596534   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.62     |\n",
      "|    n_updates        | 149108   |\n",
      "----------------------------------\n",
      "Episode reward: 84.96964\n",
      "Episode reward: 55.692384\n",
      "Episode reward: 146.813162\n",
      "Episode reward: 69.132651\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.7     |\n",
      "|    ep_rew_mean      | 65.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10736    |\n",
      "|    fps              | 2931     |\n",
      "|    time_elapsed     | 203      |\n",
      "|    total_timesteps  | 596915   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.18     |\n",
      "|    n_updates        | 149203   |\n",
      "----------------------------------\n",
      "Episode reward: 57.832558\n",
      "Episode reward: 112.693775\n",
      "Episode reward: 35.610183\n",
      "Episode reward: 52.71977\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.8     |\n",
      "|    ep_rew_mean      | 65.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10740    |\n",
      "|    fps              | 2930     |\n",
      "|    time_elapsed     | 203      |\n",
      "|    total_timesteps  | 597177   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0239   |\n",
      "|    n_updates        | 149269   |\n",
      "----------------------------------\n",
      "Episode reward: 88.446463\n",
      "Episode reward: 28.810963\n",
      "Episode reward: 58.713396\n",
      "Episode reward: 132.815503\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.7     |\n",
      "|    ep_rew_mean      | 65.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10744    |\n",
      "|    fps              | 2930     |\n",
      "|    time_elapsed     | 203      |\n",
      "|    total_timesteps  | 597490   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0349   |\n",
      "|    n_updates        | 149347   |\n",
      "----------------------------------\n",
      "Episode reward: 29.670136\n",
      "Episode reward: 84.745141\n",
      "Episode reward: 87.813175\n",
      "Episode reward: 72.150353\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68       |\n",
      "|    ep_rew_mean      | 65.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10748    |\n",
      "|    fps              | 2930     |\n",
      "|    time_elapsed     | 203      |\n",
      "|    total_timesteps  | 597834   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.889    |\n",
      "|    n_updates        | 149433   |\n",
      "----------------------------------\n",
      "Episode reward: 39.455331\n",
      "Episode reward: 43.93269\n",
      "Episode reward: 55.826324\n",
      "Episode reward: 28.751001\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.3     |\n",
      "|    ep_rew_mean      | 64.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10752    |\n",
      "|    fps              | 2930     |\n",
      "|    time_elapsed     | 204      |\n",
      "|    total_timesteps  | 598003   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.17     |\n",
      "|    n_updates        | 149475   |\n",
      "----------------------------------\n",
      "Episode reward: 64.699607\n",
      "Episode reward: 78.980771\n",
      "Episode reward: 63.583468\n",
      "Episode reward: 45.928794\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.8     |\n",
      "|    ep_rew_mean      | 65.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10756    |\n",
      "|    fps              | 2930     |\n",
      "|    time_elapsed     | 204      |\n",
      "|    total_timesteps  | 598258   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.23     |\n",
      "|    n_updates        | 149539   |\n",
      "----------------------------------\n",
      "Episode reward: 81.566671\n",
      "Episode reward: 38.834072\n",
      "Episode reward: 68.688512\n",
      "Episode reward: 97.710095\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.6     |\n",
      "|    ep_rew_mean      | 66       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10760    |\n",
      "|    fps              | 2930     |\n",
      "|    time_elapsed     | 204      |\n",
      "|    total_timesteps  | 598550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.78     |\n",
      "|    n_updates        | 149612   |\n",
      "----------------------------------\n",
      "Episode reward: 75.097158\n",
      "Episode reward: 46.896658\n",
      "Episode reward: 72.047092\n",
      "Episode reward: 81.200129\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.2     |\n",
      "|    ep_rew_mean      | 65.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10764    |\n",
      "|    fps              | 2930     |\n",
      "|    time_elapsed     | 204      |\n",
      "|    total_timesteps  | 598839   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0271   |\n",
      "|    n_updates        | 149684   |\n",
      "----------------------------------\n",
      "Episode reward: 70.243585\n",
      "Episode reward: 79.428388\n",
      "Episode reward: 47.861213\n",
      "Episode reward: 41.553086\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.3     |\n",
      "|    ep_rew_mean      | 65.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10768    |\n",
      "|    fps              | 2930     |\n",
      "|    time_elapsed     | 204      |\n",
      "|    total_timesteps  | 599082   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0203   |\n",
      "|    n_updates        | 149745   |\n",
      "----------------------------------\n",
      "Episode reward: 41.904069\n",
      "Episode reward: 45.471479\n",
      "Episode reward: 107.082418\n",
      "Episode reward: 39.376847\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.5     |\n",
      "|    ep_rew_mean      | 65.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10772    |\n",
      "|    fps              | 2930     |\n",
      "|    time_elapsed     | 204      |\n",
      "|    total_timesteps  | 599322   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0252   |\n",
      "|    n_updates        | 149805   |\n",
      "----------------------------------\n",
      "Episode reward: 51.790922\n",
      "Episode reward: 51.8775\n",
      "Episode reward: 60.818578\n",
      "Episode reward: 61.796442\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.4     |\n",
      "|    ep_rew_mean      | 65.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10776    |\n",
      "|    fps              | 2930     |\n",
      "|    time_elapsed     | 204      |\n",
      "|    total_timesteps  | 599549   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.69     |\n",
      "|    n_updates        | 149862   |\n",
      "----------------------------------\n",
      "Episode reward: 72.908287\n",
      "Episode reward: 45.535065\n",
      "Episode reward: 39.926355\n",
      "Episode reward: 39.941145\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.3     |\n",
      "|    ep_rew_mean      | 65.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10780    |\n",
      "|    fps              | 2929     |\n",
      "|    time_elapsed     | 204      |\n",
      "|    total_timesteps  | 599751   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 149912   |\n",
      "----------------------------------\n",
      "Episode reward: 53.815321\n",
      "Episode reward: 40.813076\n",
      "Episode reward: 48.869335\n",
      "Episode reward: 27.859167\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.5     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10784    |\n",
      "|    fps              | 2929     |\n",
      "|    time_elapsed     | 204      |\n",
      "|    total_timesteps  | 599923   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0471   |\n",
      "|    n_updates        | 149955   |\n",
      "----------------------------------\n",
      "Episode reward: 43.90181\n",
      "Episode reward: 82.380699\n",
      "Episode reward: 86.164362\n",
      "Episode reward: 68.092849\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.9     |\n",
      "|    ep_rew_mean      | 64.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10788    |\n",
      "|    fps              | 2929     |\n",
      "|    time_elapsed     | 204      |\n",
      "|    total_timesteps  | 600209   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.23     |\n",
      "|    n_updates        | 150027   |\n",
      "----------------------------------\n",
      "Episode reward: 110.238727\n",
      "Episode reward: 59.665453\n",
      "Episode reward: 34.939272\n",
      "Episode reward: 50.777162\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.9     |\n",
      "|    ep_rew_mean      | 64.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10792    |\n",
      "|    fps              | 2929     |\n",
      "|    time_elapsed     | 204      |\n",
      "|    total_timesteps  | 600467   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0278   |\n",
      "|    n_updates        | 150091   |\n",
      "----------------------------------\n",
      "Episode reward: 74.476675\n",
      "Episode reward: 36.551833\n",
      "Episode reward: 44.750667\n",
      "Episode reward: 96.309638\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.1     |\n",
      "|    ep_rew_mean      | 64.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10796    |\n",
      "|    fps              | 2929     |\n",
      "|    time_elapsed     | 205      |\n",
      "|    total_timesteps  | 600721   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.18     |\n",
      "|    n_updates        | 150155   |\n",
      "----------------------------------\n",
      "Episode reward: 116.564302\n",
      "Episode reward: 50.749937\n",
      "Episode reward: 96.252087\n",
      "Episode reward: 74.648038\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.5     |\n",
      "|    ep_rew_mean      | 65.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10800    |\n",
      "|    fps              | 2929     |\n",
      "|    time_elapsed     | 205      |\n",
      "|    total_timesteps  | 601062   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.901    |\n",
      "|    n_updates        | 150240   |\n",
      "----------------------------------\n",
      "Episode reward: 54.49193\n",
      "Episode reward: 73.548319\n",
      "Episode reward: 46.579128\n",
      "Episode reward: 149.761222\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.4     |\n",
      "|    ep_rew_mean      | 65.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10804    |\n",
      "|    fps              | 2929     |\n",
      "|    time_elapsed     | 205      |\n",
      "|    total_timesteps  | 601415   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 150328   |\n",
      "----------------------------------\n",
      "Episode reward: 34.61612\n",
      "Episode reward: 62.526691\n",
      "Episode reward: 31.850973\n",
      "Episode reward: 25.559916\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.2     |\n",
      "|    ep_rew_mean      | 64.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10808    |\n",
      "|    fps              | 2929     |\n",
      "|    time_elapsed     | 205      |\n",
      "|    total_timesteps  | 601571   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0364   |\n",
      "|    n_updates        | 150367   |\n",
      "----------------------------------\n",
      "Episode reward: 117.176718\n",
      "Episode reward: 101.836099\n",
      "Episode reward: 93.119789\n",
      "Episode reward: 49.768687\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.3     |\n",
      "|    ep_rew_mean      | 65.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10812    |\n",
      "|    fps              | 2929     |\n",
      "|    time_elapsed     | 205      |\n",
      "|    total_timesteps  | 601947   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0617   |\n",
      "|    n_updates        | 150461   |\n",
      "----------------------------------\n",
      "Episode reward: 43.860014\n",
      "Episode reward: 28.943655\n",
      "Episode reward: 51.677191\n",
      "Episode reward: 73.973425\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67       |\n",
      "|    ep_rew_mean      | 64.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10816    |\n",
      "|    fps              | 2928     |\n",
      "|    time_elapsed     | 205      |\n",
      "|    total_timesteps  | 602147   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.045    |\n",
      "|    n_updates        | 150511   |\n",
      "----------------------------------\n",
      "Episode reward: 55.436275\n",
      "Episode reward: 42.63108\n",
      "Episode reward: 26.841338\n",
      "Episode reward: 111.701701\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.1     |\n",
      "|    ep_rew_mean      | 64.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10820    |\n",
      "|    fps              | 2928     |\n",
      "|    time_elapsed     | 205      |\n",
      "|    total_timesteps  | 602399   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0551   |\n",
      "|    n_updates        | 150574   |\n",
      "----------------------------------\n",
      "Episode reward: 47.662439\n",
      "Episode reward: 32.919468\n",
      "Episode reward: 28.735412\n",
      "Episode reward: 63.906891\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.3     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10824    |\n",
      "|    fps              | 2928     |\n",
      "|    time_elapsed     | 205      |\n",
      "|    total_timesteps  | 602575   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0515   |\n",
      "|    n_updates        | 150618   |\n",
      "----------------------------------\n",
      "Episode reward: 103.982371\n",
      "Episode reward: 45.911139\n",
      "Episode reward: 33.878698\n",
      "Episode reward: 58.467104\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.2     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10828    |\n",
      "|    fps              | 2928     |\n",
      "|    time_elapsed     | 205      |\n",
      "|    total_timesteps  | 602839   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0302   |\n",
      "|    n_updates        | 150684   |\n",
      "----------------------------------\n",
      "Episode reward: 40.82029\n",
      "Episode reward: 55.771166\n",
      "Episode reward: 38.921321\n",
      "Episode reward: 54.790225\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65       |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10832    |\n",
      "|    fps              | 2928     |\n",
      "|    time_elapsed     | 205      |\n",
      "|    total_timesteps  | 603030   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0244   |\n",
      "|    n_updates        | 150732   |\n",
      "----------------------------------\n",
      "Episode reward: 48.848198\n",
      "Episode reward: 43.812342\n",
      "Episode reward: 36.63499\n",
      "Episode reward: 69.231909\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10836    |\n",
      "|    fps              | 2928     |\n",
      "|    time_elapsed     | 205      |\n",
      "|    total_timesteps  | 603232   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.13     |\n",
      "|    n_updates        | 150782   |\n",
      "----------------------------------\n",
      "Episode reward: 67.877485\n",
      "Episode reward: 77.279401\n",
      "Episode reward: 85.527858\n",
      "Episode reward: 42.784596\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10840    |\n",
      "|    fps              | 2928     |\n",
      "|    time_elapsed     | 206      |\n",
      "|    total_timesteps  | 603509   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0678   |\n",
      "|    n_updates        | 150852   |\n",
      "----------------------------------\n",
      "Episode reward: 54.398231\n",
      "Episode reward: 39.815236\n",
      "Episode reward: 38.639806\n",
      "Episode reward: 58.451904\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10844    |\n",
      "|    fps              | 2927     |\n",
      "|    time_elapsed     | 206      |\n",
      "|    total_timesteps  | 603702   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0298   |\n",
      "|    n_updates        | 150900   |\n",
      "----------------------------------\n",
      "Episode reward: 23.934832\n",
      "Episode reward: 56.705447\n",
      "Episode reward: 50.768242\n",
      "Episode reward: 31.503946\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10848    |\n",
      "|    fps              | 2927     |\n",
      "|    time_elapsed     | 206      |\n",
      "|    total_timesteps  | 603866   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0246   |\n",
      "|    n_updates        | 150941   |\n",
      "----------------------------------\n",
      "Episode reward: 77.160604\n",
      "Episode reward: 78.611133\n",
      "Episode reward: 79.591681\n",
      "Episode reward: 93.470273\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10852    |\n",
      "|    fps              | 2927     |\n",
      "|    time_elapsed     | 206      |\n",
      "|    total_timesteps  | 604226   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0256   |\n",
      "|    n_updates        | 151031   |\n",
      "----------------------------------\n",
      "Episode reward: 31.722776\n",
      "Episode reward: 114.405921\n",
      "Episode reward: 29.79121\n",
      "Episode reward: 124.877739\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10856    |\n",
      "|    fps              | 2927     |\n",
      "|    time_elapsed     | 206      |\n",
      "|    total_timesteps  | 604529   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0907   |\n",
      "|    n_updates        | 151107   |\n",
      "----------------------------------\n",
      "Episode reward: 50.709637\n",
      "Episode reward: 61.617803\n",
      "Episode reward: 54.677324\n",
      "Episode reward: 58.479775\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10860    |\n",
      "|    fps              | 2926     |\n",
      "|    time_elapsed     | 206      |\n",
      "|    total_timesteps  | 604757   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.32     |\n",
      "|    n_updates        | 151164   |\n",
      "----------------------------------\n",
      "Episode reward: 64.485433\n",
      "Episode reward: 61.334325\n",
      "Episode reward: 79.701787\n",
      "Episode reward: 36.77883\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10864    |\n",
      "|    fps              | 2926     |\n",
      "|    time_elapsed     | 206      |\n",
      "|    total_timesteps  | 605002   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.33     |\n",
      "|    n_updates        | 151225   |\n",
      "----------------------------------\n",
      "Episode reward: 49.775122\n",
      "Episode reward: 33.598578\n",
      "Episode reward: 105.475678\n",
      "Episode reward: 44.9128\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10868    |\n",
      "|    fps              | 2926     |\n",
      "|    time_elapsed     | 206      |\n",
      "|    total_timesteps  | 605265   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0306   |\n",
      "|    n_updates        | 151291   |\n",
      "----------------------------------\n",
      "Episode reward: 72.007307\n",
      "Episode reward: 41.702393\n",
      "Episode reward: 71.069503\n",
      "Episode reward: 53.867047\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10872    |\n",
      "|    fps              | 2926     |\n",
      "|    time_elapsed     | 206      |\n",
      "|    total_timesteps  | 605506   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.12     |\n",
      "|    n_updates        | 151351   |\n",
      "----------------------------------\n",
      "Episode reward: 85.902415\n",
      "Episode reward: 90.961866\n",
      "Episode reward: 90.736618\n",
      "Episode reward: 42.477781\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10876    |\n",
      "|    fps              | 2926     |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total_timesteps  | 605821   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.979    |\n",
      "|    n_updates        | 151430   |\n",
      "----------------------------------\n",
      "Episode reward: 53.154405\n",
      "Episode reward: 65.747506\n",
      "Episode reward: 62.636484\n",
      "Episode reward: 51.430661\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10880    |\n",
      "|    fps              | 2926     |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total_timesteps  | 606056   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 151488   |\n",
      "----------------------------------\n",
      "Episode reward: 51.548267\n",
      "Episode reward: 35.756376\n",
      "Episode reward: 93.301891\n",
      "Episode reward: 32.901889\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10884    |\n",
      "|    fps              | 2925     |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total_timesteps  | 606274   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.962    |\n",
      "|    n_updates        | 151543   |\n",
      "----------------------------------\n",
      "Episode reward: 60.818962\n",
      "Episode reward: 40.865961\n",
      "Episode reward: 30.587538\n",
      "Episode reward: 35.905789\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10888    |\n",
      "|    fps              | 2925     |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total_timesteps  | 606443   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.023    |\n",
      "|    n_updates        | 151585   |\n",
      "----------------------------------\n",
      "Episode reward: 90.330057\n",
      "Episode reward: 73.024983\n",
      "Episode reward: 54.721253\n",
      "Episode reward: 104.092694\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10892    |\n",
      "|    fps              | 2925     |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total_timesteps  | 606776   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0282   |\n",
      "|    n_updates        | 151668   |\n",
      "----------------------------------\n",
      "Episode reward: 47.814629\n",
      "Episode reward: 82.670078\n",
      "Episode reward: 57.798157\n",
      "Episode reward: 42.88019\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10896    |\n",
      "|    fps              | 2925     |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total_timesteps  | 607010   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0221   |\n",
      "|    n_updates        | 151727   |\n",
      "----------------------------------\n",
      "Episode reward: 30.533545\n",
      "Episode reward: 41.437561\n",
      "Episode reward: 79.501601\n",
      "Episode reward: 115.505749\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10900    |\n",
      "|    fps              | 2925     |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total_timesteps  | 607279   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 151794   |\n",
      "----------------------------------\n",
      "Episode reward: 36.919573\n",
      "Episode reward: 49.768815\n",
      "Episode reward: 89.099127\n",
      "Episode reward: 40.835413\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10904    |\n",
      "|    fps              | 2925     |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total_timesteps  | 607510   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.1      |\n",
      "|    n_updates        | 151852   |\n",
      "----------------------------------\n",
      "Episode reward: 54.839186\n",
      "Episode reward: 51.054463\n",
      "Episode reward: 45.672035\n",
      "Episode reward: 102.226056\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10908    |\n",
      "|    fps              | 2925     |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total_timesteps  | 607766   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.02     |\n",
      "|    n_updates        | 151916   |\n",
      "----------------------------------\n",
      "Episode reward: 51.839766\n",
      "Episode reward: 81.461438\n",
      "Episode reward: 75.643388\n",
      "Episode reward: 84.452231\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10912    |\n",
      "|    fps              | 2925     |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total_timesteps  | 608066   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 151991   |\n",
      "----------------------------------\n",
      "Episode reward: 103.640687\n",
      "Episode reward: 42.882855\n",
      "Episode reward: 48.804052\n",
      "Episode reward: 88.076641\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10916    |\n",
      "|    fps              | 2925     |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total_timesteps  | 608352   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0381   |\n",
      "|    n_updates        | 152062   |\n",
      "----------------------------------\n",
      "Episode reward: 43.911037\n",
      "Episode reward: 50.761565\n",
      "Episode reward: 33.861957\n",
      "Episode reward: 25.71162\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10920    |\n",
      "|    fps              | 2925     |\n",
      "|    time_elapsed     | 208      |\n",
      "|    total_timesteps  | 608507   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0152   |\n",
      "|    n_updates        | 152101   |\n",
      "----------------------------------\n",
      "Episode reward: 78.427925\n",
      "Episode reward: 32.677705\n",
      "Episode reward: 74.235413\n",
      "Episode reward: 29.958524\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10924    |\n",
      "|    fps              | 2924     |\n",
      "|    time_elapsed     | 208      |\n",
      "|    total_timesteps  | 608726   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0252   |\n",
      "|    n_updates        | 152156   |\n",
      "----------------------------------\n",
      "Episode reward: 72.683555\n",
      "Episode reward: 33.941742\n",
      "Episode reward: 56.927868\n",
      "Episode reward: 49.715711\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10928    |\n",
      "|    fps              | 2924     |\n",
      "|    time_elapsed     | 208      |\n",
      "|    total_timesteps  | 608943   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0326   |\n",
      "|    n_updates        | 152210   |\n",
      "----------------------------------\n",
      "Episode reward: 93.276708\n",
      "Episode reward: 59.657698\n",
      "Episode reward: 97.696915\n",
      "Episode reward: 59.717463\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10932    |\n",
      "|    fps              | 2924     |\n",
      "|    time_elapsed     | 208      |\n",
      "|    total_timesteps  | 609270   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0826   |\n",
      "|    n_updates        | 152292   |\n",
      "----------------------------------\n",
      "Episode reward: 27.804449\n",
      "Episode reward: 50.523071\n",
      "Episode reward: 65.614819\n",
      "Episode reward: 91.330019\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10936    |\n",
      "|    fps              | 2924     |\n",
      "|    time_elapsed     | 208      |\n",
      "|    total_timesteps  | 609509   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.817    |\n",
      "|    n_updates        | 152352   |\n",
      "----------------------------------\n",
      "Episode reward: 71.393356\n",
      "Episode reward: 52.555868\n",
      "Episode reward: 91.491908\n",
      "Episode reward: 40.738569\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.6     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10940    |\n",
      "|    fps              | 2924     |\n",
      "|    time_elapsed     | 208      |\n",
      "|    total_timesteps  | 609770   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.773    |\n",
      "|    n_updates        | 152417   |\n",
      "----------------------------------\n",
      "Episode reward: 39.624766\n",
      "Episode reward: 48.866681\n",
      "Episode reward: 39.456466\n",
      "Episode reward: 43.569905\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10944    |\n",
      "|    fps              | 2923     |\n",
      "|    time_elapsed     | 208      |\n",
      "|    total_timesteps  | 609943   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.126    |\n",
      "|    n_updates        | 152460   |\n",
      "----------------------------------\n",
      "Episode reward: 84.238777\n",
      "Episode reward: 89.354617\n",
      "Episode reward: 71.754062\n",
      "Episode reward: 107.597109\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10948    |\n",
      "|    fps              | 2923     |\n",
      "|    time_elapsed     | 208      |\n",
      "|    total_timesteps  | 610302   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.13     |\n",
      "|    n_updates        | 152550   |\n",
      "----------------------------------\n",
      "Episode reward: 133.359624\n",
      "Episode reward: 32.948014\n",
      "Episode reward: 95.454971\n",
      "Episode reward: 81.625982\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10952    |\n",
      "|    fps              | 2923     |\n",
      "|    time_elapsed     | 208      |\n",
      "|    total_timesteps  | 610648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0265   |\n",
      "|    n_updates        | 152636   |\n",
      "----------------------------------\n",
      "Episode reward: 31.783299\n",
      "Episode reward: 61.842356\n",
      "Episode reward: 43.734575\n",
      "Episode reward: 44.890562\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10956    |\n",
      "|    fps              | 2923     |\n",
      "|    time_elapsed     | 208      |\n",
      "|    total_timesteps  | 610831   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.29     |\n",
      "|    n_updates        | 152682   |\n",
      "----------------------------------\n",
      "Episode reward: 34.917425\n",
      "Episode reward: 61.760584\n",
      "Episode reward: 53.840178\n",
      "Episode reward: 82.742997\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10960    |\n",
      "|    fps              | 2923     |\n",
      "|    time_elapsed     | 209      |\n",
      "|    total_timesteps  | 611065   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0299   |\n",
      "|    n_updates        | 152741   |\n",
      "----------------------------------\n",
      "Episode reward: 72.931858\n",
      "Episode reward: 120.505169\n",
      "Episode reward: 29.874752\n",
      "Episode reward: 34.791465\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10964    |\n",
      "|    fps              | 2923     |\n",
      "|    time_elapsed     | 209      |\n",
      "|    total_timesteps  | 611329   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.32     |\n",
      "|    n_updates        | 152807   |\n",
      "----------------------------------\n",
      "Episode reward: 38.715232\n",
      "Episode reward: 31.861276\n",
      "Episode reward: 75.34414\n",
      "Episode reward: 65.356581\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10968    |\n",
      "|    fps              | 2923     |\n",
      "|    time_elapsed     | 209      |\n",
      "|    total_timesteps  | 611542   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0262   |\n",
      "|    n_updates        | 152860   |\n",
      "----------------------------------\n",
      "Episode reward: 80.854802\n",
      "Episode reward: 57.791009\n",
      "Episode reward: 32.937839\n",
      "Episode reward: 56.297015\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10972    |\n",
      "|    fps              | 2923     |\n",
      "|    time_elapsed     | 209      |\n",
      "|    total_timesteps  | 611772   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.967    |\n",
      "|    n_updates        | 152917   |\n",
      "----------------------------------\n",
      "Episode reward: 42.863838\n",
      "Episode reward: 33.946959\n",
      "Episode reward: 44.809173\n",
      "Episode reward: 44.876895\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10976    |\n",
      "|    fps              | 2923     |\n",
      "|    time_elapsed     | 209      |\n",
      "|    total_timesteps  | 611939   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0971   |\n",
      "|    n_updates        | 152959   |\n",
      "----------------------------------\n",
      "Episode reward: 36.616364\n",
      "Episode reward: 97.94059\n",
      "Episode reward: 43.918672\n",
      "Episode reward: 69.250862\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10980    |\n",
      "|    fps              | 2922     |\n",
      "|    time_elapsed     | 209      |\n",
      "|    total_timesteps  | 612190   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.45     |\n",
      "|    n_updates        | 153022   |\n",
      "----------------------------------\n",
      "Episode reward: 40.864975\n",
      "Episode reward: 56.468051\n",
      "Episode reward: 42.888338\n",
      "Episode reward: 56.657004\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10984    |\n",
      "|    fps              | 2922     |\n",
      "|    time_elapsed     | 209      |\n",
      "|    total_timesteps  | 612388   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.6      |\n",
      "|    n_updates        | 153071   |\n",
      "----------------------------------\n",
      "Episode reward: 51.822912\n",
      "Episode reward: 42.905332\n",
      "Episode reward: 55.51654\n",
      "Episode reward: 54.436228\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10988    |\n",
      "|    fps              | 2922     |\n",
      "|    time_elapsed     | 209      |\n",
      "|    total_timesteps  | 612594   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0194   |\n",
      "|    n_updates        | 153123   |\n",
      "----------------------------------\n",
      "Episode reward: 53.610118\n",
      "Episode reward: 91.311286\n",
      "Episode reward: 89.755906\n",
      "Episode reward: 44.656469\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10992    |\n",
      "|    fps              | 2922     |\n",
      "|    time_elapsed     | 209      |\n",
      "|    total_timesteps  | 612879   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.617    |\n",
      "|    n_updates        | 153194   |\n",
      "----------------------------------\n",
      "Episode reward: 48.790118\n",
      "Episode reward: 32.731192\n",
      "Episode reward: 82.648139\n",
      "Episode reward: 31.576979\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 10996    |\n",
      "|    fps              | 2922     |\n",
      "|    time_elapsed     | 209      |\n",
      "|    total_timesteps  | 613076   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 153243   |\n",
      "----------------------------------\n",
      "Episode reward: 66.372101\n",
      "Episode reward: 56.165471\n",
      "Episode reward: 47.857681\n",
      "Episode reward: 47.836871\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11000    |\n",
      "|    fps              | 2922     |\n",
      "|    time_elapsed     | 209      |\n",
      "|    total_timesteps  | 613296   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0619   |\n",
      "|    n_updates        | 153298   |\n",
      "----------------------------------\n",
      "Episode reward: 65.546753\n",
      "Episode reward: 32.934643\n",
      "Episode reward: 54.273667\n",
      "Episode reward: 45.688639\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11004    |\n",
      "|    fps              | 2922     |\n",
      "|    time_elapsed     | 209      |\n",
      "|    total_timesteps  | 613496   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0225   |\n",
      "|    n_updates        | 153348   |\n",
      "----------------------------------\n",
      "Episode reward: 66.196619\n",
      "Episode reward: 86.131301\n",
      "Episode reward: 61.411488\n",
      "Episode reward: 90.202173\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11008    |\n",
      "|    fps              | 2922     |\n",
      "|    time_elapsed     | 210      |\n",
      "|    total_timesteps  | 613808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.2      |\n",
      "|    n_updates        | 153426   |\n",
      "----------------------------------\n",
      "Episode reward: 70.061496\n",
      "Episode reward: 95.900648\n",
      "Episode reward: 85.114505\n",
      "Episode reward: 110.368517\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11012    |\n",
      "|    fps              | 2921     |\n",
      "|    time_elapsed     | 210      |\n",
      "|    total_timesteps  | 614175   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.372    |\n",
      "|    n_updates        | 153518   |\n",
      "----------------------------------\n",
      "Episode reward: 82.139776\n",
      "Episode reward: 48.596566\n",
      "Episode reward: 54.712095\n",
      "Episode reward: 57.104417\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11016    |\n",
      "|    fps              | 2921     |\n",
      "|    time_elapsed     | 210      |\n",
      "|    total_timesteps  | 614423   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.203    |\n",
      "|    n_updates        | 153580   |\n",
      "----------------------------------\n",
      "Episode reward: 78.671365\n",
      "Episode reward: 45.856155\n",
      "Episode reward: 33.860832\n",
      "Episode reward: 54.07444\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11020    |\n",
      "|    fps              | 2921     |\n",
      "|    time_elapsed     | 210      |\n",
      "|    total_timesteps  | 614638   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0357   |\n",
      "|    n_updates        | 153634   |\n",
      "----------------------------------\n",
      "Episode reward: 31.941366\n",
      "Episode reward: 65.988211\n",
      "Episode reward: 76.939439\n",
      "Episode reward: 65.210111\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11024    |\n",
      "|    fps              | 2921     |\n",
      "|    time_elapsed     | 210      |\n",
      "|    total_timesteps  | 614882   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.016    |\n",
      "|    n_updates        | 153695   |\n",
      "----------------------------------\n",
      "Episode reward: 69.799732\n",
      "Episode reward: 46.891596\n",
      "Episode reward: 59.84226\n",
      "Episode reward: 45.758575\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11028    |\n",
      "|    fps              | 2920     |\n",
      "|    time_elapsed     | 210      |\n",
      "|    total_timesteps  | 615185   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.318    |\n",
      "|    n_updates        | 153771   |\n",
      "----------------------------------\n",
      "Episode reward: 48.908387\n",
      "Episode reward: 84.37589\n",
      "Episode reward: 38.837414\n",
      "Episode reward: 100.317794\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11032    |\n",
      "|    fps              | 2920     |\n",
      "|    time_elapsed     | 210      |\n",
      "|    total_timesteps  | 615461   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0251   |\n",
      "|    n_updates        | 153840   |\n",
      "----------------------------------\n",
      "Episode reward: 75.887301\n",
      "Episode reward: 57.858214\n",
      "Episode reward: 115.375684\n",
      "Episode reward: 60.412295\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11036    |\n",
      "|    fps              | 2920     |\n",
      "|    time_elapsed     | 210      |\n",
      "|    total_timesteps  | 615780   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.413    |\n",
      "|    n_updates        | 153919   |\n",
      "----------------------------------\n",
      "Episode reward: 30.669705\n",
      "Episode reward: 31.790446\n",
      "Episode reward: 57.768622\n",
      "Episode reward: 48.611559\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11040    |\n",
      "|    fps              | 2920     |\n",
      "|    time_elapsed     | 210      |\n",
      "|    total_timesteps  | 615950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.49     |\n",
      "|    n_updates        | 153962   |\n",
      "----------------------------------\n",
      "Episode reward: 55.730396\n",
      "Episode reward: 54.98251\n",
      "Episode reward: 33.926442\n",
      "Episode reward: 53.685256\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11044    |\n",
      "|    fps              | 2920     |\n",
      "|    time_elapsed     | 210      |\n",
      "|    total_timesteps  | 616151   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.37     |\n",
      "|    n_updates        | 154012   |\n",
      "----------------------------------\n",
      "Episode reward: 68.38238\n",
      "Episode reward: 70.297242\n",
      "Episode reward: 45.89634\n",
      "Episode reward: 66.684126\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11048    |\n",
      "|    fps              | 2920     |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total_timesteps  | 616405   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0215   |\n",
      "|    n_updates        | 154076   |\n",
      "----------------------------------\n",
      "Episode reward: 120.503056\n",
      "Episode reward: 59.82622\n",
      "Episode reward: 64.190214\n",
      "Episode reward: 70.491265\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11052    |\n",
      "|    fps              | 2919     |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total_timesteps  | 616727   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.07     |\n",
      "|    n_updates        | 154156   |\n",
      "----------------------------------\n",
      "Episode reward: 108.386267\n",
      "Episode reward: 52.118393\n",
      "Episode reward: 69.45168\n",
      "Episode reward: 39.608309\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11056    |\n",
      "|    fps              | 2919     |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total_timesteps  | 617004   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 154225   |\n",
      "----------------------------------\n",
      "Episode reward: 52.723783\n",
      "Episode reward: 79.516418\n",
      "Episode reward: 31.561935\n",
      "Episode reward: 37.918039\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11060    |\n",
      "|    fps              | 2919     |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total_timesteps  | 617215   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0374   |\n",
      "|    n_updates        | 154278   |\n",
      "----------------------------------\n",
      "Episode reward: 59.679037\n",
      "Episode reward: 48.172218\n",
      "Episode reward: 91.424473\n",
      "Episode reward: 90.225694\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11064    |\n",
      "|    fps              | 2919     |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total_timesteps  | 617513   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0247   |\n",
      "|    n_updates        | 154353   |\n",
      "----------------------------------\n",
      "Episode reward: 78.537858\n",
      "Episode reward: 87.42838\n",
      "Episode reward: 43.90266\n",
      "Episode reward: 127.813161\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11068    |\n",
      "|    fps              | 2919     |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total_timesteps  | 617883   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.383    |\n",
      "|    n_updates        | 154445   |\n",
      "----------------------------------\n",
      "Episode reward: 54.884803\n",
      "Episode reward: 57.78244\n",
      "Episode reward: 61.464805\n",
      "Episode reward: 29.766054\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11072    |\n",
      "|    fps              | 2919     |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total_timesteps  | 618089   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0256   |\n",
      "|    n_updates        | 154497   |\n",
      "----------------------------------\n",
      "Episode reward: 34.939107\n",
      "Episode reward: 57.566796\n",
      "Episode reward: 72.977993\n",
      "Episode reward: 52.934174\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11076    |\n",
      "|    fps              | 2919     |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total_timesteps  | 618310   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0338   |\n",
      "|    n_updates        | 154552   |\n",
      "----------------------------------\n",
      "Episode reward: 26.848688\n",
      "Episode reward: 75.557559\n",
      "Episode reward: 49.796871\n",
      "Episode reward: 73.908529\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11080    |\n",
      "|    fps              | 2919     |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total_timesteps  | 618540   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.24     |\n",
      "|    n_updates        | 154609   |\n",
      "----------------------------------\n",
      "Episode reward: 43.704405\n",
      "Episode reward: 48.806467\n",
      "Episode reward: 31.73881\n",
      "Episode reward: 69.101843\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11084    |\n",
      "|    fps              | 2919     |\n",
      "|    time_elapsed     | 211      |\n",
      "|    total_timesteps  | 618735   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 154658   |\n",
      "----------------------------------\n",
      "Episode reward: 52.762648\n",
      "Episode reward: 43.778165\n",
      "Episode reward: 87.522916\n",
      "Episode reward: 64.790347\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 61.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11088    |\n",
      "|    fps              | 2919     |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 618986   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0159   |\n",
      "|    n_updates        | 154721   |\n",
      "----------------------------------\n",
      "Episode reward: 108.922422\n",
      "Episode reward: 42.802382\n",
      "Episode reward: 97.350817\n",
      "Episode reward: 44.876979\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11092    |\n",
      "|    fps              | 2919     |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 619333   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0772   |\n",
      "|    n_updates        | 154808   |\n",
      "----------------------------------\n",
      "Episode reward: 62.143903\n",
      "Episode reward: 47.56785\n",
      "Episode reward: 47.750925\n",
      "Episode reward: 63.365377\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11096    |\n",
      "|    fps              | 2919     |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 619556   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0397   |\n",
      "|    n_updates        | 154863   |\n",
      "----------------------------------\n",
      "Episode reward: 32.544217\n",
      "Episode reward: 50.237778\n",
      "Episode reward: 40.843071\n",
      "Episode reward: 54.455041\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 61.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11100    |\n",
      "|    fps              | 2919     |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 619736   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 154908   |\n",
      "----------------------------------\n",
      "Episode reward: 75.615199\n",
      "Episode reward: 39.790262\n",
      "Episode reward: 33.90912\n",
      "Episode reward: 50.80305\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 61.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11104    |\n",
      "|    fps              | 2919     |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 619938   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0826   |\n",
      "|    n_updates        | 154959   |\n",
      "----------------------------------\n",
      "Episode reward: 97.533355\n",
      "Episode reward: 31.853893\n",
      "Episode reward: 32.908845\n",
      "Episode reward: 101.670109\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11108    |\n",
      "|    fps              | 2919     |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 620205   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0392   |\n",
      "|    n_updates        | 155026   |\n",
      "----------------------------------\n",
      "Episode reward: 28.76589\n",
      "Episode reward: 59.816388\n",
      "Episode reward: 152.396466\n",
      "Episode reward: 60.689871\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11112    |\n",
      "|    fps              | 2919     |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 620514   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0453   |\n",
      "|    n_updates        | 155103   |\n",
      "----------------------------------\n",
      "Episode reward: 24.931909\n",
      "Episode reward: 49.853505\n",
      "Episode reward: 51.885441\n",
      "Episode reward: 37.685266\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.6     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11116    |\n",
      "|    fps              | 2918     |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 620679   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0259   |\n",
      "|    n_updates        | 155144   |\n",
      "----------------------------------\n",
      "Episode reward: 122.098149\n",
      "Episode reward: 46.818187\n",
      "Episode reward: 54.722308\n",
      "Episode reward: 30.938581\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11120    |\n",
      "|    fps              | 2918     |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 620935   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.9      |\n",
      "|    n_updates        | 155208   |\n",
      "----------------------------------\n",
      "Episode reward: 114.333562\n",
      "Episode reward: 50.87828\n",
      "Episode reward: 42.878618\n",
      "Episode reward: 26.814254\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11124    |\n",
      "|    fps              | 2918     |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 621174   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.63     |\n",
      "|    n_updates        | 155268   |\n",
      "----------------------------------\n",
      "Episode reward: 71.359078\n",
      "Episode reward: 62.710828\n",
      "Episode reward: 41.923948\n",
      "Episode reward: 27.931859\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11128    |\n",
      "|    fps              | 2918     |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 621379   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0436   |\n",
      "|    n_updates        | 155319   |\n",
      "----------------------------------\n",
      "Episode reward: 32.795924\n",
      "Episode reward: 33.825205\n",
      "Episode reward: 93.619995\n",
      "Episode reward: 52.826829\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11132    |\n",
      "|    fps              | 2918     |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 621593   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.704    |\n",
      "|    n_updates        | 155373   |\n",
      "----------------------------------\n",
      "Episode reward: 106.571791\n",
      "Episode reward: 76.342577\n",
      "Episode reward: 45.570493\n",
      "Episode reward: 87.822719\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11136    |\n",
      "|    fps              | 2918     |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total_timesteps  | 621912   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.803    |\n",
      "|    n_updates        | 155452   |\n",
      "----------------------------------\n",
      "Episode reward: 40.885787\n",
      "Episode reward: 39.891644\n",
      "Episode reward: 42.760001\n",
      "Episode reward: 26.898649\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11140    |\n",
      "|    fps              | 2918     |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total_timesteps  | 622063   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0348   |\n",
      "|    n_updates        | 155490   |\n",
      "----------------------------------\n",
      "Episode reward: 47.85373\n",
      "Episode reward: 36.876923\n",
      "Episode reward: 48.842394\n",
      "Episode reward: 63.72038\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11144    |\n",
      "|    fps              | 2917     |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total_timesteps  | 622261   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.701    |\n",
      "|    n_updates        | 155540   |\n",
      "----------------------------------\n",
      "Episode reward: 41.923486\n",
      "Episode reward: 68.563381\n",
      "Episode reward: 58.348588\n",
      "Episode reward: 64.756252\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11148    |\n",
      "|    fps              | 2917     |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total_timesteps  | 622496   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.85     |\n",
      "|    n_updates        | 155598   |\n",
      "----------------------------------\n",
      "Episode reward: 86.589314\n",
      "Episode reward: 56.740343\n",
      "Episode reward: 54.779603\n",
      "Episode reward: 45.794234\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11152    |\n",
      "|    fps              | 2917     |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total_timesteps  | 622741   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0495   |\n",
      "|    n_updates        | 155660   |\n",
      "----------------------------------\n",
      "Episode reward: 50.844608\n",
      "Episode reward: 46.804696\n",
      "Episode reward: 30.949646\n",
      "Episode reward: 49.86177\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11156    |\n",
      "|    fps              | 2917     |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total_timesteps  | 622920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0313   |\n",
      "|    n_updates        | 155704   |\n",
      "----------------------------------\n",
      "Episode reward: 39.683989\n",
      "Episode reward: 89.169981\n",
      "Episode reward: 62.458945\n",
      "Episode reward: 28.511682\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11160    |\n",
      "|    fps              | 2917     |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total_timesteps  | 623142   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.017    |\n",
      "|    n_updates        | 155760   |\n",
      "----------------------------------\n",
      "Episode reward: 65.59838\n",
      "Episode reward: 80.658137\n",
      "Episode reward: 60.808658\n",
      "Episode reward: 55.830926\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11164    |\n",
      "|    fps              | 2917     |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total_timesteps  | 623410   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0234   |\n",
      "|    n_updates        | 155827   |\n",
      "----------------------------------\n",
      "Episode reward: 35.720511\n",
      "Episode reward: 37.582475\n",
      "Episode reward: 41.919367\n",
      "Episode reward: 89.847274\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11168    |\n",
      "|    fps              | 2917     |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total_timesteps  | 623617   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.43     |\n",
      "|    n_updates        | 155879   |\n",
      "----------------------------------\n",
      "Episode reward: 55.637838\n",
      "Episode reward: 114.086703\n",
      "Episode reward: 37.900976\n",
      "Episode reward: 77.656309\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11172    |\n",
      "|    fps              | 2917     |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total_timesteps  | 623909   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.129    |\n",
      "|    n_updates        | 155952   |\n",
      "----------------------------------\n",
      "Episode reward: 40.839861\n",
      "Episode reward: 31.739937\n",
      "Episode reward: 109.132203\n",
      "Episode reward: 36.664378\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11176    |\n",
      "|    fps              | 2917     |\n",
      "|    time_elapsed     | 213      |\n",
      "|    total_timesteps  | 624134   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.019    |\n",
      "|    n_updates        | 156008   |\n",
      "----------------------------------\n",
      "Episode reward: 89.941017\n",
      "Episode reward: 93.893278\n",
      "Episode reward: 43.842348\n",
      "Episode reward: 89.252164\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11180    |\n",
      "|    fps              | 2917     |\n",
      "|    time_elapsed     | 214      |\n",
      "|    total_timesteps  | 624455   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0503   |\n",
      "|    n_updates        | 156088   |\n",
      "----------------------------------\n",
      "Episode reward: 35.713823\n",
      "Episode reward: 28.881382\n",
      "Episode reward: 44.828251\n",
      "Episode reward: 57.349534\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11184    |\n",
      "|    fps              | 2917     |\n",
      "|    time_elapsed     | 214      |\n",
      "|    total_timesteps  | 624623   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.65     |\n",
      "|    n_updates        | 156130   |\n",
      "----------------------------------\n",
      "Episode reward: 108.44799\n",
      "Episode reward: 98.37275\n",
      "Episode reward: 38.892062\n",
      "Episode reward: 70.741772\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11188    |\n",
      "|    fps              | 2916     |\n",
      "|    time_elapsed     | 214      |\n",
      "|    total_timesteps  | 624944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.696    |\n",
      "|    n_updates        | 156210   |\n",
      "----------------------------------\n",
      "Episode reward: 111.780563\n",
      "Episode reward: 59.842515\n",
      "Episode reward: 65.062722\n",
      "Episode reward: 64.638727\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11192    |\n",
      "|    fps              | 2916     |\n",
      "|    time_elapsed     | 214      |\n",
      "|    total_timesteps  | 625248   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.877    |\n",
      "|    n_updates        | 156286   |\n",
      "----------------------------------\n",
      "Episode reward: 88.609971\n",
      "Episode reward: 76.725673\n",
      "Episode reward: 39.76741\n",
      "Episode reward: 49.84261\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11196    |\n",
      "|    fps              | 2916     |\n",
      "|    time_elapsed     | 214      |\n",
      "|    total_timesteps  | 625504   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0263   |\n",
      "|    n_updates        | 156350   |\n",
      "----------------------------------\n",
      "Episode reward: 29.488554\n",
      "Episode reward: 49.76908\n",
      "Episode reward: 33.823022\n",
      "Episode reward: 49.472653\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11200    |\n",
      "|    fps              | 2916     |\n",
      "|    time_elapsed     | 214      |\n",
      "|    total_timesteps  | 625668   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.229    |\n",
      "|    n_updates        | 156391   |\n",
      "----------------------------------\n",
      "Episode reward: 64.430011\n",
      "Episode reward: 50.746112\n",
      "Episode reward: 51.849277\n",
      "Episode reward: 38.915319\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11204    |\n",
      "|    fps              | 2916     |\n",
      "|    time_elapsed     | 214      |\n",
      "|    total_timesteps  | 625876   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.86     |\n",
      "|    n_updates        | 156443   |\n",
      "----------------------------------\n",
      "Episode reward: 94.412247\n",
      "Episode reward: 60.569567\n",
      "Episode reward: 30.623824\n",
      "Episode reward: 45.754874\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11208    |\n",
      "|    fps              | 2916     |\n",
      "|    time_elapsed     | 214      |\n",
      "|    total_timesteps  | 626109   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0419   |\n",
      "|    n_updates        | 156502   |\n",
      "----------------------------------\n",
      "Episode reward: 75.758856\n",
      "Episode reward: 26.775882\n",
      "Episode reward: 63.778107\n",
      "Episode reward: 29.853219\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11212    |\n",
      "|    fps              | 2916     |\n",
      "|    time_elapsed     | 214      |\n",
      "|    total_timesteps  | 626324   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.91     |\n",
      "|    n_updates        | 156555   |\n",
      "----------------------------------\n",
      "Episode reward: 114.553367\n",
      "Episode reward: 91.183521\n",
      "Episode reward: 67.209959\n",
      "Episode reward: 100.154757\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11216    |\n",
      "|    fps              | 2915     |\n",
      "|    time_elapsed     | 214      |\n",
      "|    total_timesteps  | 626714   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.72     |\n",
      "|    n_updates        | 156653   |\n",
      "----------------------------------\n",
      "Episode reward: 71.683757\n",
      "Episode reward: 58.672556\n",
      "Episode reward: 40.907479\n",
      "Episode reward: 80.391951\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11220    |\n",
      "|    fps              | 2915     |\n",
      "|    time_elapsed     | 215      |\n",
      "|    total_timesteps  | 626968   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.026    |\n",
      "|    n_updates        | 156716   |\n",
      "----------------------------------\n",
      "Episode reward: 47.404352\n",
      "Episode reward: 55.830526\n",
      "Episode reward: 52.880424\n",
      "Episode reward: 72.628272\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11224    |\n",
      "|    fps              | 2915     |\n",
      "|    time_elapsed     | 215      |\n",
      "|    total_timesteps  | 627198   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 156774   |\n",
      "----------------------------------\n",
      "Episode reward: 85.837264\n",
      "Episode reward: 53.802235\n",
      "Episode reward: 143.26782\n",
      "Episode reward: 35.94965\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11228    |\n",
      "|    fps              | 2914     |\n",
      "|    time_elapsed     | 215      |\n",
      "|    total_timesteps  | 627523   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.676    |\n",
      "|    n_updates        | 156855   |\n",
      "----------------------------------\n",
      "Episode reward: 76.09536\n",
      "Episode reward: 42.674244\n",
      "Episode reward: 26.77413\n",
      "Episode reward: 39.761386\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11232    |\n",
      "|    fps              | 2914     |\n",
      "|    time_elapsed     | 215      |\n",
      "|    total_timesteps  | 627710   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.163    |\n",
      "|    n_updates        | 156902   |\n",
      "----------------------------------\n",
      "Episode reward: 49.044348\n",
      "Episode reward: 38.605777\n",
      "Episode reward: 31.819597\n",
      "Episode reward: 96.175218\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11236    |\n",
      "|    fps              | 2914     |\n",
      "|    time_elapsed     | 215      |\n",
      "|    total_timesteps  | 627928   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0238   |\n",
      "|    n_updates        | 156956   |\n",
      "----------------------------------\n",
      "Episode reward: 143.325199\n",
      "Episode reward: 90.355907\n",
      "Episode reward: 41.789273\n",
      "Episode reward: 42.844073\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11240    |\n",
      "|    fps              | 2914     |\n",
      "|    time_elapsed     | 215      |\n",
      "|    total_timesteps  | 628250   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0293   |\n",
      "|    n_updates        | 157037   |\n",
      "----------------------------------\n",
      "Episode reward: 61.435046\n",
      "Episode reward: 41.648753\n",
      "Episode reward: 34.75441\n",
      "Episode reward: 49.483659\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11244    |\n",
      "|    fps              | 2914     |\n",
      "|    time_elapsed     | 215      |\n",
      "|    total_timesteps  | 628439   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 157084   |\n",
      "----------------------------------\n",
      "Episode reward: 51.678644\n",
      "Episode reward: 65.03436\n",
      "Episode reward: 59.71956\n",
      "Episode reward: 26.767769\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11248    |\n",
      "|    fps              | 2914     |\n",
      "|    time_elapsed     | 215      |\n",
      "|    total_timesteps  | 628645   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0359   |\n",
      "|    n_updates        | 157136   |\n",
      "----------------------------------\n",
      "Episode reward: 44.818147\n",
      "Episode reward: 66.456695\n",
      "Episode reward: 42.845404\n",
      "Episode reward: 71.449808\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11252    |\n",
      "|    fps              | 2914     |\n",
      "|    time_elapsed     | 215      |\n",
      "|    total_timesteps  | 628872   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.58     |\n",
      "|    n_updates        | 157192   |\n",
      "----------------------------------\n",
      "Episode reward: 55.034021\n",
      "Episode reward: 85.664986\n",
      "Episode reward: 56.417468\n",
      "Episode reward: 58.298521\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11256    |\n",
      "|    fps              | 2914     |\n",
      "|    time_elapsed     | 215      |\n",
      "|    total_timesteps  | 629131   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0231   |\n",
      "|    n_updates        | 157257   |\n",
      "----------------------------------\n",
      "Episode reward: 97.580136\n",
      "Episode reward: 93.813106\n",
      "Episode reward: 104.532918\n",
      "Episode reward: 38.744544\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11260    |\n",
      "|    fps              | 2914     |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total_timesteps  | 629476   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 157343   |\n",
      "----------------------------------\n",
      "Episode reward: 116.325705\n",
      "Episode reward: 99.908032\n",
      "Episode reward: 79.547684\n",
      "Episode reward: 86.553154\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.7     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11264    |\n",
      "|    fps              | 2913     |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total_timesteps  | 629880   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0411   |\n",
      "|    n_updates        | 157444   |\n",
      "----------------------------------\n",
      "Episode reward: 53.450217\n",
      "Episode reward: 40.793668\n",
      "Episode reward: 100.974153\n",
      "Episode reward: 71.663382\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.4     |\n",
      "|    ep_rew_mean      | 64       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11268    |\n",
      "|    fps              | 2913     |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total_timesteps  | 630155   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.36     |\n",
      "|    n_updates        | 157513   |\n",
      "----------------------------------\n",
      "Episode reward: 70.355673\n",
      "Episode reward: 132.268706\n",
      "Episode reward: 89.409146\n",
      "Episode reward: 34.789411\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66       |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11272    |\n",
      "|    fps              | 2913     |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total_timesteps  | 630513   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0346   |\n",
      "|    n_updates        | 157603   |\n",
      "----------------------------------\n",
      "Episode reward: 75.485262\n",
      "Episode reward: 32.755383\n",
      "Episode reward: 45.912106\n",
      "Episode reward: 81.843296\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.2     |\n",
      "|    ep_rew_mean      | 64.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11276    |\n",
      "|    fps              | 2913     |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total_timesteps  | 630756   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.84     |\n",
      "|    n_updates        | 157663   |\n",
      "----------------------------------\n",
      "Episode reward: 33.802981\n",
      "Episode reward: 222.209222\n",
      "Episode reward: 40.890268\n",
      "Episode reward: 95.315593\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67       |\n",
      "|    ep_rew_mean      | 65.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11280    |\n",
      "|    fps              | 2913     |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total_timesteps  | 631152   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.06     |\n",
      "|    n_updates        | 157762   |\n",
      "----------------------------------\n",
      "Episode reward: 112.525734\n",
      "Episode reward: 32.816408\n",
      "Episode reward: 132.130319\n",
      "Episode reward: 32.840669\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.4     |\n",
      "|    ep_rew_mean      | 66.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11284    |\n",
      "|    fps              | 2913     |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total_timesteps  | 631464   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0368   |\n",
      "|    n_updates        | 157840   |\n",
      "----------------------------------\n",
      "Episode reward: 78.437304\n",
      "Episode reward: 150.637046\n",
      "Episode reward: 54.706976\n",
      "Episode reward: 39.601852\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.5     |\n",
      "|    ep_rew_mean      | 66.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11288    |\n",
      "|    fps              | 2913     |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total_timesteps  | 631790   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.49     |\n",
      "|    n_updates        | 157922   |\n",
      "----------------------------------\n",
      "Episode reward: 41.889678\n",
      "Episode reward: 35.937293\n",
      "Episode reward: 64.723813\n",
      "Episode reward: 91.985912\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.8     |\n",
      "|    ep_rew_mean      | 66.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11292    |\n",
      "|    fps              | 2912     |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total_timesteps  | 632026   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0729   |\n",
      "|    n_updates        | 157981   |\n",
      "----------------------------------\n",
      "Episode reward: 38.730711\n",
      "Episode reward: 85.545735\n",
      "Episode reward: 43.69191\n",
      "Episode reward: 81.92341\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.7     |\n",
      "|    ep_rew_mean      | 66.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11296    |\n",
      "|    fps              | 2912     |\n",
      "|    time_elapsed     | 217      |\n",
      "|    total_timesteps  | 632278   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0566   |\n",
      "|    n_updates        | 158044   |\n",
      "----------------------------------\n",
      "Episode reward: 88.398257\n",
      "Episode reward: 128.33246\n",
      "Episode reward: 43.793119\n",
      "Episode reward: 83.990953\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.6     |\n",
      "|    ep_rew_mean      | 68       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11300    |\n",
      "|    fps              | 2912     |\n",
      "|    time_elapsed     | 217      |\n",
      "|    total_timesteps  | 632625   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0258   |\n",
      "|    n_updates        | 158131   |\n",
      "----------------------------------\n",
      "Episode reward: 68.408388\n",
      "Episode reward: 43.784798\n",
      "Episode reward: 76.983044\n",
      "Episode reward: 96.44496\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.5     |\n",
      "|    ep_rew_mean      | 68.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11304    |\n",
      "|    fps              | 2912     |\n",
      "|    time_elapsed     | 217      |\n",
      "|    total_timesteps  | 632922   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0311   |\n",
      "|    n_updates        | 158205   |\n",
      "----------------------------------\n",
      "Episode reward: 92.041527\n",
      "Episode reward: 91.663553\n",
      "Episode reward: 45.840696\n",
      "Episode reward: 46.605687\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.9     |\n",
      "|    ep_rew_mean      | 69.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11308    |\n",
      "|    fps              | 2912     |\n",
      "|    time_elapsed     | 217      |\n",
      "|    total_timesteps  | 633202   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 158275   |\n",
      "----------------------------------\n",
      "Episode reward: 65.614885\n",
      "Episode reward: 52.601166\n",
      "Episode reward: 136.67539\n",
      "Episode reward: 52.839427\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71.9     |\n",
      "|    ep_rew_mean      | 70.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11312    |\n",
      "|    fps              | 2912     |\n",
      "|    time_elapsed     | 217      |\n",
      "|    total_timesteps  | 633512   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.398    |\n",
      "|    n_updates        | 158352   |\n",
      "----------------------------------\n",
      "Episode reward: 70.93276\n",
      "Episode reward: 106.040785\n",
      "Episode reward: 53.557044\n",
      "Episode reward: 56.721871\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.9     |\n",
      "|    ep_rew_mean      | 69.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11316    |\n",
      "|    fps              | 2912     |\n",
      "|    time_elapsed     | 217      |\n",
      "|    total_timesteps  | 633807   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.524    |\n",
      "|    n_updates        | 158426   |\n",
      "----------------------------------\n",
      "Episode reward: 54.327819\n",
      "Episode reward: 100.232592\n",
      "Episode reward: 63.779859\n",
      "Episode reward: 31.690917\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.9     |\n",
      "|    ep_rew_mean      | 69.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11320    |\n",
      "|    fps              | 2911     |\n",
      "|    time_elapsed     | 217      |\n",
      "|    total_timesteps  | 634059   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0249   |\n",
      "|    n_updates        | 158489   |\n",
      "----------------------------------\n",
      "Episode reward: 45.783649\n",
      "Episode reward: 60.653619\n",
      "Episode reward: 70.675566\n",
      "Episode reward: 57.696443\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71       |\n",
      "|    ep_rew_mean      | 69.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11324    |\n",
      "|    fps              | 2911     |\n",
      "|    time_elapsed     | 217      |\n",
      "|    total_timesteps  | 634295   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.021    |\n",
      "|    n_updates        | 158548   |\n",
      "----------------------------------\n",
      "Episode reward: 71.621629\n",
      "Episode reward: 59.649728\n",
      "Episode reward: 38.917851\n",
      "Episode reward: 31.915847\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.8     |\n",
      "|    ep_rew_mean      | 68.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11328    |\n",
      "|    fps              | 2911     |\n",
      "|    time_elapsed     | 217      |\n",
      "|    total_timesteps  | 634498   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0502   |\n",
      "|    n_updates        | 158599   |\n",
      "----------------------------------\n",
      "Episode reward: 116.109102\n",
      "Episode reward: 42.924009\n",
      "Episode reward: 46.625358\n",
      "Episode reward: 27.945706\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.3     |\n",
      "|    ep_rew_mean      | 68.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11332    |\n",
      "|    fps              | 2911     |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total_timesteps  | 634739   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.258    |\n",
      "|    n_updates        | 158659   |\n",
      "----------------------------------\n",
      "Episode reward: 89.338892\n",
      "Episode reward: 54.902878\n",
      "Episode reward: 58.796173\n",
      "Episode reward: 113.264999\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71.3     |\n",
      "|    ep_rew_mean      | 69.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11336    |\n",
      "|    fps              | 2911     |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total_timesteps  | 635060   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.88     |\n",
      "|    n_updates        | 158739   |\n",
      "----------------------------------\n",
      "Episode reward: 131.280159\n",
      "Episode reward: 32.907215\n",
      "Episode reward: 47.916635\n",
      "Episode reward: 71.243786\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71       |\n",
      "|    ep_rew_mean      | 69.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11340    |\n",
      "|    fps              | 2911     |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total_timesteps  | 635345   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.331    |\n",
      "|    n_updates        | 158811   |\n",
      "----------------------------------\n",
      "Episode reward: 160.822633\n",
      "Episode reward: 69.266744\n",
      "Episode reward: 35.933844\n",
      "Episode reward: 42.542983\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 72.2     |\n",
      "|    ep_rew_mean      | 70.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11344    |\n",
      "|    fps              | 2911     |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total_timesteps  | 635659   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0117   |\n",
      "|    n_updates        | 158889   |\n",
      "----------------------------------\n",
      "Episode reward: 37.89826\n",
      "Episode reward: 33.693135\n",
      "Episode reward: 56.83017\n",
      "Episode reward: 126.976694\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 72.9     |\n",
      "|    ep_rew_mean      | 71.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11348    |\n",
      "|    fps              | 2910     |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total_timesteps  | 635935   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.123    |\n",
      "|    n_updates        | 158958   |\n",
      "----------------------------------\n",
      "Episode reward: 56.170012\n",
      "Episode reward: 63.461496\n",
      "Episode reward: 85.288782\n",
      "Episode reward: 83.457696\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 73.6     |\n",
      "|    ep_rew_mean      | 71.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11352    |\n",
      "|    fps              | 2910     |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total_timesteps  | 636229   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0299   |\n",
      "|    n_updates        | 159032   |\n",
      "----------------------------------\n",
      "Episode reward: 56.809475\n",
      "Episode reward: 95.784333\n",
      "Episode reward: 61.473041\n",
      "Episode reward: 69.236288\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 73.8     |\n",
      "|    ep_rew_mean      | 72.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11356    |\n",
      "|    fps              | 2910     |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total_timesteps  | 636515   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.024    |\n",
      "|    n_updates        | 159103   |\n",
      "----------------------------------\n",
      "Episode reward: 51.301511\n",
      "Episode reward: 63.792282\n",
      "Episode reward: 31.525441\n",
      "Episode reward: 74.102032\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 72.6     |\n",
      "|    ep_rew_mean      | 71       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11360    |\n",
      "|    fps              | 2910     |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total_timesteps  | 636739   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0226   |\n",
      "|    n_updates        | 159159   |\n",
      "----------------------------------\n",
      "Episode reward: 44.846015\n",
      "Episode reward: 47.716312\n",
      "Episode reward: 75.095087\n",
      "Episode reward: 35.653075\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.6     |\n",
      "|    ep_rew_mean      | 69.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11364    |\n",
      "|    fps              | 2910     |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total_timesteps  | 636944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0399   |\n",
      "|    n_updates        | 159210   |\n",
      "----------------------------------\n",
      "Episode reward: 54.733726\n",
      "Episode reward: 36.834586\n",
      "Episode reward: 38.876814\n",
      "Episode reward: 76.838543\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70       |\n",
      "|    ep_rew_mean      | 68.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11368    |\n",
      "|    fps              | 2910     |\n",
      "|    time_elapsed     | 218      |\n",
      "|    total_timesteps  | 637159   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0277   |\n",
      "|    n_updates        | 159264   |\n",
      "----------------------------------\n",
      "Episode reward: 124.10023\n",
      "Episode reward: 117.153579\n",
      "Episode reward: 29.873898\n",
      "Episode reward: 26.693588\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.6     |\n",
      "|    ep_rew_mean      | 68.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11372    |\n",
      "|    fps              | 2910     |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 637476   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0229   |\n",
      "|    n_updates        | 159343   |\n",
      "----------------------------------\n",
      "Episode reward: 57.621917\n",
      "Episode reward: 55.735891\n",
      "Episode reward: 62.674546\n",
      "Episode reward: 54.975752\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.5     |\n",
      "|    ep_rew_mean      | 68.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11376    |\n",
      "|    fps              | 2910     |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 637709   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.17     |\n",
      "|    n_updates        | 159402   |\n",
      "----------------------------------\n",
      "Episode reward: 102.527963\n",
      "Episode reward: 92.113478\n",
      "Episode reward: 57.84076\n",
      "Episode reward: 71.69666\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69       |\n",
      "|    ep_rew_mean      | 67.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11380    |\n",
      "|    fps              | 2910     |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 638057   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.33     |\n",
      "|    n_updates        | 159489   |\n",
      "----------------------------------\n",
      "Episode reward: 57.822976\n",
      "Episode reward: 31.916077\n",
      "Episode reward: 35.863019\n",
      "Episode reward: 39.87399\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.6     |\n",
      "|    ep_rew_mean      | 66.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11384    |\n",
      "|    fps              | 2910     |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 638223   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.043    |\n",
      "|    n_updates        | 159530   |\n",
      "----------------------------------\n",
      "Episode reward: 44.91573\n",
      "Episode reward: 34.68342\n",
      "Episode reward: 66.504835\n",
      "Episode reward: 63.982934\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.5     |\n",
      "|    ep_rew_mean      | 65       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11388    |\n",
      "|    fps              | 2910     |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 638435   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.27     |\n",
      "|    n_updates        | 159583   |\n",
      "----------------------------------\n",
      "Episode reward: 133.568712\n",
      "Episode reward: 27.802872\n",
      "Episode reward: 69.427515\n",
      "Episode reward: 46.876239\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.9     |\n",
      "|    ep_rew_mean      | 65.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11392    |\n",
      "|    fps              | 2910     |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 638714   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.23     |\n",
      "|    n_updates        | 159653   |\n",
      "----------------------------------\n",
      "Episode reward: 74.479662\n",
      "Episode reward: 63.670091\n",
      "Episode reward: 135.100752\n",
      "Episode reward: 41.724685\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.8     |\n",
      "|    ep_rew_mean      | 66.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11396    |\n",
      "|    fps              | 2909     |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 639058   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.108    |\n",
      "|    n_updates        | 159739   |\n",
      "----------------------------------\n",
      "Episode reward: 27.937286\n",
      "Episode reward: 102.44379\n",
      "Episode reward: 43.847668\n",
      "Episode reward: 39.888685\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.5     |\n",
      "|    ep_rew_mean      | 64.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11400    |\n",
      "|    fps              | 2909     |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 639273   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.03     |\n",
      "|    n_updates        | 159793   |\n",
      "----------------------------------\n",
      "Episode reward: 67.721701\n",
      "Episode reward: 81.536483\n",
      "Episode reward: 30.949796\n",
      "Episode reward: 92.241904\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.3     |\n",
      "|    ep_rew_mean      | 64.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11404    |\n",
      "|    fps              | 2909     |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 639554   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 159863   |\n",
      "----------------------------------\n",
      "Episode reward: 29.856061\n",
      "Episode reward: 38.930955\n",
      "Episode reward: 57.912965\n",
      "Episode reward: 65.218787\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.5     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11408    |\n",
      "|    fps              | 2909     |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 639748   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 159911   |\n",
      "----------------------------------\n",
      "Episode reward: 52.842528\n",
      "Episode reward: 33.885867\n",
      "Episode reward: 64.482991\n",
      "Episode reward: 57.667105\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11412    |\n",
      "|    fps              | 2909     |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 639960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.63     |\n",
      "|    n_updates        | 159964   |\n",
      "----------------------------------\n",
      "Episode reward: 50.233146\n",
      "Episode reward: 73.003619\n",
      "Episode reward: 52.715397\n",
      "Episode reward: 44.900418\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11416    |\n",
      "|    fps              | 2909     |\n",
      "|    time_elapsed     | 220      |\n",
      "|    total_timesteps  | 640183   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.385    |\n",
      "|    n_updates        | 160020   |\n",
      "----------------------------------\n",
      "Episode reward: 95.506844\n",
      "Episode reward: 26.894447\n",
      "Episode reward: 88.812701\n",
      "Episode reward: 57.582671\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11420    |\n",
      "|    fps              | 2909     |\n",
      "|    time_elapsed     | 220      |\n",
      "|    total_timesteps  | 640454   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.248    |\n",
      "|    n_updates        | 160088   |\n",
      "----------------------------------\n",
      "Episode reward: 27.852063\n",
      "Episode reward: 55.834533\n",
      "Episode reward: 50.773342\n",
      "Episode reward: 67.487902\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11424    |\n",
      "|    fps              | 2908     |\n",
      "|    time_elapsed     | 220      |\n",
      "|    total_timesteps  | 640657   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 160139   |\n",
      "----------------------------------\n",
      "Episode reward: 31.76496\n",
      "Episode reward: 48.877651\n",
      "Episode reward: 34.923888\n",
      "Episode reward: 36.852021\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11428    |\n",
      "|    fps              | 2908     |\n",
      "|    time_elapsed     | 220      |\n",
      "|    total_timesteps  | 640810   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0169   |\n",
      "|    n_updates        | 160177   |\n",
      "----------------------------------\n",
      "Episode reward: 44.849446\n",
      "Episode reward: 62.7971\n",
      "Episode reward: 79.17813\n",
      "Episode reward: 60.68674\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11432    |\n",
      "|    fps              | 2908     |\n",
      "|    time_elapsed     | 220      |\n",
      "|    total_timesteps  | 641059   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.1      |\n",
      "|    n_updates        | 160239   |\n",
      "----------------------------------\n",
      "Episode reward: 54.594942\n",
      "Episode reward: 42.734675\n",
      "Episode reward: 86.230349\n",
      "Episode reward: 41.849012\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11436    |\n",
      "|    fps              | 2908     |\n",
      "|    time_elapsed     | 220      |\n",
      "|    total_timesteps  | 641290   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 160297   |\n",
      "----------------------------------\n",
      "Episode reward: 39.791434\n",
      "Episode reward: 66.507322\n",
      "Episode reward: 65.70136\n",
      "Episode reward: 40.876604\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11440    |\n",
      "|    fps              | 2908     |\n",
      "|    time_elapsed     | 220      |\n",
      "|    total_timesteps  | 641504   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.98     |\n",
      "|    n_updates        | 160350   |\n",
      "----------------------------------\n",
      "Episode reward: 85.047805\n",
      "Episode reward: 76.967559\n",
      "Episode reward: 58.840806\n",
      "Episode reward: 95.724977\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11444    |\n",
      "|    fps              | 2908     |\n",
      "|    time_elapsed     | 220      |\n",
      "|    total_timesteps  | 641895   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.026    |\n",
      "|    n_updates        | 160448   |\n",
      "----------------------------------\n",
      "Episode reward: 69.539955\n",
      "Episode reward: 62.687918\n",
      "Episode reward: 46.696719\n",
      "Episode reward: 27.947724\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11448    |\n",
      "|    fps              | 2908     |\n",
      "|    time_elapsed     | 220      |\n",
      "|    total_timesteps  | 642104   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0668   |\n",
      "|    n_updates        | 160500   |\n",
      "----------------------------------\n",
      "Episode reward: 72.894498\n",
      "Episode reward: 32.881399\n",
      "Episode reward: 62.346014\n",
      "Episode reward: 110.363583\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11452    |\n",
      "|    fps              | 2908     |\n",
      "|    time_elapsed     | 220      |\n",
      "|    total_timesteps  | 642388   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0416   |\n",
      "|    n_updates        | 160571   |\n",
      "----------------------------------\n",
      "Episode reward: 31.829158\n",
      "Episode reward: 133.392469\n",
      "Episode reward: 69.575414\n",
      "Episode reward: 64.505894\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11456    |\n",
      "|    fps              | 2908     |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total_timesteps  | 642713   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0255   |\n",
      "|    n_updates        | 160653   |\n",
      "----------------------------------\n",
      "Episode reward: 35.862981\n",
      "Episode reward: 37.880364\n",
      "Episode reward: 90.53249\n",
      "Episode reward: 30.784335\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11460    |\n",
      "|    fps              | 2907     |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total_timesteps  | 642909   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.33     |\n",
      "|    n_updates        | 160702   |\n",
      "----------------------------------\n",
      "Episode reward: 74.312349\n",
      "Episode reward: 48.829173\n",
      "Episode reward: 53.754126\n",
      "Episode reward: 36.775561\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11464    |\n",
      "|    fps              | 2907     |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total_timesteps  | 643124   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.672    |\n",
      "|    n_updates        | 160755   |\n",
      "----------------------------------\n",
      "Episode reward: 80.63362\n",
      "Episode reward: 78.616975\n",
      "Episode reward: 51.828647\n",
      "Episode reward: 58.405837\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11468    |\n",
      "|    fps              | 2907     |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total_timesteps  | 643399   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0178   |\n",
      "|    n_updates        | 160824   |\n",
      "----------------------------------\n",
      "Episode reward: 46.780027\n",
      "Episode reward: 72.251986\n",
      "Episode reward: 104.381549\n",
      "Episode reward: 39.523623\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11472    |\n",
      "|    fps              | 2907     |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total_timesteps  | 643667   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.98     |\n",
      "|    n_updates        | 160891   |\n",
      "----------------------------------\n",
      "Episode reward: 77.911\n",
      "Episode reward: 25.843958\n",
      "Episode reward: 57.826147\n",
      "Episode reward: 74.276502\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11476    |\n",
      "|    fps              | 2907     |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total_timesteps  | 643906   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0282   |\n",
      "|    n_updates        | 160951   |\n",
      "----------------------------------\n",
      "Episode reward: 53.692755\n",
      "Episode reward: 67.43114\n",
      "Episode reward: 64.226364\n",
      "Episode reward: 92.710773\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11480    |\n",
      "|    fps              | 2907     |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total_timesteps  | 644189   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0795   |\n",
      "|    n_updates        | 161022   |\n",
      "----------------------------------\n",
      "Episode reward: 43.853981\n",
      "Episode reward: 45.898884\n",
      "Episode reward: 100.83573\n",
      "Episode reward: 65.646601\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11484    |\n",
      "|    fps              | 2907     |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total_timesteps  | 644447   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.123    |\n",
      "|    n_updates        | 161086   |\n",
      "----------------------------------\n",
      "Episode reward: 27.922164\n",
      "Episode reward: 36.935245\n",
      "Episode reward: 32.703451\n",
      "Episode reward: 85.462762\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11488    |\n",
      "|    fps              | 2907     |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total_timesteps  | 644632   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0413   |\n",
      "|    n_updates        | 161132   |\n",
      "----------------------------------\n",
      "Episode reward: 84.200182\n",
      "Episode reward: 81.975963\n",
      "Episode reward: 64.703866\n",
      "Episode reward: 114.471915\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11492    |\n",
      "|    fps              | 2907     |\n",
      "|    time_elapsed     | 221      |\n",
      "|    total_timesteps  | 644984   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0436   |\n",
      "|    n_updates        | 161220   |\n",
      "----------------------------------\n",
      "Episode reward: 46.791302\n",
      "Episode reward: 142.392405\n",
      "Episode reward: 95.015413\n",
      "Episode reward: 70.751451\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11496    |\n",
      "|    fps              | 2906     |\n",
      "|    time_elapsed     | 222      |\n",
      "|    total_timesteps  | 645359   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.13     |\n",
      "|    n_updates        | 161314   |\n",
      "----------------------------------\n",
      "Episode reward: 60.145154\n",
      "Episode reward: 53.414864\n",
      "Episode reward: 62.315054\n",
      "Episode reward: 35.925968\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11500    |\n",
      "|    fps              | 2906     |\n",
      "|    time_elapsed     | 222      |\n",
      "|    total_timesteps  | 645574   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0212   |\n",
      "|    n_updates        | 161368   |\n",
      "----------------------------------\n",
      "Episode reward: 33.794848\n",
      "Episode reward: 74.52019\n",
      "Episode reward: 55.597208\n",
      "Episode reward: 65.76888\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11504    |\n",
      "|    fps              | 2906     |\n",
      "|    time_elapsed     | 222      |\n",
      "|    total_timesteps  | 645807   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0917   |\n",
      "|    n_updates        | 161426   |\n",
      "----------------------------------\n",
      "Episode reward: 51.634833\n",
      "Episode reward: 99.890243\n",
      "Episode reward: 58.620321\n",
      "Episode reward: 35.805982\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11508    |\n",
      "|    fps              | 2906     |\n",
      "|    time_elapsed     | 222      |\n",
      "|    total_timesteps  | 646085   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0241   |\n",
      "|    n_updates        | 161496   |\n",
      "----------------------------------\n",
      "Episode reward: 71.533699\n",
      "Episode reward: 45.793576\n",
      "Episode reward: 69.550622\n",
      "Episode reward: 34.863173\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11512    |\n",
      "|    fps              | 2906     |\n",
      "|    time_elapsed     | 222      |\n",
      "|    total_timesteps  | 646308   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.48     |\n",
      "|    n_updates        | 161551   |\n",
      "----------------------------------\n",
      "Episode reward: 96.613284\n",
      "Episode reward: 50.804504\n",
      "Episode reward: 53.854255\n",
      "Episode reward: 34.854023\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11516    |\n",
      "|    fps              | 2906     |\n",
      "|    time_elapsed     | 222      |\n",
      "|    total_timesteps  | 646550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.86     |\n",
      "|    n_updates        | 161612   |\n",
      "----------------------------------\n",
      "Episode reward: 79.290171\n",
      "Episode reward: 37.732823\n",
      "Episode reward: 93.040174\n",
      "Episode reward: 46.900365\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11520    |\n",
      "|    fps              | 2905     |\n",
      "|    time_elapsed     | 222      |\n",
      "|    total_timesteps  | 646821   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.906    |\n",
      "|    n_updates        | 161680   |\n",
      "----------------------------------\n",
      "Episode reward: 97.667825\n",
      "Episode reward: 95.852516\n",
      "Episode reward: 65.628805\n",
      "Episode reward: 78.135694\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.2     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11524    |\n",
      "|    fps              | 2905     |\n",
      "|    time_elapsed     | 222      |\n",
      "|    total_timesteps  | 647177   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0193   |\n",
      "|    n_updates        | 161769   |\n",
      "----------------------------------\n",
      "Episode reward: 55.749671\n",
      "Episode reward: 44.812479\n",
      "Episode reward: 71.279669\n",
      "Episode reward: 71.589834\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.1     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11528    |\n",
      "|    fps              | 2905     |\n",
      "|    time_elapsed     | 222      |\n",
      "|    total_timesteps  | 647423   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.218    |\n",
      "|    n_updates        | 161830   |\n",
      "----------------------------------\n",
      "Episode reward: 46.227914\n",
      "Episode reward: 47.531895\n",
      "Episode reward: 35.764152\n",
      "Episode reward: 82.549674\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.8     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11532    |\n",
      "|    fps              | 2905     |\n",
      "|    time_elapsed     | 222      |\n",
      "|    total_timesteps  | 647637   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 161884   |\n",
      "----------------------------------\n",
      "Episode reward: 93.107887\n",
      "Episode reward: 48.8871\n",
      "Episode reward: 71.606842\n",
      "Episode reward: 92.829192\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.6     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11536    |\n",
      "|    fps              | 2905     |\n",
      "|    time_elapsed     | 223      |\n",
      "|    total_timesteps  | 647946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.23     |\n",
      "|    n_updates        | 161961   |\n",
      "----------------------------------\n",
      "Episode reward: 88.22307\n",
      "Episode reward: 28.936555\n",
      "Episode reward: 57.817412\n",
      "Episode reward: 68.252697\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.9     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11540    |\n",
      "|    fps              | 2904     |\n",
      "|    time_elapsed     | 223      |\n",
      "|    total_timesteps  | 648192   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0343   |\n",
      "|    n_updates        | 162022   |\n",
      "----------------------------------\n",
      "Episode reward: 42.787278\n",
      "Episode reward: 59.839548\n",
      "Episode reward: 26.949469\n",
      "Episode reward: 49.828383\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11544    |\n",
      "|    fps              | 2904     |\n",
      "|    time_elapsed     | 223      |\n",
      "|    total_timesteps  | 648373   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0258   |\n",
      "|    n_updates        | 162068   |\n",
      "----------------------------------\n",
      "Episode reward: 56.436411\n",
      "Episode reward: 93.384811\n",
      "Episode reward: 48.632589\n",
      "Episode reward: 52.825723\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.2     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11548    |\n",
      "|    fps              | 2904     |\n",
      "|    time_elapsed     | 223      |\n",
      "|    total_timesteps  | 648628   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.15     |\n",
      "|    n_updates        | 162131   |\n",
      "----------------------------------\n",
      "Episode reward: 38.893514\n",
      "Episode reward: 83.694296\n",
      "Episode reward: 39.811159\n",
      "Episode reward: 43.507257\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11552    |\n",
      "|    fps              | 2904     |\n",
      "|    time_elapsed     | 223      |\n",
      "|    total_timesteps  | 648839   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0248   |\n",
      "|    n_updates        | 162184   |\n",
      "----------------------------------\n",
      "Episode reward: 75.222258\n",
      "Episode reward: 48.689143\n",
      "Episode reward: 45.684102\n",
      "Episode reward: 53.129881\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11556    |\n",
      "|    fps              | 2904     |\n",
      "|    time_elapsed     | 223      |\n",
      "|    total_timesteps  | 649064   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.23     |\n",
      "|    n_updates        | 162240   |\n",
      "----------------------------------\n",
      "Episode reward: 46.6537\n",
      "Episode reward: 33.879021\n",
      "Episode reward: 80.335341\n",
      "Episode reward: 64.290514\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11560    |\n",
      "|    fps              | 2903     |\n",
      "|    time_elapsed     | 223      |\n",
      "|    total_timesteps  | 649296   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.59     |\n",
      "|    n_updates        | 162298   |\n",
      "----------------------------------\n",
      "Episode reward: 42.917157\n",
      "Episode reward: 81.552772\n",
      "Episode reward: 72.27661\n",
      "Episode reward: 35.911555\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.1     |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11564    |\n",
      "|    fps              | 2903     |\n",
      "|    time_elapsed     | 223      |\n",
      "|    total_timesteps  | 649530   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.275    |\n",
      "|    n_updates        | 162357   |\n",
      "----------------------------------\n",
      "Episode reward: 87.324412\n",
      "Episode reward: 79.616749\n",
      "Episode reward: 47.658866\n",
      "Episode reward: 80.729854\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11568    |\n",
      "|    fps              | 2903     |\n",
      "|    time_elapsed     | 223      |\n",
      "|    total_timesteps  | 649830   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0261   |\n",
      "|    n_updates        | 162432   |\n",
      "----------------------------------\n",
      "Episode reward: 77.675569\n",
      "Episode reward: 57.777916\n",
      "Episode reward: 61.657231\n",
      "Episode reward: 97.402426\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11572    |\n",
      "|    fps              | 2903     |\n",
      "|    time_elapsed     | 223      |\n",
      "|    total_timesteps  | 650126   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0484   |\n",
      "|    n_updates        | 162506   |\n",
      "----------------------------------\n",
      "Episode reward: 91.298582\n",
      "Episode reward: 42.2826\n",
      "Episode reward: 130.291102\n",
      "Episode reward: 50.761969\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.4     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11576    |\n",
      "|    fps              | 2903     |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total_timesteps  | 650448   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0566   |\n",
      "|    n_updates        | 162586   |\n",
      "----------------------------------\n",
      "Episode reward: 60.771411\n",
      "Episode reward: 72.986269\n",
      "Episode reward: 83.753334\n",
      "Episode reward: 31.580495\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.1     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11580    |\n",
      "|    fps              | 2902     |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total_timesteps  | 650700   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 162649   |\n",
      "----------------------------------\n",
      "Episode reward: 64.729468\n",
      "Episode reward: 43.556214\n",
      "Episode reward: 65.377624\n",
      "Episode reward: 62.501197\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.9     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11584    |\n",
      "|    fps              | 2902     |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total_timesteps  | 650939   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.38     |\n",
      "|    n_updates        | 162709   |\n",
      "----------------------------------\n",
      "Episode reward: 39.868895\n",
      "Episode reward: 36.708383\n",
      "Episode reward: 45.759234\n",
      "Episode reward: 59.62715\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.9     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11588    |\n",
      "|    fps              | 2902     |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total_timesteps  | 651122   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0908   |\n",
      "|    n_updates        | 162755   |\n",
      "----------------------------------\n",
      "Episode reward: 24.798649\n",
      "Episode reward: 101.841403\n",
      "Episode reward: 27.750486\n",
      "Episode reward: 108.334832\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11592    |\n",
      "|    fps              | 2902     |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total_timesteps  | 651411   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0319   |\n",
      "|    n_updates        | 162827   |\n",
      "----------------------------------\n",
      "Episode reward: 66.286619\n",
      "Episode reward: 55.059461\n",
      "Episode reward: 81.790884\n",
      "Episode reward: 29.92567\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11596    |\n",
      "|    fps              | 2902     |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total_timesteps  | 651648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.29     |\n",
      "|    n_updates        | 162886   |\n",
      "----------------------------------\n",
      "Episode reward: 132.930001\n",
      "Episode reward: 49.703717\n",
      "Episode reward: 87.958321\n",
      "Episode reward: 51.599068\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11600    |\n",
      "|    fps              | 2902     |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total_timesteps  | 652006   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0233   |\n",
      "|    n_updates        | 162976   |\n",
      "----------------------------------\n",
      "Episode reward: 84.074747\n",
      "Episode reward: 78.750593\n",
      "Episode reward: 58.725472\n",
      "Episode reward: 45.802045\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.7     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11604    |\n",
      "|    fps              | 2902     |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total_timesteps  | 652277   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.25     |\n",
      "|    n_updates        | 163044   |\n",
      "----------------------------------\n",
      "Episode reward: 125.210683\n",
      "Episode reward: 72.35248\n",
      "Episode reward: 76.534488\n",
      "Episode reward: 104.089492\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.2     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11608    |\n",
      "|    fps              | 2902     |\n",
      "|    time_elapsed     | 224      |\n",
      "|    total_timesteps  | 652704   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0339   |\n",
      "|    n_updates        | 163150   |\n",
      "----------------------------------\n",
      "Episode reward: 85.035169\n",
      "Episode reward: 48.74541\n",
      "Episode reward: 129.984069\n",
      "Episode reward: 125.93482\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68       |\n",
      "|    ep_rew_mean      | 65.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11612    |\n",
      "|    fps              | 2902     |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total_timesteps  | 653105   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0308   |\n",
      "|    n_updates        | 163251   |\n",
      "----------------------------------\n",
      "Episode reward: 44.822513\n",
      "Episode reward: 58.735088\n",
      "Episode reward: 72.074274\n",
      "Episode reward: 32.827066\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.7     |\n",
      "|    ep_rew_mean      | 65.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11616    |\n",
      "|    fps              | 2902     |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total_timesteps  | 653317   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0407   |\n",
      "|    n_updates        | 163304   |\n",
      "----------------------------------\n",
      "Episode reward: 95.589665\n",
      "Episode reward: 48.876816\n",
      "Episode reward: 34.908116\n",
      "Episode reward: 63.769022\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.4     |\n",
      "|    ep_rew_mean      | 65.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11620    |\n",
      "|    fps              | 2902     |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total_timesteps  | 653564   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.033    |\n",
      "|    n_updates        | 163365   |\n",
      "----------------------------------\n",
      "Episode reward: 38.80529\n",
      "Episode reward: 46.825153\n",
      "Episode reward: 46.857472\n",
      "Episode reward: 46.870407\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.7     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11624    |\n",
      "|    fps              | 2902     |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total_timesteps  | 653744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.54     |\n",
      "|    n_updates        | 163410   |\n",
      "----------------------------------\n",
      "Episode reward: 81.024892\n",
      "Episode reward: 55.856774\n",
      "Episode reward: 39.842055\n",
      "Episode reward: 29.827462\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.3     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11628    |\n",
      "|    fps              | 2902     |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total_timesteps  | 653952   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0435   |\n",
      "|    n_updates        | 163462   |\n",
      "----------------------------------\n",
      "Episode reward: 43.815949\n",
      "Episode reward: 87.540258\n",
      "Episode reward: 76.924156\n",
      "Episode reward: 37.898878\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.7     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11632    |\n",
      "|    fps              | 2902     |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total_timesteps  | 654205   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.756    |\n",
      "|    n_updates        | 163526   |\n",
      "----------------------------------\n",
      "Episode reward: 51.670459\n",
      "Episode reward: 108.650927\n",
      "Episode reward: 38.897149\n",
      "Episode reward: 56.758245\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.5     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11636    |\n",
      "|    fps              | 2901     |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total_timesteps  | 654491   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.83     |\n",
      "|    n_updates        | 163597   |\n",
      "----------------------------------\n",
      "Episode reward: 66.35133\n",
      "Episode reward: 69.700138\n",
      "Episode reward: 52.85571\n",
      "Episode reward: 91.829223\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.9     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11640    |\n",
      "|    fps              | 2901     |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total_timesteps  | 654780   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.654    |\n",
      "|    n_updates        | 163669   |\n",
      "----------------------------------\n",
      "Episode reward: 92.952426\n",
      "Episode reward: 45.831677\n",
      "Episode reward: 69.043144\n",
      "Episode reward: 46.866117\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.6     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11644    |\n",
      "|    fps              | 2901     |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total_timesteps  | 655037   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.87     |\n",
      "|    n_updates        | 163734   |\n",
      "----------------------------------\n",
      "Episode reward: 91.310944\n",
      "Episode reward: 74.302479\n",
      "Episode reward: 36.936672\n",
      "Episode reward: 47.705751\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.7     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11648    |\n",
      "|    fps              | 2901     |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total_timesteps  | 655296   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0176   |\n",
      "|    n_updates        | 163798   |\n",
      "----------------------------------\n",
      "Episode reward: 36.613449\n",
      "Episode reward: 31.883274\n",
      "Episode reward: 57.978525\n",
      "Episode reward: 78.479674\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.6     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11652    |\n",
      "|    fps              | 2901     |\n",
      "|    time_elapsed     | 225      |\n",
      "|    total_timesteps  | 655503   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0273   |\n",
      "|    n_updates        | 163850   |\n",
      "----------------------------------\n",
      "Episode reward: 83.394471\n",
      "Episode reward: 62.338338\n",
      "Episode reward: 93.857333\n",
      "Episode reward: 48.750582\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.4     |\n",
      "|    ep_rew_mean      | 65       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11656    |\n",
      "|    fps              | 2901     |\n",
      "|    time_elapsed     | 226      |\n",
      "|    total_timesteps  | 655802   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0251   |\n",
      "|    n_updates        | 163925   |\n",
      "----------------------------------\n",
      "Episode reward: 54.742198\n",
      "Episode reward: 85.119426\n",
      "Episode reward: 63.365786\n",
      "Episode reward: 53.714178\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.7     |\n",
      "|    ep_rew_mean      | 65.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11660    |\n",
      "|    fps              | 2900     |\n",
      "|    time_elapsed     | 226      |\n",
      "|    total_timesteps  | 656061   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0259   |\n",
      "|    n_updates        | 163990   |\n",
      "----------------------------------\n",
      "Episode reward: 101.053125\n",
      "Episode reward: 37.830855\n",
      "Episode reward: 66.499982\n",
      "Episode reward: 38.889699\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.8     |\n",
      "|    ep_rew_mean      | 65.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11664    |\n",
      "|    fps              | 2900     |\n",
      "|    time_elapsed     | 226      |\n",
      "|    total_timesteps  | 656307   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.106    |\n",
      "|    n_updates        | 164051   |\n",
      "----------------------------------\n",
      "Episode reward: 38.935646\n",
      "Episode reward: 31.603185\n",
      "Episode reward: 69.540484\n",
      "Episode reward: 42.889941\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.6     |\n",
      "|    ep_rew_mean      | 64.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11668    |\n",
      "|    fps              | 2900     |\n",
      "|    time_elapsed     | 226      |\n",
      "|    total_timesteps  | 656491   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.35     |\n",
      "|    n_updates        | 164097   |\n",
      "----------------------------------\n",
      "Episode reward: 58.512164\n",
      "Episode reward: 86.209318\n",
      "Episode reward: 54.728045\n",
      "Episode reward: 34.788172\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.1     |\n",
      "|    ep_rew_mean      | 63.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11672    |\n",
      "|    fps              | 2900     |\n",
      "|    time_elapsed     | 226      |\n",
      "|    total_timesteps  | 656739   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0253   |\n",
      "|    n_updates        | 164159   |\n",
      "----------------------------------\n",
      "Episode reward: 54.787071\n",
      "Episode reward: 144.925012\n",
      "Episode reward: 69.635471\n",
      "Episode reward: 31.567263\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.9     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11676    |\n",
      "|    fps              | 2900     |\n",
      "|    time_elapsed     | 226      |\n",
      "|    total_timesteps  | 657042   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0277   |\n",
      "|    n_updates        | 164235   |\n",
      "----------------------------------\n",
      "Episode reward: 31.839758\n",
      "Episode reward: 69.629899\n",
      "Episode reward: 107.246446\n",
      "Episode reward: 69.383821\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.2     |\n",
      "|    ep_rew_mean      | 63.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11680    |\n",
      "|    fps              | 2900     |\n",
      "|    time_elapsed     | 226      |\n",
      "|    total_timesteps  | 657324   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0335   |\n",
      "|    n_updates        | 164305   |\n",
      "----------------------------------\n",
      "Episode reward: 145.289457\n",
      "Episode reward: 28.868973\n",
      "Episode reward: 96.782922\n",
      "Episode reward: 35.828243\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.1     |\n",
      "|    ep_rew_mean      | 64.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11684    |\n",
      "|    fps              | 2899     |\n",
      "|    time_elapsed     | 226      |\n",
      "|    total_timesteps  | 657649   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 164387   |\n",
      "----------------------------------\n",
      "Episode reward: 59.386085\n",
      "Episode reward: 80.906353\n",
      "Episode reward: 48.738361\n",
      "Episode reward: 200.643993\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.3     |\n",
      "|    ep_rew_mean      | 66.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11688    |\n",
      "|    fps              | 2899     |\n",
      "|    time_elapsed     | 226      |\n",
      "|    total_timesteps  | 658049   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.48     |\n",
      "|    n_updates        | 164487   |\n",
      "----------------------------------\n",
      "Episode reward: 63.955422\n",
      "Episode reward: 75.968164\n",
      "Episode reward: 55.508476\n",
      "Episode reward: 47.880501\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.9     |\n",
      "|    ep_rew_mean      | 66.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11692    |\n",
      "|    fps              | 2899     |\n",
      "|    time_elapsed     | 227      |\n",
      "|    total_timesteps  | 658298   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0365   |\n",
      "|    n_updates        | 164549   |\n",
      "----------------------------------\n",
      "Episode reward: 71.036517\n",
      "Episode reward: 114.55833\n",
      "Episode reward: 125.294383\n",
      "Episode reward: 89.651229\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.6     |\n",
      "|    ep_rew_mean      | 68.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11696    |\n",
      "|    fps              | 2899     |\n",
      "|    time_elapsed     | 227      |\n",
      "|    total_timesteps  | 658710   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 164652   |\n",
      "----------------------------------\n",
      "Episode reward: 35.919621\n",
      "Episode reward: 36.737216\n",
      "Episode reward: 31.4043\n",
      "Episode reward: 48.678536\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.6     |\n",
      "|    ep_rew_mean      | 66.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11700    |\n",
      "|    fps              | 2899     |\n",
      "|    time_elapsed     | 227      |\n",
      "|    total_timesteps  | 658864   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.71     |\n",
      "|    n_updates        | 164690   |\n",
      "----------------------------------\n",
      "Episode reward: 63.295538\n",
      "Episode reward: 86.24159\n",
      "Episode reward: 62.777559\n",
      "Episode reward: 111.423566\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.1     |\n",
      "|    ep_rew_mean      | 67       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11704    |\n",
      "|    fps              | 2899     |\n",
      "|    time_elapsed     | 227      |\n",
      "|    total_timesteps  | 659190   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0399   |\n",
      "|    n_updates        | 164772   |\n",
      "----------------------------------\n",
      "Episode reward: 54.274516\n",
      "Episode reward: 76.952592\n",
      "Episode reward: 59.526604\n",
      "Episode reward: 151.456919\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.5     |\n",
      "|    ep_rew_mean      | 66.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11708    |\n",
      "|    fps              | 2899     |\n",
      "|    time_elapsed     | 227      |\n",
      "|    total_timesteps  | 659556   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.018    |\n",
      "|    n_updates        | 164863   |\n",
      "----------------------------------\n",
      "Episode reward: 59.859456\n",
      "Episode reward: 35.595815\n",
      "Episode reward: 60.114776\n",
      "Episode reward: 32.891497\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.4     |\n",
      "|    ep_rew_mean      | 64.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11712    |\n",
      "|    fps              | 2899     |\n",
      "|    time_elapsed     | 227      |\n",
      "|    total_timesteps  | 659747   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0208   |\n",
      "|    n_updates        | 164911   |\n",
      "----------------------------------\n",
      "Episode reward: 69.424898\n",
      "Episode reward: 50.540304\n",
      "Episode reward: 89.019918\n",
      "Episode reward: 74.210506\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.8     |\n",
      "|    ep_rew_mean      | 65.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11716    |\n",
      "|    fps              | 2898     |\n",
      "|    time_elapsed     | 227      |\n",
      "|    total_timesteps  | 660097   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0643   |\n",
      "|    n_updates        | 164999   |\n",
      "----------------------------------\n",
      "Episode reward: 80.823175\n",
      "Episode reward: 63.666439\n",
      "Episode reward: 41.166575\n",
      "Episode reward: 46.832478\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.8     |\n",
      "|    ep_rew_mean      | 65.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11720    |\n",
      "|    fps              | 2898     |\n",
      "|    time_elapsed     | 227      |\n",
      "|    total_timesteps  | 660340   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 165059   |\n",
      "----------------------------------\n",
      "Episode reward: 48.736386\n",
      "Episode reward: 110.810843\n",
      "Episode reward: 51.544484\n",
      "Episode reward: 58.639437\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.7     |\n",
      "|    ep_rew_mean      | 66.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11724    |\n",
      "|    fps              | 2898     |\n",
      "|    time_elapsed     | 227      |\n",
      "|    total_timesteps  | 660613   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0267   |\n",
      "|    n_updates        | 165128   |\n",
      "----------------------------------\n",
      "Episode reward: 70.589853\n",
      "Episode reward: 40.917062\n",
      "Episode reward: 41.576219\n",
      "Episode reward: 64.409516\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.8     |\n",
      "|    ep_rew_mean      | 66.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11728    |\n",
      "|    fps              | 2898     |\n",
      "|    time_elapsed     | 227      |\n",
      "|    total_timesteps  | 660832   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.61     |\n",
      "|    n_updates        | 165182   |\n",
      "----------------------------------\n",
      "Episode reward: 49.847982\n",
      "Episode reward: 40.896558\n",
      "Episode reward: 82.97179\n",
      "Episode reward: 64.181297\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.7     |\n",
      "|    ep_rew_mean      | 66.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11732    |\n",
      "|    fps              | 2898     |\n",
      "|    time_elapsed     | 228      |\n",
      "|    total_timesteps  | 661073   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.19     |\n",
      "|    n_updates        | 165243   |\n",
      "----------------------------------\n",
      "Episode reward: 37.775826\n",
      "Episode reward: 138.002016\n",
      "Episode reward: 74.753351\n",
      "Episode reward: 82.367211\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.2     |\n",
      "|    ep_rew_mean      | 67       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11736    |\n",
      "|    fps              | 2898     |\n",
      "|    time_elapsed     | 228      |\n",
      "|    total_timesteps  | 661410   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.043    |\n",
      "|    n_updates        | 165327   |\n",
      "----------------------------------\n",
      "Episode reward: 109.444578\n",
      "Episode reward: 43.873797\n",
      "Episode reward: 46.907316\n",
      "Episode reward: 39.920906\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.8     |\n",
      "|    ep_rew_mean      | 66.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11740    |\n",
      "|    fps              | 2898     |\n",
      "|    time_elapsed     | 228      |\n",
      "|    total_timesteps  | 661660   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.01     |\n",
      "|    n_updates        | 165389   |\n",
      "----------------------------------\n",
      "Episode reward: 33.929019\n",
      "Episode reward: 85.848974\n",
      "Episode reward: 33.820071\n",
      "Episode reward: 33.727624\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.1     |\n",
      "|    ep_rew_mean      | 65.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11744    |\n",
      "|    fps              | 2898     |\n",
      "|    time_elapsed     | 228      |\n",
      "|    total_timesteps  | 661849   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 165437   |\n",
      "----------------------------------\n",
      "Episode reward: 88.163703\n",
      "Episode reward: 61.398439\n",
      "Episode reward: 103.902492\n",
      "Episode reward: 58.809432\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.8     |\n",
      "|    ep_rew_mean      | 66.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11748    |\n",
      "|    fps              | 2898     |\n",
      "|    time_elapsed     | 228      |\n",
      "|    total_timesteps  | 662180   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.856    |\n",
      "|    n_updates        | 165519   |\n",
      "----------------------------------\n",
      "Episode reward: 52.617751\n",
      "Episode reward: 93.999234\n",
      "Episode reward: 79.480805\n",
      "Episode reward: 44.410928\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.5     |\n",
      "|    ep_rew_mean      | 67.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11752    |\n",
      "|    fps              | 2897     |\n",
      "|    time_elapsed     | 228      |\n",
      "|    total_timesteps  | 662453   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0285   |\n",
      "|    n_updates        | 165588   |\n",
      "----------------------------------\n",
      "Episode reward: 46.718139\n",
      "Episode reward: 116.943602\n",
      "Episode reward: 75.361626\n",
      "Episode reward: 48.881226\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.5     |\n",
      "|    ep_rew_mean      | 67.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11756    |\n",
      "|    fps              | 2897     |\n",
      "|    time_elapsed     | 228      |\n",
      "|    total_timesteps  | 662751   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0659   |\n",
      "|    n_updates        | 165662   |\n",
      "----------------------------------\n",
      "Episode reward: 38.90641\n",
      "Episode reward: 46.813041\n",
      "Episode reward: 51.396917\n",
      "Episode reward: 78.455585\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.1     |\n",
      "|    ep_rew_mean      | 66.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11760    |\n",
      "|    fps              | 2897     |\n",
      "|    time_elapsed     | 228      |\n",
      "|    total_timesteps  | 662968   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0336   |\n",
      "|    n_updates        | 165716   |\n",
      "----------------------------------\n",
      "Episode reward: 152.676537\n",
      "Episode reward: 136.883156\n",
      "Episode reward: 29.747456\n",
      "Episode reward: 60.179677\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.6     |\n",
      "|    ep_rew_mean      | 68.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11764    |\n",
      "|    fps              | 2897     |\n",
      "|    time_elapsed     | 228      |\n",
      "|    total_timesteps  | 663367   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0151   |\n",
      "|    n_updates        | 165816   |\n",
      "----------------------------------\n",
      "Episode reward: 44.763816\n",
      "Episode reward: 27.93733\n",
      "Episode reward: 64.652741\n",
      "Episode reward: 62.764593\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.8     |\n",
      "|    ep_rew_mean      | 68.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11768    |\n",
      "|    fps              | 2897     |\n",
      "|    time_elapsed     | 229      |\n",
      "|    total_timesteps  | 663568   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0634   |\n",
      "|    n_updates        | 165866   |\n",
      "----------------------------------\n",
      "Episode reward: 72.617276\n",
      "Episode reward: 63.492338\n",
      "Episode reward: 38.646713\n",
      "Episode reward: 39.903017\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.5     |\n",
      "|    ep_rew_mean      | 68.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11772    |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 229      |\n",
      "|    total_timesteps  | 663784   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 165920   |\n",
      "----------------------------------\n",
      "Episode reward: 89.994947\n",
      "Episode reward: 51.759237\n",
      "Episode reward: 44.864478\n",
      "Episode reward: 62.608472\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70       |\n",
      "|    ep_rew_mean      | 67.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11776    |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 229      |\n",
      "|    total_timesteps  | 664040   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.348    |\n",
      "|    n_updates        | 165984   |\n",
      "----------------------------------\n",
      "Episode reward: 103.319815\n",
      "Episode reward: 32.895001\n",
      "Episode reward: 48.759773\n",
      "Episode reward: 40.788292\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.5     |\n",
      "|    ep_rew_mean      | 67       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11780    |\n",
      "|    fps              | 2897     |\n",
      "|    time_elapsed     | 229      |\n",
      "|    total_timesteps  | 664271   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.22     |\n",
      "|    n_updates        | 166042   |\n",
      "----------------------------------\n",
      "Episode reward: 35.516653\n",
      "Episode reward: 57.76615\n",
      "Episode reward: 72.61286\n",
      "Episode reward: 62.627128\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.5     |\n",
      "|    ep_rew_mean      | 66.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11784    |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 229      |\n",
      "|    total_timesteps  | 664502   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.22     |\n",
      "|    n_updates        | 166100   |\n",
      "----------------------------------\n",
      "Episode reward: 164.990081\n",
      "Episode reward: 103.499943\n",
      "Episode reward: 88.799463\n",
      "Episode reward: 69.656303\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.1     |\n",
      "|    ep_rew_mean      | 66.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11788    |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 229      |\n",
      "|    total_timesteps  | 664956   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0274   |\n",
      "|    n_updates        | 166213   |\n",
      "----------------------------------\n",
      "Episode reward: 69.388102\n",
      "Episode reward: 58.850757\n",
      "Episode reward: 47.878622\n",
      "Episode reward: 99.047916\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.4     |\n",
      "|    ep_rew_mean      | 67       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11792    |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 229      |\n",
      "|    total_timesteps  | 665236   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0784   |\n",
      "|    n_updates        | 166283   |\n",
      "----------------------------------\n",
      "Episode reward: 92.98923\n",
      "Episode reward: 33.89039\n",
      "Episode reward: 70.469587\n",
      "Episode reward: 132.252238\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.6     |\n",
      "|    ep_rew_mean      | 66.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11796    |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 229      |\n",
      "|    total_timesteps  | 665570   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0989   |\n",
      "|    n_updates        | 166367   |\n",
      "----------------------------------\n",
      "Episode reward: 41.704163\n",
      "Episode reward: 82.598945\n",
      "Episode reward: 86.517654\n",
      "Episode reward: 62.979792\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.9     |\n",
      "|    ep_rew_mean      | 67.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11800    |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 229      |\n",
      "|    total_timesteps  | 665852   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.9      |\n",
      "|    n_updates        | 166437   |\n",
      "----------------------------------\n",
      "Episode reward: 48.757347\n",
      "Episode reward: 30.944609\n",
      "Episode reward: 107.3823\n",
      "Episode reward: 126.16145\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.8     |\n",
      "|    ep_rew_mean      | 67.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11804    |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 229      |\n",
      "|    total_timesteps  | 666173   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.03     |\n",
      "|    n_updates        | 166518   |\n",
      "----------------------------------\n",
      "Episode reward: 88.414727\n",
      "Episode reward: 54.705242\n",
      "Episode reward: 56.507088\n",
      "Episode reward: 104.239919\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.2     |\n",
      "|    ep_rew_mean      | 67       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11808    |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 230      |\n",
      "|    total_timesteps  | 666479   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.324    |\n",
      "|    n_updates        | 166594   |\n",
      "----------------------------------\n",
      "Episode reward: 58.732446\n",
      "Episode reward: 49.871173\n",
      "Episode reward: 58.525756\n",
      "Episode reward: 83.790071\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.9     |\n",
      "|    ep_rew_mean      | 67.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11812    |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 230      |\n",
      "|    total_timesteps  | 666733   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.536    |\n",
      "|    n_updates        | 166658   |\n",
      "----------------------------------\n",
      "Episode reward: 60.772055\n",
      "Episode reward: 146.386939\n",
      "Episode reward: 28.899754\n",
      "Episode reward: 33.681268\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.2     |\n",
      "|    ep_rew_mean      | 67.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11816    |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 230      |\n",
      "|    total_timesteps  | 667016   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0223   |\n",
      "|    n_updates        | 166728   |\n",
      "----------------------------------\n",
      "Episode reward: 44.768057\n",
      "Episode reward: 63.759214\n",
      "Episode reward: 56.763625\n",
      "Episode reward: 68.949989\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.1     |\n",
      "|    ep_rew_mean      | 67.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11820    |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 230      |\n",
      "|    total_timesteps  | 667253   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.366    |\n",
      "|    n_updates        | 166788   |\n",
      "----------------------------------\n",
      "Episode reward: 32.587649\n",
      "Episode reward: 43.864109\n",
      "Episode reward: 91.026598\n",
      "Episode reward: 49.83856\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.7     |\n",
      "|    ep_rew_mean      | 66.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11824    |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 230      |\n",
      "|    total_timesteps  | 667481   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0186   |\n",
      "|    n_updates        | 166845   |\n",
      "----------------------------------\n",
      "Episode reward: 72.190343\n",
      "Episode reward: 125.149572\n",
      "Episode reward: 64.613755\n",
      "Episode reward: 61.262743\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.9     |\n",
      "|    ep_rew_mean      | 68       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11828    |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 230      |\n",
      "|    total_timesteps  | 667818   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0517   |\n",
      "|    n_updates        | 166929   |\n",
      "----------------------------------\n",
      "Episode reward: 99.113924\n",
      "Episode reward: 24.817461\n",
      "Episode reward: 32.937849\n",
      "Episode reward: 40.928943\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.5     |\n",
      "|    ep_rew_mean      | 67.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11832    |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 230      |\n",
      "|    total_timesteps  | 668019   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.43     |\n",
      "|    n_updates        | 166979   |\n",
      "----------------------------------\n",
      "Episode reward: 46.814954\n",
      "Episode reward: 62.700321\n",
      "Episode reward: 57.446901\n",
      "Episode reward: 72.775204\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.5     |\n",
      "|    ep_rew_mean      | 66.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11836    |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 230      |\n",
      "|    total_timesteps  | 668265   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.015    |\n",
      "|    n_updates        | 167041   |\n",
      "----------------------------------\n",
      "Episode reward: 100.450085\n",
      "Episode reward: 72.254575\n",
      "Episode reward: 66.303489\n",
      "Episode reward: 56.638021\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69       |\n",
      "|    ep_rew_mean      | 67.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11840    |\n",
      "|    fps              | 2896     |\n",
      "|    time_elapsed     | 230      |\n",
      "|    total_timesteps  | 668564   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0232   |\n",
      "|    n_updates        | 167115   |\n",
      "----------------------------------\n",
      "Episode reward: 78.870331\n",
      "Episode reward: 56.774786\n",
      "Episode reward: 63.346365\n",
      "Episode reward: 73.327983\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.9     |\n",
      "|    ep_rew_mean      | 68.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11844    |\n",
      "|    fps              | 2895     |\n",
      "|    time_elapsed     | 230      |\n",
      "|    total_timesteps  | 668839   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0361   |\n",
      "|    n_updates        | 167184   |\n",
      "----------------------------------\n",
      "Episode reward: 33.919609\n",
      "Episode reward: 43.887215\n",
      "Episode reward: 59.692199\n",
      "Episode reward: 68.681641\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.7     |\n",
      "|    ep_rew_mean      | 67       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11848    |\n",
      "|    fps              | 2895     |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 669047   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0318   |\n",
      "|    n_updates        | 167236   |\n",
      "----------------------------------\n",
      "Episode reward: 38.712286\n",
      "Episode reward: 52.696621\n",
      "Episode reward: 35.921014\n",
      "Episode reward: 71.643442\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.9     |\n",
      "|    ep_rew_mean      | 66.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11852    |\n",
      "|    fps              | 2895     |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 669247   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 167286   |\n",
      "----------------------------------\n",
      "Episode reward: 62.521297\n",
      "Episode reward: 35.936953\n",
      "Episode reward: 27.739082\n",
      "Episode reward: 49.795953\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.7     |\n",
      "|    ep_rew_mean      | 65.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11856    |\n",
      "|    fps              | 2895     |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 669425   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0286   |\n",
      "|    n_updates        | 167331   |\n",
      "----------------------------------\n",
      "Episode reward: 42.821275\n",
      "Episode reward: 107.059808\n",
      "Episode reward: 79.746148\n",
      "Episode reward: 61.626053\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.6     |\n",
      "|    ep_rew_mean      | 65.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11860    |\n",
      "|    fps              | 2895     |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 669724   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0302   |\n",
      "|    n_updates        | 167405   |\n",
      "----------------------------------\n",
      "Episode reward: 32.940519\n",
      "Episode reward: 39.685397\n",
      "Episode reward: 35.889586\n",
      "Episode reward: 91.919936\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.6     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11864    |\n",
      "|    fps              | 2895     |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 669927   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.337    |\n",
      "|    n_updates        | 167456   |\n",
      "----------------------------------\n",
      "Episode reward: 53.709652\n",
      "Episode reward: 30.58804\n",
      "Episode reward: 72.556159\n",
      "Episode reward: 42.905871\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.6     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11868    |\n",
      "|    fps              | 2895     |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 670129   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.204    |\n",
      "|    n_updates        | 167507   |\n",
      "----------------------------------\n",
      "Episode reward: 77.285832\n",
      "Episode reward: 91.035385\n",
      "Episode reward: 49.786141\n",
      "Episode reward: 50.871236\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.2     |\n",
      "|    ep_rew_mean      | 64.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11872    |\n",
      "|    fps              | 2895     |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 670401   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0927   |\n",
      "|    n_updates        | 167575   |\n",
      "----------------------------------\n",
      "Episode reward: 61.750346\n",
      "Episode reward: 42.814122\n",
      "Episode reward: 34.864575\n",
      "Episode reward: 29.803423\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.3     |\n",
      "|    ep_rew_mean      | 63.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11876    |\n",
      "|    fps              | 2895     |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 670571   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.155    |\n",
      "|    n_updates        | 167617   |\n",
      "----------------------------------\n",
      "Episode reward: 46.802979\n",
      "Episode reward: 40.655917\n",
      "Episode reward: 40.644949\n",
      "Episode reward: 50.80499\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11880    |\n",
      "|    fps              | 2894     |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 670751   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0452   |\n",
      "|    n_updates        | 167662   |\n",
      "----------------------------------\n",
      "Episode reward: 70.474255\n",
      "Episode reward: 71.315284\n",
      "Episode reward: 26.907422\n",
      "Episode reward: 48.711227\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.7     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11884    |\n",
      "|    fps              | 2894     |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 670970   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0329   |\n",
      "|    n_updates        | 167717   |\n",
      "----------------------------------\n",
      "Episode reward: 79.936626\n",
      "Episode reward: 45.487272\n",
      "Episode reward: 39.870576\n",
      "Episode reward: 46.855938\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11888    |\n",
      "|    fps              | 2894     |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 671184   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0298   |\n",
      "|    n_updates        | 167770   |\n",
      "----------------------------------\n",
      "Episode reward: 82.962906\n",
      "Episode reward: 70.037477\n",
      "Episode reward: 81.59454\n",
      "Episode reward: 35.660517\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11892    |\n",
      "|    fps              | 2894     |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 671463   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.042    |\n",
      "|    n_updates        | 167840   |\n",
      "----------------------------------\n",
      "Episode reward: 69.619448\n",
      "Episode reward: 79.077482\n",
      "Episode reward: 68.170602\n",
      "Episode reward: 76.505611\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11896    |\n",
      "|    fps              | 2894     |\n",
      "|    time_elapsed     | 232      |\n",
      "|    total_timesteps  | 671759   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.96     |\n",
      "|    n_updates        | 167914   |\n",
      "----------------------------------\n",
      "Episode reward: 42.856978\n",
      "Episode reward: 63.548874\n",
      "Episode reward: 48.540406\n",
      "Episode reward: 45.767187\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11900    |\n",
      "|    fps              | 2894     |\n",
      "|    time_elapsed     | 232      |\n",
      "|    total_timesteps  | 671961   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.027    |\n",
      "|    n_updates        | 167965   |\n",
      "----------------------------------\n",
      "Episode reward: 33.925834\n",
      "Episode reward: 105.604343\n",
      "Episode reward: 49.900552\n",
      "Episode reward: 45.866412\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11904    |\n",
      "|    fps              | 2894     |\n",
      "|    time_elapsed     | 232      |\n",
      "|    total_timesteps  | 672207   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.75     |\n",
      "|    n_updates        | 168026   |\n",
      "----------------------------------\n",
      "Episode reward: 62.44512\n",
      "Episode reward: 77.817403\n",
      "Episode reward: 32.811042\n",
      "Episode reward: 43.81529\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11908    |\n",
      "|    fps              | 2894     |\n",
      "|    time_elapsed     | 232      |\n",
      "|    total_timesteps  | 672431   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.805    |\n",
      "|    n_updates        | 168082   |\n",
      "----------------------------------\n",
      "Episode reward: 51.861572\n",
      "Episode reward: 34.869519\n",
      "Episode reward: 70.321212\n",
      "Episode reward: 48.616356\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11912    |\n",
      "|    fps              | 2894     |\n",
      "|    time_elapsed     | 232      |\n",
      "|    total_timesteps  | 672638   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 168134   |\n",
      "----------------------------------\n",
      "Episode reward: 55.820562\n",
      "Episode reward: 37.727849\n",
      "Episode reward: 90.832954\n",
      "Episode reward: 73.217231\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11916    |\n",
      "|    fps              | 2894     |\n",
      "|    time_elapsed     | 232      |\n",
      "|    total_timesteps  | 672898   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0359   |\n",
      "|    n_updates        | 168199   |\n",
      "----------------------------------\n",
      "Episode reward: 86.055346\n",
      "Episode reward: 96.803869\n",
      "Episode reward: 63.176585\n",
      "Episode reward: 89.906378\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11920    |\n",
      "|    fps              | 2894     |\n",
      "|    time_elapsed     | 232      |\n",
      "|    total_timesteps  | 673238   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0344   |\n",
      "|    n_updates        | 168284   |\n",
      "----------------------------------\n",
      "Episode reward: 115.084708\n",
      "Episode reward: 82.188359\n",
      "Episode reward: 79.450985\n",
      "Episode reward: 46.770354\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11924    |\n",
      "|    fps              | 2894     |\n",
      "|    time_elapsed     | 232      |\n",
      "|    total_timesteps  | 673570   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.432    |\n",
      "|    n_updates        | 168367   |\n",
      "----------------------------------\n",
      "Episode reward: 103.887724\n",
      "Episode reward: 119.489099\n",
      "Episode reward: 52.752321\n",
      "Episode reward: 58.482719\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11928    |\n",
      "|    fps              | 2894     |\n",
      "|    time_elapsed     | 232      |\n",
      "|    total_timesteps  | 673909   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.76     |\n",
      "|    n_updates        | 168452   |\n",
      "----------------------------------\n",
      "Episode reward: 63.393021\n",
      "Episode reward: 53.632121\n",
      "Episode reward: 69.436008\n",
      "Episode reward: 106.314262\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11932    |\n",
      "|    fps              | 2894     |\n",
      "|    time_elapsed     | 232      |\n",
      "|    total_timesteps  | 674204   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0367   |\n",
      "|    n_updates        | 168525   |\n",
      "----------------------------------\n",
      "Episode reward: 50.521626\n",
      "Episode reward: 56.449872\n",
      "Episode reward: 30.541322\n",
      "Episode reward: 41.875878\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11936    |\n",
      "|    fps              | 2894     |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total_timesteps  | 674385   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.26     |\n",
      "|    n_updates        | 168571   |\n",
      "----------------------------------\n",
      "Episode reward: 46.777471\n",
      "Episode reward: 48.852654\n",
      "Episode reward: 46.90504\n",
      "Episode reward: 31.841102\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11940    |\n",
      "|    fps              | 2894     |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total_timesteps  | 674560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0255   |\n",
      "|    n_updates        | 168614   |\n",
      "----------------------------------\n",
      "Episode reward: 76.376512\n",
      "Episode reward: 73.702222\n",
      "Episode reward: 52.473056\n",
      "Episode reward: 32.888773\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11944    |\n",
      "|    fps              | 2894     |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total_timesteps  | 674801   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0219   |\n",
      "|    n_updates        | 168675   |\n",
      "----------------------------------\n",
      "Episode reward: 43.678625\n",
      "Episode reward: 75.033138\n",
      "Episode reward: 139.518441\n",
      "Episode reward: 60.708625\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11948    |\n",
      "|    fps              | 2893     |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total_timesteps  | 675126   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.341    |\n",
      "|    n_updates        | 168756   |\n",
      "----------------------------------\n",
      "Episode reward: 58.826591\n",
      "Episode reward: 70.608391\n",
      "Episode reward: 79.761539\n",
      "Episode reward: 87.329462\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11952    |\n",
      "|    fps              | 2893     |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total_timesteps  | 675425   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0313   |\n",
      "|    n_updates        | 168831   |\n",
      "----------------------------------\n",
      "Episode reward: 36.542751\n",
      "Episode reward: 60.478246\n",
      "Episode reward: 73.362351\n",
      "Episode reward: 69.438763\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11956    |\n",
      "|    fps              | 2893     |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total_timesteps  | 675667   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0277   |\n",
      "|    n_updates        | 168891   |\n",
      "----------------------------------\n",
      "Episode reward: 79.296411\n",
      "Episode reward: 29.911956\n",
      "Episode reward: 102.193592\n",
      "Episode reward: 122.575165\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11960    |\n",
      "|    fps              | 2893     |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total_timesteps  | 676017   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.126    |\n",
      "|    n_updates        | 168979   |\n",
      "----------------------------------\n",
      "Episode reward: 48.739619\n",
      "Episode reward: 42.530868\n",
      "Episode reward: 27.94804\n",
      "Episode reward: 124.410876\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11964    |\n",
      "|    fps              | 2893     |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total_timesteps  | 676266   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.17     |\n",
      "|    n_updates        | 169041   |\n",
      "----------------------------------\n",
      "Episode reward: 36.847062\n",
      "Episode reward: 67.215152\n",
      "Episode reward: 69.157048\n",
      "Episode reward: 33.853537\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11968    |\n",
      "|    fps              | 2892     |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total_timesteps  | 676475   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0257   |\n",
      "|    n_updates        | 169093   |\n",
      "----------------------------------\n",
      "Episode reward: 39.721286\n",
      "Episode reward: 89.855261\n",
      "Episode reward: 78.577069\n",
      "Episode reward: 101.951115\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11972    |\n",
      "|    fps              | 2892     |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total_timesteps  | 676792   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0293   |\n",
      "|    n_updates        | 169172   |\n",
      "----------------------------------\n",
      "Episode reward: 61.426695\n",
      "Episode reward: 40.518673\n",
      "Episode reward: 54.755512\n",
      "Episode reward: 92.732437\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11976    |\n",
      "|    fps              | 2892     |\n",
      "|    time_elapsed     | 234      |\n",
      "|    total_timesteps  | 677049   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0491   |\n",
      "|    n_updates        | 169237   |\n",
      "----------------------------------\n",
      "Episode reward: 64.990652\n",
      "Episode reward: 30.920597\n",
      "Episode reward: 45.825821\n",
      "Episode reward: 92.627244\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.3     |\n",
      "|    ep_rew_mean      | 64.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11980    |\n",
      "|    fps              | 2892     |\n",
      "|    time_elapsed     | 234      |\n",
      "|    total_timesteps  | 677286   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.277    |\n",
      "|    n_updates        | 169296   |\n",
      "----------------------------------\n",
      "Episode reward: 125.367549\n",
      "Episode reward: 47.747009\n",
      "Episode reward: 49.875535\n",
      "Episode reward: 115.988601\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.8     |\n",
      "|    ep_rew_mean      | 65.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11984    |\n",
      "|    fps              | 2892     |\n",
      "|    time_elapsed     | 234      |\n",
      "|    total_timesteps  | 677649   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.863    |\n",
      "|    n_updates        | 169387   |\n",
      "----------------------------------\n",
      "Episode reward: 49.806729\n",
      "Episode reward: 50.65474\n",
      "Episode reward: 48.850955\n",
      "Episode reward: 33.835172\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.5     |\n",
      "|    ep_rew_mean      | 65.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11988    |\n",
      "|    fps              | 2892     |\n",
      "|    time_elapsed     | 234      |\n",
      "|    total_timesteps  | 677833   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0313   |\n",
      "|    n_updates        | 169433   |\n",
      "----------------------------------\n",
      "Episode reward: 30.932446\n",
      "Episode reward: 53.688405\n",
      "Episode reward: 70.588575\n",
      "Episode reward: 35.655562\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.6     |\n",
      "|    ep_rew_mean      | 64.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11992    |\n",
      "|    fps              | 2892     |\n",
      "|    time_elapsed     | 234      |\n",
      "|    total_timesteps  | 678025   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0353   |\n",
      "|    n_updates        | 169481   |\n",
      "----------------------------------\n",
      "Episode reward: 39.902691\n",
      "Episode reward: 97.210131\n",
      "Episode reward: 114.133967\n",
      "Episode reward: 93.201762\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.8     |\n",
      "|    ep_rew_mean      | 64.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 11996    |\n",
      "|    fps              | 2892     |\n",
      "|    time_elapsed     | 234      |\n",
      "|    total_timesteps  | 678434   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0255   |\n",
      "|    n_updates        | 169583   |\n",
      "----------------------------------\n",
      "Episode reward: 87.998206\n",
      "Episode reward: 51.831883\n",
      "Episode reward: 61.432318\n",
      "Episode reward: 42.877458\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.2     |\n",
      "|    ep_rew_mean      | 65.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12000    |\n",
      "|    fps              | 2892     |\n",
      "|    time_elapsed     | 234      |\n",
      "|    total_timesteps  | 678683   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0714   |\n",
      "|    n_updates        | 169645   |\n",
      "----------------------------------\n",
      "Episode reward: 104.020957\n",
      "Episode reward: 65.687516\n",
      "Episode reward: 45.71248\n",
      "Episode reward: 30.615202\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.3     |\n",
      "|    ep_rew_mean      | 65.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12004    |\n",
      "|    fps              | 2892     |\n",
      "|    time_elapsed     | 234      |\n",
      "|    total_timesteps  | 678935   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0752   |\n",
      "|    n_updates        | 169708   |\n",
      "----------------------------------\n",
      "Episode reward: 43.445465\n",
      "Episode reward: 66.633908\n",
      "Episode reward: 98.930171\n",
      "Episode reward: 129.444019\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.5     |\n",
      "|    ep_rew_mean      | 66.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12008    |\n",
      "|    fps              | 2892     |\n",
      "|    time_elapsed     | 234      |\n",
      "|    total_timesteps  | 679277   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0306   |\n",
      "|    n_updates        | 169794   |\n",
      "----------------------------------\n",
      "Episode reward: 69.547704\n",
      "Episode reward: 59.654163\n",
      "Episode reward: 92.008213\n",
      "Episode reward: 145.927969\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.3     |\n",
      "|    ep_rew_mean      | 68.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12012    |\n",
      "|    fps              | 2891     |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total_timesteps  | 679667   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.01     |\n",
      "|    n_updates        | 169891   |\n",
      "----------------------------------\n",
      "Episode reward: 116.23281\n",
      "Episode reward: 51.70001\n",
      "Episode reward: 60.689893\n",
      "Episode reward: 96.930842\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71       |\n",
      "|    ep_rew_mean      | 68.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12016    |\n",
      "|    fps              | 2891     |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total_timesteps  | 680001   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0971   |\n",
      "|    n_updates        | 169975   |\n",
      "----------------------------------\n",
      "Episode reward: 41.625413\n",
      "Episode reward: 56.496231\n",
      "Episode reward: 56.686054\n",
      "Episode reward: 30.910105\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.5     |\n",
      "|    ep_rew_mean      | 67.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12020    |\n",
      "|    fps              | 2891     |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total_timesteps  | 680188   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0527   |\n",
      "|    n_updates        | 170021   |\n",
      "----------------------------------\n",
      "Episode reward: 33.692808\n",
      "Episode reward: 48.868146\n",
      "Episode reward: 100.842191\n",
      "Episode reward: 61.008649\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.7     |\n",
      "|    ep_rew_mean      | 66.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12024    |\n",
      "|    fps              | 2891     |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total_timesteps  | 680435   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0428   |\n",
      "|    n_updates        | 170083   |\n",
      "----------------------------------\n",
      "Episode reward: 91.257133\n",
      "Episode reward: 56.42904\n",
      "Episode reward: 148.940971\n",
      "Episode reward: 66.609426\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69       |\n",
      "|    ep_rew_mean      | 66.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12028    |\n",
      "|    fps              | 2890     |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total_timesteps  | 680804   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0704   |\n",
      "|    n_updates        | 170175   |\n",
      "----------------------------------\n",
      "Episode reward: 83.354391\n",
      "Episode reward: 136.065694\n",
      "Episode reward: 78.329701\n",
      "Episode reward: 47.783415\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.8     |\n",
      "|    ep_rew_mean      | 67.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12032    |\n",
      "|    fps              | 2890     |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total_timesteps  | 681182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.02     |\n",
      "|    n_updates        | 170270   |\n",
      "----------------------------------\n",
      "Episode reward: 44.55364\n",
      "Episode reward: 68.10468\n",
      "Episode reward: 46.80217\n",
      "Episode reward: 52.720707\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.1     |\n",
      "|    ep_rew_mean      | 67.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12036    |\n",
      "|    fps              | 2890     |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total_timesteps  | 681396   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0328   |\n",
      "|    n_updates        | 170323   |\n",
      "----------------------------------\n",
      "Episode reward: 34.834818\n",
      "Episode reward: 86.730832\n",
      "Episode reward: 60.505271\n",
      "Episode reward: 46.496391\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.7     |\n",
      "|    ep_rew_mean      | 68.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12040    |\n",
      "|    fps              | 2890     |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total_timesteps  | 681627   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0669   |\n",
      "|    n_updates        | 170381   |\n",
      "----------------------------------\n",
      "Episode reward: 66.206723\n",
      "Episode reward: 37.750812\n",
      "Episode reward: 74.668446\n",
      "Episode reward: 41.350229\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.5     |\n",
      "|    ep_rew_mean      | 68.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12044    |\n",
      "|    fps              | 2890     |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total_timesteps  | 681851   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.904    |\n",
      "|    n_updates        | 170437   |\n",
      "----------------------------------\n",
      "Episode reward: 64.691416\n",
      "Episode reward: 91.423139\n",
      "Episode reward: 85.351374\n",
      "Episode reward: 54.822067\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.3     |\n",
      "|    ep_rew_mean      | 67.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12048    |\n",
      "|    fps              | 2891     |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total_timesteps  | 682152   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.7      |\n",
      "|    n_updates        | 170512   |\n",
      "----------------------------------\n",
      "Episode reward: 28.867005\n",
      "Episode reward: 102.061662\n",
      "Episode reward: 40.893269\n",
      "Episode reward: 42.822148\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.5     |\n",
      "|    ep_rew_mean      | 67.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12052    |\n",
      "|    fps              | 2891     |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total_timesteps  | 682370   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.01     |\n",
      "|    n_updates        | 170567   |\n",
      "----------------------------------\n",
      "Episode reward: 29.878716\n",
      "Episode reward: 74.896425\n",
      "Episode reward: 128.27583\n",
      "Episode reward: 50.828577\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.9     |\n",
      "|    ep_rew_mean      | 67.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12056    |\n",
      "|    fps              | 2891     |\n",
      "|    time_elapsed     | 236      |\n",
      "|    total_timesteps  | 682661   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.19     |\n",
      "|    n_updates        | 170640   |\n",
      "----------------------------------\n",
      "Episode reward: 127.686668\n",
      "Episode reward: 39.82007\n",
      "Episode reward: 77.322084\n",
      "Episode reward: 63.721207\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.5     |\n",
      "|    ep_rew_mean      | 67.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12060    |\n",
      "|    fps              | 2892     |\n",
      "|    time_elapsed     | 236      |\n",
      "|    total_timesteps  | 682972   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.7      |\n",
      "|    n_updates        | 170717   |\n",
      "----------------------------------\n",
      "Episode reward: 34.931715\n",
      "Episode reward: 44.818391\n",
      "Episode reward: 33.88359\n",
      "Episode reward: 70.632611\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.9     |\n",
      "|    ep_rew_mean      | 66.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12064    |\n",
      "|    fps              | 2891     |\n",
      "|    time_elapsed     | 236      |\n",
      "|    total_timesteps  | 683158   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.83     |\n",
      "|    n_updates        | 170764   |\n",
      "----------------------------------\n",
      "Episode reward: 122.948785\n",
      "Episode reward: 34.928907\n",
      "Episode reward: 59.574844\n",
      "Episode reward: 71.04941\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.9     |\n",
      "|    ep_rew_mean      | 67.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12068    |\n",
      "|    fps              | 2891     |\n",
      "|    time_elapsed     | 236      |\n",
      "|    total_timesteps  | 683469   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0298   |\n",
      "|    n_updates        | 170842   |\n",
      "----------------------------------\n",
      "Episode reward: 28.945471\n",
      "Episode reward: 80.022186\n",
      "Episode reward: 31.811671\n",
      "Episode reward: 68.180559\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.9     |\n",
      "|    ep_rew_mean      | 66.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12072    |\n",
      "|    fps              | 2891     |\n",
      "|    time_elapsed     | 236      |\n",
      "|    total_timesteps  | 683681   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.078    |\n",
      "|    n_updates        | 170895   |\n",
      "----------------------------------\n",
      "Episode reward: 47.845088\n",
      "Episode reward: 38.353576\n",
      "Episode reward: 49.632339\n",
      "Episode reward: 64.707946\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.4     |\n",
      "|    ep_rew_mean      | 66       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12076    |\n",
      "|    fps              | 2891     |\n",
      "|    time_elapsed     | 236      |\n",
      "|    total_timesteps  | 683885   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.208    |\n",
      "|    n_updates        | 170946   |\n",
      "----------------------------------\n",
      "Episode reward: 40.817235\n",
      "Episode reward: 35.783138\n",
      "Episode reward: 74.961226\n",
      "Episode reward: 63.920034\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.2     |\n",
      "|    ep_rew_mean      | 65.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12080    |\n",
      "|    fps              | 2890     |\n",
      "|    time_elapsed     | 236      |\n",
      "|    total_timesteps  | 684103   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.34     |\n",
      "|    n_updates        | 171000   |\n",
      "----------------------------------\n",
      "Episode reward: 50.589398\n",
      "Episode reward: 76.561813\n",
      "Episode reward: 41.913431\n",
      "Episode reward: 33.806961\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.6     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12084    |\n",
      "|    fps              | 2889     |\n",
      "|    time_elapsed     | 236      |\n",
      "|    total_timesteps  | 684307   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.37     |\n",
      "|    n_updates        | 171051   |\n",
      "----------------------------------\n",
      "Episode reward: 70.493445\n",
      "Episode reward: 62.378789\n",
      "Episode reward: 60.458144\n",
      "Episode reward: 73.560233\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.5     |\n",
      "|    ep_rew_mean      | 65.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12088    |\n",
      "|    fps              | 2889     |\n",
      "|    time_elapsed     | 236      |\n",
      "|    total_timesteps  | 684581   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.234    |\n",
      "|    n_updates        | 171120   |\n",
      "----------------------------------\n",
      "Episode reward: 130.410445\n",
      "Episode reward: 71.721936\n",
      "Episode reward: 103.684832\n",
      "Episode reward: 52.808161\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.2     |\n",
      "|    ep_rew_mean      | 66.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12092    |\n",
      "|    fps              | 2889     |\n",
      "|    time_elapsed     | 237      |\n",
      "|    total_timesteps  | 684946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 171211   |\n",
      "----------------------------------\n",
      "Episode reward: 51.558841\n",
      "Episode reward: 68.147849\n",
      "Episode reward: 32.933293\n",
      "Episode reward: 51.80125\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.2     |\n",
      "|    ep_rew_mean      | 65.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12096    |\n",
      "|    fps              | 2889     |\n",
      "|    time_elapsed     | 237      |\n",
      "|    total_timesteps  | 685152   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.739    |\n",
      "|    n_updates        | 171262   |\n",
      "----------------------------------\n",
      "Episode reward: 82.323536\n",
      "Episode reward: 59.766943\n",
      "Episode reward: 62.611684\n",
      "Episode reward: 214.68244\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69       |\n",
      "|    ep_rew_mean      | 67.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12100    |\n",
      "|    fps              | 2888     |\n",
      "|    time_elapsed     | 237      |\n",
      "|    total_timesteps  | 685579   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0784   |\n",
      "|    n_updates        | 171369   |\n",
      "----------------------------------\n",
      "Episode reward: 38.923047\n",
      "Episode reward: 92.560696\n",
      "Episode reward: 31.786027\n",
      "Episode reward: 68.32105\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.8     |\n",
      "|    ep_rew_mean      | 67.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12104    |\n",
      "|    fps              | 2888     |\n",
      "|    time_elapsed     | 237      |\n",
      "|    total_timesteps  | 685813   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.483    |\n",
      "|    n_updates        | 171428   |\n",
      "----------------------------------\n",
      "Episode reward: 62.603834\n",
      "Episode reward: 127.155469\n",
      "Episode reward: 107.172475\n",
      "Episode reward: 99.576669\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.4     |\n",
      "|    ep_rew_mean      | 67.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12108    |\n",
      "|    fps              | 2888     |\n",
      "|    time_elapsed     | 237      |\n",
      "|    total_timesteps  | 686214   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.337    |\n",
      "|    n_updates        | 171528   |\n",
      "----------------------------------\n",
      "Episode reward: 115.820619\n",
      "Episode reward: 36.590078\n",
      "Episode reward: 77.963762\n",
      "Episode reward: 73.293325\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.6     |\n",
      "|    ep_rew_mean      | 67.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12112    |\n",
      "|    fps              | 2888     |\n",
      "|    time_elapsed     | 237      |\n",
      "|    total_timesteps  | 686528   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0332   |\n",
      "|    n_updates        | 171606   |\n",
      "----------------------------------\n",
      "Episode reward: 74.481704\n",
      "Episode reward: 57.803633\n",
      "Episode reward: 99.198287\n",
      "Episode reward: 41.809473\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68       |\n",
      "|    ep_rew_mean      | 66.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12116    |\n",
      "|    fps              | 2888     |\n",
      "|    time_elapsed     | 237      |\n",
      "|    total_timesteps  | 686805   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.37     |\n",
      "|    n_updates        | 171676   |\n",
      "----------------------------------\n",
      "Episode reward: 61.887828\n",
      "Episode reward: 51.805413\n",
      "Episode reward: 42.550502\n",
      "Episode reward: 39.847665\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.2     |\n",
      "|    ep_rew_mean      | 66.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12120    |\n",
      "|    fps              | 2888     |\n",
      "|    time_elapsed     | 237      |\n",
      "|    total_timesteps  | 687003   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.95     |\n",
      "|    n_updates        | 171725   |\n",
      "----------------------------------\n",
      "Episode reward: 127.051171\n",
      "Episode reward: 73.763532\n",
      "Episode reward: 33.523015\n",
      "Episode reward: 29.824729\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.4     |\n",
      "|    ep_rew_mean      | 66.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12124    |\n",
      "|    fps              | 2888     |\n",
      "|    time_elapsed     | 237      |\n",
      "|    total_timesteps  | 687271   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.13     |\n",
      "|    n_updates        | 171792   |\n",
      "----------------------------------\n",
      "Episode reward: 82.080437\n",
      "Episode reward: 94.363286\n",
      "Episode reward: 59.725089\n",
      "Episode reward: 65.040669\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.8     |\n",
      "|    ep_rew_mean      | 66.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12128    |\n",
      "|    fps              | 2888     |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total_timesteps  | 687580   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.174    |\n",
      "|    n_updates        | 171869   |\n",
      "----------------------------------\n",
      "Episode reward: 36.930718\n",
      "Episode reward: 33.672994\n",
      "Episode reward: 34.796702\n",
      "Episode reward: 56.296369\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.6     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12132    |\n",
      "|    fps              | 2888     |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total_timesteps  | 687743   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0318   |\n",
      "|    n_updates        | 171910   |\n",
      "----------------------------------\n",
      "Episode reward: 77.105102\n",
      "Episode reward: 83.252058\n",
      "Episode reward: 73.55502\n",
      "Episode reward: 31.648511\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.2     |\n",
      "|    ep_rew_mean      | 65       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12136    |\n",
      "|    fps              | 2887     |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total_timesteps  | 688017   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.247    |\n",
      "|    n_updates        | 171979   |\n",
      "----------------------------------\n",
      "Episode reward: 40.912764\n",
      "Episode reward: 98.4835\n",
      "Episode reward: 26.947604\n",
      "Episode reward: 37.912979\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66       |\n",
      "|    ep_rew_mean      | 64.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12140    |\n",
      "|    fps              | 2887     |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total_timesteps  | 688224   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0331   |\n",
      "|    n_updates        | 172030   |\n",
      "----------------------------------\n",
      "Episode reward: 113.823482\n",
      "Episode reward: 29.896846\n",
      "Episode reward: 43.780436\n",
      "Episode reward: 70.721322\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.5     |\n",
      "|    ep_rew_mean      | 65.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12144    |\n",
      "|    fps              | 2887     |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total_timesteps  | 688496   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0472   |\n",
      "|    n_updates        | 172098   |\n",
      "----------------------------------\n",
      "Episode reward: 42.857131\n",
      "Episode reward: 41.609715\n",
      "Episode reward: 43.827937\n",
      "Episode reward: 140.475685\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.2     |\n",
      "|    ep_rew_mean      | 64.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12148    |\n",
      "|    fps              | 2887     |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total_timesteps  | 688772   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0469   |\n",
      "|    n_updates        | 172167   |\n",
      "----------------------------------\n",
      "Episode reward: 39.683143\n",
      "Episode reward: 61.649568\n",
      "Episode reward: 56.790224\n",
      "Episode reward: 88.770577\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.5     |\n",
      "|    ep_rew_mean      | 65.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12152    |\n",
      "|    fps              | 2887     |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total_timesteps  | 689025   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.41     |\n",
      "|    n_updates        | 172231   |\n",
      "----------------------------------\n",
      "Episode reward: 70.939838\n",
      "Episode reward: 26.934191\n",
      "Episode reward: 24.860598\n",
      "Episode reward: 38.940888\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.3     |\n",
      "|    ep_rew_mean      | 63.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12156    |\n",
      "|    fps              | 2887     |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total_timesteps  | 689188   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0342   |\n",
      "|    n_updates        | 172271   |\n",
      "----------------------------------\n",
      "Episode reward: 66.89086\n",
      "Episode reward: 35.683544\n",
      "Episode reward: 58.377351\n",
      "Episode reward: 66.52637\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12160    |\n",
      "|    fps              | 2887     |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total_timesteps  | 689418   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0294   |\n",
      "|    n_updates        | 172329   |\n",
      "----------------------------------\n",
      "Episode reward: 27.873248\n",
      "Episode reward: 77.739539\n",
      "Episode reward: 55.732305\n",
      "Episode reward: 26.842714\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12164    |\n",
      "|    fps              | 2887     |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total_timesteps  | 689608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.558    |\n",
      "|    n_updates        | 172376   |\n",
      "----------------------------------\n",
      "Episode reward: 54.833652\n",
      "Episode reward: 26.943788\n",
      "Episode reward: 33.925949\n",
      "Episode reward: 32.747994\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12168    |\n",
      "|    fps              | 2887     |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total_timesteps  | 689757   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0621   |\n",
      "|    n_updates        | 172414   |\n",
      "----------------------------------\n",
      "Episode reward: 83.397595\n",
      "Episode reward: 49.77922\n",
      "Episode reward: 93.762517\n",
      "Episode reward: 56.64668\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12172    |\n",
      "|    fps              | 2887     |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total_timesteps  | 690046   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0651   |\n",
      "|    n_updates        | 172486   |\n",
      "----------------------------------\n",
      "Episode reward: 75.341853\n",
      "Episode reward: 46.646019\n",
      "Episode reward: 34.819224\n",
      "Episode reward: 49.721609\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12176    |\n",
      "|    fps              | 2887     |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total_timesteps  | 690254   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0677   |\n",
      "|    n_updates        | 172538   |\n",
      "----------------------------------\n",
      "Episode reward: 35.722166\n",
      "Episode reward: 79.672899\n",
      "Episode reward: 47.836877\n",
      "Episode reward: 135.013137\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12180    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total_timesteps  | 690556   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0295   |\n",
      "|    n_updates        | 172613   |\n",
      "----------------------------------\n",
      "Episode reward: 77.70215\n",
      "Episode reward: 105.511992\n",
      "Episode reward: 40.907186\n",
      "Episode reward: 42.875123\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.2     |\n",
      "|    ep_rew_mean      | 64       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12184    |\n",
      "|    fps              | 2887     |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total_timesteps  | 690831   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0396   |\n",
      "|    n_updates        | 172682   |\n",
      "----------------------------------\n",
      "Episode reward: 90.053496\n",
      "Episode reward: 25.806075\n",
      "Episode reward: 56.330197\n",
      "Episode reward: 131.771486\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.8     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12188    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total_timesteps  | 691162   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.405    |\n",
      "|    n_updates        | 172765   |\n",
      "----------------------------------\n",
      "Episode reward: 30.872518\n",
      "Episode reward: 29.728964\n",
      "Episode reward: 100.103542\n",
      "Episode reward: 56.606636\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12192    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total_timesteps  | 691383   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.115    |\n",
      "|    n_updates        | 172820   |\n",
      "----------------------------------\n",
      "Episode reward: 43.566042\n",
      "Episode reward: 55.752022\n",
      "Episode reward: 53.64693\n",
      "Episode reward: 48.357379\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12196    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total_timesteps  | 691586   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0418   |\n",
      "|    n_updates        | 172871   |\n",
      "----------------------------------\n",
      "Episode reward: 36.942977\n",
      "Episode reward: 42.916989\n",
      "Episode reward: 54.765922\n",
      "Episode reward: 82.525073\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12200    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total_timesteps  | 691805   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0293   |\n",
      "|    n_updates        | 172926   |\n",
      "----------------------------------\n",
      "Episode reward: 43.885977\n",
      "Episode reward: 54.698166\n",
      "Episode reward: 67.541493\n",
      "Episode reward: 36.690273\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12204    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total_timesteps  | 692009   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.594    |\n",
      "|    n_updates        | 172977   |\n",
      "----------------------------------\n",
      "Episode reward: 68.201061\n",
      "Episode reward: 58.275189\n",
      "Episode reward: 134.270755\n",
      "Episode reward: 44.64799\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12208    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total_timesteps  | 692340   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.13     |\n",
      "|    n_updates        | 173059   |\n",
      "----------------------------------\n",
      "Episode reward: 34.776301\n",
      "Episode reward: 73.610092\n",
      "Episode reward: 29.866221\n",
      "Episode reward: 60.106209\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12212    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total_timesteps  | 692542   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.525    |\n",
      "|    n_updates        | 173110   |\n",
      "----------------------------------\n",
      "Episode reward: 96.158034\n",
      "Episode reward: 50.40102\n",
      "Episode reward: 54.760996\n",
      "Episode reward: 34.929128\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12216    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 239      |\n",
      "|    total_timesteps  | 692787   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.23     |\n",
      "|    n_updates        | 173171   |\n",
      "----------------------------------\n",
      "Episode reward: 35.756316\n",
      "Episode reward: 99.925587\n",
      "Episode reward: 34.475157\n",
      "Episode reward: 72.554724\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12220    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total_timesteps  | 693034   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.315    |\n",
      "|    n_updates        | 173233   |\n",
      "----------------------------------\n",
      "Episode reward: 65.681152\n",
      "Episode reward: 221.714954\n",
      "Episode reward: 126.122255\n",
      "Episode reward: 33.950806\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12224    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total_timesteps  | 693485   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.568    |\n",
      "|    n_updates        | 173346   |\n",
      "----------------------------------\n",
      "Episode reward: 96.217797\n",
      "Episode reward: 106.955897\n",
      "Episode reward: 47.826555\n",
      "Episode reward: 36.854884\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12228    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total_timesteps  | 693787   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.48     |\n",
      "|    n_updates        | 173421   |\n",
      "----------------------------------\n",
      "Episode reward: 36.937092\n",
      "Episode reward: 77.173854\n",
      "Episode reward: 32.874006\n",
      "Episode reward: 96.039501\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12232    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total_timesteps  | 694038   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0256   |\n",
      "|    n_updates        | 173484   |\n",
      "----------------------------------\n",
      "Episode reward: 39.891102\n",
      "Episode reward: 48.725052\n",
      "Episode reward: 32.872795\n",
      "Episode reward: 35.845374\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12236    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total_timesteps  | 694196   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0199   |\n",
      "|    n_updates        | 173523   |\n",
      "----------------------------------\n",
      "Episode reward: 46.886413\n",
      "Episode reward: 42.841427\n",
      "Episode reward: 37.914113\n",
      "Episode reward: 65.31414\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12240    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total_timesteps  | 694390   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0185   |\n",
      "|    n_updates        | 173572   |\n",
      "----------------------------------\n",
      "Episode reward: 44.447075\n",
      "Episode reward: 104.04704\n",
      "Episode reward: 56.795066\n",
      "Episode reward: 59.057217\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12244    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total_timesteps  | 694664   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.93     |\n",
      "|    n_updates        | 173640   |\n",
      "----------------------------------\n",
      "Episode reward: 36.734416\n",
      "Episode reward: 144.037211\n",
      "Episode reward: 35.889529\n",
      "Episode reward: 61.478746\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12248    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total_timesteps  | 695019   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.72     |\n",
      "|    n_updates        | 173729   |\n",
      "----------------------------------\n",
      "Episode reward: 69.653351\n",
      "Episode reward: 42.868295\n",
      "Episode reward: 33.883662\n",
      "Episode reward: 100.066869\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12252    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 240      |\n",
      "|    total_timesteps  | 695271   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0461   |\n",
      "|    n_updates        | 173792   |\n",
      "----------------------------------\n",
      "Episode reward: 40.923427\n",
      "Episode reward: 77.131737\n",
      "Episode reward: 38.925583\n",
      "Episode reward: 120.295154\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12256    |\n",
      "|    fps              | 2886     |\n",
      "|    time_elapsed     | 241      |\n",
      "|    total_timesteps  | 695550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0309   |\n",
      "|    n_updates        | 173862   |\n",
      "----------------------------------\n",
      "Episode reward: 98.194811\n",
      "Episode reward: 130.448492\n",
      "Episode reward: 110.685076\n",
      "Episode reward: 43.716042\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.3     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12260    |\n",
      "|    fps              | 2885     |\n",
      "|    time_elapsed     | 241      |\n",
      "|    total_timesteps  | 695953   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0211   |\n",
      "|    n_updates        | 173963   |\n",
      "----------------------------------\n",
      "Episode reward: 36.894571\n",
      "Episode reward: 84.929635\n",
      "Episode reward: 131.394501\n",
      "Episode reward: 57.262838\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.7     |\n",
      "|    ep_rew_mean      | 64.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12264    |\n",
      "|    fps              | 2885     |\n",
      "|    time_elapsed     | 241      |\n",
      "|    total_timesteps  | 696275   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0235   |\n",
      "|    n_updates        | 174043   |\n",
      "----------------------------------\n",
      "Episode reward: 55.38873\n",
      "Episode reward: 39.650984\n",
      "Episode reward: 40.859101\n",
      "Episode reward: 71.437791\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.3     |\n",
      "|    ep_rew_mean      | 64.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12268    |\n",
      "|    fps              | 2885     |\n",
      "|    time_elapsed     | 241      |\n",
      "|    total_timesteps  | 696484   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0501   |\n",
      "|    n_updates        | 174095   |\n",
      "----------------------------------\n",
      "Episode reward: 68.628506\n",
      "Episode reward: 68.705121\n",
      "Episode reward: 28.853973\n",
      "Episode reward: 50.836555\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.6     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12272    |\n",
      "|    fps              | 2885     |\n",
      "|    time_elapsed     | 241      |\n",
      "|    total_timesteps  | 696706   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 174151   |\n",
      "----------------------------------\n",
      "Episode reward: 147.79426\n",
      "Episode reward: 96.654693\n",
      "Episode reward: 67.578865\n",
      "Episode reward: 101.428147\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.8     |\n",
      "|    ep_rew_mean      | 66.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12276    |\n",
      "|    fps              | 2885     |\n",
      "|    time_elapsed     | 241      |\n",
      "|    total_timesteps  | 697136   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0381   |\n",
      "|    n_updates        | 174258   |\n",
      "----------------------------------\n",
      "Episode reward: 110.984206\n",
      "Episode reward: 30.741732\n",
      "Episode reward: 65.26817\n",
      "Episode reward: 43.623656\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.4     |\n",
      "|    ep_rew_mean      | 65.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12280    |\n",
      "|    fps              | 2884     |\n",
      "|    time_elapsed     | 241      |\n",
      "|    total_timesteps  | 697392   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.11     |\n",
      "|    n_updates        | 174322   |\n",
      "----------------------------------\n",
      "Episode reward: 53.627661\n",
      "Episode reward: 127.82781\n",
      "Episode reward: 73.60763\n",
      "Episode reward: 63.130064\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69       |\n",
      "|    ep_rew_mean      | 66.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12284    |\n",
      "|    fps              | 2884     |\n",
      "|    time_elapsed     | 241      |\n",
      "|    total_timesteps  | 697734   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0295   |\n",
      "|    n_updates        | 174408   |\n",
      "----------------------------------\n",
      "Episode reward: 50.706219\n",
      "Episode reward: 43.655008\n",
      "Episode reward: 83.983179\n",
      "Episode reward: 37.913651\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68       |\n",
      "|    ep_rew_mean      | 65.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12288    |\n",
      "|    fps              | 2884     |\n",
      "|    time_elapsed     | 241      |\n",
      "|    total_timesteps  | 697957   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.56     |\n",
      "|    n_updates        | 174464   |\n",
      "----------------------------------\n",
      "Episode reward: 60.714208\n",
      "Episode reward: 39.757405\n",
      "Episode reward: 86.697438\n",
      "Episode reward: 42.760437\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.1     |\n",
      "|    ep_rew_mean      | 65.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12292    |\n",
      "|    fps              | 2884     |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total_timesteps  | 698189   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0315   |\n",
      "|    n_updates        | 174522   |\n",
      "----------------------------------\n",
      "Episode reward: 61.380934\n",
      "Episode reward: 108.597138\n",
      "Episode reward: 67.720242\n",
      "Episode reward: 108.865112\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.6     |\n",
      "|    ep_rew_mean      | 66.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12296    |\n",
      "|    fps              | 2884     |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total_timesteps  | 698542   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0596   |\n",
      "|    n_updates        | 174610   |\n",
      "----------------------------------\n",
      "Episode reward: 43.61741\n",
      "Episode reward: 78.249758\n",
      "Episode reward: 71.144359\n",
      "Episode reward: 40.913476\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.8     |\n",
      "|    ep_rew_mean      | 67.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12300    |\n",
      "|    fps              | 2883     |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total_timesteps  | 698781   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 174670   |\n",
      "----------------------------------\n",
      "Episode reward: 24.840538\n",
      "Episode reward: 86.439278\n",
      "Episode reward: 76.616608\n",
      "Episode reward: 86.229175\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.5     |\n",
      "|    ep_rew_mean      | 67.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12304    |\n",
      "|    fps              | 2883     |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total_timesteps  | 699059   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.636    |\n",
      "|    n_updates        | 174739   |\n",
      "----------------------------------\n",
      "Episode reward: 96.272142\n",
      "Episode reward: 41.930557\n",
      "Episode reward: 72.423065\n",
      "Episode reward: 24.854622\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.6     |\n",
      "|    ep_rew_mean      | 67.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12308    |\n",
      "|    fps              | 2883     |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total_timesteps  | 699301   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0226   |\n",
      "|    n_updates        | 174800   |\n",
      "----------------------------------\n",
      "Episode reward: 74.497324\n",
      "Episode reward: 51.668657\n",
      "Episode reward: 47.837585\n",
      "Episode reward: 110.023068\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.7     |\n",
      "|    ep_rew_mean      | 67.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12312    |\n",
      "|    fps              | 2883     |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total_timesteps  | 699616   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0302   |\n",
      "|    n_updates        | 174878   |\n",
      "----------------------------------\n",
      "Episode reward: 91.171895\n",
      "Episode reward: 44.592251\n",
      "Episode reward: 71.623331\n",
      "Episode reward: 61.750018\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71       |\n",
      "|    ep_rew_mean      | 68.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12316    |\n",
      "|    fps              | 2882     |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total_timesteps  | 699890   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.033    |\n",
      "|    n_updates        | 174947   |\n",
      "----------------------------------\n",
      "Episode reward: 63.811688\n",
      "Episode reward: 72.15505\n",
      "Episode reward: 36.567004\n",
      "Episode reward: 87.12967\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71.2     |\n",
      "|    ep_rew_mean      | 68.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12320    |\n",
      "|    fps              | 2882     |\n",
      "|    time_elapsed     | 242      |\n",
      "|    total_timesteps  | 700152   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0535   |\n",
      "|    n_updates        | 175012   |\n",
      "----------------------------------\n",
      "Episode reward: 59.561766\n",
      "Episode reward: 66.278258\n",
      "Episode reward: 79.255475\n",
      "Episode reward: 28.897859\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69       |\n",
      "|    ep_rew_mean      | 66.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12324    |\n",
      "|    fps              | 2882     |\n",
      "|    time_elapsed     | 243      |\n",
      "|    total_timesteps  | 700389   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.54     |\n",
      "|    n_updates        | 175072   |\n",
      "----------------------------------\n",
      "Episode reward: 63.62734\n",
      "Episode reward: 123.338093\n",
      "Episode reward: 92.051081\n",
      "Episode reward: 38.926693\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.2     |\n",
      "|    ep_rew_mean      | 66.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12328    |\n",
      "|    fps              | 2881     |\n",
      "|    time_elapsed     | 243      |\n",
      "|    total_timesteps  | 700710   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0588   |\n",
      "|    n_updates        | 175152   |\n",
      "----------------------------------\n",
      "Episode reward: 43.762808\n",
      "Episode reward: 65.468923\n",
      "Episode reward: 52.78541\n",
      "Episode reward: 66.636877\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69       |\n",
      "|    ep_rew_mean      | 66.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12332    |\n",
      "|    fps              | 2881     |\n",
      "|    time_elapsed     | 243      |\n",
      "|    total_timesteps  | 700941   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0458   |\n",
      "|    n_updates        | 175210   |\n",
      "----------------------------------\n",
      "Episode reward: 103.169601\n",
      "Episode reward: 44.909725\n",
      "Episode reward: 68.675813\n",
      "Episode reward: 65.40954\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.3     |\n",
      "|    ep_rew_mean      | 67.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12336    |\n",
      "|    fps              | 2880     |\n",
      "|    time_elapsed     | 243      |\n",
      "|    total_timesteps  | 701228   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.23     |\n",
      "|    n_updates        | 175281   |\n",
      "----------------------------------\n",
      "Episode reward: 101.703984\n",
      "Episode reward: 44.792883\n",
      "Episode reward: 44.894607\n",
      "Episode reward: 101.173768\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71.3     |\n",
      "|    ep_rew_mean      | 68.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12340    |\n",
      "|    fps              | 2880     |\n",
      "|    time_elapsed     | 243      |\n",
      "|    total_timesteps  | 701523   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.55     |\n",
      "|    n_updates        | 175355   |\n",
      "----------------------------------\n",
      "Episode reward: 50.872583\n",
      "Episode reward: 60.443505\n",
      "Episode reward: 35.618634\n",
      "Episode reward: 75.359644\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.8     |\n",
      "|    ep_rew_mean      | 68.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12344    |\n",
      "|    fps              | 2880     |\n",
      "|    time_elapsed     | 243      |\n",
      "|    total_timesteps  | 701749   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.41     |\n",
      "|    n_updates        | 175412   |\n",
      "----------------------------------\n",
      "Episode reward: 37.407306\n",
      "Episode reward: 82.782088\n",
      "Episode reward: 142.102121\n",
      "Episode reward: 55.812467\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.5     |\n",
      "|    ep_rew_mean      | 68.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12348    |\n",
      "|    fps              | 2880     |\n",
      "|    time_elapsed     | 243      |\n",
      "|    total_timesteps  | 702070   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0606   |\n",
      "|    n_updates        | 175492   |\n",
      "----------------------------------\n",
      "Episode reward: 83.460174\n",
      "Episode reward: 57.72087\n",
      "Episode reward: 33.887795\n",
      "Episode reward: 72.339207\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.5     |\n",
      "|    ep_rew_mean      | 68.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12352    |\n",
      "|    fps              | 2880     |\n",
      "|    time_elapsed     | 243      |\n",
      "|    total_timesteps  | 702321   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.56     |\n",
      "|    n_updates        | 175555   |\n",
      "----------------------------------\n",
      "Episode reward: 49.597734\n",
      "Episode reward: 79.725698\n",
      "Episode reward: 58.388346\n",
      "Episode reward: 44.895493\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.1     |\n",
      "|    ep_rew_mean      | 68.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12356    |\n",
      "|    fps              | 2880     |\n",
      "|    time_elapsed     | 243      |\n",
      "|    total_timesteps  | 702562   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0286   |\n",
      "|    n_updates        | 175615   |\n",
      "----------------------------------\n",
      "Episode reward: 31.781719\n",
      "Episode reward: 98.926543\n",
      "Episode reward: 102.739635\n",
      "Episode reward: 50.793491\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.2     |\n",
      "|    ep_rew_mean      | 67.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12360    |\n",
      "|    fps              | 2879     |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total_timesteps  | 702868   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0448   |\n",
      "|    n_updates        | 175691   |\n",
      "----------------------------------\n",
      "Episode reward: 39.87139\n",
      "Episode reward: 100.802588\n",
      "Episode reward: 37.855498\n",
      "Episode reward: 88.092519\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.6     |\n",
      "|    ep_rew_mean      | 66.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12364    |\n",
      "|    fps              | 2879     |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total_timesteps  | 703139   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.523    |\n",
      "|    n_updates        | 175759   |\n",
      "----------------------------------\n",
      "Episode reward: 61.365349\n",
      "Episode reward: 33.90057\n",
      "Episode reward: 85.724546\n",
      "Episode reward: 32.663149\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.7     |\n",
      "|    ep_rew_mean      | 66.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12368    |\n",
      "|    fps              | 2879     |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total_timesteps  | 703357   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0313   |\n",
      "|    n_updates        | 175814   |\n",
      "----------------------------------\n",
      "Episode reward: 82.354135\n",
      "Episode reward: 57.266112\n",
      "Episode reward: 57.292365\n",
      "Episode reward: 66.555588\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.2     |\n",
      "|    ep_rew_mean      | 67.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12372    |\n",
      "|    fps              | 2879     |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total_timesteps  | 703623   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0331   |\n",
      "|    n_updates        | 175880   |\n",
      "----------------------------------\n",
      "Episode reward: 74.06232\n",
      "Episode reward: 56.500373\n",
      "Episode reward: 31.923808\n",
      "Episode reward: 31.92025\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.9     |\n",
      "|    ep_rew_mean      | 65.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12376    |\n",
      "|    fps              | 2878     |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total_timesteps  | 703823   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0258   |\n",
      "|    n_updates        | 175930   |\n",
      "----------------------------------\n",
      "Episode reward: 57.629528\n",
      "Episode reward: 99.976919\n",
      "Episode reward: 37.856243\n",
      "Episode reward: 171.526244\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68       |\n",
      "|    ep_rew_mean      | 66.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12380    |\n",
      "|    fps              | 2878     |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total_timesteps  | 704196   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0282   |\n",
      "|    n_updates        | 176023   |\n",
      "----------------------------------\n",
      "Episode reward: 28.709793\n",
      "Episode reward: 71.444763\n",
      "Episode reward: 71.565174\n",
      "Episode reward: 74.253645\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.1     |\n",
      "|    ep_rew_mean      | 65.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12384    |\n",
      "|    fps              | 2877     |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total_timesteps  | 704444   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0283   |\n",
      "|    n_updates        | 176085   |\n",
      "----------------------------------\n",
      "Episode reward: 45.890131\n",
      "Episode reward: 29.630547\n",
      "Episode reward: 127.339319\n",
      "Episode reward: 47.759207\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.4     |\n",
      "|    ep_rew_mean      | 65.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12388    |\n",
      "|    fps              | 2877     |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total_timesteps  | 704698   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0785   |\n",
      "|    n_updates        | 176149   |\n",
      "----------------------------------\n",
      "Episode reward: 94.43387\n",
      "Episode reward: 54.365961\n",
      "Episode reward: 34.698955\n",
      "Episode reward: 94.462503\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68       |\n",
      "|    ep_rew_mean      | 66.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12392    |\n",
      "|    fps              | 2877     |\n",
      "|    time_elapsed     | 244      |\n",
      "|    total_timesteps  | 704986   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.391    |\n",
      "|    n_updates        | 176221   |\n",
      "----------------------------------\n",
      "Episode reward: 72.605042\n",
      "Episode reward: 74.414694\n",
      "Episode reward: 61.412643\n",
      "Episode reward: 28.744494\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.8     |\n",
      "|    ep_rew_mean      | 65.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12396    |\n",
      "|    fps              | 2877     |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total_timesteps  | 705227   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.71     |\n",
      "|    n_updates        | 176281   |\n",
      "----------------------------------\n",
      "Episode reward: 39.903489\n",
      "Episode reward: 73.367505\n",
      "Episode reward: 119.039687\n",
      "Episode reward: 48.599829\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.3     |\n",
      "|    ep_rew_mean      | 65.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12400    |\n",
      "|    fps              | 2877     |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total_timesteps  | 705514   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0323   |\n",
      "|    n_updates        | 176353   |\n",
      "----------------------------------\n",
      "Episode reward: 64.518196\n",
      "Episode reward: 70.694364\n",
      "Episode reward: 71.662198\n",
      "Episode reward: 79.054275\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.5     |\n",
      "|    ep_rew_mean      | 65.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12404    |\n",
      "|    fps              | 2877     |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total_timesteps  | 705805   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.34     |\n",
      "|    n_updates        | 176426   |\n",
      "----------------------------------\n",
      "Episode reward: 147.302454\n",
      "Episode reward: 46.887237\n",
      "Episode reward: 48.82608\n",
      "Episode reward: 116.598657\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.8     |\n",
      "|    ep_rew_mean      | 67.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12408    |\n",
      "|    fps              | 2876     |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total_timesteps  | 706186   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.04     |\n",
      "|    n_updates        | 176521   |\n",
      "----------------------------------\n",
      "Episode reward: 53.848024\n",
      "Episode reward: 94.831949\n",
      "Episode reward: 85.043534\n",
      "Episode reward: 67.15742\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.8     |\n",
      "|    ep_rew_mean      | 67.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12412    |\n",
      "|    fps              | 2876     |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total_timesteps  | 706494   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.987    |\n",
      "|    n_updates        | 176598   |\n",
      "----------------------------------\n",
      "Episode reward: 77.492739\n",
      "Episode reward: 39.610344\n",
      "Episode reward: 59.009157\n",
      "Episode reward: 40.774308\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.2     |\n",
      "|    ep_rew_mean      | 66.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12416    |\n",
      "|    fps              | 2875     |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total_timesteps  | 706713   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0276   |\n",
      "|    n_updates        | 176653   |\n",
      "----------------------------------\n",
      "Episode reward: 62.541257\n",
      "Episode reward: 101.895332\n",
      "Episode reward: 90.249627\n",
      "Episode reward: 43.762646\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.7     |\n",
      "|    ep_rew_mean      | 67.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12420    |\n",
      "|    fps              | 2875     |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total_timesteps  | 707017   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.73     |\n",
      "|    n_updates        | 176729   |\n",
      "----------------------------------\n",
      "Episode reward: 43.911789\n",
      "Episode reward: 82.039564\n",
      "Episode reward: 88.506368\n",
      "Episode reward: 38.614441\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.8     |\n",
      "|    ep_rew_mean      | 67.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12424    |\n",
      "|    fps              | 2875     |\n",
      "|    time_elapsed     | 245      |\n",
      "|    total_timesteps  | 707272   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.47     |\n",
      "|    n_updates        | 176792   |\n",
      "----------------------------------\n",
      "Episode reward: 65.155507\n",
      "Episode reward: 61.187742\n",
      "Episode reward: 73.536396\n",
      "Episode reward: 95.304831\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.6     |\n",
      "|    ep_rew_mean      | 67.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12428    |\n",
      "|    fps              | 2875     |\n",
      "|    time_elapsed     | 246      |\n",
      "|    total_timesteps  | 707571   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0891   |\n",
      "|    n_updates        | 176867   |\n",
      "----------------------------------\n",
      "Episode reward: 160.925852\n",
      "Episode reward: 51.083628\n",
      "Episode reward: 74.840801\n",
      "Episode reward: 43.893269\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.8     |\n",
      "|    ep_rew_mean      | 68.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12432    |\n",
      "|    fps              | 2875     |\n",
      "|    time_elapsed     | 246      |\n",
      "|    total_timesteps  | 707924   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.85     |\n",
      "|    n_updates        | 176955   |\n",
      "----------------------------------\n",
      "Episode reward: 45.868989\n",
      "Episode reward: 76.853549\n",
      "Episode reward: 57.792809\n",
      "Episode reward: 73.08256\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.5     |\n",
      "|    ep_rew_mean      | 67.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12436    |\n",
      "|    fps              | 2875     |\n",
      "|    time_elapsed     | 246      |\n",
      "|    total_timesteps  | 708180   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0364   |\n",
      "|    n_updates        | 177019   |\n",
      "----------------------------------\n",
      "Episode reward: 54.546836\n",
      "Episode reward: 84.020806\n",
      "Episode reward: 48.452332\n",
      "Episode reward: 49.539742\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69       |\n",
      "|    ep_rew_mean      | 67.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12440    |\n",
      "|    fps              | 2874     |\n",
      "|    time_elapsed     | 246      |\n",
      "|    total_timesteps  | 708420   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0355   |\n",
      "|    n_updates        | 177079   |\n",
      "----------------------------------\n",
      "Episode reward: 129.787885\n",
      "Episode reward: 28.701259\n",
      "Episode reward: 43.903852\n",
      "Episode reward: 93.814397\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.7     |\n",
      "|    ep_rew_mean      | 68.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12444    |\n",
      "|    fps              | 2874     |\n",
      "|    time_elapsed     | 246      |\n",
      "|    total_timesteps  | 708723   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0511   |\n",
      "|    n_updates        | 177155   |\n",
      "----------------------------------\n",
      "Episode reward: 69.645137\n",
      "Episode reward: 135.359216\n",
      "Episode reward: 33.889019\n",
      "Episode reward: 59.597992\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.7     |\n",
      "|    ep_rew_mean      | 67.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12448    |\n",
      "|    fps              | 2874     |\n",
      "|    time_elapsed     | 246      |\n",
      "|    total_timesteps  | 709036   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.05     |\n",
      "|    n_updates        | 177233   |\n",
      "----------------------------------\n",
      "Episode reward: 84.327577\n",
      "Episode reward: 60.654007\n",
      "Episode reward: 65.275073\n",
      "Episode reward: 102.844873\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.3     |\n",
      "|    ep_rew_mean      | 68.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12452    |\n",
      "|    fps              | 2874     |\n",
      "|    time_elapsed     | 246      |\n",
      "|    total_timesteps  | 709355   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.032    |\n",
      "|    n_updates        | 177313   |\n",
      "----------------------------------\n",
      "Episode reward: 27.730083\n",
      "Episode reward: 45.780443\n",
      "Episode reward: 67.758635\n",
      "Episode reward: 25.786823\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.6     |\n",
      "|    ep_rew_mean      | 67.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12456    |\n",
      "|    fps              | 2874     |\n",
      "|    time_elapsed     | 246      |\n",
      "|    total_timesteps  | 709524   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.353    |\n",
      "|    n_updates        | 177355   |\n",
      "----------------------------------\n",
      "Episode reward: 118.800554\n",
      "Episode reward: 50.727142\n",
      "Episode reward: 49.734798\n",
      "Episode reward: 31.805559\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.1     |\n",
      "|    ep_rew_mean      | 67.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12460    |\n",
      "|    fps              | 2873     |\n",
      "|    time_elapsed     | 246      |\n",
      "|    total_timesteps  | 709781   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.81     |\n",
      "|    n_updates        | 177420   |\n",
      "----------------------------------\n",
      "Episode reward: 68.673569\n",
      "Episode reward: 119.216104\n",
      "Episode reward: 52.852007\n",
      "Episode reward: 34.903385\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.2     |\n",
      "|    ep_rew_mean      | 67.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12464    |\n",
      "|    fps              | 2873     |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total_timesteps  | 710058   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0592   |\n",
      "|    n_updates        | 177489   |\n",
      "----------------------------------\n",
      "Episode reward: 65.574523\n",
      "Episode reward: 48.890552\n",
      "Episode reward: 57.674836\n",
      "Episode reward: 36.851201\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.1     |\n",
      "|    ep_rew_mean      | 67.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12468    |\n",
      "|    fps              | 2873     |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total_timesteps  | 710268   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0433   |\n",
      "|    n_updates        | 177541   |\n",
      "----------------------------------\n",
      "Episode reward: 39.817181\n",
      "Episode reward: 70.757528\n",
      "Episode reward: 42.807454\n",
      "Episode reward: 28.766474\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.3     |\n",
      "|    ep_rew_mean      | 66.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12472    |\n",
      "|    fps              | 2873     |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total_timesteps  | 710452   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0237   |\n",
      "|    n_updates        | 177587   |\n",
      "----------------------------------\n",
      "Episode reward: 59.251714\n",
      "Episode reward: 78.516565\n",
      "Episode reward: 35.948507\n",
      "Episode reward: 35.900866\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.4     |\n",
      "|    ep_rew_mean      | 66.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12476    |\n",
      "|    fps              | 2873     |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total_timesteps  | 710663   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.59     |\n",
      "|    n_updates        | 177640   |\n",
      "----------------------------------\n",
      "Episode reward: 45.867837\n",
      "Episode reward: 92.755378\n",
      "Episode reward: 69.002944\n",
      "Episode reward: 71.79506\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.5     |\n",
      "|    ep_rew_mean      | 66.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12480    |\n",
      "|    fps              | 2873     |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total_timesteps  | 710946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0706   |\n",
      "|    n_updates        | 177711   |\n",
      "----------------------------------\n",
      "Episode reward: 68.139327\n",
      "Episode reward: 37.764958\n",
      "Episode reward: 51.863094\n",
      "Episode reward: 43.854885\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67       |\n",
      "|    ep_rew_mean      | 65.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12484    |\n",
      "|    fps              | 2873     |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total_timesteps  | 711149   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0222   |\n",
      "|    n_updates        | 177762   |\n",
      "----------------------------------\n",
      "Episode reward: 36.871697\n",
      "Episode reward: 54.502274\n",
      "Episode reward: 31.90836\n",
      "Episode reward: 89.622293\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.7     |\n",
      "|    ep_rew_mean      | 65.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12488    |\n",
      "|    fps              | 2873     |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total_timesteps  | 711365   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.693    |\n",
      "|    n_updates        | 177816   |\n",
      "----------------------------------\n",
      "Episode reward: 37.690339\n",
      "Episode reward: 31.761247\n",
      "Episode reward: 45.904248\n",
      "Episode reward: 63.567076\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.6     |\n",
      "|    ep_rew_mean      | 64.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12492    |\n",
      "|    fps              | 2873     |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total_timesteps  | 711545   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0748   |\n",
      "|    n_updates        | 177861   |\n",
      "----------------------------------\n",
      "Episode reward: 107.908938\n",
      "Episode reward: 51.773633\n",
      "Episode reward: 38.801799\n",
      "Episode reward: 159.275169\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.9     |\n",
      "|    ep_rew_mean      | 65.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12496    |\n",
      "|    fps              | 2873     |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total_timesteps  | 711914   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0321   |\n",
      "|    n_updates        | 177953   |\n",
      "----------------------------------\n",
      "Episode reward: 99.449597\n",
      "Episode reward: 78.765198\n",
      "Episode reward: 38.905116\n",
      "Episode reward: 47.880465\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.7     |\n",
      "|    ep_rew_mean      | 65.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12500    |\n",
      "|    fps              | 2872     |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total_timesteps  | 712184   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.087    |\n",
      "|    n_updates        | 178020   |\n",
      "----------------------------------\n",
      "Episode reward: 77.591871\n",
      "Episode reward: 84.562566\n",
      "Episode reward: 40.908853\n",
      "Episode reward: 42.921663\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.3     |\n",
      "|    ep_rew_mean      | 64.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12504    |\n",
      "|    fps              | 2872     |\n",
      "|    time_elapsed     | 247      |\n",
      "|    total_timesteps  | 712432   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0865   |\n",
      "|    n_updates        | 178082   |\n",
      "----------------------------------\n",
      "Episode reward: 141.101467\n",
      "Episode reward: 57.788527\n",
      "Episode reward: 114.474427\n",
      "Episode reward: 58.756734\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.2     |\n",
      "|    ep_rew_mean      | 65       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12508    |\n",
      "|    fps              | 2872     |\n",
      "|    time_elapsed     | 248      |\n",
      "|    total_timesteps  | 712807   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.318    |\n",
      "|    n_updates        | 178176   |\n",
      "----------------------------------\n",
      "Episode reward: 31.716825\n",
      "Episode reward: 33.73077\n",
      "Episode reward: 55.740017\n",
      "Episode reward: 75.389652\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.1     |\n",
      "|    ep_rew_mean      | 64       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12512    |\n",
      "|    fps              | 2872     |\n",
      "|    time_elapsed     | 248      |\n",
      "|    total_timesteps  | 713005   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.09     |\n",
      "|    n_updates        | 178226   |\n",
      "----------------------------------\n",
      "Episode reward: 41.895831\n",
      "Episode reward: 61.768704\n",
      "Episode reward: 40.916219\n",
      "Episode reward: 59.590128\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65       |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12516    |\n",
      "|    fps              | 2872     |\n",
      "|    time_elapsed     | 248      |\n",
      "|    total_timesteps  | 713210   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0464   |\n",
      "|    n_updates        | 178277   |\n",
      "----------------------------------\n",
      "Episode reward: 36.818401\n",
      "Episode reward: 61.343566\n",
      "Episode reward: 142.898544\n",
      "Episode reward: 38.729545\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 63.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12520    |\n",
      "|    fps              | 2872     |\n",
      "|    time_elapsed     | 248      |\n",
      "|    total_timesteps  | 713496   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0306   |\n",
      "|    n_updates        | 178348   |\n",
      "----------------------------------\n",
      "Episode reward: 71.34894\n",
      "Episode reward: 38.763069\n",
      "Episode reward: 92.323023\n",
      "Episode reward: 85.572953\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.2     |\n",
      "|    ep_rew_mean      | 64       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12524    |\n",
      "|    fps              | 2872     |\n",
      "|    time_elapsed     | 248      |\n",
      "|    total_timesteps  | 713789   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0929   |\n",
      "|    n_updates        | 178422   |\n",
      "----------------------------------\n",
      "Episode reward: 74.61591\n",
      "Episode reward: 61.144073\n",
      "Episode reward: 98.014292\n",
      "Episode reward: 55.371252\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.2     |\n",
      "|    ep_rew_mean      | 63.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12528    |\n",
      "|    fps              | 2871     |\n",
      "|    time_elapsed     | 248      |\n",
      "|    total_timesteps  | 714089   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.377    |\n",
      "|    n_updates        | 178497   |\n",
      "----------------------------------\n",
      "Episode reward: 32.819685\n",
      "Episode reward: 32.642106\n",
      "Episode reward: 39.842784\n",
      "Episode reward: 30.897348\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12532    |\n",
      "|    fps              | 2872     |\n",
      "|    time_elapsed     | 248      |\n",
      "|    total_timesteps  | 714226   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0822   |\n",
      "|    n_updates        | 178531   |\n",
      "----------------------------------\n",
      "Episode reward: 113.764873\n",
      "Episode reward: 56.733544\n",
      "Episode reward: 64.148504\n",
      "Episode reward: 79.014051\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12536    |\n",
      "|    fps              | 2871     |\n",
      "|    time_elapsed     | 248      |\n",
      "|    total_timesteps  | 714544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0405   |\n",
      "|    n_updates        | 178610   |\n",
      "----------------------------------\n",
      "Episode reward: 53.805051\n",
      "Episode reward: 49.327469\n",
      "Episode reward: 39.849694\n",
      "Episode reward: 32.891646\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12540    |\n",
      "|    fps              | 2871     |\n",
      "|    time_elapsed     | 248      |\n",
      "|    total_timesteps  | 714721   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0306   |\n",
      "|    n_updates        | 178655   |\n",
      "----------------------------------\n",
      "Episode reward: 95.865734\n",
      "Episode reward: 36.863635\n",
      "Episode reward: 127.388132\n",
      "Episode reward: 49.826343\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12544    |\n",
      "|    fps              | 2871     |\n",
      "|    time_elapsed     | 249      |\n",
      "|    total_timesteps  | 715042   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0299   |\n",
      "|    n_updates        | 178735   |\n",
      "----------------------------------\n",
      "Episode reward: 47.773976\n",
      "Episode reward: 41.788885\n",
      "Episode reward: 33.946885\n",
      "Episode reward: 36.939996\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12548    |\n",
      "|    fps              | 2871     |\n",
      "|    time_elapsed     | 249      |\n",
      "|    total_timesteps  | 715203   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.309    |\n",
      "|    n_updates        | 178775   |\n",
      "----------------------------------\n",
      "Episode reward: 97.028952\n",
      "Episode reward: 62.686535\n",
      "Episode reward: 40.577021\n",
      "Episode reward: 51.745696\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12552    |\n",
      "|    fps              | 2871     |\n",
      "|    time_elapsed     | 249      |\n",
      "|    total_timesteps  | 715462   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0487   |\n",
      "|    n_updates        | 178840   |\n",
      "----------------------------------\n",
      "Episode reward: 58.827797\n",
      "Episode reward: 52.868534\n",
      "Episode reward: 61.689917\n",
      "Episode reward: 53.815075\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12556    |\n",
      "|    fps              | 2870     |\n",
      "|    time_elapsed     | 249      |\n",
      "|    total_timesteps  | 715690   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0211   |\n",
      "|    n_updates        | 178897   |\n",
      "----------------------------------\n",
      "Episode reward: 61.476342\n",
      "Episode reward: 32.926758\n",
      "Episode reward: 28.799803\n",
      "Episode reward: 31.868673\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12560    |\n",
      "|    fps              | 2870     |\n",
      "|    time_elapsed     | 249      |\n",
      "|    total_timesteps  | 715846   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.868    |\n",
      "|    n_updates        | 178936   |\n",
      "----------------------------------\n",
      "Episode reward: 46.749809\n",
      "Episode reward: 35.945798\n",
      "Episode reward: 92.043698\n",
      "Episode reward: 65.998076\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12564    |\n",
      "|    fps              | 2870     |\n",
      "|    time_elapsed     | 249      |\n",
      "|    total_timesteps  | 716089   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0404   |\n",
      "|    n_updates        | 178997   |\n",
      "----------------------------------\n",
      "Episode reward: 63.98347\n",
      "Episode reward: 65.979716\n",
      "Episode reward: 34.949436\n",
      "Episode reward: 29.94904\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12568    |\n",
      "|    fps              | 2870     |\n",
      "|    time_elapsed     | 249      |\n",
      "|    total_timesteps  | 716287   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0269   |\n",
      "|    n_updates        | 179046   |\n",
      "----------------------------------\n",
      "Episode reward: 93.521545\n",
      "Episode reward: 123.741973\n",
      "Episode reward: 64.682627\n",
      "Episode reward: 32.907546\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12572    |\n",
      "|    fps              | 2870     |\n",
      "|    time_elapsed     | 249      |\n",
      "|    total_timesteps  | 716638   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0283   |\n",
      "|    n_updates        | 179134   |\n",
      "----------------------------------\n",
      "Episode reward: 29.917407\n",
      "Episode reward: 31.926424\n",
      "Episode reward: 66.679813\n",
      "Episode reward: 54.68732\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12576    |\n",
      "|    fps              | 2870     |\n",
      "|    time_elapsed     | 249      |\n",
      "|    total_timesteps  | 716825   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.108    |\n",
      "|    n_updates        | 179181   |\n",
      "----------------------------------\n",
      "Episode reward: 30.733598\n",
      "Episode reward: 44.903715\n",
      "Episode reward: 116.725594\n",
      "Episode reward: 41.857805\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12580    |\n",
      "|    fps              | 2870     |\n",
      "|    time_elapsed     | 249      |\n",
      "|    total_timesteps  | 717061   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0422   |\n",
      "|    n_updates        | 179240   |\n",
      "----------------------------------\n",
      "Episode reward: 50.650747\n",
      "Episode reward: 35.874627\n",
      "Episode reward: 122.64843\n",
      "Episode reward: 46.672991\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12584    |\n",
      "|    fps              | 2870     |\n",
      "|    time_elapsed     | 249      |\n",
      "|    total_timesteps  | 717346   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0386   |\n",
      "|    n_updates        | 179311   |\n",
      "----------------------------------\n",
      "Episode reward: 39.922805\n",
      "Episode reward: 65.634158\n",
      "Episode reward: 60.744207\n",
      "Episode reward: 38.893732\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12588    |\n",
      "|    fps              | 2869     |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 717552   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.214    |\n",
      "|    n_updates        | 179362   |\n",
      "----------------------------------\n",
      "Episode reward: 53.768267\n",
      "Episode reward: 84.650543\n",
      "Episode reward: 40.888142\n",
      "Episode reward: 96.293343\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12592    |\n",
      "|    fps              | 2869     |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 717829   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.18     |\n",
      "|    n_updates        | 179432   |\n",
      "----------------------------------\n",
      "Episode reward: 59.406821\n",
      "Episode reward: 73.612785\n",
      "Episode reward: 67.556668\n",
      "Episode reward: 47.863533\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12596    |\n",
      "|    fps              | 2869     |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 718079   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0294   |\n",
      "|    n_updates        | 179494   |\n",
      "----------------------------------\n",
      "Episode reward: 38.376879\n",
      "Episode reward: 43.621843\n",
      "Episode reward: 95.881821\n",
      "Episode reward: 81.465516\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12600    |\n",
      "|    fps              | 2869     |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 718343   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.767    |\n",
      "|    n_updates        | 179560   |\n",
      "----------------------------------\n",
      "Episode reward: 70.489116\n",
      "Episode reward: 55.422814\n",
      "Episode reward: 53.835208\n",
      "Episode reward: 47.839459\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12604    |\n",
      "|    fps              | 2869     |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 718572   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.082    |\n",
      "|    n_updates        | 179617   |\n",
      "----------------------------------\n",
      "Episode reward: 36.706155\n",
      "Episode reward: 87.841807\n",
      "Episode reward: 81.193755\n",
      "Episode reward: 128.590815\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12608    |\n",
      "|    fps              | 2869     |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 718914   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0229   |\n",
      "|    n_updates        | 179703   |\n",
      "----------------------------------\n",
      "Episode reward: 90.197146\n",
      "Episode reward: 48.73322\n",
      "Episode reward: 55.631962\n",
      "Episode reward: 83.915447\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12612    |\n",
      "|    fps              | 2869     |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 719196   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.45     |\n",
      "|    n_updates        | 179773   |\n",
      "----------------------------------\n",
      "Episode reward: 57.768194\n",
      "Episode reward: 46.857118\n",
      "Episode reward: 51.672117\n",
      "Episode reward: 81.584292\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12616    |\n",
      "|    fps              | 2869     |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 719436   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0885   |\n",
      "|    n_updates        | 179833   |\n",
      "----------------------------------\n",
      "Episode reward: 84.086216\n",
      "Episode reward: 51.682997\n",
      "Episode reward: 66.518548\n",
      "Episode reward: 96.540932\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12620    |\n",
      "|    fps              | 2869     |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 719739   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0254   |\n",
      "|    n_updates        | 179909   |\n",
      "----------------------------------\n",
      "Episode reward: 106.039199\n",
      "Episode reward: 39.711191\n",
      "Episode reward: 63.690477\n",
      "Episode reward: 48.795534\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12624    |\n",
      "|    fps              | 2868     |\n",
      "|    time_elapsed     | 250      |\n",
      "|    total_timesteps  | 720003   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.141    |\n",
      "|    n_updates        | 179975   |\n",
      "----------------------------------\n",
      "Episode reward: 67.295193\n",
      "Episode reward: 69.543531\n",
      "Episode reward: 155.121527\n",
      "Episode reward: 65.654539\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12628    |\n",
      "|    fps              | 2868     |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total_timesteps  | 720366   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.068    |\n",
      "|    n_updates        | 180066   |\n",
      "----------------------------------\n",
      "Episode reward: 55.830288\n",
      "Episode reward: 96.406521\n",
      "Episode reward: 75.535693\n",
      "Episode reward: 35.905327\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12632    |\n",
      "|    fps              | 2868     |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total_timesteps  | 720631   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.23     |\n",
      "|    n_updates        | 180132   |\n",
      "----------------------------------\n",
      "Episode reward: 34.863725\n",
      "Episode reward: 61.620957\n",
      "Episode reward: 57.549541\n",
      "Episode reward: 88.04368\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12636    |\n",
      "|    fps              | 2868     |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total_timesteps  | 720875   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.111    |\n",
      "|    n_updates        | 180193   |\n",
      "----------------------------------\n",
      "Episode reward: 38.616507\n",
      "Episode reward: 56.330652\n",
      "Episode reward: 29.745951\n",
      "Episode reward: 47.597033\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12640    |\n",
      "|    fps              | 2868     |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total_timesteps  | 721049   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.438    |\n",
      "|    n_updates        | 180237   |\n",
      "----------------------------------\n",
      "Episode reward: 49.810929\n",
      "Episode reward: 74.870788\n",
      "Episode reward: 36.862701\n",
      "Episode reward: 66.285912\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12644    |\n",
      "|    fps              | 2868     |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total_timesteps  | 721283   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0705   |\n",
      "|    n_updates        | 180295   |\n",
      "----------------------------------\n",
      "Episode reward: 43.881357\n",
      "Episode reward: 76.972542\n",
      "Episode reward: 65.721334\n",
      "Episode reward: 31.483449\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12648    |\n",
      "|    fps              | 2868     |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total_timesteps  | 721505   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0471   |\n",
      "|    n_updates        | 180351   |\n",
      "----------------------------------\n",
      "Episode reward: 29.831189\n",
      "Episode reward: 62.60582\n",
      "Episode reward: 85.417829\n",
      "Episode reward: 110.339914\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12652    |\n",
      "|    fps              | 2868     |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total_timesteps  | 721806   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0419   |\n",
      "|    n_updates        | 180426   |\n",
      "----------------------------------\n",
      "Episode reward: 46.026957\n",
      "Episode reward: 113.522983\n",
      "Episode reward: 102.574919\n",
      "Episode reward: 58.778795\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12656    |\n",
      "|    fps              | 2868     |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total_timesteps  | 722151   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.048    |\n",
      "|    n_updates        | 180512   |\n",
      "----------------------------------\n",
      "Episode reward: 53.825549\n",
      "Episode reward: 63.844287\n",
      "Episode reward: 50.399235\n",
      "Episode reward: 44.799069\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.2     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12660    |\n",
      "|    fps              | 2868     |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total_timesteps  | 722366   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0216   |\n",
      "|    n_updates        | 180566   |\n",
      "----------------------------------\n",
      "Episode reward: 104.435949\n",
      "Episode reward: 70.239382\n",
      "Episode reward: 62.696953\n",
      "Episode reward: 118.522878\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.4     |\n",
      "|    ep_rew_mean      | 64.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12664    |\n",
      "|    fps              | 2867     |\n",
      "|    time_elapsed     | 251      |\n",
      "|    total_timesteps  | 722727   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.057    |\n",
      "|    n_updates        | 180656   |\n",
      "----------------------------------\n",
      "Episode reward: 71.654503\n",
      "Episode reward: 29.861855\n",
      "Episode reward: 76.486774\n",
      "Episode reward: 24.748618\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.4     |\n",
      "|    ep_rew_mean      | 64.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12668    |\n",
      "|    fps              | 2868     |\n",
      "|    time_elapsed     | 252      |\n",
      "|    total_timesteps  | 722931   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.05     |\n",
      "|    n_updates        | 180707   |\n",
      "----------------------------------\n",
      "Episode reward: 38.921018\n",
      "Episode reward: 98.36793\n",
      "Episode reward: 153.891912\n",
      "Episode reward: 62.985048\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.7     |\n",
      "|    ep_rew_mean      | 65.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12672    |\n",
      "|    fps              | 2867     |\n",
      "|    time_elapsed     | 252      |\n",
      "|    total_timesteps  | 723306   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0476   |\n",
      "|    n_updates        | 180801   |\n",
      "----------------------------------\n",
      "Episode reward: 87.91294\n",
      "Episode reward: 68.683327\n",
      "Episode reward: 27.914853\n",
      "Episode reward: 50.815105\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.2     |\n",
      "|    ep_rew_mean      | 65.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12676    |\n",
      "|    fps              | 2867     |\n",
      "|    time_elapsed     | 252      |\n",
      "|    total_timesteps  | 723547   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0309   |\n",
      "|    n_updates        | 180861   |\n",
      "----------------------------------\n",
      "Episode reward: 87.836422\n",
      "Episode reward: 32.821654\n",
      "Episode reward: 99.225507\n",
      "Episode reward: 95.911502\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.1     |\n",
      "|    ep_rew_mean      | 66.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12680    |\n",
      "|    fps              | 2867     |\n",
      "|    time_elapsed     | 252      |\n",
      "|    total_timesteps  | 723871   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.389    |\n",
      "|    n_updates        | 180942   |\n",
      "----------------------------------\n",
      "Episode reward: 48.737178\n",
      "Episode reward: 64.971249\n",
      "Episode reward: 120.205707\n",
      "Episode reward: 58.53359\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.2     |\n",
      "|    ep_rew_mean      | 66.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12684    |\n",
      "|    fps              | 2867     |\n",
      "|    time_elapsed     | 252      |\n",
      "|    total_timesteps  | 724166   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0318   |\n",
      "|    n_updates        | 181016   |\n",
      "----------------------------------\n",
      "Episode reward: 106.942018\n",
      "Episode reward: 89.960217\n",
      "Episode reward: 45.801508\n",
      "Episode reward: 60.736052\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.2     |\n",
      "|    ep_rew_mean      | 67.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12688    |\n",
      "|    fps              | 2867     |\n",
      "|    time_elapsed     | 252      |\n",
      "|    total_timesteps  | 724474   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0672   |\n",
      "|    n_updates        | 181093   |\n",
      "----------------------------------\n",
      "Episode reward: 90.760011\n",
      "Episode reward: 59.318965\n",
      "Episode reward: 52.548358\n",
      "Episode reward: 35.900318\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.9     |\n",
      "|    ep_rew_mean      | 67.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12692    |\n",
      "|    fps              | 2867     |\n",
      "|    time_elapsed     | 252      |\n",
      "|    total_timesteps  | 724716   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0689   |\n",
      "|    n_updates        | 181153   |\n",
      "----------------------------------\n",
      "Episode reward: 133.499706\n",
      "Episode reward: 43.756518\n",
      "Episode reward: 33.784589\n",
      "Episode reward: 117.101772\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.8     |\n",
      "|    ep_rew_mean      | 68.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12696    |\n",
      "|    fps              | 2867     |\n",
      "|    time_elapsed     | 252      |\n",
      "|    total_timesteps  | 725064   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.43     |\n",
      "|    n_updates        | 181240   |\n",
      "----------------------------------\n",
      "Episode reward: 81.67492\n",
      "Episode reward: 157.150457\n",
      "Episode reward: 35.676075\n",
      "Episode reward: 36.828987\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.4     |\n",
      "|    ep_rew_mean      | 68.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12700    |\n",
      "|    fps              | 2867     |\n",
      "|    time_elapsed     | 252      |\n",
      "|    total_timesteps  | 725379   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 181319   |\n",
      "----------------------------------\n",
      "Episode reward: 68.965436\n",
      "Episode reward: 66.639208\n",
      "Episode reward: 23.919659\n",
      "Episode reward: 46.807231\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.2     |\n",
      "|    ep_rew_mean      | 68.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12704    |\n",
      "|    fps              | 2866     |\n",
      "|    time_elapsed     | 253      |\n",
      "|    total_timesteps  | 725588   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 181371   |\n",
      "----------------------------------\n",
      "Episode reward: 60.862566\n",
      "Episode reward: 75.617742\n",
      "Episode reward: 218.591524\n",
      "Episode reward: 67.589135\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71.1     |\n",
      "|    ep_rew_mean      | 69.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12708    |\n",
      "|    fps              | 2866     |\n",
      "|    time_elapsed     | 253      |\n",
      "|    total_timesteps  | 726022   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0159   |\n",
      "|    n_updates        | 181480   |\n",
      "----------------------------------\n",
      "Episode reward: 47.753834\n",
      "Episode reward: 102.383949\n",
      "Episode reward: 65.696701\n",
      "Episode reward: 47.318782\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71       |\n",
      "|    ep_rew_mean      | 69.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12712    |\n",
      "|    fps              | 2866     |\n",
      "|    time_elapsed     | 253      |\n",
      "|    total_timesteps  | 726292   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.411    |\n",
      "|    n_updates        | 181547   |\n",
      "----------------------------------\n",
      "Episode reward: 50.797422\n",
      "Episode reward: 80.753735\n",
      "Episode reward: 69.327773\n",
      "Episode reward: 66.55469\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71.2     |\n",
      "|    ep_rew_mean      | 69.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12716    |\n",
      "|    fps              | 2866     |\n",
      "|    time_elapsed     | 253      |\n",
      "|    total_timesteps  | 726561   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0394   |\n",
      "|    n_updates        | 181615   |\n",
      "----------------------------------\n",
      "Episode reward: 87.270332\n",
      "Episode reward: 30.919152\n",
      "Episode reward: 45.830094\n",
      "Episode reward: 46.582419\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.4     |\n",
      "|    ep_rew_mean      | 68.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12720    |\n",
      "|    fps              | 2866     |\n",
      "|    time_elapsed     | 253      |\n",
      "|    total_timesteps  | 726777   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0653   |\n",
      "|    n_updates        | 181669   |\n",
      "----------------------------------\n",
      "Episode reward: 67.209031\n",
      "Episode reward: 37.923234\n",
      "Episode reward: 140.159664\n",
      "Episode reward: 30.789048\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.7     |\n",
      "|    ep_rew_mean      | 68.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12724    |\n",
      "|    fps              | 2866     |\n",
      "|    time_elapsed     | 253      |\n",
      "|    total_timesteps  | 727072   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0533   |\n",
      "|    n_updates        | 181742   |\n",
      "----------------------------------\n",
      "Episode reward: 50.71661\n",
      "Episode reward: 114.199513\n",
      "Episode reward: 96.048044\n",
      "Episode reward: 127.78434\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71       |\n",
      "|    ep_rew_mean      | 69.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12728    |\n",
      "|    fps              | 2866     |\n",
      "|    time_elapsed     | 253      |\n",
      "|    total_timesteps  | 727468   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.27     |\n",
      "|    n_updates        | 181841   |\n",
      "----------------------------------\n",
      "Episode reward: 81.175832\n",
      "Episode reward: 37.940989\n",
      "Episode reward: 49.869146\n",
      "Episode reward: 63.686686\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.7     |\n",
      "|    ep_rew_mean      | 68.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12732    |\n",
      "|    fps              | 2866     |\n",
      "|    time_elapsed     | 253      |\n",
      "|    total_timesteps  | 727702   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0577   |\n",
      "|    n_updates        | 181900   |\n",
      "----------------------------------\n",
      "Episode reward: 71.572252\n",
      "Episode reward: 55.843698\n",
      "Episode reward: 43.919409\n",
      "Episode reward: 56.680569\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.6     |\n",
      "|    ep_rew_mean      | 68.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12736    |\n",
      "|    fps              | 2866     |\n",
      "|    time_elapsed     | 253      |\n",
      "|    total_timesteps  | 727931   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.321    |\n",
      "|    n_updates        | 181957   |\n",
      "----------------------------------\n",
      "Episode reward: 35.828105\n",
      "Episode reward: 230.038434\n",
      "Episode reward: 134.44429\n",
      "Episode reward: 81.784006\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 73.8     |\n",
      "|    ep_rew_mean      | 71.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12740    |\n",
      "|    fps              | 2866     |\n",
      "|    time_elapsed     | 254      |\n",
      "|    total_timesteps  | 728429   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.032    |\n",
      "|    n_updates        | 182082   |\n",
      "----------------------------------\n",
      "Episode reward: 53.76913\n",
      "Episode reward: 105.235822\n",
      "Episode reward: 122.787671\n",
      "Episode reward: 88.14679\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 75.2     |\n",
      "|    ep_rew_mean      | 73.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12744    |\n",
      "|    fps              | 2865     |\n",
      "|    time_elapsed     | 254      |\n",
      "|    total_timesteps  | 728802   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0259   |\n",
      "|    n_updates        | 182175   |\n",
      "----------------------------------\n",
      "Episode reward: 67.175344\n",
      "Episode reward: 50.903498\n",
      "Episode reward: 26.912281\n",
      "Episode reward: 45.836769\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 74.9     |\n",
      "|    ep_rew_mean      | 73       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12748    |\n",
      "|    fps              | 2865     |\n",
      "|    time_elapsed     | 254      |\n",
      "|    total_timesteps  | 728994   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.028    |\n",
      "|    n_updates        | 182223   |\n",
      "----------------------------------\n",
      "Episode reward: 34.937067\n",
      "Episode reward: 66.932916\n",
      "Episode reward: 82.587338\n",
      "Episode reward: 43.911817\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 74.2     |\n",
      "|    ep_rew_mean      | 72.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12752    |\n",
      "|    fps              | 2865     |\n",
      "|    time_elapsed     | 254      |\n",
      "|    total_timesteps  | 729224   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.804    |\n",
      "|    n_updates        | 182280   |\n",
      "----------------------------------\n",
      "Episode reward: 23.925467\n",
      "Episode reward: 84.426235\n",
      "Episode reward: 33.704242\n",
      "Episode reward: 75.667415\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 72.9     |\n",
      "|    ep_rew_mean      | 71.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12756    |\n",
      "|    fps              | 2865     |\n",
      "|    time_elapsed     | 254      |\n",
      "|    total_timesteps  | 729444   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0489   |\n",
      "|    n_updates        | 182335   |\n",
      "----------------------------------\n",
      "Episode reward: 83.228985\n",
      "Episode reward: 88.634079\n",
      "Episode reward: 34.94046\n",
      "Episode reward: 47.768723\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 73.4     |\n",
      "|    ep_rew_mean      | 71.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12760    |\n",
      "|    fps              | 2865     |\n",
      "|    time_elapsed     | 254      |\n",
      "|    total_timesteps  | 729703   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0794   |\n",
      "|    n_updates        | 182400   |\n",
      "----------------------------------\n",
      "Episode reward: 101.531694\n",
      "Episode reward: 133.485477\n",
      "Episode reward: 50.866545\n",
      "Episode reward: 56.723104\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 73.2     |\n",
      "|    ep_rew_mean      | 71.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12764    |\n",
      "|    fps              | 2865     |\n",
      "|    time_elapsed     | 254      |\n",
      "|    total_timesteps  | 730049   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.36     |\n",
      "|    n_updates        | 182487   |\n",
      "----------------------------------\n",
      "Episode reward: 39.901015\n",
      "Episode reward: 43.804003\n",
      "Episode reward: 73.575293\n",
      "Episode reward: 65.446141\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 73.4     |\n",
      "|    ep_rew_mean      | 71.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12768    |\n",
      "|    fps              | 2865     |\n",
      "|    time_elapsed     | 254      |\n",
      "|    total_timesteps  | 730273   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0623   |\n",
      "|    n_updates        | 182543   |\n",
      "----------------------------------\n",
      "Episode reward: 52.872924\n",
      "Episode reward: 62.273208\n",
      "Episode reward: 31.855737\n",
      "Episode reward: 88.017221\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 72.1     |\n",
      "|    ep_rew_mean      | 70.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12772    |\n",
      "|    fps              | 2865     |\n",
      "|    time_elapsed     | 254      |\n",
      "|    total_timesteps  | 730512   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1        |\n",
      "|    n_updates        | 182602   |\n",
      "----------------------------------\n",
      "Episode reward: 118.794866\n",
      "Episode reward: 41.620376\n",
      "Episode reward: 50.799513\n",
      "Episode reward: 66.597434\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 72.8     |\n",
      "|    ep_rew_mean      | 71.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12776    |\n",
      "|    fps              | 2864     |\n",
      "|    time_elapsed     | 255      |\n",
      "|    total_timesteps  | 730829   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.32     |\n",
      "|    n_updates        | 182682   |\n",
      "----------------------------------\n",
      "Episode reward: 110.708555\n",
      "Episode reward: 108.232922\n",
      "Episode reward: 86.606285\n",
      "Episode reward: 59.794424\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 73.3     |\n",
      "|    ep_rew_mean      | 71.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12780    |\n",
      "|    fps              | 2864     |\n",
      "|    time_elapsed     | 255      |\n",
      "|    total_timesteps  | 731201   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0707   |\n",
      "|    n_updates        | 182775   |\n",
      "----------------------------------\n",
      "Episode reward: 82.605946\n",
      "Episode reward: 36.918768\n",
      "Episode reward: 80.420435\n",
      "Episode reward: 57.721104\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 72.9     |\n",
      "|    ep_rew_mean      | 71.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12784    |\n",
      "|    fps              | 2864     |\n",
      "|    time_elapsed     | 255      |\n",
      "|    total_timesteps  | 731460   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0736   |\n",
      "|    n_updates        | 182839   |\n",
      "----------------------------------\n",
      "Episode reward: 66.631259\n",
      "Episode reward: 63.736647\n",
      "Episode reward: 36.530883\n",
      "Episode reward: 89.219339\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 72.5     |\n",
      "|    ep_rew_mean      | 70.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12788    |\n",
      "|    fps              | 2864     |\n",
      "|    time_elapsed     | 255      |\n",
      "|    total_timesteps  | 731720   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0338   |\n",
      "|    n_updates        | 182904   |\n",
      "----------------------------------\n",
      "Episode reward: 31.839544\n",
      "Episode reward: 62.375847\n",
      "Episode reward: 40.744409\n",
      "Episode reward: 92.083846\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 72.3     |\n",
      "|    ep_rew_mean      | 70.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12792    |\n",
      "|    fps              | 2865     |\n",
      "|    time_elapsed     | 255      |\n",
      "|    total_timesteps  | 731949   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0487   |\n",
      "|    n_updates        | 182962   |\n",
      "----------------------------------\n",
      "Episode reward: 45.769484\n",
      "Episode reward: 50.78923\n",
      "Episode reward: 33.85005\n",
      "Episode reward: 81.670804\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71       |\n",
      "|    ep_rew_mean      | 69.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12796    |\n",
      "|    fps              | 2864     |\n",
      "|    time_elapsed     | 255      |\n",
      "|    total_timesteps  | 732165   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.82     |\n",
      "|    n_updates        | 183016   |\n",
      "----------------------------------\n",
      "Episode reward: 34.890211\n",
      "Episode reward: 45.829198\n",
      "Episode reward: 116.593299\n",
      "Episode reward: 126.358888\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71.2     |\n",
      "|    ep_rew_mean      | 69.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12800    |\n",
      "|    fps              | 2864     |\n",
      "|    time_elapsed     | 255      |\n",
      "|    total_timesteps  | 732501   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0226   |\n",
      "|    n_updates        | 183100   |\n",
      "----------------------------------\n",
      "Episode reward: 53.849118\n",
      "Episode reward: 59.669592\n",
      "Episode reward: 60.06739\n",
      "Episode reward: 54.452324\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71.4     |\n",
      "|    ep_rew_mean      | 69.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12804    |\n",
      "|    fps              | 2864     |\n",
      "|    time_elapsed     | 255      |\n",
      "|    total_timesteps  | 732732   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.144    |\n",
      "|    n_updates        | 183157   |\n",
      "----------------------------------\n",
      "Episode reward: 49.554448\n",
      "Episode reward: 37.689497\n",
      "Episode reward: 32.6072\n",
      "Episode reward: 63.607819\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69       |\n",
      "|    ep_rew_mean      | 67.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12808    |\n",
      "|    fps              | 2864     |\n",
      "|    time_elapsed     | 255      |\n",
      "|    total_timesteps  | 732917   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0348   |\n",
      "|    n_updates        | 183204   |\n",
      "----------------------------------\n",
      "Episode reward: 77.560393\n",
      "Episode reward: 32.852849\n",
      "Episode reward: 40.904687\n",
      "Episode reward: 42.74511\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.2     |\n",
      "|    ep_rew_mean      | 66.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12812    |\n",
      "|    fps              | 2864     |\n",
      "|    time_elapsed     | 255      |\n",
      "|    total_timesteps  | 733112   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.059    |\n",
      "|    n_updates        | 183252   |\n",
      "----------------------------------\n",
      "Episode reward: 55.399363\n",
      "Episode reward: 31.933841\n",
      "Episode reward: 58.633675\n",
      "Episode reward: 52.771398\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.5     |\n",
      "|    ep_rew_mean      | 66       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12816    |\n",
      "|    fps              | 2864     |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total_timesteps  | 733312   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0797   |\n",
      "|    n_updates        | 183302   |\n",
      "----------------------------------\n",
      "Episode reward: 55.836358\n",
      "Episode reward: 34.950799\n",
      "Episode reward: 60.76997\n",
      "Episode reward: 98.974959\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.9     |\n",
      "|    ep_rew_mean      | 66.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12820    |\n",
      "|    fps              | 2864     |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total_timesteps  | 733566   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0287   |\n",
      "|    n_updates        | 183366   |\n",
      "----------------------------------\n",
      "Episode reward: 35.811742\n",
      "Episode reward: 72.29292\n",
      "Episode reward: 115.774509\n",
      "Episode reward: 29.935026\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.5     |\n",
      "|    ep_rew_mean      | 66.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12824    |\n",
      "|    fps              | 2864     |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total_timesteps  | 733822   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.116    |\n",
      "|    n_updates        | 183430   |\n",
      "----------------------------------\n",
      "Episode reward: 39.845269\n",
      "Episode reward: 50.767249\n",
      "Episode reward: 127.399067\n",
      "Episode reward: 56.517933\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.3     |\n",
      "|    ep_rew_mean      | 65.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12828    |\n",
      "|    fps              | 2863     |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total_timesteps  | 734099   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.31     |\n",
      "|    n_updates        | 183499   |\n",
      "----------------------------------\n",
      "Episode reward: 31.823209\n",
      "Episode reward: 83.339053\n",
      "Episode reward: 49.822317\n",
      "Episode reward: 139.508127\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.3     |\n",
      "|    ep_rew_mean      | 65.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12832    |\n",
      "|    fps              | 2863     |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total_timesteps  | 734429   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.01     |\n",
      "|    n_updates        | 183582   |\n",
      "----------------------------------\n",
      "Episode reward: 37.879289\n",
      "Episode reward: 58.272357\n",
      "Episode reward: 81.278782\n",
      "Episode reward: 47.803831\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.2     |\n",
      "|    ep_rew_mean      | 65.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12836    |\n",
      "|    fps              | 2862     |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total_timesteps  | 734656   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.127    |\n",
      "|    n_updates        | 183638   |\n",
      "----------------------------------\n",
      "Episode reward: 57.433568\n",
      "Episode reward: 46.788364\n",
      "Episode reward: 60.787\n",
      "Episode reward: 39.85401\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12840    |\n",
      "|    fps              | 2862     |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total_timesteps  | 734862   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0438   |\n",
      "|    n_updates        | 183690   |\n",
      "----------------------------------\n",
      "Episode reward: 103.066035\n",
      "Episode reward: 141.361239\n",
      "Episode reward: 54.168462\n",
      "Episode reward: 51.801602\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12844    |\n",
      "|    fps              | 2862     |\n",
      "|    time_elapsed     | 256      |\n",
      "|    total_timesteps  | 735222   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0378   |\n",
      "|    n_updates        | 183780   |\n",
      "----------------------------------\n",
      "Episode reward: 37.762279\n",
      "Episode reward: 109.240902\n",
      "Episode reward: 73.092393\n",
      "Episode reward: 55.922045\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.1     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12848    |\n",
      "|    fps              | 2861     |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total_timesteps  | 735504   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0236   |\n",
      "|    n_updates        | 183850   |\n",
      "----------------------------------\n",
      "Episode reward: 50.902908\n",
      "Episode reward: 65.445954\n",
      "Episode reward: 28.80712\n",
      "Episode reward: 63.573189\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.9     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12852    |\n",
      "|    fps              | 2861     |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total_timesteps  | 735715   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.84     |\n",
      "|    n_updates        | 183903   |\n",
      "----------------------------------\n",
      "Episode reward: 58.250994\n",
      "Episode reward: 40.914153\n",
      "Episode reward: 32.798414\n",
      "Episode reward: 123.408445\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.3     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12856    |\n",
      "|    fps              | 2860     |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total_timesteps  | 735977   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.402    |\n",
      "|    n_updates        | 183969   |\n",
      "----------------------------------\n",
      "Episode reward: 69.090433\n",
      "Episode reward: 35.935471\n",
      "Episode reward: 88.521659\n",
      "Episode reward: 37.838461\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.1     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12860    |\n",
      "|    fps              | 2860     |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total_timesteps  | 736210   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0737   |\n",
      "|    n_updates        | 184027   |\n",
      "----------------------------------\n",
      "Episode reward: 30.697579\n",
      "Episode reward: 58.382225\n",
      "Episode reward: 61.144912\n",
      "Episode reward: 51.705131\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12864    |\n",
      "|    fps              | 2860     |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total_timesteps  | 736414   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.04     |\n",
      "|    n_updates        | 184078   |\n",
      "----------------------------------\n",
      "Episode reward: 54.835579\n",
      "Episode reward: 50.500748\n",
      "Episode reward: 32.725656\n",
      "Episode reward: 31.86011\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12868    |\n",
      "|    fps              | 2860     |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total_timesteps  | 736585   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.35     |\n",
      "|    n_updates        | 184121   |\n",
      "----------------------------------\n",
      "Episode reward: 45.875014\n",
      "Episode reward: 101.429351\n",
      "Episode reward: 41.894024\n",
      "Episode reward: 36.944906\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12872    |\n",
      "|    fps              | 2859     |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total_timesteps  | 736814   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.68     |\n",
      "|    n_updates        | 184178   |\n",
      "----------------------------------\n",
      "Episode reward: 43.76261\n",
      "Episode reward: 29.936435\n",
      "Episode reward: 47.8862\n",
      "Episode reward: 70.758089\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12876    |\n",
      "|    fps              | 2859     |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total_timesteps  | 737008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.485    |\n",
      "|    n_updates        | 184226   |\n",
      "----------------------------------\n",
      "Episode reward: 54.818055\n",
      "Episode reward: 63.687217\n",
      "Episode reward: 61.661777\n",
      "Episode reward: 33.926375\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12880    |\n",
      "|    fps              | 2859     |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total_timesteps  | 737223   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0339   |\n",
      "|    n_updates        | 184280   |\n",
      "----------------------------------\n",
      "Episode reward: 64.33626\n",
      "Episode reward: 58.775105\n",
      "Episode reward: 66.544276\n",
      "Episode reward: 27.724417\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12884    |\n",
      "|    fps              | 2859     |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total_timesteps  | 737444   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0498   |\n",
      "|    n_updates        | 184335   |\n",
      "----------------------------------\n",
      "Episode reward: 43.415796\n",
      "Episode reward: 35.917326\n",
      "Episode reward: 52.837707\n",
      "Episode reward: 69.667263\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12888    |\n",
      "|    fps              | 2859     |\n",
      "|    time_elapsed     | 257      |\n",
      "|    total_timesteps  | 737647   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0351   |\n",
      "|    n_updates        | 184386   |\n",
      "----------------------------------\n",
      "Episode reward: 73.422369\n",
      "Episode reward: 48.672628\n",
      "Episode reward: 84.145859\n",
      "Episode reward: 58.335606\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12892    |\n",
      "|    fps              | 2858     |\n",
      "|    time_elapsed     | 258      |\n",
      "|    total_timesteps  | 737915   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 184453   |\n",
      "----------------------------------\n",
      "Episode reward: 104.493732\n",
      "Episode reward: 74.207584\n",
      "Episode reward: 70.561315\n",
      "Episode reward: 114.463159\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12896    |\n",
      "|    fps              | 2858     |\n",
      "|    time_elapsed     | 258      |\n",
      "|    total_timesteps  | 738287   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.476    |\n",
      "|    n_updates        | 184546   |\n",
      "----------------------------------\n",
      "Episode reward: 59.72308\n",
      "Episode reward: 105.621326\n",
      "Episode reward: 47.896789\n",
      "Episode reward: 73.494163\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12900    |\n",
      "|    fps              | 2858     |\n",
      "|    time_elapsed     | 258      |\n",
      "|    total_timesteps  | 738577   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 184619   |\n",
      "----------------------------------\n",
      "Episode reward: 69.581733\n",
      "Episode reward: 71.188663\n",
      "Episode reward: 48.791788\n",
      "Episode reward: 122.920335\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12904    |\n",
      "|    fps              | 2858     |\n",
      "|    time_elapsed     | 258      |\n",
      "|    total_timesteps  | 738893   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.944    |\n",
      "|    n_updates        | 184698   |\n",
      "----------------------------------\n",
      "Episode reward: 93.642767\n",
      "Episode reward: 76.238536\n",
      "Episode reward: 42.916969\n",
      "Episode reward: 84.942035\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 61.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12908    |\n",
      "|    fps              | 2857     |\n",
      "|    time_elapsed     | 258      |\n",
      "|    total_timesteps  | 739206   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.06     |\n",
      "|    n_updates        | 184776   |\n",
      "----------------------------------\n",
      "Episode reward: 70.459422\n",
      "Episode reward: 34.811477\n",
      "Episode reward: 81.596801\n",
      "Episode reward: 44.714993\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12912    |\n",
      "|    fps              | 2857     |\n",
      "|    time_elapsed     | 258      |\n",
      "|    total_timesteps  | 739442   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.046    |\n",
      "|    n_updates        | 184835   |\n",
      "----------------------------------\n",
      "Episode reward: 28.891389\n",
      "Episode reward: 27.931968\n",
      "Episode reward: 54.821911\n",
      "Episode reward: 72.48437\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12916    |\n",
      "|    fps              | 2857     |\n",
      "|    time_elapsed     | 258      |\n",
      "|    total_timesteps  | 739627   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0457   |\n",
      "|    n_updates        | 184881   |\n",
      "----------------------------------\n",
      "Episode reward: 48.83144\n",
      "Episode reward: 49.896156\n",
      "Episode reward: 34.931914\n",
      "Episode reward: 33.76027\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12920    |\n",
      "|    fps              | 2857     |\n",
      "|    time_elapsed     | 258      |\n",
      "|    total_timesteps  | 739795   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.77     |\n",
      "|    n_updates        | 184923   |\n",
      "----------------------------------\n",
      "Episode reward: 54.344227\n",
      "Episode reward: 32.751234\n",
      "Episode reward: 39.899329\n",
      "Episode reward: 58.796118\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12924    |\n",
      "|    fps              | 2857     |\n",
      "|    time_elapsed     | 258      |\n",
      "|    total_timesteps  | 739982   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0346   |\n",
      "|    n_updates        | 184970   |\n",
      "----------------------------------\n",
      "Episode reward: 62.504511\n",
      "Episode reward: 66.716158\n",
      "Episode reward: 83.303444\n",
      "Episode reward: 35.894196\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12928    |\n",
      "|    fps              | 2857     |\n",
      "|    time_elapsed     | 259      |\n",
      "|    total_timesteps  | 740233   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0397   |\n",
      "|    n_updates        | 185033   |\n",
      "----------------------------------\n",
      "Episode reward: 115.034837\n",
      "Episode reward: 87.814966\n",
      "Episode reward: 178.937118\n",
      "Episode reward: 65.427815\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.6     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12932    |\n",
      "|    fps              | 2857     |\n",
      "|    time_elapsed     | 259      |\n",
      "|    total_timesteps  | 740686   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.35     |\n",
      "|    n_updates        | 185146   |\n",
      "----------------------------------\n",
      "Episode reward: 70.595832\n",
      "Episode reward: 29.939124\n",
      "Episode reward: 83.684142\n",
      "Episode reward: 48.802693\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.6     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12936    |\n",
      "|    fps              | 2857     |\n",
      "|    time_elapsed     | 259      |\n",
      "|    total_timesteps  | 740921   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.29     |\n",
      "|    n_updates        | 185205   |\n",
      "----------------------------------\n",
      "Episode reward: 32.818512\n",
      "Episode reward: 42.653758\n",
      "Episode reward: 73.346774\n",
      "Episode reward: 30.736969\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12940    |\n",
      "|    fps              | 2856     |\n",
      "|    time_elapsed     | 259      |\n",
      "|    total_timesteps  | 741102   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.01     |\n",
      "|    n_updates        | 185250   |\n",
      "----------------------------------\n",
      "Episode reward: 68.669372\n",
      "Episode reward: 52.621684\n",
      "Episode reward: 46.475733\n",
      "Episode reward: 56.262262\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12944    |\n",
      "|    fps              | 2856     |\n",
      "|    time_elapsed     | 259      |\n",
      "|    total_timesteps  | 741328   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0588   |\n",
      "|    n_updates        | 185306   |\n",
      "----------------------------------\n",
      "Episode reward: 79.454453\n",
      "Episode reward: 48.854318\n",
      "Episode reward: 48.840756\n",
      "Episode reward: 34.81264\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12948    |\n",
      "|    fps              | 2856     |\n",
      "|    time_elapsed     | 259      |\n",
      "|    total_timesteps  | 741541   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.66     |\n",
      "|    n_updates        | 185360   |\n",
      "----------------------------------\n",
      "Episode reward: 70.674779\n",
      "Episode reward: 28.860885\n",
      "Episode reward: 35.473862\n",
      "Episode reward: 69.358193\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12952    |\n",
      "|    fps              | 2856     |\n",
      "|    time_elapsed     | 259      |\n",
      "|    total_timesteps  | 741749   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0431   |\n",
      "|    n_updates        | 185412   |\n",
      "----------------------------------\n",
      "Episode reward: 53.67859\n",
      "Episode reward: 59.744322\n",
      "Episode reward: 48.711635\n",
      "Episode reward: 73.414944\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12956    |\n",
      "|    fps              | 2856     |\n",
      "|    time_elapsed     | 259      |\n",
      "|    total_timesteps  | 741986   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0445   |\n",
      "|    n_updates        | 185471   |\n",
      "----------------------------------\n",
      "Episode reward: 34.940635\n",
      "Episode reward: 35.857363\n",
      "Episode reward: 74.422557\n",
      "Episode reward: 50.696414\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12960    |\n",
      "|    fps              | 2856     |\n",
      "|    time_elapsed     | 259      |\n",
      "|    total_timesteps  | 742187   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.4      |\n",
      "|    n_updates        | 185521   |\n",
      "----------------------------------\n",
      "Episode reward: 30.642354\n",
      "Episode reward: 31.852986\n",
      "Episode reward: 44.748532\n",
      "Episode reward: 43.900028\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12964    |\n",
      "|    fps              | 2855     |\n",
      "|    time_elapsed     | 259      |\n",
      "|    total_timesteps  | 742339   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0535   |\n",
      "|    n_updates        | 185559   |\n",
      "----------------------------------\n",
      "Episode reward: 33.934397\n",
      "Episode reward: 53.707062\n",
      "Episode reward: 31.82396\n",
      "Episode reward: 107.692199\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12968    |\n",
      "|    fps              | 2855     |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total_timesteps  | 742568   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.18     |\n",
      "|    n_updates        | 185616   |\n",
      "----------------------------------\n",
      "Episode reward: 27.814832\n",
      "Episode reward: 54.742484\n",
      "Episode reward: 63.600007\n",
      "Episode reward: 50.86341\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12972    |\n",
      "|    fps              | 2855     |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total_timesteps  | 742766   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.121    |\n",
      "|    n_updates        | 185666   |\n",
      "----------------------------------\n",
      "Episode reward: 101.285815\n",
      "Episode reward: 49.776015\n",
      "Episode reward: 39.815829\n",
      "Episode reward: 60.1137\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12976    |\n",
      "|    fps              | 2855     |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total_timesteps  | 743031   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.231    |\n",
      "|    n_updates        | 185732   |\n",
      "----------------------------------\n",
      "Episode reward: 60.434705\n",
      "Episode reward: 53.280815\n",
      "Episode reward: 93.989734\n",
      "Episode reward: 55.526494\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12980    |\n",
      "|    fps              | 2855     |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total_timesteps  | 743298   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0524   |\n",
      "|    n_updates        | 185799   |\n",
      "----------------------------------\n",
      "Episode reward: 104.159465\n",
      "Episode reward: 30.872555\n",
      "Episode reward: 75.469315\n",
      "Episode reward: 70.682874\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12984    |\n",
      "|    fps              | 2854     |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total_timesteps  | 743584   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0395   |\n",
      "|    n_updates        | 185870   |\n",
      "----------------------------------\n",
      "Episode reward: 38.942111\n",
      "Episode reward: 62.51431\n",
      "Episode reward: 37.866495\n",
      "Episode reward: 73.487641\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12988    |\n",
      "|    fps              | 2854     |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total_timesteps  | 743798   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0578   |\n",
      "|    n_updates        | 185924   |\n",
      "----------------------------------\n",
      "Episode reward: 32.949303\n",
      "Episode reward: 64.754268\n",
      "Episode reward: 112.625842\n",
      "Episode reward: 89.721644\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12992    |\n",
      "|    fps              | 2854     |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total_timesteps  | 744107   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0311   |\n",
      "|    n_updates        | 186001   |\n",
      "----------------------------------\n",
      "Episode reward: 68.667779\n",
      "Episode reward: 37.304763\n",
      "Episode reward: 37.869938\n",
      "Episode reward: 49.819778\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 12996    |\n",
      "|    fps              | 2854     |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total_timesteps  | 744302   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0325   |\n",
      "|    n_updates        | 186050   |\n",
      "----------------------------------\n",
      "Episode reward: 99.263092\n",
      "Episode reward: 29.813661\n",
      "Episode reward: 48.870152\n",
      "Episode reward: 79.722547\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13000    |\n",
      "|    fps              | 2854     |\n",
      "|    time_elapsed     | 260      |\n",
      "|    total_timesteps  | 744563   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.039    |\n",
      "|    n_updates        | 186115   |\n",
      "----------------------------------\n",
      "Episode reward: 36.71426\n",
      "Episode reward: 34.701221\n",
      "Episode reward: 56.749865\n",
      "Episode reward: 148.014008\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13004    |\n",
      "|    fps              | 2853     |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total_timesteps  | 744865   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.68     |\n",
      "|    n_updates        | 186191   |\n",
      "----------------------------------\n",
      "Episode reward: 59.789257\n",
      "Episode reward: 24.928755\n",
      "Episode reward: 103.351105\n",
      "Episode reward: 89.12843\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13008    |\n",
      "|    fps              | 2852     |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total_timesteps  | 745144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0278   |\n",
      "|    n_updates        | 186260   |\n",
      "----------------------------------\n",
      "Episode reward: 68.55525\n",
      "Episode reward: 35.745214\n",
      "Episode reward: 35.765887\n",
      "Episode reward: 96.124853\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13012    |\n",
      "|    fps              | 2852     |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total_timesteps  | 745386   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.516    |\n",
      "|    n_updates        | 186321   |\n",
      "----------------------------------\n",
      "Episode reward: 44.838972\n",
      "Episode reward: 72.458715\n",
      "Episode reward: 41.456316\n",
      "Episode reward: 42.924273\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13016    |\n",
      "|    fps              | 2852     |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total_timesteps  | 745590   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.748    |\n",
      "|    n_updates        | 186372   |\n",
      "----------------------------------\n",
      "Episode reward: 53.813496\n",
      "Episode reward: 53.859035\n",
      "Episode reward: 35.834405\n",
      "Episode reward: 46.903689\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13020    |\n",
      "|    fps              | 2852     |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total_timesteps  | 745781   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0172   |\n",
      "|    n_updates        | 186420   |\n",
      "----------------------------------\n",
      "Episode reward: 105.218334\n",
      "Episode reward: 43.825314\n",
      "Episode reward: 32.937418\n",
      "Episode reward: 29.923972\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13024    |\n",
      "|    fps              | 2852     |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total_timesteps  | 746009   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0357   |\n",
      "|    n_updates        | 186477   |\n",
      "----------------------------------\n",
      "Episode reward: 64.761684\n",
      "Episode reward: 46.635118\n",
      "Episode reward: 71.65723\n",
      "Episode reward: 109.665088\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13028    |\n",
      "|    fps              | 2852     |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total_timesteps  | 746305   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0426   |\n",
      "|    n_updates        | 186551   |\n",
      "----------------------------------\n",
      "Episode reward: 64.531052\n",
      "Episode reward: 64.500653\n",
      "Episode reward: 86.657999\n",
      "Episode reward: 150.399435\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13032    |\n",
      "|    fps              | 2852     |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total_timesteps  | 746706   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0419   |\n",
      "|    n_updates        | 186651   |\n",
      "----------------------------------\n",
      "Episode reward: 41.714877\n",
      "Episode reward: 45.629021\n",
      "Episode reward: 28.672563\n",
      "Episode reward: 71.129762\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13036    |\n",
      "|    fps              | 2852     |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total_timesteps  | 746895   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0375   |\n",
      "|    n_updates        | 186698   |\n",
      "----------------------------------\n",
      "Episode reward: 110.970124\n",
      "Episode reward: 143.000209\n",
      "Episode reward: 62.425557\n",
      "Episode reward: 126.329045\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13040    |\n",
      "|    fps              | 2851     |\n",
      "|    time_elapsed     | 262      |\n",
      "|    total_timesteps  | 747386   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0425   |\n",
      "|    n_updates        | 186821   |\n",
      "----------------------------------\n",
      "Episode reward: 83.226368\n",
      "Episode reward: 77.646809\n",
      "Episode reward: 101.119445\n",
      "Episode reward: 35.929553\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13044    |\n",
      "|    fps              | 2851     |\n",
      "|    time_elapsed     | 262      |\n",
      "|    total_timesteps  | 747688   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.32     |\n",
      "|    n_updates        | 186896   |\n",
      "----------------------------------\n",
      "Episode reward: 56.381695\n",
      "Episode reward: 129.577837\n",
      "Episode reward: 72.31395\n",
      "Episode reward: 71.66286\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13048    |\n",
      "|    fps              | 2851     |\n",
      "|    time_elapsed     | 262      |\n",
      "|    total_timesteps  | 748021   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.58     |\n",
      "|    n_updates        | 186980   |\n",
      "----------------------------------\n",
      "Episode reward: 61.721935\n",
      "Episode reward: 52.552748\n",
      "Episode reward: 115.287553\n",
      "Episode reward: 33.77816\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.5     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13052    |\n",
      "|    fps              | 2851     |\n",
      "|    time_elapsed     | 262      |\n",
      "|    total_timesteps  | 748296   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0494   |\n",
      "|    n_updates        | 187048   |\n",
      "----------------------------------\n",
      "Episode reward: 43.839064\n",
      "Episode reward: 76.398883\n",
      "Episode reward: 67.259671\n",
      "Episode reward: 111.717425\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.2     |\n",
      "|    ep_rew_mean      | 64       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13056    |\n",
      "|    fps              | 2851     |\n",
      "|    time_elapsed     | 262      |\n",
      "|    total_timesteps  | 748605   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.09     |\n",
      "|    n_updates        | 187126   |\n",
      "----------------------------------\n",
      "Episode reward: 116.458527\n",
      "Episode reward: 163.466808\n",
      "Episode reward: 84.130733\n",
      "Episode reward: 37.761029\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.4     |\n",
      "|    ep_rew_mean      | 66.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13060    |\n",
      "|    fps              | 2851     |\n",
      "|    time_elapsed     | 262      |\n",
      "|    total_timesteps  | 749027   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0349   |\n",
      "|    n_updates        | 187231   |\n",
      "----------------------------------\n",
      "Episode reward: 81.393644\n",
      "Episode reward: 38.824131\n",
      "Episode reward: 49.832663\n",
      "Episode reward: 55.722541\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.2     |\n",
      "|    ep_rew_mean      | 66.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13064    |\n",
      "|    fps              | 2851     |\n",
      "|    time_elapsed     | 262      |\n",
      "|    total_timesteps  | 749256   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0332   |\n",
      "|    n_updates        | 187288   |\n",
      "----------------------------------\n",
      "Episode reward: 99.207941\n",
      "Episode reward: 64.671563\n",
      "Episode reward: 31.899804\n",
      "Episode reward: 28.675298\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.1     |\n",
      "|    ep_rew_mean      | 66.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13068    |\n",
      "|    fps              | 2850     |\n",
      "|    time_elapsed     | 262      |\n",
      "|    total_timesteps  | 749482   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.31     |\n",
      "|    n_updates        | 187345   |\n",
      "----------------------------------\n",
      "Episode reward: 61.565164\n",
      "Episode reward: 75.849703\n",
      "Episode reward: 77.446992\n",
      "Episode reward: 51.796905\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.9     |\n",
      "|    ep_rew_mean      | 67.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13072    |\n",
      "|    fps              | 2850     |\n",
      "|    time_elapsed     | 263      |\n",
      "|    total_timesteps  | 749752   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0301   |\n",
      "|    n_updates        | 187412   |\n",
      "----------------------------------\n",
      "Episode reward: 31.743963\n",
      "Episode reward: 44.853942\n",
      "Episode reward: 62.264819\n",
      "Episode reward: 69.431903\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.3     |\n",
      "|    ep_rew_mean      | 67.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13076    |\n",
      "|    fps              | 2850     |\n",
      "|    time_elapsed     | 263      |\n",
      "|    total_timesteps  | 749962   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0235   |\n",
      "|    n_updates        | 187465   |\n",
      "----------------------------------\n",
      "Episode reward: 82.184854\n",
      "Episode reward: 122.234697\n",
      "Episode reward: 68.585315\n",
      "Episode reward: 48.459636\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70       |\n",
      "|    ep_rew_mean      | 67.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13080    |\n",
      "|    fps              | 2850     |\n",
      "|    time_elapsed     | 263      |\n",
      "|    total_timesteps  | 750293   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.19     |\n",
      "|    n_updates        | 187548   |\n",
      "----------------------------------\n",
      "Episode reward: 44.297844\n",
      "Episode reward: 72.597357\n",
      "Episode reward: 72.572388\n",
      "Episode reward: 43.700617\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.4     |\n",
      "|    ep_rew_mean      | 67.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13084    |\n",
      "|    fps              | 2850     |\n",
      "|    time_elapsed     | 263      |\n",
      "|    total_timesteps  | 750528   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0447   |\n",
      "|    n_updates        | 187606   |\n",
      "----------------------------------\n",
      "Episode reward: 48.309919\n",
      "Episode reward: 84.445023\n",
      "Episode reward: 108.91587\n",
      "Episode reward: 83.534067\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.7     |\n",
      "|    ep_rew_mean      | 68.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13088    |\n",
      "|    fps              | 2850     |\n",
      "|    time_elapsed     | 263      |\n",
      "|    total_timesteps  | 750865   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.182    |\n",
      "|    n_updates        | 187691   |\n",
      "----------------------------------\n",
      "Episode reward: 32.814884\n",
      "Episode reward: 39.936152\n",
      "Episode reward: 48.806928\n",
      "Episode reward: 27.745426\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.1     |\n",
      "|    ep_rew_mean      | 66.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13092    |\n",
      "|    fps              | 2850     |\n",
      "|    time_elapsed     | 263      |\n",
      "|    total_timesteps  | 751015   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.632    |\n",
      "|    n_updates        | 187728   |\n",
      "----------------------------------\n",
      "Episode reward: 60.787819\n",
      "Episode reward: 88.803688\n",
      "Episode reward: 55.661241\n",
      "Episode reward: 116.3684\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.6     |\n",
      "|    ep_rew_mean      | 68.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13096    |\n",
      "|    fps              | 2849     |\n",
      "|    time_elapsed     | 263      |\n",
      "|    total_timesteps  | 751364   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0839   |\n",
      "|    n_updates        | 187815   |\n",
      "----------------------------------\n",
      "Episode reward: 31.716214\n",
      "Episode reward: 42.895522\n",
      "Episode reward: 57.564666\n",
      "Episode reward: 45.903695\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.8     |\n",
      "|    ep_rew_mean      | 67.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13100    |\n",
      "|    fps              | 2849     |\n",
      "|    time_elapsed     | 263      |\n",
      "|    total_timesteps  | 751543   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0525   |\n",
      "|    n_updates        | 187860   |\n",
      "----------------------------------\n",
      "Episode reward: 59.753671\n",
      "Episode reward: 51.649997\n",
      "Episode reward: 37.785434\n",
      "Episode reward: 38.880583\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.7     |\n",
      "|    ep_rew_mean      | 66.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13104    |\n",
      "|    fps              | 2849     |\n",
      "|    time_elapsed     | 263      |\n",
      "|    total_timesteps  | 751733   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0367   |\n",
      "|    n_updates        | 187908   |\n",
      "----------------------------------\n",
      "Episode reward: 70.331833\n",
      "Episode reward: 73.612716\n",
      "Episode reward: 88.142525\n",
      "Episode reward: 133.852443\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.6     |\n",
      "|    ep_rew_mean      | 67.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13108    |\n",
      "|    fps              | 2849     |\n",
      "|    time_elapsed     | 263      |\n",
      "|    total_timesteps  | 752107   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0456   |\n",
      "|    n_updates        | 188001   |\n",
      "----------------------------------\n",
      "Episode reward: 74.743992\n",
      "Episode reward: 73.84137\n",
      "Episode reward: 67.764693\n",
      "Episode reward: 38.889409\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.8     |\n",
      "|    ep_rew_mean      | 67.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13112    |\n",
      "|    fps              | 2849     |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total_timesteps  | 752365   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0612   |\n",
      "|    n_updates        | 188066   |\n",
      "----------------------------------\n",
      "Episode reward: 107.614986\n",
      "Episode reward: 69.336252\n",
      "Episode reward: 44.786872\n",
      "Episode reward: 73.046808\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.8     |\n",
      "|    ep_rew_mean      | 68.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13116    |\n",
      "|    fps              | 2849     |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total_timesteps  | 752670   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.622    |\n",
      "|    n_updates        | 188142   |\n",
      "----------------------------------\n",
      "Episode reward: 31.890813\n",
      "Episode reward: 26.764085\n",
      "Episode reward: 70.329189\n",
      "Episode reward: 90.770527\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71.1     |\n",
      "|    ep_rew_mean      | 68.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13120    |\n",
      "|    fps              | 2849     |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total_timesteps  | 752892   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0478   |\n",
      "|    n_updates        | 188197   |\n",
      "----------------------------------\n",
      "Episode reward: 31.91268\n",
      "Episode reward: 112.870849\n",
      "Episode reward: 48.912316\n",
      "Episode reward: 49.815039\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 71.3     |\n",
      "|    ep_rew_mean      | 69       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13124    |\n",
      "|    fps              | 2849     |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total_timesteps  | 753137   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.643    |\n",
      "|    n_updates        | 188259   |\n",
      "----------------------------------\n",
      "Episode reward: 45.90076\n",
      "Episode reward: 90.645801\n",
      "Episode reward: 71.682276\n",
      "Episode reward: 42.597643\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 70.8     |\n",
      "|    ep_rew_mean      | 68.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13128    |\n",
      "|    fps              | 2849     |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total_timesteps  | 753390   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.64     |\n",
      "|    n_updates        | 188322   |\n",
      "----------------------------------\n",
      "Episode reward: 43.793163\n",
      "Episode reward: 36.91512\n",
      "Episode reward: 50.594319\n",
      "Episode reward: 38.9139\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.5     |\n",
      "|    ep_rew_mean      | 66.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13132    |\n",
      "|    fps              | 2849     |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total_timesteps  | 753561   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0401   |\n",
      "|    n_updates        | 188365   |\n",
      "----------------------------------\n",
      "Episode reward: 32.948307\n",
      "Episode reward: 63.528938\n",
      "Episode reward: 47.840024\n",
      "Episode reward: 46.824494\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.6     |\n",
      "|    ep_rew_mean      | 66.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13136    |\n",
      "|    fps              | 2849     |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total_timesteps  | 753754   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.75     |\n",
      "|    n_updates        | 188413   |\n",
      "----------------------------------\n",
      "Episode reward: 125.421638\n",
      "Episode reward: 56.85964\n",
      "Episode reward: 98.117711\n",
      "Episode reward: 54.767081\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67       |\n",
      "|    ep_rew_mean      | 65.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13140    |\n",
      "|    fps              | 2849     |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total_timesteps  | 754091   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.56     |\n",
      "|    n_updates        | 188497   |\n",
      "----------------------------------\n",
      "Episode reward: 51.856303\n",
      "Episode reward: 45.915862\n",
      "Episode reward: 45.81534\n",
      "Episode reward: 39.739363\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.9     |\n",
      "|    ep_rew_mean      | 64.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13144    |\n",
      "|    fps              | 2848     |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total_timesteps  | 754276   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0491   |\n",
      "|    n_updates        | 188543   |\n",
      "----------------------------------\n",
      "Episode reward: 32.664406\n",
      "Episode reward: 54.622562\n",
      "Episode reward: 57.601639\n",
      "Episode reward: 39.915086\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13148    |\n",
      "|    fps              | 2848     |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total_timesteps  | 754462   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0356   |\n",
      "|    n_updates        | 188590   |\n",
      "----------------------------------\n",
      "Episode reward: 61.462824\n",
      "Episode reward: 122.865821\n",
      "Episode reward: 69.007598\n",
      "Episode reward: 53.82247\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13152    |\n",
      "|    fps              | 2848     |\n",
      "|    time_elapsed     | 264      |\n",
      "|    total_timesteps  | 754772   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.01     |\n",
      "|    n_updates        | 188667   |\n",
      "----------------------------------\n",
      "Episode reward: 81.546125\n",
      "Episode reward: 45.519782\n",
      "Episode reward: 84.066179\n",
      "Episode reward: 32.746596\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13156    |\n",
      "|    fps              | 2848     |\n",
      "|    time_elapsed     | 265      |\n",
      "|    total_timesteps  | 755020   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.56     |\n",
      "|    n_updates        | 188729   |\n",
      "----------------------------------\n",
      "Episode reward: 47.830142\n",
      "Episode reward: 63.619442\n",
      "Episode reward: 57.296064\n",
      "Episode reward: 72.655259\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13160    |\n",
      "|    fps              | 2848     |\n",
      "|    time_elapsed     | 265      |\n",
      "|    total_timesteps  | 755263   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0518   |\n",
      "|    n_updates        | 188790   |\n",
      "----------------------------------\n",
      "Episode reward: 120.64966\n",
      "Episode reward: 34.934026\n",
      "Episode reward: 46.62173\n",
      "Episode reward: 60.465445\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13164    |\n",
      "|    fps              | 2847     |\n",
      "|    time_elapsed     | 265      |\n",
      "|    total_timesteps  | 755549   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.7      |\n",
      "|    n_updates        | 188862   |\n",
      "----------------------------------\n",
      "Episode reward: 54.778215\n",
      "Episode reward: 206.025896\n",
      "Episode reward: 91.703244\n",
      "Episode reward: 42.617992\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.7     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13168    |\n",
      "|    fps              | 2847     |\n",
      "|    time_elapsed     | 265      |\n",
      "|    total_timesteps  | 755950   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0672   |\n",
      "|    n_updates        | 188962   |\n",
      "----------------------------------\n",
      "Episode reward: 93.67441\n",
      "Episode reward: 87.268667\n",
      "Episode reward: 64.594087\n",
      "Episode reward: 37.932828\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13172    |\n",
      "|    fps              | 2847     |\n",
      "|    time_elapsed     | 265      |\n",
      "|    total_timesteps  | 756236   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.047    |\n",
      "|    n_updates        | 189033   |\n",
      "----------------------------------\n",
      "Episode reward: 64.389055\n",
      "Episode reward: 94.042968\n",
      "Episode reward: 28.626652\n",
      "Episode reward: 50.763734\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.2     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13176    |\n",
      "|    fps              | 2847     |\n",
      "|    time_elapsed     | 265      |\n",
      "|    total_timesteps  | 756477   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.334    |\n",
      "|    n_updates        | 189094   |\n",
      "----------------------------------\n",
      "Episode reward: 44.88669\n",
      "Episode reward: 34.778165\n",
      "Episode reward: 49.788937\n",
      "Episode reward: 41.926275\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13180    |\n",
      "|    fps              | 2847     |\n",
      "|    time_elapsed     | 265      |\n",
      "|    total_timesteps  | 756649   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0509   |\n",
      "|    n_updates        | 189137   |\n",
      "----------------------------------\n",
      "Episode reward: 93.425664\n",
      "Episode reward: 58.806705\n",
      "Episode reward: 47.746368\n",
      "Episode reward: 80.775682\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13184    |\n",
      "|    fps              | 2847     |\n",
      "|    time_elapsed     | 265      |\n",
      "|    total_timesteps  | 756932   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 189207   |\n",
      "----------------------------------\n",
      "Episode reward: 44.878961\n",
      "Episode reward: 71.39871\n",
      "Episode reward: 55.603893\n",
      "Episode reward: 148.92013\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13188    |\n",
      "|    fps              | 2847     |\n",
      "|    time_elapsed     | 265      |\n",
      "|    total_timesteps  | 757268   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0631   |\n",
      "|    n_updates        | 189291   |\n",
      "----------------------------------\n",
      "Episode reward: 26.950873\n",
      "Episode reward: 42.913373\n",
      "Episode reward: 85.122228\n",
      "Episode reward: 63.972354\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13192    |\n",
      "|    fps              | 2846     |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total_timesteps  | 757490   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0369   |\n",
      "|    n_updates        | 189347   |\n",
      "----------------------------------\n",
      "Episode reward: 91.796462\n",
      "Episode reward: 129.987283\n",
      "Episode reward: 29.849769\n",
      "Episode reward: 80.579378\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13196    |\n",
      "|    fps              | 2846     |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total_timesteps  | 757828   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0795   |\n",
      "|    n_updates        | 189431   |\n",
      "----------------------------------\n",
      "Episode reward: 54.682585\n",
      "Episode reward: 114.963153\n",
      "Episode reward: 55.703203\n",
      "Episode reward: 29.911793\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.4     |\n",
      "|    ep_rew_mean      | 64.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13200    |\n",
      "|    fps              | 2846     |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total_timesteps  | 758085   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.219    |\n",
      "|    n_updates        | 189496   |\n",
      "----------------------------------\n",
      "Episode reward: 44.891095\n",
      "Episode reward: 37.656429\n",
      "Episode reward: 54.645956\n",
      "Episode reward: 33.787724\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.2     |\n",
      "|    ep_rew_mean      | 64.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13204    |\n",
      "|    fps              | 2846     |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total_timesteps  | 758257   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 189539   |\n",
      "----------------------------------\n",
      "Episode reward: 47.69875\n",
      "Episode reward: 27.879207\n",
      "Episode reward: 89.233038\n",
      "Episode reward: 77.426492\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13208    |\n",
      "|    fps              | 2846     |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total_timesteps  | 758504   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0429   |\n",
      "|    n_updates        | 189600   |\n",
      "----------------------------------\n",
      "Episode reward: 58.730433\n",
      "Episode reward: 92.433115\n",
      "Episode reward: 96.343515\n",
      "Episode reward: 53.831505\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13212    |\n",
      "|    fps              | 2846     |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total_timesteps  | 758807   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0906   |\n",
      "|    n_updates        | 189676   |\n",
      "----------------------------------\n",
      "Episode reward: 85.35687\n",
      "Episode reward: 77.261503\n",
      "Episode reward: 60.539582\n",
      "Episode reward: 47.869438\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.1     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13216    |\n",
      "|    fps              | 2846     |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total_timesteps  | 759080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0383   |\n",
      "|    n_updates        | 189744   |\n",
      "----------------------------------\n",
      "Episode reward: 54.744866\n",
      "Episode reward: 32.888129\n",
      "Episode reward: 28.789994\n",
      "Episode reward: 31.934781\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13220    |\n",
      "|    fps              | 2846     |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total_timesteps  | 759229   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0401   |\n",
      "|    n_updates        | 189782   |\n",
      "----------------------------------\n",
      "Episode reward: 47.140656\n",
      "Episode reward: 91.654306\n",
      "Episode reward: 66.647127\n",
      "Episode reward: 57.634492\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13224    |\n",
      "|    fps              | 2846     |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total_timesteps  | 759494   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.334    |\n",
      "|    n_updates        | 189848   |\n",
      "----------------------------------\n",
      "Episode reward: 72.142373\n",
      "Episode reward: 32.892708\n",
      "Episode reward: 32.865336\n",
      "Episode reward: 56.613087\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13228    |\n",
      "|    fps              | 2845     |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total_timesteps  | 759690   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.058    |\n",
      "|    n_updates        | 189897   |\n",
      "----------------------------------\n",
      "Episode reward: 68.573542\n",
      "Episode reward: 35.845525\n",
      "Episode reward: 140.826381\n",
      "Episode reward: 53.525704\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13232    |\n",
      "|    fps              | 2845     |\n",
      "|    time_elapsed     | 267      |\n",
      "|    total_timesteps  | 760003   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.831    |\n",
      "|    n_updates        | 189975   |\n",
      "----------------------------------\n",
      "Episode reward: 82.207911\n",
      "Episode reward: 94.286868\n",
      "Episode reward: 115.50136\n",
      "Episode reward: 48.63651\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66       |\n",
      "|    ep_rew_mean      | 64.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13236    |\n",
      "|    fps              | 2845     |\n",
      "|    time_elapsed     | 267      |\n",
      "|    total_timesteps  | 760352   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.088    |\n",
      "|    n_updates        | 190062   |\n",
      "----------------------------------\n",
      "Episode reward: 36.930063\n",
      "Episode reward: 56.464853\n",
      "Episode reward: 61.726809\n",
      "Episode reward: 29.690029\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13240    |\n",
      "|    fps              | 2845     |\n",
      "|    time_elapsed     | 267      |\n",
      "|    total_timesteps  | 760538   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0441   |\n",
      "|    n_updates        | 190109   |\n",
      "----------------------------------\n",
      "Episode reward: 35.651509\n",
      "Episode reward: 74.448507\n",
      "Episode reward: 69.334621\n",
      "Episode reward: 65.620972\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.1     |\n",
      "|    ep_rew_mean      | 64       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13244    |\n",
      "|    fps              | 2845     |\n",
      "|    time_elapsed     | 267      |\n",
      "|    total_timesteps  | 760786   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0671   |\n",
      "|    n_updates        | 190171   |\n",
      "----------------------------------\n",
      "Episode reward: 39.68716\n",
      "Episode reward: 82.645519\n",
      "Episode reward: 48.215474\n",
      "Episode reward: 43.868461\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.4     |\n",
      "|    ep_rew_mean      | 64.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13248    |\n",
      "|    fps              | 2845     |\n",
      "|    time_elapsed     | 267      |\n",
      "|    total_timesteps  | 761003   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0439   |\n",
      "|    n_updates        | 190225   |\n",
      "----------------------------------\n",
      "Episode reward: 95.792135\n",
      "Episode reward: 52.778817\n",
      "Episode reward: 85.806175\n",
      "Episode reward: 44.673729\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.1     |\n",
      "|    ep_rew_mean      | 64       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13252    |\n",
      "|    fps              | 2845     |\n",
      "|    time_elapsed     | 267      |\n",
      "|    total_timesteps  | 761285   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.35     |\n",
      "|    n_updates        | 190296   |\n",
      "----------------------------------\n",
      "Episode reward: 79.127701\n",
      "Episode reward: 35.933033\n",
      "Episode reward: 79.543137\n",
      "Episode reward: 84.092972\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.5     |\n",
      "|    ep_rew_mean      | 64.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13256    |\n",
      "|    fps              | 2845     |\n",
      "|    time_elapsed     | 267      |\n",
      "|    total_timesteps  | 761568   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.566    |\n",
      "|    n_updates        | 190366   |\n",
      "----------------------------------\n",
      "Episode reward: 69.219911\n",
      "Episode reward: 31.705378\n",
      "Episode reward: 26.873773\n",
      "Episode reward: 39.675115\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13260    |\n",
      "|    fps              | 2845     |\n",
      "|    time_elapsed     | 267      |\n",
      "|    total_timesteps  | 761738   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.845    |\n",
      "|    n_updates        | 190409   |\n",
      "----------------------------------\n",
      "Episode reward: 32.950815\n",
      "Episode reward: 47.872721\n",
      "Episode reward: 146.24462\n",
      "Episode reward: 50.866494\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.7     |\n",
      "|    ep_rew_mean      | 63.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13264    |\n",
      "|    fps              | 2845     |\n",
      "|    time_elapsed     | 267      |\n",
      "|    total_timesteps  | 762017   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.93     |\n",
      "|    n_updates        | 190479   |\n",
      "----------------------------------\n",
      "Episode reward: 61.784068\n",
      "Episode reward: 52.554595\n",
      "Episode reward: 32.847742\n",
      "Episode reward: 73.197137\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13268    |\n",
      "|    fps              | 2845     |\n",
      "|    time_elapsed     | 267      |\n",
      "|    total_timesteps  | 762243   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0554   |\n",
      "|    n_updates        | 190535   |\n",
      "----------------------------------\n",
      "Episode reward: 82.467304\n",
      "Episode reward: 86.997929\n",
      "Episode reward: 54.360232\n",
      "Episode reward: 58.594707\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13272    |\n",
      "|    fps              | 2845     |\n",
      "|    time_elapsed     | 268      |\n",
      "|    total_timesteps  | 762528   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0464   |\n",
      "|    n_updates        | 190606   |\n",
      "----------------------------------\n",
      "Episode reward: 52.766414\n",
      "Episode reward: 88.664831\n",
      "Episode reward: 41.630321\n",
      "Episode reward: 202.378641\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13276    |\n",
      "|    fps              | 2844     |\n",
      "|    time_elapsed     | 268      |\n",
      "|    total_timesteps  | 762940   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0536   |\n",
      "|    n_updates        | 190709   |\n",
      "----------------------------------\n",
      "Episode reward: 109.19395\n",
      "Episode reward: 57.809063\n",
      "Episode reward: 48.861661\n",
      "Episode reward: 47.708831\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.6     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13280    |\n",
      "|    fps              | 2844     |\n",
      "|    time_elapsed     | 268      |\n",
      "|    total_timesteps  | 763209   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0719   |\n",
      "|    n_updates        | 190777   |\n",
      "----------------------------------\n",
      "Episode reward: 55.350834\n",
      "Episode reward: 46.734202\n",
      "Episode reward: 49.871647\n",
      "Episode reward: 47.855927\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13284    |\n",
      "|    fps              | 2844     |\n",
      "|    time_elapsed     | 268      |\n",
      "|    total_timesteps  | 763410   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0538   |\n",
      "|    n_updates        | 190827   |\n",
      "----------------------------------\n",
      "Episode reward: 64.809582\n",
      "Episode reward: 40.276523\n",
      "Episode reward: 35.905021\n",
      "Episode reward: 66.600519\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13288    |\n",
      "|    fps              | 2844     |\n",
      "|    time_elapsed     | 268      |\n",
      "|    total_timesteps  | 763619   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.58     |\n",
      "|    n_updates        | 190879   |\n",
      "----------------------------------\n",
      "Episode reward: 110.244409\n",
      "Episode reward: 64.625737\n",
      "Episode reward: 75.661835\n",
      "Episode reward: 61.525935\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13292    |\n",
      "|    fps              | 2844     |\n",
      "|    time_elapsed     | 268      |\n",
      "|    total_timesteps  | 763934   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.922    |\n",
      "|    n_updates        | 190958   |\n",
      "----------------------------------\n",
      "Episode reward: 41.496919\n",
      "Episode reward: 35.926831\n",
      "Episode reward: 81.79532\n",
      "Episode reward: 32.854801\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13296    |\n",
      "|    fps              | 2844     |\n",
      "|    time_elapsed     | 268      |\n",
      "|    total_timesteps  | 764128   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0481   |\n",
      "|    n_updates        | 191006   |\n",
      "----------------------------------\n",
      "Episode reward: 86.504624\n",
      "Episode reward: 52.256287\n",
      "Episode reward: 72.337568\n",
      "Episode reward: 56.616349\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13300    |\n",
      "|    fps              | 2844     |\n",
      "|    time_elapsed     | 268      |\n",
      "|    total_timesteps  | 764400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.34     |\n",
      "|    n_updates        | 191074   |\n",
      "----------------------------------\n",
      "Episode reward: 48.88963\n",
      "Episode reward: 75.667226\n",
      "Episode reward: 64.945397\n",
      "Episode reward: 63.81459\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13304    |\n",
      "|    fps              | 2844     |\n",
      "|    time_elapsed     | 268      |\n",
      "|    total_timesteps  | 764657   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.41     |\n",
      "|    n_updates        | 191139   |\n",
      "----------------------------------\n",
      "Episode reward: 37.795973\n",
      "Episode reward: 40.816417\n",
      "Episode reward: 53.852723\n",
      "Episode reward: 51.812223\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13308    |\n",
      "|    fps              | 2844     |\n",
      "|    time_elapsed     | 268      |\n",
      "|    total_timesteps  | 764842   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.81     |\n",
      "|    n_updates        | 191185   |\n",
      "----------------------------------\n",
      "Episode reward: 106.07601\n",
      "Episode reward: 63.762982\n",
      "Episode reward: 69.939479\n",
      "Episode reward: 60.644872\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13312    |\n",
      "|    fps              | 2844     |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total_timesteps  | 765146   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0602   |\n",
      "|    n_updates        | 191261   |\n",
      "----------------------------------\n",
      "Episode reward: 55.578178\n",
      "Episode reward: 28.942683\n",
      "Episode reward: 35.798797\n",
      "Episode reward: 59.66705\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13316    |\n",
      "|    fps              | 2844     |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total_timesteps  | 765327   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.346    |\n",
      "|    n_updates        | 191306   |\n",
      "----------------------------------\n",
      "Episode reward: 39.715353\n",
      "Episode reward: 67.482026\n",
      "Episode reward: 46.609787\n",
      "Episode reward: 86.811351\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13320    |\n",
      "|    fps              | 2843     |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total_timesteps  | 765573   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.491    |\n",
      "|    n_updates        | 191368   |\n",
      "----------------------------------\n",
      "Episode reward: 64.741833\n",
      "Episode reward: 42.89493\n",
      "Episode reward: 35.913487\n",
      "Episode reward: 40.918139\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.6     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13324    |\n",
      "|    fps              | 2843     |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total_timesteps  | 765758   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.3      |\n",
      "|    n_updates        | 191414   |\n",
      "----------------------------------\n",
      "Episode reward: 42.918714\n",
      "Episode reward: 40.931932\n",
      "Episode reward: 77.907187\n",
      "Episode reward: 60.76102\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 61.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13328    |\n",
      "|    fps              | 2843     |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total_timesteps  | 765983   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.24     |\n",
      "|    n_updates        | 191470   |\n",
      "----------------------------------\n",
      "Episode reward: 72.732157\n",
      "Episode reward: 97.156065\n",
      "Episode reward: 50.72051\n",
      "Episode reward: 33.800394\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13332    |\n",
      "|    fps              | 2843     |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total_timesteps  | 766241   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0389   |\n",
      "|    n_updates        | 191535   |\n",
      "----------------------------------\n",
      "Episode reward: 70.023103\n",
      "Episode reward: 83.321471\n",
      "Episode reward: 43.892794\n",
      "Episode reward: 33.712355\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13336    |\n",
      "|    fps              | 2842     |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total_timesteps  | 766475   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0748   |\n",
      "|    n_updates        | 191593   |\n",
      "----------------------------------\n",
      "Episode reward: 27.775442\n",
      "Episode reward: 71.685176\n",
      "Episode reward: 105.427428\n",
      "Episode reward: 45.828889\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13340    |\n",
      "|    fps              | 2842     |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total_timesteps  | 766729   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0306   |\n",
      "|    n_updates        | 191657   |\n",
      "----------------------------------\n",
      "Episode reward: 78.724875\n",
      "Episode reward: 44.828743\n",
      "Episode reward: 128.184458\n",
      "Episode reward: 48.57547\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13344    |\n",
      "|    fps              | 2842     |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total_timesteps  | 767033   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.47     |\n",
      "|    n_updates        | 191733   |\n",
      "----------------------------------\n",
      "Episode reward: 120.525019\n",
      "Episode reward: 72.69095\n",
      "Episode reward: 98.426211\n",
      "Episode reward: 63.049202\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13348    |\n",
      "|    fps              | 2842     |\n",
      "|    time_elapsed     | 269      |\n",
      "|    total_timesteps  | 767400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0394   |\n",
      "|    n_updates        | 191824   |\n",
      "----------------------------------\n",
      "Episode reward: 55.805927\n",
      "Episode reward: 81.560512\n",
      "Episode reward: 42.844071\n",
      "Episode reward: 89.624868\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13352    |\n",
      "|    fps              | 2841     |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total_timesteps  | 767671   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.15     |\n",
      "|    n_updates        | 191892   |\n",
      "----------------------------------\n",
      "Episode reward: 51.679416\n",
      "Episode reward: 77.438287\n",
      "Episode reward: 66.690658\n",
      "Episode reward: 25.772779\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13356    |\n",
      "|    fps              | 2841     |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total_timesteps  | 767894   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0426   |\n",
      "|    n_updates        | 191948   |\n",
      "----------------------------------\n",
      "Episode reward: 109.977527\n",
      "Episode reward: 59.80818\n",
      "Episode reward: 65.608608\n",
      "Episode reward: 31.62204\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13360    |\n",
      "|    fps              | 2841     |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total_timesteps  | 768164   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0491   |\n",
      "|    n_updates        | 192015   |\n",
      "----------------------------------\n",
      "Episode reward: 60.844426\n",
      "Episode reward: 66.685438\n",
      "Episode reward: 57.837683\n",
      "Episode reward: 53.687479\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13364    |\n",
      "|    fps              | 2841     |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total_timesteps  | 768404   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0999   |\n",
      "|    n_updates        | 192075   |\n",
      "----------------------------------\n",
      "Episode reward: 50.824349\n",
      "Episode reward: 64.589494\n",
      "Episode reward: 107.30652\n",
      "Episode reward: 43.67965\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13368    |\n",
      "|    fps              | 2841     |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total_timesteps  | 768674   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0261   |\n",
      "|    n_updates        | 192143   |\n",
      "----------------------------------\n",
      "Episode reward: 95.991132\n",
      "Episode reward: 76.183982\n",
      "Episode reward: 41.897417\n",
      "Episode reward: 89.775622\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13372    |\n",
      "|    fps              | 2841     |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total_timesteps  | 768983   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.431    |\n",
      "|    n_updates        | 192220   |\n",
      "----------------------------------\n",
      "Episode reward: 70.798317\n",
      "Episode reward: 50.739116\n",
      "Episode reward: 45.800174\n",
      "Episode reward: 66.453035\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13376    |\n",
      "|    fps              | 2841     |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total_timesteps  | 769219   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.189    |\n",
      "|    n_updates        | 192279   |\n",
      "----------------------------------\n",
      "Episode reward: 46.63539\n",
      "Episode reward: 48.829286\n",
      "Episode reward: 111.283556\n",
      "Episode reward: 57.676072\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13380    |\n",
      "|    fps              | 2841     |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total_timesteps  | 769486   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0464   |\n",
      "|    n_updates        | 192346   |\n",
      "----------------------------------\n",
      "Episode reward: 33.914018\n",
      "Episode reward: 85.57173\n",
      "Episode reward: 36.92429\n",
      "Episode reward: 52.547702\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13384    |\n",
      "|    fps              | 2841     |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total_timesteps  | 769696   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.755    |\n",
      "|    n_updates        | 192398   |\n",
      "----------------------------------\n",
      "Episode reward: 93.057623\n",
      "Episode reward: 53.706217\n",
      "Episode reward: 30.929965\n",
      "Episode reward: 72.877757\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13388    |\n",
      "|    fps              | 2841     |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total_timesteps  | 769953   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.84     |\n",
      "|    n_updates        | 192463   |\n",
      "----------------------------------\n",
      "Episode reward: 32.773338\n",
      "Episode reward: 63.784016\n",
      "Episode reward: 36.92465\n",
      "Episode reward: 61.321224\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13392    |\n",
      "|    fps              | 2841     |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total_timesteps  | 770150   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0551   |\n",
      "|    n_updates        | 192512   |\n",
      "----------------------------------\n",
      "Episode reward: 29.58545\n",
      "Episode reward: 105.014894\n",
      "Episode reward: 94.632107\n",
      "Episode reward: 56.76076\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13396    |\n",
      "|    fps              | 2841     |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total_timesteps  | 770438   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0563   |\n",
      "|    n_updates        | 192584   |\n",
      "----------------------------------\n",
      "Episode reward: 32.885215\n",
      "Episode reward: 56.834511\n",
      "Episode reward: 58.020756\n",
      "Episode reward: 30.920577\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13400    |\n",
      "|    fps              | 2840     |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total_timesteps  | 770618   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.88     |\n",
      "|    n_updates        | 192629   |\n",
      "----------------------------------\n",
      "Episode reward: 39.925924\n",
      "Episode reward: 42.878487\n",
      "Episode reward: 47.808259\n",
      "Episode reward: 40.866548\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13404    |\n",
      "|    fps              | 2840     |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total_timesteps  | 770790   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0459   |\n",
      "|    n_updates        | 192672   |\n",
      "----------------------------------\n",
      "Episode reward: 52.838924\n",
      "Episode reward: 47.83297\n",
      "Episode reward: 36.882935\n",
      "Episode reward: 41.883295\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13408    |\n",
      "|    fps              | 2840     |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total_timesteps  | 770970   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.6      |\n",
      "|    n_updates        | 192717   |\n",
      "----------------------------------\n",
      "Episode reward: 60.439748\n",
      "Episode reward: 26.6349\n",
      "Episode reward: 40.924986\n",
      "Episode reward: 43.73502\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13412    |\n",
      "|    fps              | 2840     |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total_timesteps  | 771143   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0469   |\n",
      "|    n_updates        | 192760   |\n",
      "----------------------------------\n",
      "Episode reward: 33.642821\n",
      "Episode reward: 60.619802\n",
      "Episode reward: 38.669688\n",
      "Episode reward: 90.404114\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13416    |\n",
      "|    fps              | 2840     |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total_timesteps  | 771372   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0475   |\n",
      "|    n_updates        | 192817   |\n",
      "----------------------------------\n",
      "Episode reward: 46.836637\n",
      "Episode reward: 87.133164\n",
      "Episode reward: 28.784507\n",
      "Episode reward: 94.473539\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13420    |\n",
      "|    fps              | 2840     |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total_timesteps  | 771633   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0362   |\n",
      "|    n_updates        | 192883   |\n",
      "----------------------------------\n",
      "Episode reward: 94.970615\n",
      "Episode reward: 60.152672\n",
      "Episode reward: 34.781507\n",
      "Episode reward: 44.645559\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13424    |\n",
      "|    fps              | 2840     |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total_timesteps  | 771871   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.13     |\n",
      "|    n_updates        | 192942   |\n",
      "----------------------------------\n",
      "Episode reward: 56.265111\n",
      "Episode reward: 37.719328\n",
      "Episode reward: 33.886061\n",
      "Episode reward: 42.636505\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13428    |\n",
      "|    fps              | 2840     |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total_timesteps  | 772043   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.933    |\n",
      "|    n_updates        | 192985   |\n",
      "----------------------------------\n",
      "Episode reward: 56.720293\n",
      "Episode reward: 34.887416\n",
      "Episode reward: 42.898579\n",
      "Episode reward: 75.697366\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13432    |\n",
      "|    fps              | 2840     |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total_timesteps  | 772254   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.215    |\n",
      "|    n_updates        | 193038   |\n",
      "----------------------------------\n",
      "Episode reward: 41.929821\n",
      "Episode reward: 64.64506\n",
      "Episode reward: 43.760549\n",
      "Episode reward: 45.79537\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13436    |\n",
      "|    fps              | 2840     |\n",
      "|    time_elapsed     | 271      |\n",
      "|    total_timesteps  | 772451   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.8      |\n",
      "|    n_updates        | 193087   |\n",
      "----------------------------------\n",
      "Episode reward: 65.395005\n",
      "Episode reward: 30.798061\n",
      "Episode reward: 85.536631\n",
      "Episode reward: 94.260875\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13440    |\n",
      "|    fps              | 2840     |\n",
      "|    time_elapsed     | 272      |\n",
      "|    total_timesteps  | 772731   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0454   |\n",
      "|    n_updates        | 193157   |\n",
      "----------------------------------\n",
      "Episode reward: 127.01783\n",
      "Episode reward: 79.06959\n",
      "Episode reward: 42.833692\n",
      "Episode reward: 76.254471\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13444    |\n",
      "|    fps              | 2839     |\n",
      "|    time_elapsed     | 272      |\n",
      "|    total_timesteps  | 773066   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.365    |\n",
      "|    n_updates        | 193241   |\n",
      "----------------------------------\n",
      "Episode reward: 36.869373\n",
      "Episode reward: 29.884545\n",
      "Episode reward: 58.321194\n",
      "Episode reward: 36.924251\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13448    |\n",
      "|    fps              | 2839     |\n",
      "|    time_elapsed     | 272      |\n",
      "|    total_timesteps  | 773229   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0518   |\n",
      "|    n_updates        | 193282   |\n",
      "----------------------------------\n",
      "Episode reward: 81.86817\n",
      "Episode reward: 100.616624\n",
      "Episode reward: 90.027366\n",
      "Episode reward: 37.934907\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13452    |\n",
      "|    fps              | 2839     |\n",
      "|    time_elapsed     | 272      |\n",
      "|    total_timesteps  | 773547   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0532   |\n",
      "|    n_updates        | 193361   |\n",
      "----------------------------------\n",
      "Episode reward: 30.944697\n",
      "Episode reward: 72.625946\n",
      "Episode reward: 56.577697\n",
      "Episode reward: 50.85427\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13456    |\n",
      "|    fps              | 2839     |\n",
      "|    time_elapsed     | 272      |\n",
      "|    total_timesteps  | 773761   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0905   |\n",
      "|    n_updates        | 193415   |\n",
      "----------------------------------\n",
      "Episode reward: 78.264133\n",
      "Episode reward: 64.724712\n",
      "Episode reward: 36.747867\n",
      "Episode reward: 54.426423\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13460    |\n",
      "|    fps              | 2839     |\n",
      "|    time_elapsed     | 272      |\n",
      "|    total_timesteps  | 773998   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.34     |\n",
      "|    n_updates        | 193474   |\n",
      "----------------------------------\n",
      "Episode reward: 42.851895\n",
      "Episode reward: 81.443902\n",
      "Episode reward: 39.865721\n",
      "Episode reward: 78.30312\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13464    |\n",
      "|    fps              | 2839     |\n",
      "|    time_elapsed     | 272      |\n",
      "|    total_timesteps  | 774242   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0397   |\n",
      "|    n_updates        | 193535   |\n",
      "----------------------------------\n",
      "Episode reward: 47.813703\n",
      "Episode reward: 48.881495\n",
      "Episode reward: 42.932967\n",
      "Episode reward: 36.936717\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13468    |\n",
      "|    fps              | 2838     |\n",
      "|    time_elapsed     | 272      |\n",
      "|    total_timesteps  | 774419   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.27     |\n",
      "|    n_updates        | 193579   |\n",
      "----------------------------------\n",
      "Episode reward: 38.904978\n",
      "Episode reward: 51.886802\n",
      "Episode reward: 45.61222\n",
      "Episode reward: 33.945749\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13472    |\n",
      "|    fps              | 2838     |\n",
      "|    time_elapsed     | 272      |\n",
      "|    total_timesteps  | 774590   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.49     |\n",
      "|    n_updates        | 193622   |\n",
      "----------------------------------\n",
      "Episode reward: 81.202549\n",
      "Episode reward: 83.381168\n",
      "Episode reward: 45.528628\n",
      "Episode reward: 33.599185\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13476    |\n",
      "|    fps              | 2838     |\n",
      "|    time_elapsed     | 272      |\n",
      "|    total_timesteps  | 774836   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0558   |\n",
      "|    n_updates        | 193683   |\n",
      "----------------------------------\n",
      "Episode reward: 103.092609\n",
      "Episode reward: 42.645469\n",
      "Episode reward: 61.510392\n",
      "Episode reward: 61.716246\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13480    |\n",
      "|    fps              | 2837     |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total_timesteps  | 775107   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.112    |\n",
      "|    n_updates        | 193751   |\n",
      "----------------------------------\n",
      "Episode reward: 70.081577\n",
      "Episode reward: 45.840263\n",
      "Episode reward: 31.929913\n",
      "Episode reward: 71.770377\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13484    |\n",
      "|    fps              | 2837     |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total_timesteps  | 775329   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.225    |\n",
      "|    n_updates        | 193807   |\n",
      "----------------------------------\n",
      "Episode reward: 101.124261\n",
      "Episode reward: 39.906456\n",
      "Episode reward: 84.27207\n",
      "Episode reward: 46.805872\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13488    |\n",
      "|    fps              | 2837     |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total_timesteps  | 775604   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0384   |\n",
      "|    n_updates        | 193875   |\n",
      "----------------------------------\n",
      "Episode reward: 45.70203\n",
      "Episode reward: 34.880406\n",
      "Episode reward: 58.130411\n",
      "Episode reward: 95.297789\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13492    |\n",
      "|    fps              | 2837     |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total_timesteps  | 775840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 193934   |\n",
      "----------------------------------\n",
      "Episode reward: 30.800172\n",
      "Episode reward: 60.731736\n",
      "Episode reward: 36.884041\n",
      "Episode reward: 32.910734\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.6     |\n",
      "|    ep_rew_mean      | 55       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13496    |\n",
      "|    fps              | 2836     |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total_timesteps  | 776002   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.051    |\n",
      "|    n_updates        | 193975   |\n",
      "----------------------------------\n",
      "Episode reward: 47.71518\n",
      "Episode reward: 190.790644\n",
      "Episode reward: 53.665353\n",
      "Episode reward: 74.508166\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13500    |\n",
      "|    fps              | 2836     |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total_timesteps  | 776372   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0448   |\n",
      "|    n_updates        | 194067   |\n",
      "----------------------------------\n",
      "Episode reward: 43.920905\n",
      "Episode reward: 43.848883\n",
      "Episode reward: 38.943135\n",
      "Episode reward: 57.791296\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13504    |\n",
      "|    fps              | 2836     |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total_timesteps  | 776557   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0511   |\n",
      "|    n_updates        | 194114   |\n",
      "----------------------------------\n",
      "Episode reward: 54.427435\n",
      "Episode reward: 41.899871\n",
      "Episode reward: 51.364884\n",
      "Episode reward: 48.738168\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13508    |\n",
      "|    fps              | 2836     |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total_timesteps  | 776755   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0385   |\n",
      "|    n_updates        | 194163   |\n",
      "----------------------------------\n",
      "Episode reward: 46.859513\n",
      "Episode reward: 57.348421\n",
      "Episode reward: 68.387226\n",
      "Episode reward: 53.611676\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13512    |\n",
      "|    fps              | 2836     |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total_timesteps  | 776983   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.6      |\n",
      "|    n_updates        | 194220   |\n",
      "----------------------------------\n",
      "Episode reward: 36.898673\n",
      "Episode reward: 71.572908\n",
      "Episode reward: 120.9677\n",
      "Episode reward: 53.731701\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13516    |\n",
      "|    fps              | 2836     |\n",
      "|    time_elapsed     | 274      |\n",
      "|    total_timesteps  | 777273   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.1      |\n",
      "|    n_updates        | 194293   |\n",
      "----------------------------------\n",
      "Episode reward: 58.166269\n",
      "Episode reward: 74.991459\n",
      "Episode reward: 115.423986\n",
      "Episode reward: 62.799485\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13520    |\n",
      "|    fps              | 2836     |\n",
      "|    time_elapsed     | 274      |\n",
      "|    total_timesteps  | 777598   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0552   |\n",
      "|    n_updates        | 194374   |\n",
      "----------------------------------\n",
      "Episode reward: 40.662214\n",
      "Episode reward: 70.131296\n",
      "Episode reward: 35.937404\n",
      "Episode reward: 79.931191\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13524    |\n",
      "|    fps              | 2835     |\n",
      "|    time_elapsed     | 274      |\n",
      "|    total_timesteps  | 777832   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0587   |\n",
      "|    n_updates        | 194432   |\n",
      "----------------------------------\n",
      "Episode reward: 54.706245\n",
      "Episode reward: 32.941329\n",
      "Episode reward: 61.687849\n",
      "Episode reward: 64.486245\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13528    |\n",
      "|    fps              | 2835     |\n",
      "|    time_elapsed     | 274      |\n",
      "|    total_timesteps  | 778048   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0474   |\n",
      "|    n_updates        | 194486   |\n",
      "----------------------------------\n",
      "Episode reward: 43.254043\n",
      "Episode reward: 96.081711\n",
      "Episode reward: 60.223716\n",
      "Episode reward: 44.913267\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13532    |\n",
      "|    fps              | 2835     |\n",
      "|    time_elapsed     | 274      |\n",
      "|    total_timesteps  | 778295   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0228   |\n",
      "|    n_updates        | 194548   |\n",
      "----------------------------------\n",
      "Episode reward: 89.331374\n",
      "Episode reward: 28.906851\n",
      "Episode reward: 91.49928\n",
      "Episode reward: 50.825615\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13536    |\n",
      "|    fps              | 2835     |\n",
      "|    time_elapsed     | 274      |\n",
      "|    total_timesteps  | 778558   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0471   |\n",
      "|    n_updates        | 194614   |\n",
      "----------------------------------\n",
      "Episode reward: 66.957213\n",
      "Episode reward: 37.856386\n",
      "Episode reward: 85.631929\n",
      "Episode reward: 27.869271\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13540    |\n",
      "|    fps              | 2835     |\n",
      "|    time_elapsed     | 274      |\n",
      "|    total_timesteps  | 778781   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0898   |\n",
      "|    n_updates        | 194670   |\n",
      "----------------------------------\n",
      "Episode reward: 156.930466\n",
      "Episode reward: 104.334227\n",
      "Episode reward: 91.789672\n",
      "Episode reward: 111.783637\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13544    |\n",
      "|    fps              | 2834     |\n",
      "|    time_elapsed     | 274      |\n",
      "|    total_timesteps  | 779261   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0711   |\n",
      "|    n_updates        | 194790   |\n",
      "----------------------------------\n",
      "Episode reward: 40.716317\n",
      "Episode reward: 33.632419\n",
      "Episode reward: 64.673015\n",
      "Episode reward: 46.90508\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13548    |\n",
      "|    fps              | 2834     |\n",
      "|    time_elapsed     | 274      |\n",
      "|    total_timesteps  | 779448   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.317    |\n",
      "|    n_updates        | 194836   |\n",
      "----------------------------------\n",
      "Episode reward: 95.005828\n",
      "Episode reward: 27.911592\n",
      "Episode reward: 36.758847\n",
      "Episode reward: 73.765876\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13552    |\n",
      "|    fps              | 2834     |\n",
      "|    time_elapsed     | 275      |\n",
      "|    total_timesteps  | 779683   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.6      |\n",
      "|    n_updates        | 194895   |\n",
      "----------------------------------\n",
      "Episode reward: 78.408561\n",
      "Episode reward: 79.706482\n",
      "Episode reward: 46.882153\n",
      "Episode reward: 31.914638\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13556    |\n",
      "|    fps              | 2834     |\n",
      "|    time_elapsed     | 275      |\n",
      "|    total_timesteps  | 779922   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0459   |\n",
      "|    n_updates        | 194955   |\n",
      "----------------------------------\n",
      "Episode reward: 30.956853\n",
      "Episode reward: 69.231865\n",
      "Episode reward: 37.758238\n",
      "Episode reward: 43.896565\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13560    |\n",
      "|    fps              | 2833     |\n",
      "|    time_elapsed     | 275      |\n",
      "|    total_timesteps  | 780106   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.318    |\n",
      "|    n_updates        | 195001   |\n",
      "----------------------------------\n",
      "Episode reward: 32.782314\n",
      "Episode reward: 73.696535\n",
      "Episode reward: 70.283436\n",
      "Episode reward: 74.497622\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13564    |\n",
      "|    fps              | 2832     |\n",
      "|    time_elapsed     | 275      |\n",
      "|    total_timesteps  | 780360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0479   |\n",
      "|    n_updates        | 195064   |\n",
      "----------------------------------\n",
      "Episode reward: 79.636699\n",
      "Episode reward: 42.775182\n",
      "Episode reward: 82.532185\n",
      "Episode reward: 93.393388\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13568    |\n",
      "|    fps              | 2832     |\n",
      "|    time_elapsed     | 275      |\n",
      "|    total_timesteps  | 780660   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.47     |\n",
      "|    n_updates        | 195139   |\n",
      "----------------------------------\n",
      "Episode reward: 64.667046\n",
      "Episode reward: 92.148515\n",
      "Episode reward: 33.932436\n",
      "Episode reward: 111.455651\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13572    |\n",
      "|    fps              | 2832     |\n",
      "|    time_elapsed     | 275      |\n",
      "|    total_timesteps  | 780970   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.22     |\n",
      "|    n_updates        | 195217   |\n",
      "----------------------------------\n",
      "Episode reward: 79.074001\n",
      "Episode reward: 65.891582\n",
      "Episode reward: 67.31204\n",
      "Episode reward: 38.805232\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13576    |\n",
      "|    fps              | 2832     |\n",
      "|    time_elapsed     | 275      |\n",
      "|    total_timesteps  | 781225   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0417   |\n",
      "|    n_updates        | 195281   |\n",
      "----------------------------------\n",
      "Episode reward: 54.630572\n",
      "Episode reward: 44.894981\n",
      "Episode reward: 165.396911\n",
      "Episode reward: 28.676598\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13580    |\n",
      "|    fps              | 2831     |\n",
      "|    time_elapsed     | 275      |\n",
      "|    total_timesteps  | 781525   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.28     |\n",
      "|    n_updates        | 195356   |\n",
      "----------------------------------\n",
      "Episode reward: 45.866307\n",
      "Episode reward: 49.629991\n",
      "Episode reward: 33.844334\n",
      "Episode reward: 72.990456\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13584    |\n",
      "|    fps              | 2831     |\n",
      "|    time_elapsed     | 276      |\n",
      "|    total_timesteps  | 781730   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0683   |\n",
      "|    n_updates        | 195407   |\n",
      "----------------------------------\n",
      "Episode reward: 84.397565\n",
      "Episode reward: 58.816293\n",
      "Episode reward: 41.408439\n",
      "Episode reward: 30.869109\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13588    |\n",
      "|    fps              | 2831     |\n",
      "|    time_elapsed     | 276      |\n",
      "|    total_timesteps  | 781947   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.72     |\n",
      "|    n_updates        | 195461   |\n",
      "----------------------------------\n",
      "Episode reward: 46.915678\n",
      "Episode reward: 51.159284\n",
      "Episode reward: 82.88503\n",
      "Episode reward: 94.158862\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13592    |\n",
      "|    fps              | 2831     |\n",
      "|    time_elapsed     | 276      |\n",
      "|    total_timesteps  | 782229   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0611   |\n",
      "|    n_updates        | 195532   |\n",
      "----------------------------------\n",
      "Episode reward: 42.778603\n",
      "Episode reward: 46.631024\n",
      "Episode reward: 50.765439\n",
      "Episode reward: 75.72737\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13596    |\n",
      "|    fps              | 2831     |\n",
      "|    time_elapsed     | 276      |\n",
      "|    total_timesteps  | 782447   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0514   |\n",
      "|    n_updates        | 195586   |\n",
      "----------------------------------\n",
      "Episode reward: 27.919815\n",
      "Episode reward: 65.689799\n",
      "Episode reward: 32.665741\n",
      "Episode reward: 89.446597\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13600    |\n",
      "|    fps              | 2831     |\n",
      "|    time_elapsed     | 276      |\n",
      "|    total_timesteps  | 782665   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0491   |\n",
      "|    n_updates        | 195641   |\n",
      "----------------------------------\n",
      "Episode reward: 39.918783\n",
      "Episode reward: 40.8892\n",
      "Episode reward: 42.848316\n",
      "Episode reward: 43.851455\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13604    |\n",
      "|    fps              | 2830     |\n",
      "|    time_elapsed     | 276      |\n",
      "|    total_timesteps  | 782833   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.2      |\n",
      "|    n_updates        | 195683   |\n",
      "----------------------------------\n",
      "Episode reward: 53.713479\n",
      "Episode reward: 52.605329\n",
      "Episode reward: 39.8747\n",
      "Episode reward: 48.66463\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13608    |\n",
      "|    fps              | 2830     |\n",
      "|    time_elapsed     | 276      |\n",
      "|    total_timesteps  | 783029   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0717   |\n",
      "|    n_updates        | 195732   |\n",
      "----------------------------------\n",
      "Episode reward: 54.128227\n",
      "Episode reward: 43.599767\n",
      "Episode reward: 47.838165\n",
      "Episode reward: 82.617202\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13612    |\n",
      "|    fps              | 2830     |\n",
      "|    time_elapsed     | 276      |\n",
      "|    total_timesteps  | 783259   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0348   |\n",
      "|    n_updates        | 195789   |\n",
      "----------------------------------\n",
      "Episode reward: 100.075474\n",
      "Episode reward: 33.818678\n",
      "Episode reward: 84.6145\n",
      "Episode reward: 52.82087\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.6     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13616    |\n",
      "|    fps              | 2830     |\n",
      "|    time_elapsed     | 276      |\n",
      "|    total_timesteps  | 783535   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.6      |\n",
      "|    n_updates        | 195858   |\n",
      "----------------------------------\n",
      "Episode reward: 91.63072\n",
      "Episode reward: 60.69839\n",
      "Episode reward: 169.30779\n",
      "Episode reward: 132.907822\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13620    |\n",
      "|    fps              | 2830     |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 783993   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0513   |\n",
      "|    n_updates        | 195973   |\n",
      "----------------------------------\n",
      "Episode reward: 62.302467\n",
      "Episode reward: 94.136328\n",
      "Episode reward: 63.374599\n",
      "Episode reward: 102.659677\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.9     |\n",
      "|    ep_rew_mean      | 64       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13624    |\n",
      "|    fps              | 2830     |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 784321   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0433   |\n",
      "|    n_updates        | 196055   |\n",
      "----------------------------------\n",
      "Episode reward: 31.808452\n",
      "Episode reward: 48.355548\n",
      "Episode reward: 38.743432\n",
      "Episode reward: 47.886963\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13628    |\n",
      "|    fps              | 2829     |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 784489   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.292    |\n",
      "|    n_updates        | 196097   |\n",
      "----------------------------------\n",
      "Episode reward: 43.901992\n",
      "Episode reward: 37.615095\n",
      "Episode reward: 25.834047\n",
      "Episode reward: 56.714543\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13632    |\n",
      "|    fps              | 2829     |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 784654   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0464   |\n",
      "|    n_updates        | 196138   |\n",
      "----------------------------------\n",
      "Episode reward: 56.896946\n",
      "Episode reward: 60.836364\n",
      "Episode reward: 66.741878\n",
      "Episode reward: 69.672373\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13636    |\n",
      "|    fps              | 2829     |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 784911   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0397   |\n",
      "|    n_updates        | 196202   |\n",
      "----------------------------------\n",
      "Episode reward: 47.769356\n",
      "Episode reward: 39.825452\n",
      "Episode reward: 40.913039\n",
      "Episode reward: 87.475916\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13640    |\n",
      "|    fps              | 2829     |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 785128   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0616   |\n",
      "|    n_updates        | 196256   |\n",
      "----------------------------------\n",
      "Episode reward: 46.916175\n",
      "Episode reward: 39.798696\n",
      "Episode reward: 37.92403\n",
      "Episode reward: 48.852653\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13644    |\n",
      "|    fps              | 2829     |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 785302   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.21     |\n",
      "|    n_updates        | 196300   |\n",
      "----------------------------------\n",
      "Episode reward: 39.468405\n",
      "Episode reward: 32.862463\n",
      "Episode reward: 72.247091\n",
      "Episode reward: 98.634781\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13648    |\n",
      "|    fps              | 2829     |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 785550   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0796   |\n",
      "|    n_updates        | 196362   |\n",
      "----------------------------------\n",
      "Episode reward: 63.861002\n",
      "Episode reward: 63.703156\n",
      "Episode reward: 48.835006\n",
      "Episode reward: 50.844834\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13652    |\n",
      "|    fps              | 2829     |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 785780   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0511   |\n",
      "|    n_updates        | 196419   |\n",
      "----------------------------------\n",
      "Episode reward: 44.827656\n",
      "Episode reward: 42.890218\n",
      "Episode reward: 147.150854\n",
      "Episode reward: 32.848924\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13656    |\n",
      "|    fps              | 2829     |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 786051   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0404   |\n",
      "|    n_updates        | 196487   |\n",
      "----------------------------------\n",
      "Episode reward: 78.255852\n",
      "Episode reward: 27.920508\n",
      "Episode reward: 68.72935\n",
      "Episode reward: 33.893236\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13660    |\n",
      "|    fps              | 2829     |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 786262   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.029    |\n",
      "|    n_updates        | 196540   |\n",
      "----------------------------------\n",
      "Episode reward: 129.697606\n",
      "Episode reward: 64.729444\n",
      "Episode reward: 57.040784\n",
      "Episode reward: 41.771098\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13664    |\n",
      "|    fps              | 2828     |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total_timesteps  | 786557   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.67     |\n",
      "|    n_updates        | 196614   |\n",
      "----------------------------------\n",
      "Episode reward: 50.835545\n",
      "Episode reward: 56.141737\n",
      "Episode reward: 80.542981\n",
      "Episode reward: 71.570283\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13668    |\n",
      "|    fps              | 2828     |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total_timesteps  | 786819   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.29     |\n",
      "|    n_updates        | 196679   |\n",
      "----------------------------------\n",
      "Episode reward: 51.717762\n",
      "Episode reward: 63.727669\n",
      "Episode reward: 60.570013\n",
      "Episode reward: 44.795734\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13672    |\n",
      "|    fps              | 2828     |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total_timesteps  | 787042   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0253   |\n",
      "|    n_updates        | 196735   |\n",
      "----------------------------------\n",
      "Episode reward: 127.217666\n",
      "Episode reward: 36.865499\n",
      "Episode reward: 112.566298\n",
      "Episode reward: 77.596671\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13676    |\n",
      "|    fps              | 2828     |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total_timesteps  | 787405   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0258   |\n",
      "|    n_updates        | 196826   |\n",
      "----------------------------------\n",
      "Episode reward: 47.638025\n",
      "Episode reward: 88.741199\n",
      "Episode reward: 32.698979\n",
      "Episode reward: 73.097731\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13680    |\n",
      "|    fps              | 2828     |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total_timesteps  | 787649   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0555   |\n",
      "|    n_updates        | 196887   |\n",
      "----------------------------------\n",
      "Episode reward: 35.901665\n",
      "Episode reward: 26.905261\n",
      "Episode reward: 41.936717\n",
      "Episode reward: 55.698821\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13684    |\n",
      "|    fps              | 2828     |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total_timesteps  | 787810   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0371   |\n",
      "|    n_updates        | 196927   |\n",
      "----------------------------------\n",
      "Episode reward: 85.635648\n",
      "Episode reward: 86.271269\n",
      "Episode reward: 89.395609\n",
      "Episode reward: 36.836492\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13688    |\n",
      "|    fps              | 2827     |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total_timesteps  | 788110   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0289   |\n",
      "|    n_updates        | 197002   |\n",
      "----------------------------------\n",
      "Episode reward: 54.425016\n",
      "Episode reward: 35.720126\n",
      "Episode reward: 39.874496\n",
      "Episode reward: 50.791877\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13692    |\n",
      "|    fps              | 2827     |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total_timesteps  | 788292   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.499    |\n",
      "|    n_updates        | 197047   |\n",
      "----------------------------------\n",
      "Episode reward: 93.223504\n",
      "Episode reward: 62.777222\n",
      "Episode reward: 113.240832\n",
      "Episode reward: 49.895075\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13696    |\n",
      "|    fps              | 2827     |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total_timesteps  | 788619   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.13     |\n",
      "|    n_updates        | 197129   |\n",
      "----------------------------------\n",
      "Episode reward: 38.908058\n",
      "Episode reward: 75.584458\n",
      "Episode reward: 47.819509\n",
      "Episode reward: 83.265794\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13700    |\n",
      "|    fps              | 2827     |\n",
      "|    time_elapsed     | 279      |\n",
      "|    total_timesteps  | 788866   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.303    |\n",
      "|    n_updates        | 197191   |\n",
      "----------------------------------\n",
      "Episode reward: 42.698296\n",
      "Episode reward: 132.363557\n",
      "Episode reward: 69.13585\n",
      "Episode reward: 40.932919\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13704    |\n",
      "|    fps              | 2826     |\n",
      "|    time_elapsed     | 279      |\n",
      "|    total_timesteps  | 789153   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.164    |\n",
      "|    n_updates        | 197263   |\n",
      "----------------------------------\n",
      "Episode reward: 94.38094\n",
      "Episode reward: 85.75673\n",
      "Episode reward: 81.475668\n",
      "Episode reward: 84.773847\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.7     |\n",
      "|    ep_rew_mean      | 64       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13708    |\n",
      "|    fps              | 2826     |\n",
      "|    time_elapsed     | 279      |\n",
      "|    total_timesteps  | 789503   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.61     |\n",
      "|    n_updates        | 197350   |\n",
      "----------------------------------\n",
      "Episode reward: 31.836265\n",
      "Episode reward: 75.543258\n",
      "Episode reward: 97.889667\n",
      "Episode reward: 65.758265\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.2     |\n",
      "|    ep_rew_mean      | 64.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13712    |\n",
      "|    fps              | 2826     |\n",
      "|    time_elapsed     | 279      |\n",
      "|    total_timesteps  | 789779   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.16     |\n",
      "|    n_updates        | 197419   |\n",
      "----------------------------------\n",
      "Episode reward: 67.289304\n",
      "Episode reward: 43.90674\n",
      "Episode reward: 62.838344\n",
      "Episode reward: 81.55878\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65       |\n",
      "|    ep_rew_mean      | 64.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13716    |\n",
      "|    fps              | 2826     |\n",
      "|    time_elapsed     | 279      |\n",
      "|    total_timesteps  | 790036   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.156    |\n",
      "|    n_updates        | 197483   |\n",
      "----------------------------------\n",
      "Episode reward: 54.595267\n",
      "Episode reward: 29.766105\n",
      "Episode reward: 74.570725\n",
      "Episode reward: 56.743558\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.6     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13720    |\n",
      "|    fps              | 2826     |\n",
      "|    time_elapsed     | 279      |\n",
      "|    total_timesteps  | 790253   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0468   |\n",
      "|    n_updates        | 197538   |\n",
      "----------------------------------\n",
      "Episode reward: 156.1226\n",
      "Episode reward: 87.186018\n",
      "Episode reward: 36.94429\n",
      "Episode reward: 53.845116\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13724    |\n",
      "|    fps              | 2826     |\n",
      "|    time_elapsed     | 279      |\n",
      "|    total_timesteps  | 790589   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.128    |\n",
      "|    n_updates        | 197622   |\n",
      "----------------------------------\n",
      "Episode reward: 97.602154\n",
      "Episode reward: 45.848277\n",
      "Episode reward: 76.408552\n",
      "Episode reward: 95.47198\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13728    |\n",
      "|    fps              | 2825     |\n",
      "|    time_elapsed     | 279      |\n",
      "|    total_timesteps  | 790911   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0835   |\n",
      "|    n_updates        | 197702   |\n",
      "----------------------------------\n",
      "Episode reward: 92.769637\n",
      "Episode reward: 67.517925\n",
      "Episode reward: 70.441614\n",
      "Episode reward: 55.333408\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.5     |\n",
      "|    ep_rew_mean      | 64.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13732    |\n",
      "|    fps              | 2825     |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total_timesteps  | 791200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0747   |\n",
      "|    n_updates        | 197774   |\n",
      "----------------------------------\n",
      "Episode reward: 62.784946\n",
      "Episode reward: 39.608692\n",
      "Episode reward: 39.752861\n",
      "Episode reward: 62.792285\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65       |\n",
      "|    ep_rew_mean      | 64.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13736    |\n",
      "|    fps              | 2825     |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total_timesteps  | 791406   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0415   |\n",
      "|    n_updates        | 197826   |\n",
      "----------------------------------\n",
      "Episode reward: 76.116541\n",
      "Episode reward: 44.712592\n",
      "Episode reward: 51.414748\n",
      "Episode reward: 85.110348\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.4     |\n",
      "|    ep_rew_mean      | 64.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13740    |\n",
      "|    fps              | 2825     |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total_timesteps  | 791666   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0548   |\n",
      "|    n_updates        | 197891   |\n",
      "----------------------------------\n",
      "Episode reward: 30.841814\n",
      "Episode reward: 39.85582\n",
      "Episode reward: 40.633263\n",
      "Episode reward: 40.872929\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.2     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13744    |\n",
      "|    fps              | 2825     |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total_timesteps  | 791819   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.274    |\n",
      "|    n_updates        | 197929   |\n",
      "----------------------------------\n",
      "Episode reward: 51.304147\n",
      "Episode reward: 86.847906\n",
      "Episode reward: 34.926544\n",
      "Episode reward: 73.530853\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.2     |\n",
      "|    ep_rew_mean      | 64.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13748    |\n",
      "|    fps              | 2824     |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total_timesteps  | 792068   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.108    |\n",
      "|    n_updates        | 197991   |\n",
      "----------------------------------\n",
      "Episode reward: 105.148409\n",
      "Episode reward: 85.883877\n",
      "Episode reward: 46.848267\n",
      "Episode reward: 29.814017\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.6     |\n",
      "|    ep_rew_mean      | 64.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13752    |\n",
      "|    fps              | 2824     |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total_timesteps  | 792342   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0519   |\n",
      "|    n_updates        | 198060   |\n",
      "----------------------------------\n",
      "Episode reward: 63.44744\n",
      "Episode reward: 69.286917\n",
      "Episode reward: 56.172059\n",
      "Episode reward: 59.664429\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.4     |\n",
      "|    ep_rew_mean      | 64.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13756    |\n",
      "|    fps              | 2824     |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total_timesteps  | 792594   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0768   |\n",
      "|    n_updates        | 198123   |\n",
      "----------------------------------\n",
      "Episode reward: 34.714728\n",
      "Episode reward: 34.843967\n",
      "Episode reward: 37.821184\n",
      "Episode reward: 46.835327\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.9     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13760    |\n",
      "|    fps              | 2824     |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total_timesteps  | 792750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 198162   |\n",
      "----------------------------------\n",
      "Episode reward: 53.668806\n",
      "Episode reward: 113.588697\n",
      "Episode reward: 103.716069\n",
      "Episode reward: 30.716945\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65       |\n",
      "|    ep_rew_mean      | 64.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13764    |\n",
      "|    fps              | 2824     |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total_timesteps  | 793060   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0862   |\n",
      "|    n_updates        | 198239   |\n",
      "----------------------------------\n",
      "Episode reward: 41.883097\n",
      "Episode reward: 56.708596\n",
      "Episode reward: 47.847427\n",
      "Episode reward: 78.47658\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.7     |\n",
      "|    ep_rew_mean      | 63.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13768    |\n",
      "|    fps              | 2824     |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total_timesteps  | 793287   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.15     |\n",
      "|    n_updates        | 198296   |\n",
      "----------------------------------\n",
      "Episode reward: 41.773926\n",
      "Episode reward: 74.204653\n",
      "Episode reward: 41.83816\n",
      "Episode reward: 39.856337\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 63.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13772    |\n",
      "|    fps              | 2824     |\n",
      "|    time_elapsed     | 280      |\n",
      "|    total_timesteps  | 793488   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0247   |\n",
      "|    n_updates        | 198346   |\n",
      "----------------------------------\n",
      "Episode reward: 68.308659\n",
      "Episode reward: 106.859915\n",
      "Episode reward: 57.950013\n",
      "Episode reward: 33.955009\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13776    |\n",
      "|    fps              | 2824     |\n",
      "|    time_elapsed     | 281      |\n",
      "|    total_timesteps  | 793761   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0506   |\n",
      "|    n_updates        | 198415   |\n",
      "----------------------------------\n",
      "Episode reward: 84.011037\n",
      "Episode reward: 40.925169\n",
      "Episode reward: 60.626712\n",
      "Episode reward: 94.335385\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13780    |\n",
      "|    fps              | 2823     |\n",
      "|    time_elapsed     | 281      |\n",
      "|    total_timesteps  | 794043   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 198485   |\n",
      "----------------------------------\n",
      "Episode reward: 63.651464\n",
      "Episode reward: 67.24143\n",
      "Episode reward: 77.406979\n",
      "Episode reward: 73.626741\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.2     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13784    |\n",
      "|    fps              | 2823     |\n",
      "|    time_elapsed     | 281      |\n",
      "|    total_timesteps  | 794329   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.25     |\n",
      "|    n_updates        | 198557   |\n",
      "----------------------------------\n",
      "Episode reward: 88.191079\n",
      "Episode reward: 34.839642\n",
      "Episode reward: 62.082869\n",
      "Episode reward: 110.244367\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.3     |\n",
      "|    ep_rew_mean      | 64.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13788    |\n",
      "|    fps              | 2823     |\n",
      "|    time_elapsed     | 281      |\n",
      "|    total_timesteps  | 794636   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0348   |\n",
      "|    n_updates        | 198633   |\n",
      "----------------------------------\n",
      "Episode reward: 85.788232\n",
      "Episode reward: 54.776411\n",
      "Episode reward: 118.097743\n",
      "Episode reward: 68.647669\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.9     |\n",
      "|    ep_rew_mean      | 65.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13792    |\n",
      "|    fps              | 2823     |\n",
      "|    time_elapsed     | 281      |\n",
      "|    total_timesteps  | 794981   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.088    |\n",
      "|    n_updates        | 198720   |\n",
      "----------------------------------\n",
      "Episode reward: 50.75448\n",
      "Episode reward: 43.93499\n",
      "Episode reward: 32.859953\n",
      "Episode reward: 34.556784\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.2     |\n",
      "|    ep_rew_mean      | 64.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13796    |\n",
      "|    fps              | 2823     |\n",
      "|    time_elapsed     | 281      |\n",
      "|    total_timesteps  | 795144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0598   |\n",
      "|    n_updates        | 198760   |\n",
      "----------------------------------\n",
      "Episode reward: 51.833587\n",
      "Episode reward: 99.657292\n",
      "Episode reward: 50.778275\n",
      "Episode reward: 48.689392\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.3     |\n",
      "|    ep_rew_mean      | 64.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13800    |\n",
      "|    fps              | 2823     |\n",
      "|    time_elapsed     | 281      |\n",
      "|    total_timesteps  | 795400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0646   |\n",
      "|    n_updates        | 198824   |\n",
      "----------------------------------\n",
      "Episode reward: 48.385401\n",
      "Episode reward: 103.14969\n",
      "Episode reward: 44.822754\n",
      "Episode reward: 73.138109\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.2     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13804    |\n",
      "|    fps              | 2822     |\n",
      "|    time_elapsed     | 281      |\n",
      "|    total_timesteps  | 795672   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.66     |\n",
      "|    n_updates        | 198892   |\n",
      "----------------------------------\n",
      "Episode reward: 158.283415\n",
      "Episode reward: 106.637511\n",
      "Episode reward: 90.085456\n",
      "Episode reward: 73.144228\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66       |\n",
      "|    ep_rew_mean      | 65       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13808    |\n",
      "|    fps              | 2822     |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 796106   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0461   |\n",
      "|    n_updates        | 199001   |\n",
      "----------------------------------\n",
      "Episode reward: 49.894605\n",
      "Episode reward: 69.682712\n",
      "Episode reward: 36.850968\n",
      "Episode reward: 46.75786\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.3     |\n",
      "|    ep_rew_mean      | 64.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13812    |\n",
      "|    fps              | 2822     |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 796310   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0558   |\n",
      "|    n_updates        | 199052   |\n",
      "----------------------------------\n",
      "Episode reward: 57.748249\n",
      "Episode reward: 34.746689\n",
      "Episode reward: 31.566935\n",
      "Episode reward: 129.488642\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.3     |\n",
      "|    ep_rew_mean      | 64.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13816    |\n",
      "|    fps              | 2821     |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 796570   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.752    |\n",
      "|    n_updates        | 199117   |\n",
      "----------------------------------\n",
      "Episode reward: 61.57731\n",
      "Episode reward: 58.793991\n",
      "Episode reward: 103.231941\n",
      "Episode reward: 47.45976\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.9     |\n",
      "|    ep_rew_mean      | 64.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13820    |\n",
      "|    fps              | 2821     |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 796846   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.061    |\n",
      "|    n_updates        | 199186   |\n",
      "----------------------------------\n",
      "Episode reward: 57.286456\n",
      "Episode reward: 57.566219\n",
      "Episode reward: 40.891563\n",
      "Episode reward: 36.915379\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13824    |\n",
      "|    fps              | 2821     |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 797040   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0351   |\n",
      "|    n_updates        | 199234   |\n",
      "----------------------------------\n",
      "Episode reward: 68.516845\n",
      "Episode reward: 79.729193\n",
      "Episode reward: 82.940705\n",
      "Episode reward: 63.921718\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13828    |\n",
      "|    fps              | 2820     |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 797338   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.283    |\n",
      "|    n_updates        | 199309   |\n",
      "----------------------------------\n",
      "Episode reward: 105.971276\n",
      "Episode reward: 42.858062\n",
      "Episode reward: 31.765181\n",
      "Episode reward: 63.720177\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13832    |\n",
      "|    fps              | 2820     |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 797585   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.062    |\n",
      "|    n_updates        | 199371   |\n",
      "----------------------------------\n",
      "Episode reward: 87.638975\n",
      "Episode reward: 69.575721\n",
      "Episode reward: 45.830468\n",
      "Episode reward: 30.908898\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.1     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13836    |\n",
      "|    fps              | 2820     |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 797820   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.315    |\n",
      "|    n_updates        | 199429   |\n",
      "----------------------------------\n",
      "Episode reward: 31.629831\n",
      "Episode reward: 37.912128\n",
      "Episode reward: 68.761948\n",
      "Episode reward: 30.725998\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13840    |\n",
      "|    fps              | 2820     |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 797990   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.266    |\n",
      "|    n_updates        | 199472   |\n",
      "----------------------------------\n",
      "Episode reward: 27.772177\n",
      "Episode reward: 87.694103\n",
      "Episode reward: 47.855746\n",
      "Episode reward: 35.907649\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13844    |\n",
      "|    fps              | 2820     |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 798191   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0876   |\n",
      "|    n_updates        | 199522   |\n",
      "----------------------------------\n",
      "Episode reward: 112.222441\n",
      "Episode reward: 71.049338\n",
      "Episode reward: 33.643652\n",
      "Episode reward: 52.881795\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13848    |\n",
      "|    fps              | 2820     |\n",
      "|    time_elapsed     | 283      |\n",
      "|    total_timesteps  | 798469   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.24     |\n",
      "|    n_updates        | 199592   |\n",
      "----------------------------------\n",
      "Episode reward: 67.392204\n",
      "Episode reward: 56.564514\n",
      "Episode reward: 83.486224\n",
      "Episode reward: 46.74899\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13852    |\n",
      "|    fps              | 2820     |\n",
      "|    time_elapsed     | 283      |\n",
      "|    total_timesteps  | 798725   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0591   |\n",
      "|    n_updates        | 199656   |\n",
      "----------------------------------\n",
      "Episode reward: 85.859933\n",
      "Episode reward: 79.557281\n",
      "Episode reward: 36.802285\n",
      "Episode reward: 60.111442\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13856    |\n",
      "|    fps              | 2820     |\n",
      "|    time_elapsed     | 283      |\n",
      "|    total_timesteps  | 798993   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0543   |\n",
      "|    n_updates        | 199723   |\n",
      "----------------------------------\n",
      "Episode reward: 28.906399\n",
      "Episode reward: 61.741437\n",
      "Episode reward: 49.839165\n",
      "Episode reward: 81.725226\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.7     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13860    |\n",
      "|    fps              | 2820     |\n",
      "|    time_elapsed     | 283      |\n",
      "|    total_timesteps  | 799216   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0341   |\n",
      "|    n_updates        | 199778   |\n",
      "----------------------------------\n",
      "Episode reward: 80.41642\n",
      "Episode reward: 46.872265\n",
      "Episode reward: 73.526492\n",
      "Episode reward: 81.34269\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13864    |\n",
      "|    fps              | 2819     |\n",
      "|    time_elapsed     | 283      |\n",
      "|    total_timesteps  | 799501   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.42     |\n",
      "|    n_updates        | 199850   |\n",
      "----------------------------------\n",
      "Episode reward: 33.704648\n",
      "Episode reward: 48.874485\n",
      "Episode reward: 53.543422\n",
      "Episode reward: 64.579792\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13868    |\n",
      "|    fps              | 2819     |\n",
      "|    time_elapsed     | 283      |\n",
      "|    total_timesteps  | 799703   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.342    |\n",
      "|    n_updates        | 199900   |\n",
      "----------------------------------\n",
      "Episode reward: 53.775913\n",
      "Episode reward: 44.866896\n",
      "Episode reward: 41.731797\n",
      "Episode reward: 46.909189\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13872    |\n",
      "|    fps              | 2819     |\n",
      "|    time_elapsed     | 283      |\n",
      "|    total_timesteps  | 799891   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.551    |\n",
      "|    n_updates        | 199947   |\n",
      "----------------------------------\n",
      "Episode reward: 67.835295\n",
      "Episode reward: 52.5732\n",
      "Episode reward: 63.643557\n",
      "Episode reward: 84.482405\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13876    |\n",
      "|    fps              | 2819     |\n",
      "|    time_elapsed     | 283      |\n",
      "|    total_timesteps  | 800161   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.263    |\n",
      "|    n_updates        | 200015   |\n",
      "----------------------------------\n",
      "Episode reward: 54.647075\n",
      "Episode reward: 93.762399\n",
      "Episode reward: 70.398416\n",
      "Episode reward: 82.115661\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13880    |\n",
      "|    fps              | 2819     |\n",
      "|    time_elapsed     | 283      |\n",
      "|    total_timesteps  | 800466   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.91     |\n",
      "|    n_updates        | 200091   |\n",
      "----------------------------------\n",
      "Episode reward: 52.877784\n",
      "Episode reward: 157.280012\n",
      "Episode reward: 30.833069\n",
      "Episode reward: 44.540073\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13884    |\n",
      "|    fps              | 2818     |\n",
      "|    time_elapsed     | 284      |\n",
      "|    total_timesteps  | 800756   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.57     |\n",
      "|    n_updates        | 200163   |\n",
      "----------------------------------\n",
      "Episode reward: 47.872513\n",
      "Episode reward: 94.876011\n",
      "Episode reward: 38.933639\n",
      "Episode reward: 56.680334\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13888    |\n",
      "|    fps              | 2818     |\n",
      "|    time_elapsed     | 284      |\n",
      "|    total_timesteps  | 800999   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.84     |\n",
      "|    n_updates        | 200224   |\n",
      "----------------------------------\n",
      "Episode reward: 79.747865\n",
      "Episode reward: 53.792515\n",
      "Episode reward: 39.80965\n",
      "Episode reward: 41.833244\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13892    |\n",
      "|    fps              | 2818     |\n",
      "|    time_elapsed     | 284      |\n",
      "|    total_timesteps  | 801215   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0556   |\n",
      "|    n_updates        | 200278   |\n",
      "----------------------------------\n",
      "Episode reward: 84.578682\n",
      "Episode reward: 85.789157\n",
      "Episode reward: 108.549716\n",
      "Episode reward: 36.923424\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13896    |\n",
      "|    fps              | 2818     |\n",
      "|    time_elapsed     | 284      |\n",
      "|    total_timesteps  | 801545   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.223    |\n",
      "|    n_updates        | 200361   |\n",
      "----------------------------------\n",
      "Episode reward: 62.453004\n",
      "Episode reward: 46.785471\n",
      "Episode reward: 28.953797\n",
      "Episode reward: 63.807224\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13900    |\n",
      "|    fps              | 2818     |\n",
      "|    time_elapsed     | 284      |\n",
      "|    total_timesteps  | 801750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.35     |\n",
      "|    n_updates        | 200412   |\n",
      "----------------------------------\n",
      "Episode reward: 47.86584\n",
      "Episode reward: 47.890064\n",
      "Episode reward: 37.844513\n",
      "Episode reward: 121.819784\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13904    |\n",
      "|    fps              | 2818     |\n",
      "|    time_elapsed     | 284      |\n",
      "|    total_timesteps  | 802011   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0666   |\n",
      "|    n_updates        | 200477   |\n",
      "----------------------------------\n",
      "Episode reward: 55.741507\n",
      "Episode reward: 57.693359\n",
      "Episode reward: 75.556416\n",
      "Episode reward: 117.324377\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13908    |\n",
      "|    fps              | 2818     |\n",
      "|    time_elapsed     | 284      |\n",
      "|    total_timesteps  | 802328   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0772   |\n",
      "|    n_updates        | 200556   |\n",
      "----------------------------------\n",
      "Episode reward: 36.58196\n",
      "Episode reward: 35.917274\n",
      "Episode reward: 52.790598\n",
      "Episode reward: 97.639258\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13912    |\n",
      "|    fps              | 2817     |\n",
      "|    time_elapsed     | 284      |\n",
      "|    total_timesteps  | 802552   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.368    |\n",
      "|    n_updates        | 200612   |\n",
      "----------------------------------\n",
      "Episode reward: 30.918366\n",
      "Episode reward: 94.333412\n",
      "Episode reward: 72.320844\n",
      "Episode reward: 66.710348\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13916    |\n",
      "|    fps              | 2817     |\n",
      "|    time_elapsed     | 284      |\n",
      "|    total_timesteps  | 802819   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.245    |\n",
      "|    n_updates        | 200679   |\n",
      "----------------------------------\n",
      "Episode reward: 47.85445\n",
      "Episode reward: 43.82296\n",
      "Episode reward: 170.933401\n",
      "Episode reward: 38.866659\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13920    |\n",
      "|    fps              | 2817     |\n",
      "|    time_elapsed     | 285      |\n",
      "|    total_timesteps  | 803123   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.7      |\n",
      "|    n_updates        | 200755   |\n",
      "----------------------------------\n",
      "Episode reward: 56.208187\n",
      "Episode reward: 37.791489\n",
      "Episode reward: 42.378774\n",
      "Episode reward: 77.249719\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13924    |\n",
      "|    fps              | 2817     |\n",
      "|    time_elapsed     | 285      |\n",
      "|    total_timesteps  | 803339   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0424   |\n",
      "|    n_updates        | 200809   |\n",
      "----------------------------------\n",
      "Episode reward: 106.041149\n",
      "Episode reward: 55.850517\n",
      "Episode reward: 36.747751\n",
      "Episode reward: 87.957313\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13928    |\n",
      "|    fps              | 2816     |\n",
      "|    time_elapsed     | 285      |\n",
      "|    total_timesteps  | 803629   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0585   |\n",
      "|    n_updates        | 200882   |\n",
      "----------------------------------\n",
      "Episode reward: 42.907616\n",
      "Episode reward: 90.699166\n",
      "Episode reward: 94.734728\n",
      "Episode reward: 43.62314\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13932    |\n",
      "|    fps              | 2815     |\n",
      "|    time_elapsed     | 285      |\n",
      "|    total_timesteps  | 803902   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.366    |\n",
      "|    n_updates        | 200950   |\n",
      "----------------------------------\n",
      "Episode reward: 72.807502\n",
      "Episode reward: 70.183521\n",
      "Episode reward: 49.885312\n",
      "Episode reward: 54.639303\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13936    |\n",
      "|    fps              | 2815     |\n",
      "|    time_elapsed     | 285      |\n",
      "|    total_timesteps  | 804151   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0989   |\n",
      "|    n_updates        | 201012   |\n",
      "----------------------------------\n",
      "Episode reward: 117.831526\n",
      "Episode reward: 168.742504\n",
      "Episode reward: 127.970634\n",
      "Episode reward: 34.913843\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.2     |\n",
      "|    ep_rew_mean      | 65.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13940    |\n",
      "|    fps              | 2814     |\n",
      "|    time_elapsed     | 285      |\n",
      "|    total_timesteps  | 804613   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0498   |\n",
      "|    n_updates        | 201128   |\n",
      "----------------------------------\n",
      "Episode reward: 68.303917\n",
      "Episode reward: 76.591566\n",
      "Episode reward: 78.030906\n",
      "Episode reward: 68.662597\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.2     |\n",
      "|    ep_rew_mean      | 66.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13944    |\n",
      "|    fps              | 2814     |\n",
      "|    time_elapsed     | 285      |\n",
      "|    total_timesteps  | 804910   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0236   |\n",
      "|    n_updates        | 201202   |\n",
      "----------------------------------\n",
      "Episode reward: 64.848159\n",
      "Episode reward: 48.776355\n",
      "Episode reward: 50.512813\n",
      "Episode reward: 51.861157\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.6     |\n",
      "|    ep_rew_mean      | 65.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13948    |\n",
      "|    fps              | 2813     |\n",
      "|    time_elapsed     | 286      |\n",
      "|    total_timesteps  | 805127   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.39     |\n",
      "|    n_updates        | 201256   |\n",
      "----------------------------------\n",
      "Episode reward: 39.760086\n",
      "Episode reward: 66.154021\n",
      "Episode reward: 33.934647\n",
      "Episode reward: 41.657183\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.9     |\n",
      "|    ep_rew_mean      | 64.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13952    |\n",
      "|    fps              | 2813     |\n",
      "|    time_elapsed     | 286      |\n",
      "|    total_timesteps  | 805311   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0347   |\n",
      "|    n_updates        | 201302   |\n",
      "----------------------------------\n",
      "Episode reward: 66.629775\n",
      "Episode reward: 77.643425\n",
      "Episode reward: 105.87195\n",
      "Episode reward: 53.503677\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.2     |\n",
      "|    ep_rew_mean      | 65.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13956    |\n",
      "|    fps              | 2812     |\n",
      "|    time_elapsed     | 286      |\n",
      "|    total_timesteps  | 805618   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0417   |\n",
      "|    n_updates        | 201379   |\n",
      "----------------------------------\n",
      "Episode reward: 60.73363\n",
      "Episode reward: 144.687888\n",
      "Episode reward: 55.702419\n",
      "Episode reward: 40.266291\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.1     |\n",
      "|    ep_rew_mean      | 66.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13960    |\n",
      "|    fps              | 2812     |\n",
      "|    time_elapsed     | 286      |\n",
      "|    total_timesteps  | 805922   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0368   |\n",
      "|    n_updates        | 201455   |\n",
      "----------------------------------\n",
      "Episode reward: 68.234235\n",
      "Episode reward: 55.343022\n",
      "Episode reward: 40.934004\n",
      "Episode reward: 46.291998\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.3     |\n",
      "|    ep_rew_mean      | 65.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13964    |\n",
      "|    fps              | 2812     |\n",
      "|    time_elapsed     | 286      |\n",
      "|    total_timesteps  | 806135   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0286   |\n",
      "|    n_updates        | 201508   |\n",
      "----------------------------------\n",
      "Episode reward: 66.135323\n",
      "Episode reward: 48.774943\n",
      "Episode reward: 77.754302\n",
      "Episode reward: 59.535369\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.9     |\n",
      "|    ep_rew_mean      | 65.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13968    |\n",
      "|    fps              | 2812     |\n",
      "|    time_elapsed     | 286      |\n",
      "|    total_timesteps  | 806390   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.048    |\n",
      "|    n_updates        | 201572   |\n",
      "----------------------------------\n",
      "Episode reward: 38.933676\n",
      "Episode reward: 38.719976\n",
      "Episode reward: 45.853063\n",
      "Episode reward: 70.184593\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.9     |\n",
      "|    ep_rew_mean      | 66       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13972    |\n",
      "|    fps              | 2811     |\n",
      "|    time_elapsed     | 286      |\n",
      "|    total_timesteps  | 806585   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.297    |\n",
      "|    n_updates        | 201621   |\n",
      "----------------------------------\n",
      "Episode reward: 41.557041\n",
      "Episode reward: 55.868258\n",
      "Episode reward: 48.697433\n",
      "Episode reward: 58.74312\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.3     |\n",
      "|    ep_rew_mean      | 65.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13976    |\n",
      "|    fps              | 2811     |\n",
      "|    time_elapsed     | 286      |\n",
      "|    total_timesteps  | 806791   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0339   |\n",
      "|    n_updates        | 201672   |\n",
      "----------------------------------\n",
      "Episode reward: 25.902413\n",
      "Episode reward: 60.561694\n",
      "Episode reward: 86.548288\n",
      "Episode reward: 48.888409\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.5     |\n",
      "|    ep_rew_mean      | 64.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13980    |\n",
      "|    fps              | 2811     |\n",
      "|    time_elapsed     | 287      |\n",
      "|    total_timesteps  | 807016   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.577    |\n",
      "|    n_updates        | 201728   |\n",
      "----------------------------------\n",
      "Episode reward: 43.867805\n",
      "Episode reward: 42.852571\n",
      "Episode reward: 27.85245\n",
      "Episode reward: 38.833635\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.1     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13984    |\n",
      "|    fps              | 2811     |\n",
      "|    time_elapsed     | 287      |\n",
      "|    total_timesteps  | 807170   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0229   |\n",
      "|    n_updates        | 201767   |\n",
      "----------------------------------\n",
      "Episode reward: 44.887789\n",
      "Episode reward: 46.70078\n",
      "Episode reward: 37.92829\n",
      "Episode reward: 85.168003\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13988    |\n",
      "|    fps              | 2810     |\n",
      "|    time_elapsed     | 287      |\n",
      "|    total_timesteps  | 807386   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0634   |\n",
      "|    n_updates        | 201821   |\n",
      "----------------------------------\n",
      "Episode reward: 81.443374\n",
      "Episode reward: 57.630024\n",
      "Episode reward: 48.71572\n",
      "Episode reward: 54.347001\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13992    |\n",
      "|    fps              | 2810     |\n",
      "|    time_elapsed     | 287      |\n",
      "|    total_timesteps  | 807631   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0756   |\n",
      "|    n_updates        | 201882   |\n",
      "----------------------------------\n",
      "Episode reward: 85.791737\n",
      "Episode reward: 32.796458\n",
      "Episode reward: 45.920628\n",
      "Episode reward: 88.708568\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 13996    |\n",
      "|    fps              | 2810     |\n",
      "|    time_elapsed     | 287      |\n",
      "|    total_timesteps  | 807887   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0704   |\n",
      "|    n_updates        | 201946   |\n",
      "----------------------------------\n",
      "Episode reward: 85.54839\n",
      "Episode reward: 36.706884\n",
      "Episode reward: 47.772695\n",
      "Episode reward: 44.738988\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14000    |\n",
      "|    fps              | 2810     |\n",
      "|    time_elapsed     | 287      |\n",
      "|    total_timesteps  | 808103   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.518    |\n",
      "|    n_updates        | 202000   |\n",
      "----------------------------------\n",
      "Episode reward: 39.886483\n",
      "Episode reward: 45.793991\n",
      "Episode reward: 47.870868\n",
      "Episode reward: 71.169409\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14004    |\n",
      "|    fps              | 2810     |\n",
      "|    time_elapsed     | 287      |\n",
      "|    total_timesteps  | 808310   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 202052   |\n",
      "----------------------------------\n",
      "Episode reward: 48.871813\n",
      "Episode reward: 67.152014\n",
      "Episode reward: 76.378972\n",
      "Episode reward: 35.888178\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14008    |\n",
      "|    fps              | 2809     |\n",
      "|    time_elapsed     | 287      |\n",
      "|    total_timesteps  | 808540   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0548   |\n",
      "|    n_updates        | 202109   |\n",
      "----------------------------------\n",
      "Episode reward: 75.324291\n",
      "Episode reward: 53.846259\n",
      "Episode reward: 39.795825\n",
      "Episode reward: 48.766122\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14012    |\n",
      "|    fps              | 2809     |\n",
      "|    time_elapsed     | 287      |\n",
      "|    total_timesteps  | 808759   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0754   |\n",
      "|    n_updates        | 202164   |\n",
      "----------------------------------\n",
      "Episode reward: 32.755184\n",
      "Episode reward: 33.921172\n",
      "Episode reward: 62.300858\n",
      "Episode reward: 74.751467\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14016    |\n",
      "|    fps              | 2809     |\n",
      "|    time_elapsed     | 287      |\n",
      "|    total_timesteps  | 808964   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0739   |\n",
      "|    n_updates        | 202215   |\n",
      "----------------------------------\n",
      "Episode reward: 62.245709\n",
      "Episode reward: 112.724467\n",
      "Episode reward: 80.037563\n",
      "Episode reward: 75.62499\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14020    |\n",
      "|    fps              | 2809     |\n",
      "|    time_elapsed     | 288      |\n",
      "|    total_timesteps  | 809300   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.393    |\n",
      "|    n_updates        | 202299   |\n",
      "----------------------------------\n",
      "Episode reward: 64.695446\n",
      "Episode reward: 28.899923\n",
      "Episode reward: 48.65266\n",
      "Episode reward: 66.711918\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14024    |\n",
      "|    fps              | 2809     |\n",
      "|    time_elapsed     | 288      |\n",
      "|    total_timesteps  | 809510   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0419   |\n",
      "|    n_updates        | 202352   |\n",
      "----------------------------------\n",
      "Episode reward: 74.364313\n",
      "Episode reward: 72.584273\n",
      "Episode reward: 111.053648\n",
      "Episode reward: 33.819347\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14028    |\n",
      "|    fps              | 2808     |\n",
      "|    time_elapsed     | 288      |\n",
      "|    total_timesteps  | 809804   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.25     |\n",
      "|    n_updates        | 202425   |\n",
      "----------------------------------\n",
      "Episode reward: 79.740885\n",
      "Episode reward: 162.860328\n",
      "Episode reward: 82.425485\n",
      "Episode reward: 39.747354\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14032    |\n",
      "|    fps              | 2808     |\n",
      "|    time_elapsed     | 288      |\n",
      "|    total_timesteps  | 810173   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.111    |\n",
      "|    n_updates        | 202518   |\n",
      "----------------------------------\n",
      "Episode reward: 67.395708\n",
      "Episode reward: 51.37993\n",
      "Episode reward: 69.701753\n",
      "Episode reward: 155.580229\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14036    |\n",
      "|    fps              | 2808     |\n",
      "|    time_elapsed     | 288      |\n",
      "|    total_timesteps  | 810540   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 202609   |\n",
      "----------------------------------\n",
      "Episode reward: 74.243911\n",
      "Episode reward: 61.679014\n",
      "Episode reward: 43.897659\n",
      "Episode reward: 43.590341\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14040    |\n",
      "|    fps              | 2807     |\n",
      "|    time_elapsed     | 288      |\n",
      "|    total_timesteps  | 810765   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.94     |\n",
      "|    n_updates        | 202666   |\n",
      "----------------------------------\n",
      "Episode reward: 50.850887\n",
      "Episode reward: 46.920834\n",
      "Episode reward: 65.139094\n",
      "Episode reward: 31.955784\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14044    |\n",
      "|    fps              | 2807     |\n",
      "|    time_elapsed     | 288      |\n",
      "|    total_timesteps  | 810961   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0393   |\n",
      "|    n_updates        | 202715   |\n",
      "----------------------------------\n",
      "Episode reward: 65.938912\n",
      "Episode reward: 38.914639\n",
      "Episode reward: 62.033191\n",
      "Episode reward: 60.839265\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14048    |\n",
      "|    fps              | 2807     |\n",
      "|    time_elapsed     | 288      |\n",
      "|    total_timesteps  | 811191   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0748   |\n",
      "|    n_updates        | 202772   |\n",
      "----------------------------------\n",
      "Episode reward: 70.498101\n",
      "Episode reward: 77.156099\n",
      "Episode reward: 31.899877\n",
      "Episode reward: 55.648447\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14052    |\n",
      "|    fps              | 2807     |\n",
      "|    time_elapsed     | 289      |\n",
      "|    total_timesteps  | 811428   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0959   |\n",
      "|    n_updates        | 202831   |\n",
      "----------------------------------\n",
      "Episode reward: 40.913317\n",
      "Episode reward: 57.863974\n",
      "Episode reward: 98.094377\n",
      "Episode reward: 34.929998\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14056    |\n",
      "|    fps              | 2806     |\n",
      "|    time_elapsed     | 289      |\n",
      "|    total_timesteps  | 811661   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0427   |\n",
      "|    n_updates        | 202890   |\n",
      "----------------------------------\n",
      "Episode reward: 50.759541\n",
      "Episode reward: 126.454247\n",
      "Episode reward: 33.827602\n",
      "Episode reward: 64.777907\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14060    |\n",
      "|    fps              | 2806     |\n",
      "|    time_elapsed     | 289      |\n",
      "|    total_timesteps  | 811942   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0504   |\n",
      "|    n_updates        | 202960   |\n",
      "----------------------------------\n",
      "Episode reward: 65.710868\n",
      "Episode reward: 59.836237\n",
      "Episode reward: 22.938791\n",
      "Episode reward: 53.591874\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14064    |\n",
      "|    fps              | 2806     |\n",
      "|    time_elapsed     | 289      |\n",
      "|    total_timesteps  | 812147   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.31     |\n",
      "|    n_updates        | 203011   |\n",
      "----------------------------------\n",
      "Episode reward: 35.864925\n",
      "Episode reward: 36.941626\n",
      "Episode reward: 64.977544\n",
      "Episode reward: 83.446398\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14068    |\n",
      "|    fps              | 2806     |\n",
      "|    time_elapsed     | 289      |\n",
      "|    total_timesteps  | 812371   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.422    |\n",
      "|    n_updates        | 203067   |\n",
      "----------------------------------\n",
      "Episode reward: 95.596006\n",
      "Episode reward: 70.432133\n",
      "Episode reward: 55.837074\n",
      "Episode reward: 58.867921\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14072    |\n",
      "|    fps              | 2806     |\n",
      "|    time_elapsed     | 289      |\n",
      "|    total_timesteps  | 812654   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.116    |\n",
      "|    n_updates        | 203138   |\n",
      "----------------------------------\n",
      "Episode reward: 26.805419\n",
      "Episode reward: 110.118479\n",
      "Episode reward: 40.903083\n",
      "Episode reward: 30.917684\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14076    |\n",
      "|    fps              | 2805     |\n",
      "|    time_elapsed     | 289      |\n",
      "|    total_timesteps  | 812866   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.272    |\n",
      "|    n_updates        | 203191   |\n",
      "----------------------------------\n",
      "Episode reward: 39.277897\n",
      "Episode reward: 64.532517\n",
      "Episode reward: 141.619894\n",
      "Episode reward: 56.651491\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14080    |\n",
      "|    fps              | 2805     |\n",
      "|    time_elapsed     | 289      |\n",
      "|    total_timesteps  | 813172   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.371    |\n",
      "|    n_updates        | 203267   |\n",
      "----------------------------------\n",
      "Episode reward: 95.801555\n",
      "Episode reward: 80.235297\n",
      "Episode reward: 45.846875\n",
      "Episode reward: 60.722305\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14084    |\n",
      "|    fps              | 2805     |\n",
      "|    time_elapsed     | 289      |\n",
      "|    total_timesteps  | 813458   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.359    |\n",
      "|    n_updates        | 203339   |\n",
      "----------------------------------\n",
      "Episode reward: 53.768022\n",
      "Episode reward: 75.186791\n",
      "Episode reward: 72.674206\n",
      "Episode reward: 65.698618\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14088    |\n",
      "|    fps              | 2805     |\n",
      "|    time_elapsed     | 290      |\n",
      "|    total_timesteps  | 813727   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.071    |\n",
      "|    n_updates        | 203406   |\n",
      "----------------------------------\n",
      "Episode reward: 31.699479\n",
      "Episode reward: 34.847993\n",
      "Episode reward: 39.940351\n",
      "Episode reward: 118.542255\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14092    |\n",
      "|    fps              | 2805     |\n",
      "|    time_elapsed     | 290      |\n",
      "|    total_timesteps  | 813954   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.144    |\n",
      "|    n_updates        | 203463   |\n",
      "----------------------------------\n",
      "Episode reward: 84.434459\n",
      "Episode reward: 64.754255\n",
      "Episode reward: 29.865197\n",
      "Episode reward: 75.652323\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14096    |\n",
      "|    fps              | 2805     |\n",
      "|    time_elapsed     | 290      |\n",
      "|    total_timesteps  | 814213   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0524   |\n",
      "|    n_updates        | 203528   |\n",
      "----------------------------------\n",
      "Episode reward: 59.825618\n",
      "Episode reward: 129.16977\n",
      "Episode reward: 75.840541\n",
      "Episode reward: 39.810378\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14100    |\n",
      "|    fps              | 2804     |\n",
      "|    time_elapsed     | 290      |\n",
      "|    total_timesteps  | 814520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0714   |\n",
      "|    n_updates        | 203604   |\n",
      "----------------------------------\n",
      "Episode reward: 70.752251\n",
      "Episode reward: 43.602496\n",
      "Episode reward: 43.749583\n",
      "Episode reward: 34.738347\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14104    |\n",
      "|    fps              | 2804     |\n",
      "|    time_elapsed     | 290      |\n",
      "|    total_timesteps  | 814715   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.335    |\n",
      "|    n_updates        | 203653   |\n",
      "----------------------------------\n",
      "Episode reward: 57.573056\n",
      "Episode reward: 59.662916\n",
      "Episode reward: 44.782715\n",
      "Episode reward: 32.567278\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14108    |\n",
      "|    fps              | 2804     |\n",
      "|    time_elapsed     | 290      |\n",
      "|    total_timesteps  | 814911   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.352    |\n",
      "|    n_updates        | 203702   |\n",
      "----------------------------------\n",
      "Episode reward: 62.592692\n",
      "Episode reward: 60.70313\n",
      "Episode reward: 37.94629\n",
      "Episode reward: 76.889896\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14112    |\n",
      "|    fps              | 2804     |\n",
      "|    time_elapsed     | 290      |\n",
      "|    total_timesteps  | 815152   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.85     |\n",
      "|    n_updates        | 203762   |\n",
      "----------------------------------\n",
      "Episode reward: 54.71877\n",
      "Episode reward: 96.049937\n",
      "Episode reward: 53.557381\n",
      "Episode reward: 50.76386\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14116    |\n",
      "|    fps              | 2804     |\n",
      "|    time_elapsed     | 290      |\n",
      "|    total_timesteps  | 815410   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.589    |\n",
      "|    n_updates        | 203827   |\n",
      "----------------------------------\n",
      "Episode reward: 54.779661\n",
      "Episode reward: 54.096264\n",
      "Episode reward: 31.890235\n",
      "Episode reward: 43.592781\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14120    |\n",
      "|    fps              | 2804     |\n",
      "|    time_elapsed     | 290      |\n",
      "|    total_timesteps  | 815596   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.03     |\n",
      "|    n_updates        | 203873   |\n",
      "----------------------------------\n",
      "Episode reward: 50.906571\n",
      "Episode reward: 50.901266\n",
      "Episode reward: 71.74467\n",
      "Episode reward: 36.702243\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14124    |\n",
      "|    fps              | 2803     |\n",
      "|    time_elapsed     | 290      |\n",
      "|    total_timesteps  | 815809   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0523   |\n",
      "|    n_updates        | 203927   |\n",
      "----------------------------------\n",
      "Episode reward: 39.928834\n",
      "Episode reward: 45.872395\n",
      "Episode reward: 72.443729\n",
      "Episode reward: 62.149591\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14128    |\n",
      "|    fps              | 2803     |\n",
      "|    time_elapsed     | 291      |\n",
      "|    total_timesteps  | 816031   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0569   |\n",
      "|    n_updates        | 203982   |\n",
      "----------------------------------\n",
      "Episode reward: 61.830811\n",
      "Episode reward: 55.830344\n",
      "Episode reward: 76.59628\n",
      "Episode reward: 138.21636\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14132    |\n",
      "|    fps              | 2803     |\n",
      "|    time_elapsed     | 291      |\n",
      "|    total_timesteps  | 816365   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.201    |\n",
      "|    n_updates        | 204066   |\n",
      "----------------------------------\n",
      "Episode reward: 40.875517\n",
      "Episode reward: 68.233134\n",
      "Episode reward: 63.715791\n",
      "Episode reward: 71.44818\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14136    |\n",
      "|    fps              | 2803     |\n",
      "|    time_elapsed     | 291      |\n",
      "|    total_timesteps  | 816611   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.046    |\n",
      "|    n_updates        | 204127   |\n",
      "----------------------------------\n",
      "Episode reward: 129.948267\n",
      "Episode reward: 68.664836\n",
      "Episode reward: 65.677547\n",
      "Episode reward: 36.907412\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14140    |\n",
      "|    fps              | 2803     |\n",
      "|    time_elapsed     | 291      |\n",
      "|    total_timesteps  | 816925   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0874   |\n",
      "|    n_updates        | 204206   |\n",
      "----------------------------------\n",
      "Episode reward: 70.767358\n",
      "Episode reward: 95.50955\n",
      "Episode reward: 103.772084\n",
      "Episode reward: 42.938006\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14144    |\n",
      "|    fps              | 2802     |\n",
      "|    time_elapsed     | 291      |\n",
      "|    total_timesteps  | 817246   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.484    |\n",
      "|    n_updates        | 204286   |\n",
      "----------------------------------\n",
      "Episode reward: 53.64373\n",
      "Episode reward: 67.204334\n",
      "Episode reward: 35.910891\n",
      "Episode reward: 85.651374\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14148    |\n",
      "|    fps              | 2802     |\n",
      "|    time_elapsed     | 291      |\n",
      "|    total_timesteps  | 817490   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0604   |\n",
      "|    n_updates        | 204347   |\n",
      "----------------------------------\n",
      "Episode reward: 46.80592\n",
      "Episode reward: 59.756858\n",
      "Episode reward: 41.903718\n",
      "Episode reward: 58.985135\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14152    |\n",
      "|    fps              | 2802     |\n",
      "|    time_elapsed     | 291      |\n",
      "|    total_timesteps  | 817699   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0666   |\n",
      "|    n_updates        | 204399   |\n",
      "----------------------------------\n",
      "Episode reward: 59.595904\n",
      "Episode reward: 67.84204\n",
      "Episode reward: 120.563853\n",
      "Episode reward: 47.910367\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14156    |\n",
      "|    fps              | 2801     |\n",
      "|    time_elapsed     | 291      |\n",
      "|    total_timesteps  | 817997   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0419   |\n",
      "|    n_updates        | 204474   |\n",
      "----------------------------------\n",
      "Episode reward: 64.796417\n",
      "Episode reward: 43.811389\n",
      "Episode reward: 147.942386\n",
      "Episode reward: 50.866803\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14160    |\n",
      "|    fps              | 2801     |\n",
      "|    time_elapsed     | 292      |\n",
      "|    total_timesteps  | 818308   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0941   |\n",
      "|    n_updates        | 204551   |\n",
      "----------------------------------\n",
      "Episode reward: 48.769784\n",
      "Episode reward: 101.568574\n",
      "Episode reward: 33.695484\n",
      "Episode reward: 30.788533\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14164    |\n",
      "|    fps              | 2801     |\n",
      "|    time_elapsed     | 292      |\n",
      "|    total_timesteps  | 818524   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0628   |\n",
      "|    n_updates        | 204605   |\n",
      "----------------------------------\n",
      "Episode reward: 44.91653\n",
      "Episode reward: 40.900682\n",
      "Episode reward: 58.662468\n",
      "Episode reward: 31.836695\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14168    |\n",
      "|    fps              | 2801     |\n",
      "|    time_elapsed     | 292      |\n",
      "|    total_timesteps  | 818701   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0692   |\n",
      "|    n_updates        | 204650   |\n",
      "----------------------------------\n",
      "Episode reward: 51.916436\n",
      "Episode reward: 38.937727\n",
      "Episode reward: 78.681342\n",
      "Episode reward: 30.923133\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14172    |\n",
      "|    fps              | 2801     |\n",
      "|    time_elapsed     | 292      |\n",
      "|    total_timesteps  | 818907   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0691   |\n",
      "|    n_updates        | 204701   |\n",
      "----------------------------------\n",
      "Episode reward: 76.746656\n",
      "Episode reward: 62.798478\n",
      "Episode reward: 58.78422\n",
      "Episode reward: 63.582792\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14176    |\n",
      "|    fps              | 2800     |\n",
      "|    time_elapsed     | 292      |\n",
      "|    total_timesteps  | 819171   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.051    |\n",
      "|    n_updates        | 204767   |\n",
      "----------------------------------\n",
      "Episode reward: 40.656843\n",
      "Episode reward: 61.378566\n",
      "Episode reward: 58.714194\n",
      "Episode reward: 104.774702\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14180    |\n",
      "|    fps              | 2800     |\n",
      "|    time_elapsed     | 292      |\n",
      "|    total_timesteps  | 819442   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.66     |\n",
      "|    n_updates        | 204835   |\n",
      "----------------------------------\n",
      "Episode reward: 93.101157\n",
      "Episode reward: 34.738337\n",
      "Episode reward: 57.381158\n",
      "Episode reward: 71.678405\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14184    |\n",
      "|    fps              | 2800     |\n",
      "|    time_elapsed     | 292      |\n",
      "|    total_timesteps  | 819701   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.066    |\n",
      "|    n_updates        | 204900   |\n",
      "----------------------------------\n",
      "Episode reward: 58.853969\n",
      "Episode reward: 118.668502\n",
      "Episode reward: 123.326195\n",
      "Episode reward: 81.372976\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14188    |\n",
      "|    fps              | 2800     |\n",
      "|    time_elapsed     | 292      |\n",
      "|    total_timesteps  | 820087   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0836   |\n",
      "|    n_updates        | 204996   |\n",
      "----------------------------------\n",
      "Episode reward: 92.62612\n",
      "Episode reward: 51.633496\n",
      "Episode reward: 77.75681\n",
      "Episode reward: 72.476497\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14192    |\n",
      "|    fps              | 2800     |\n",
      "|    time_elapsed     | 292      |\n",
      "|    total_timesteps  | 820384   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.087    |\n",
      "|    n_updates        | 205070   |\n",
      "----------------------------------\n",
      "Episode reward: 32.824776\n",
      "Episode reward: 30.755231\n",
      "Episode reward: 95.327213\n",
      "Episode reward: 43.889624\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14196    |\n",
      "|    fps              | 2800     |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total_timesteps  | 820588   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0399   |\n",
      "|    n_updates        | 205121   |\n",
      "----------------------------------\n",
      "Episode reward: 67.1272\n",
      "Episode reward: 54.34806\n",
      "Episode reward: 115.225394\n",
      "Episode reward: 59.975344\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14200    |\n",
      "|    fps              | 2799     |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total_timesteps  | 820897   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.33     |\n",
      "|    n_updates        | 205199   |\n",
      "----------------------------------\n",
      "Episode reward: 57.808496\n",
      "Episode reward: 44.864925\n",
      "Episode reward: 35.552604\n",
      "Episode reward: 43.826847\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14204    |\n",
      "|    fps              | 2799     |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total_timesteps  | 821080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0827   |\n",
      "|    n_updates        | 205244   |\n",
      "----------------------------------\n",
      "Episode reward: 100.436543\n",
      "Episode reward: 59.817071\n",
      "Episode reward: 51.608854\n",
      "Episode reward: 92.786565\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 63.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14208    |\n",
      "|    fps              | 2799     |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total_timesteps  | 821390   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.6      |\n",
      "|    n_updates        | 205322   |\n",
      "----------------------------------\n",
      "Episode reward: 47.918488\n",
      "Episode reward: 29.902502\n",
      "Episode reward: 121.046226\n",
      "Episode reward: 39.70955\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65       |\n",
      "|    ep_rew_mean      | 63.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14212    |\n",
      "|    fps              | 2799     |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total_timesteps  | 821647   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0587   |\n",
      "|    n_updates        | 205386   |\n",
      "----------------------------------\n",
      "Episode reward: 58.796036\n",
      "Episode reward: 36.859749\n",
      "Episode reward: 61.586022\n",
      "Episode reward: 49.839222\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14216    |\n",
      "|    fps              | 2799     |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total_timesteps  | 821855   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0306   |\n",
      "|    n_updates        | 205438   |\n",
      "----------------------------------\n",
      "Episode reward: 38.895988\n",
      "Episode reward: 70.75544\n",
      "Episode reward: 73.433096\n",
      "Episode reward: 92.663675\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.4     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14220    |\n",
      "|    fps              | 2799     |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total_timesteps  | 822134   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0591   |\n",
      "|    n_updates        | 205508   |\n",
      "----------------------------------\n",
      "Episode reward: 34.856542\n",
      "Episode reward: 48.370095\n",
      "Episode reward: 44.819598\n",
      "Episode reward: 55.706433\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.1     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14224    |\n",
      "|    fps              | 2798     |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total_timesteps  | 822320   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.226    |\n",
      "|    n_updates        | 205554   |\n",
      "----------------------------------\n",
      "Episode reward: 34.886432\n",
      "Episode reward: 32.940099\n",
      "Episode reward: 52.814429\n",
      "Episode reward: 58.861186\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.7     |\n",
      "|    ep_rew_mean      | 63.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14228    |\n",
      "|    fps              | 2798     |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total_timesteps  | 822500   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0922   |\n",
      "|    n_updates        | 205599   |\n",
      "----------------------------------\n",
      "Episode reward: 87.302304\n",
      "Episode reward: 40.918073\n",
      "Episode reward: 29.675845\n",
      "Episode reward: 51.84974\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14232    |\n",
      "|    fps              | 2798     |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total_timesteps  | 822711   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.26     |\n",
      "|    n_updates        | 205652   |\n",
      "----------------------------------\n",
      "Episode reward: 110.653683\n",
      "Episode reward: 150.3766\n",
      "Episode reward: 52.770757\n",
      "Episode reward: 94.7578\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.2     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14236    |\n",
      "|    fps              | 2798     |\n",
      "|    time_elapsed     | 294      |\n",
      "|    total_timesteps  | 823132   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.308    |\n",
      "|    n_updates        | 205757   |\n",
      "----------------------------------\n",
      "Episode reward: 67.194347\n",
      "Episode reward: 35.947014\n",
      "Episode reward: 141.352127\n",
      "Episode reward: 56.636253\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.1     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14240    |\n",
      "|    fps              | 2798     |\n",
      "|    time_elapsed     | 294      |\n",
      "|    total_timesteps  | 823439   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.18     |\n",
      "|    n_updates        | 205834   |\n",
      "----------------------------------\n",
      "Episode reward: 61.485411\n",
      "Episode reward: 42.671621\n",
      "Episode reward: 46.885938\n",
      "Episode reward: 44.871934\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14244    |\n",
      "|    fps              | 2798     |\n",
      "|    time_elapsed     | 294      |\n",
      "|    total_timesteps  | 823636   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.128    |\n",
      "|    n_updates        | 205883   |\n",
      "----------------------------------\n",
      "Episode reward: 49.889833\n",
      "Episode reward: 68.415391\n",
      "Episode reward: 127.578883\n",
      "Episode reward: 32.781291\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14248    |\n",
      "|    fps              | 2798     |\n",
      "|    time_elapsed     | 294      |\n",
      "|    total_timesteps  | 823924   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0553   |\n",
      "|    n_updates        | 205955   |\n",
      "----------------------------------\n",
      "Episode reward: 64.843133\n",
      "Episode reward: 64.10765\n",
      "Episode reward: 67.200438\n",
      "Episode reward: 68.776359\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.9     |\n",
      "|    ep_rew_mean      | 63.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14252    |\n",
      "|    fps              | 2798     |\n",
      "|    time_elapsed     | 294      |\n",
      "|    total_timesteps  | 824193   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0318   |\n",
      "|    n_updates        | 206023   |\n",
      "----------------------------------\n",
      "Episode reward: 77.463516\n",
      "Episode reward: 79.377135\n",
      "Episode reward: 69.858818\n",
      "Episode reward: 200.346922\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.3     |\n",
      "|    ep_rew_mean      | 65.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14256    |\n",
      "|    fps              | 2797     |\n",
      "|    time_elapsed     | 294      |\n",
      "|    total_timesteps  | 824625   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.132    |\n",
      "|    n_updates        | 206131   |\n",
      "----------------------------------\n",
      "Episode reward: 61.893004\n",
      "Episode reward: 78.682456\n",
      "Episode reward: 42.652504\n",
      "Episode reward: 35.901013\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.4     |\n",
      "|    ep_rew_mean      | 64.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14260    |\n",
      "|    fps              | 2797     |\n",
      "|    time_elapsed     | 294      |\n",
      "|    total_timesteps  | 824846   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0437   |\n",
      "|    n_updates        | 206186   |\n",
      "----------------------------------\n",
      "Episode reward: 67.165966\n",
      "Episode reward: 83.308161\n",
      "Episode reward: 36.890731\n",
      "Episode reward: 52.749357\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.7     |\n",
      "|    ep_rew_mean      | 64.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14264    |\n",
      "|    fps              | 2797     |\n",
      "|    time_elapsed     | 294      |\n",
      "|    total_timesteps  | 825089   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.42     |\n",
      "|    n_updates        | 206247   |\n",
      "----------------------------------\n",
      "Episode reward: 47.643419\n",
      "Episode reward: 55.541714\n",
      "Episode reward: 32.911744\n",
      "Episode reward: 85.267468\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.1     |\n",
      "|    ep_rew_mean      | 65       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14268    |\n",
      "|    fps              | 2797     |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total_timesteps  | 825313   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.182    |\n",
      "|    n_updates        | 206303   |\n",
      "----------------------------------\n",
      "Episode reward: 46.803654\n",
      "Episode reward: 54.868574\n",
      "Episode reward: 52.779575\n",
      "Episode reward: 37.941856\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66       |\n",
      "|    ep_rew_mean      | 64.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14272    |\n",
      "|    fps              | 2797     |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total_timesteps  | 825506   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.16     |\n",
      "|    n_updates        | 206351   |\n",
      "----------------------------------\n",
      "Episode reward: 26.901735\n",
      "Episode reward: 82.550129\n",
      "Episode reward: 65.466262\n",
      "Episode reward: 40.837549\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.5     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14276    |\n",
      "|    fps              | 2797     |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total_timesteps  | 825724   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 206405   |\n",
      "----------------------------------\n",
      "Episode reward: 53.580646\n",
      "Episode reward: 54.661817\n",
      "Episode reward: 30.726082\n",
      "Episode reward: 39.550273\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14280    |\n",
      "|    fps              | 2797     |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total_timesteps  | 825904   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0786   |\n",
      "|    n_updates        | 206450   |\n",
      "----------------------------------\n",
      "Episode reward: 96.570936\n",
      "Episode reward: 74.660698\n",
      "Episode reward: 61.742049\n",
      "Episode reward: 60.603247\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65       |\n",
      "|    ep_rew_mean      | 63.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14284    |\n",
      "|    fps              | 2797     |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total_timesteps  | 826204   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 206525   |\n",
      "----------------------------------\n",
      "Episode reward: 55.646165\n",
      "Episode reward: 88.612205\n",
      "Episode reward: 45.865587\n",
      "Episode reward: 36.947897\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14288    |\n",
      "|    fps              | 2797     |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total_timesteps  | 826432   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.248    |\n",
      "|    n_updates        | 206582   |\n",
      "----------------------------------\n",
      "Episode reward: 33.566782\n",
      "Episode reward: 35.872948\n",
      "Episode reward: 78.7873\n",
      "Episode reward: 39.827239\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14292    |\n",
      "|    fps              | 2797     |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total_timesteps  | 826621   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.065    |\n",
      "|    n_updates        | 206630   |\n",
      "----------------------------------\n",
      "Episode reward: 79.376362\n",
      "Episode reward: 107.267443\n",
      "Episode reward: 119.750907\n",
      "Episode reward: 39.373765\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14296    |\n",
      "|    fps              | 2797     |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total_timesteps  | 826969   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 206717   |\n",
      "----------------------------------\n",
      "Episode reward: 42.943369\n",
      "Episode reward: 89.449492\n",
      "Episode reward: 45.897173\n",
      "Episode reward: 148.217524\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14300    |\n",
      "|    fps              | 2797     |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total_timesteps  | 827300   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 206799   |\n",
      "----------------------------------\n",
      "Episode reward: 39.928852\n",
      "Episode reward: 44.915586\n",
      "Episode reward: 40.934978\n",
      "Episode reward: 32.563863\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14304    |\n",
      "|    fps              | 2797     |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total_timesteps  | 827459   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0766   |\n",
      "|    n_updates        | 206839   |\n",
      "----------------------------------\n",
      "Episode reward: 86.01718\n",
      "Episode reward: 99.62314\n",
      "Episode reward: 29.894172\n",
      "Episode reward: 44.873645\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14308    |\n",
      "|    fps              | 2797     |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total_timesteps  | 827724   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0358   |\n",
      "|    n_updates        | 206905   |\n",
      "----------------------------------\n",
      "Episode reward: 37.909636\n",
      "Episode reward: 50.814353\n",
      "Episode reward: 50.570495\n",
      "Episode reward: 103.542107\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14312    |\n",
      "|    fps              | 2797     |\n",
      "|    time_elapsed     | 295      |\n",
      "|    total_timesteps  | 827968   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0907   |\n",
      "|    n_updates        | 206966   |\n",
      "----------------------------------\n",
      "Episode reward: 96.411301\n",
      "Episode reward: 35.896598\n",
      "Episode reward: 72.867393\n",
      "Episode reward: 47.514456\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14316    |\n",
      "|    fps              | 2797     |\n",
      "|    time_elapsed     | 296      |\n",
      "|    total_timesteps  | 828223   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0522   |\n",
      "|    n_updates        | 207030   |\n",
      "----------------------------------\n",
      "Episode reward: 70.739112\n",
      "Episode reward: 50.823479\n",
      "Episode reward: 43.722532\n",
      "Episode reward: 97.643412\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14320    |\n",
      "|    fps              | 2797     |\n",
      "|    time_elapsed     | 296      |\n",
      "|    total_timesteps  | 828487   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0934   |\n",
      "|    n_updates        | 207096   |\n",
      "----------------------------------\n",
      "Episode reward: 72.78894\n",
      "Episode reward: 65.012138\n",
      "Episode reward: 91.05569\n",
      "Episode reward: 80.495412\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 64       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14324    |\n",
      "|    fps              | 2797     |\n",
      "|    time_elapsed     | 296      |\n",
      "|    total_timesteps  | 828800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.403    |\n",
      "|    n_updates        | 207174   |\n",
      "----------------------------------\n",
      "Episode reward: 96.541325\n",
      "Episode reward: 84.849791\n",
      "Episode reward: 34.938954\n",
      "Episode reward: 69.099662\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.9     |\n",
      "|    ep_rew_mean      | 65.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14328    |\n",
      "|    fps              | 2796     |\n",
      "|    time_elapsed     | 296      |\n",
      "|    total_timesteps  | 829089   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0663   |\n",
      "|    n_updates        | 207247   |\n",
      "----------------------------------\n",
      "Episode reward: 71.293682\n",
      "Episode reward: 60.340512\n",
      "Episode reward: 62.637146\n",
      "Episode reward: 23.851323\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66       |\n",
      "|    ep_rew_mean      | 65.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14332    |\n",
      "|    fps              | 2796     |\n",
      "|    time_elapsed     | 296      |\n",
      "|    total_timesteps  | 829309   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.23     |\n",
      "|    n_updates        | 207302   |\n",
      "----------------------------------\n",
      "Episode reward: 44.913353\n",
      "Episode reward: 167.870218\n",
      "Episode reward: 45.656782\n",
      "Episode reward: 53.885558\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65       |\n",
      "|    ep_rew_mean      | 64.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14336    |\n",
      "|    fps              | 2796     |\n",
      "|    time_elapsed     | 296      |\n",
      "|    total_timesteps  | 829627   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.055    |\n",
      "|    n_updates        | 207381   |\n",
      "----------------------------------\n",
      "Episode reward: 45.866254\n",
      "Episode reward: 42.540567\n",
      "Episode reward: 66.394761\n",
      "Episode reward: 87.788833\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14340    |\n",
      "|    fps              | 2796     |\n",
      "|    time_elapsed     | 296      |\n",
      "|    total_timesteps  | 829873   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0356   |\n",
      "|    n_updates        | 207443   |\n",
      "----------------------------------\n",
      "Episode reward: 45.780938\n",
      "Episode reward: 86.793771\n",
      "Episode reward: 29.956737\n",
      "Episode reward: 60.770082\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 63.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14344    |\n",
      "|    fps              | 2796     |\n",
      "|    time_elapsed     | 296      |\n",
      "|    total_timesteps  | 830100   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0778   |\n",
      "|    n_updates        | 207499   |\n",
      "----------------------------------\n",
      "Episode reward: 50.847567\n",
      "Episode reward: 81.721083\n",
      "Episode reward: 46.361248\n",
      "Episode reward: 32.945199\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14348    |\n",
      "|    fps              | 2796     |\n",
      "|    time_elapsed     | 296      |\n",
      "|    total_timesteps  | 830313   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0456   |\n",
      "|    n_updates        | 207553   |\n",
      "----------------------------------\n",
      "Episode reward: 33.584936\n",
      "Episode reward: 68.234564\n",
      "Episode reward: 62.786279\n",
      "Episode reward: 51.872266\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14352    |\n",
      "|    fps              | 2796     |\n",
      "|    time_elapsed     | 296      |\n",
      "|    total_timesteps  | 830533   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0535   |\n",
      "|    n_updates        | 207608   |\n",
      "----------------------------------\n",
      "Episode reward: 23.71533\n",
      "Episode reward: 49.663457\n",
      "Episode reward: 121.235555\n",
      "Episode reward: 154.825907\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14356    |\n",
      "|    fps              | 2796     |\n",
      "|    time_elapsed     | 297      |\n",
      "|    total_timesteps  | 830895   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.043    |\n",
      "|    n_updates        | 207698   |\n",
      "----------------------------------\n",
      "Episode reward: 52.491042\n",
      "Episode reward: 46.884956\n",
      "Episode reward: 67.53432\n",
      "Episode reward: 46.920211\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.6     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14360    |\n",
      "|    fps              | 2796     |\n",
      "|    time_elapsed     | 297      |\n",
      "|    total_timesteps  | 831110   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0339   |\n",
      "|    n_updates        | 207752   |\n",
      "----------------------------------\n",
      "Episode reward: 89.303253\n",
      "Episode reward: 98.687476\n",
      "Episode reward: 49.974755\n",
      "Episode reward: 47.812899\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14364    |\n",
      "|    fps              | 2796     |\n",
      "|    time_elapsed     | 297      |\n",
      "|    total_timesteps  | 831399   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0781   |\n",
      "|    n_updates        | 207824   |\n",
      "----------------------------------\n",
      "Episode reward: 33.952269\n",
      "Episode reward: 74.800688\n",
      "Episode reward: 68.555097\n",
      "Episode reward: 86.317393\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14368    |\n",
      "|    fps              | 2795     |\n",
      "|    time_elapsed     | 297      |\n",
      "|    total_timesteps  | 831665   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0565   |\n",
      "|    n_updates        | 207891   |\n",
      "----------------------------------\n",
      "Episode reward: 88.024187\n",
      "Episode reward: 100.341373\n",
      "Episode reward: 65.850856\n",
      "Episode reward: 35.939775\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 63.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14372    |\n",
      "|    fps              | 2795     |\n",
      "|    time_elapsed     | 297      |\n",
      "|    total_timesteps  | 831963   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.222    |\n",
      "|    n_updates        | 207965   |\n",
      "----------------------------------\n",
      "Episode reward: 35.918297\n",
      "Episode reward: 50.772425\n",
      "Episode reward: 51.826913\n",
      "Episode reward: 82.483336\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14376    |\n",
      "|    fps              | 2795     |\n",
      "|    time_elapsed     | 297      |\n",
      "|    total_timesteps  | 832185   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0607   |\n",
      "|    n_updates        | 208021   |\n",
      "----------------------------------\n",
      "Episode reward: 96.443036\n",
      "Episode reward: 39.920924\n",
      "Episode reward: 34.903535\n",
      "Episode reward: 115.549502\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.4     |\n",
      "|    ep_rew_mean      | 64.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14380    |\n",
      "|    fps              | 2795     |\n",
      "|    time_elapsed     | 297      |\n",
      "|    total_timesteps  | 832543   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0486   |\n",
      "|    n_updates        | 208110   |\n",
      "----------------------------------\n",
      "Episode reward: 46.687887\n",
      "Episode reward: 40.871396\n",
      "Episode reward: 32.799279\n",
      "Episode reward: 68.058494\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.3     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14384    |\n",
      "|    fps              | 2795     |\n",
      "|    time_elapsed     | 297      |\n",
      "|    total_timesteps  | 832733   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0391   |\n",
      "|    n_updates        | 208158   |\n",
      "----------------------------------\n",
      "Episode reward: 59.832726\n",
      "Episode reward: 61.667449\n",
      "Episode reward: 112.455233\n",
      "Episode reward: 35.874631\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.7     |\n",
      "|    ep_rew_mean      | 64.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14388    |\n",
      "|    fps              | 2795     |\n",
      "|    time_elapsed     | 298      |\n",
      "|    total_timesteps  | 833004   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.338    |\n",
      "|    n_updates        | 208225   |\n",
      "----------------------------------\n",
      "Episode reward: 39.914658\n",
      "Episode reward: 145.80487\n",
      "Episode reward: 43.780894\n",
      "Episode reward: 37.764064\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.6     |\n",
      "|    ep_rew_mean      | 65.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14392    |\n",
      "|    fps              | 2794     |\n",
      "|    time_elapsed     | 298      |\n",
      "|    total_timesteps  | 833281   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0434   |\n",
      "|    n_updates        | 208295   |\n",
      "----------------------------------\n",
      "Episode reward: 42.86374\n",
      "Episode reward: 157.805761\n",
      "Episode reward: 67.83666\n",
      "Episode reward: 38.943065\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.2     |\n",
      "|    ep_rew_mean      | 64.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14396    |\n",
      "|    fps              | 2794     |\n",
      "|    time_elapsed     | 298      |\n",
      "|    total_timesteps  | 833591   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.99     |\n",
      "|    n_updates        | 208372   |\n",
      "----------------------------------\n",
      "Episode reward: 41.884396\n",
      "Episode reward: 30.755255\n",
      "Episode reward: 55.862834\n",
      "Episode reward: 73.663871\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.9     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14400    |\n",
      "|    fps              | 2794     |\n",
      "|    time_elapsed     | 298      |\n",
      "|    total_timesteps  | 833794   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.139    |\n",
      "|    n_updates        | 208423   |\n",
      "----------------------------------\n",
      "Episode reward: 60.831641\n",
      "Episode reward: 46.921757\n",
      "Episode reward: 35.915692\n",
      "Episode reward: 109.718561\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.9     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14404    |\n",
      "|    fps              | 2794     |\n",
      "|    time_elapsed     | 298      |\n",
      "|    total_timesteps  | 834048   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.56     |\n",
      "|    n_updates        | 208486   |\n",
      "----------------------------------\n",
      "Episode reward: 65.14525\n",
      "Episode reward: 141.254297\n",
      "Episode reward: 58.465116\n",
      "Episode reward: 70.752675\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.8     |\n",
      "|    ep_rew_mean      | 65.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14408    |\n",
      "|    fps              | 2794     |\n",
      "|    time_elapsed     | 298      |\n",
      "|    total_timesteps  | 834406   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0725   |\n",
      "|    n_updates        | 208576   |\n",
      "----------------------------------\n",
      "Episode reward: 34.93149\n",
      "Episode reward: 35.889811\n",
      "Episode reward: 88.327972\n",
      "Episode reward: 53.888296\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.5     |\n",
      "|    ep_rew_mean      | 64.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14412    |\n",
      "|    fps              | 2794     |\n",
      "|    time_elapsed     | 298      |\n",
      "|    total_timesteps  | 834620   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0866   |\n",
      "|    n_updates        | 208629   |\n",
      "----------------------------------\n",
      "Episode reward: 82.915748\n",
      "Episode reward: 73.039401\n",
      "Episode reward: 51.380212\n",
      "Episode reward: 75.482213\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.9     |\n",
      "|    ep_rew_mean      | 65.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14416    |\n",
      "|    fps              | 2794     |\n",
      "|    time_elapsed     | 298      |\n",
      "|    total_timesteps  | 834909   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.83     |\n",
      "|    n_updates        | 208702   |\n",
      "----------------------------------\n",
      "Episode reward: 93.583781\n",
      "Episode reward: 36.764478\n",
      "Episode reward: 153.623259\n",
      "Episode reward: 52.664352\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.6     |\n",
      "|    ep_rew_mean      | 65.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14420    |\n",
      "|    fps              | 2794     |\n",
      "|    time_elapsed     | 298      |\n",
      "|    total_timesteps  | 835251   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 208787   |\n",
      "----------------------------------\n",
      "Episode reward: 80.467087\n",
      "Episode reward: 91.565802\n",
      "Episode reward: 48.870801\n",
      "Episode reward: 47.877823\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.2     |\n",
      "|    ep_rew_mean      | 65.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14424    |\n",
      "|    fps              | 2793     |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total_timesteps  | 835522   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0962   |\n",
      "|    n_updates        | 208855   |\n",
      "----------------------------------\n",
      "Episode reward: 52.866426\n",
      "Episode reward: 28.743735\n",
      "Episode reward: 55.990948\n",
      "Episode reward: 44.78274\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.2     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14428    |\n",
      "|    fps              | 2793     |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total_timesteps  | 835706   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0538   |\n",
      "|    n_updates        | 208901   |\n",
      "----------------------------------\n",
      "Episode reward: 38.911734\n",
      "Episode reward: 47.867071\n",
      "Episode reward: 75.977614\n",
      "Episode reward: 43.866265\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.1     |\n",
      "|    ep_rew_mean      | 64.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14432    |\n",
      "|    fps              | 2793     |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total_timesteps  | 835918   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0658   |\n",
      "|    n_updates        | 208954   |\n",
      "----------------------------------\n",
      "Episode reward: 46.854231\n",
      "Episode reward: 93.388394\n",
      "Episode reward: 44.888615\n",
      "Episode reward: 42.910584\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.2     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14436    |\n",
      "|    fps              | 2793     |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total_timesteps  | 836147   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.06     |\n",
      "|    n_updates        | 209011   |\n",
      "----------------------------------\n",
      "Episode reward: 80.134134\n",
      "Episode reward: 31.875794\n",
      "Episode reward: 44.647272\n",
      "Episode reward: 38.817844\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.7     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14440    |\n",
      "|    fps              | 2793     |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total_timesteps  | 836345   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.317    |\n",
      "|    n_updates        | 209061   |\n",
      "----------------------------------\n",
      "Episode reward: 60.6785\n",
      "Episode reward: 72.701176\n",
      "Episode reward: 51.701144\n",
      "Episode reward: 31.505528\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14444    |\n",
      "|    fps              | 2793     |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total_timesteps  | 836563   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.859    |\n",
      "|    n_updates        | 209115   |\n",
      "----------------------------------\n",
      "Episode reward: 71.310454\n",
      "Episode reward: 49.856508\n",
      "Episode reward: 48.855617\n",
      "Episode reward: 40.726747\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14448    |\n",
      "|    fps              | 2793     |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total_timesteps  | 836775   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.359    |\n",
      "|    n_updates        | 209168   |\n",
      "----------------------------------\n",
      "Episode reward: 71.021336\n",
      "Episode reward: 59.417952\n",
      "Episode reward: 56.553367\n",
      "Episode reward: 61.793422\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.9     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14452    |\n",
      "|    fps              | 2793     |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total_timesteps  | 837026   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0385   |\n",
      "|    n_updates        | 209231   |\n",
      "----------------------------------\n",
      "Episode reward: 53.883018\n",
      "Episode reward: 56.704924\n",
      "Episode reward: 54.537307\n",
      "Episode reward: 168.003443\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.7     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14456    |\n",
      "|    fps              | 2793     |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total_timesteps  | 837361   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0469   |\n",
      "|    n_updates        | 209315   |\n",
      "----------------------------------\n",
      "Episode reward: 57.842434\n",
      "Episode reward: 72.418593\n",
      "Episode reward: 95.493274\n",
      "Episode reward: 56.62603\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.4     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14460    |\n",
      "|    fps              | 2792     |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total_timesteps  | 837646   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.389    |\n",
      "|    n_updates        | 209386   |\n",
      "----------------------------------\n",
      "Episode reward: 66.730966\n",
      "Episode reward: 34.858754\n",
      "Episode reward: 31.840637\n",
      "Episode reward: 73.654088\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14464    |\n",
      "|    fps              | 2792     |\n",
      "|    time_elapsed     | 300      |\n",
      "|    total_timesteps  | 837856   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0894   |\n",
      "|    n_updates        | 209438   |\n",
      "----------------------------------\n",
      "Episode reward: 80.267143\n",
      "Episode reward: 99.649683\n",
      "Episode reward: 126.729932\n",
      "Episode reward: 58.75506\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.7     |\n",
      "|    ep_rew_mean      | 64       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14468    |\n",
      "|    fps              | 2792     |\n",
      "|    time_elapsed     | 300      |\n",
      "|    total_timesteps  | 838238   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0656   |\n",
      "|    n_updates        | 209534   |\n",
      "----------------------------------\n",
      "Episode reward: 38.515256\n",
      "Episode reward: 49.182858\n",
      "Episode reward: 39.915995\n",
      "Episode reward: 28.889716\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14472    |\n",
      "|    fps              | 2792     |\n",
      "|    time_elapsed     | 300      |\n",
      "|    total_timesteps  | 838396   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0307   |\n",
      "|    n_updates        | 209573   |\n",
      "----------------------------------\n",
      "Episode reward: 41.813177\n",
      "Episode reward: 37.808978\n",
      "Episode reward: 79.885659\n",
      "Episode reward: 114.306266\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.9     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14476    |\n",
      "|    fps              | 2792     |\n",
      "|    time_elapsed     | 300      |\n",
      "|    total_timesteps  | 838672   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0479   |\n",
      "|    n_updates        | 209642   |\n",
      "----------------------------------\n",
      "Episode reward: 74.639416\n",
      "Episode reward: 91.390449\n",
      "Episode reward: 40.888245\n",
      "Episode reward: 36.952517\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14480    |\n",
      "|    fps              | 2792     |\n",
      "|    time_elapsed     | 300      |\n",
      "|    total_timesteps  | 838917   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0443   |\n",
      "|    n_updates        | 209704   |\n",
      "----------------------------------\n",
      "Episode reward: 80.026253\n",
      "Episode reward: 57.763318\n",
      "Episode reward: 84.253556\n",
      "Episode reward: 28.924417\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14484    |\n",
      "|    fps              | 2792     |\n",
      "|    time_elapsed     | 300      |\n",
      "|    total_timesteps  | 839173   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.063    |\n",
      "|    n_updates        | 209768   |\n",
      "----------------------------------\n",
      "Episode reward: 45.917967\n",
      "Episode reward: 35.808285\n",
      "Episode reward: 35.862061\n",
      "Episode reward: 84.598976\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14488    |\n",
      "|    fps              | 2792     |\n",
      "|    time_elapsed     | 300      |\n",
      "|    total_timesteps  | 839376   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0417   |\n",
      "|    n_updates        | 209818   |\n",
      "----------------------------------\n",
      "Episode reward: 64.638079\n",
      "Episode reward: 38.805895\n",
      "Episode reward: 59.558276\n",
      "Episode reward: 52.839506\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14492    |\n",
      "|    fps              | 2792     |\n",
      "|    time_elapsed     | 300      |\n",
      "|    total_timesteps  | 839593   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.86     |\n",
      "|    n_updates        | 209873   |\n",
      "----------------------------------\n",
      "Episode reward: 44.447451\n",
      "Episode reward: 52.832382\n",
      "Episode reward: 89.270944\n",
      "Episode reward: 58.832639\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14496    |\n",
      "|    fps              | 2791     |\n",
      "|    time_elapsed     | 300      |\n",
      "|    total_timesteps  | 839840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.29     |\n",
      "|    n_updates        | 209934   |\n",
      "----------------------------------\n",
      "Episode reward: 181.123278\n",
      "Episode reward: 25.824889\n",
      "Episode reward: 66.615709\n",
      "Episode reward: 46.831586\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14500    |\n",
      "|    fps              | 2791     |\n",
      "|    time_elapsed     | 300      |\n",
      "|    total_timesteps  | 840173   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.109    |\n",
      "|    n_updates        | 210018   |\n",
      "----------------------------------\n",
      "Episode reward: 46.543787\n",
      "Episode reward: 48.897054\n",
      "Episode reward: 39.938213\n",
      "Episode reward: 28.703743\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14504    |\n",
      "|    fps              | 2791     |\n",
      "|    time_elapsed     | 300      |\n",
      "|    total_timesteps  | 840338   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0644   |\n",
      "|    n_updates        | 210059   |\n",
      "----------------------------------\n",
      "Episode reward: 58.795512\n",
      "Episode reward: 75.703514\n",
      "Episode reward: 31.82396\n",
      "Episode reward: 56.848339\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14508    |\n",
      "|    fps              | 2791     |\n",
      "|    time_elapsed     | 301      |\n",
      "|    total_timesteps  | 840562   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0954   |\n",
      "|    n_updates        | 210115   |\n",
      "----------------------------------\n",
      "Episode reward: 58.827566\n",
      "Episode reward: 72.724856\n",
      "Episode reward: 58.638732\n",
      "Episode reward: 55.864774\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14512    |\n",
      "|    fps              | 2791     |\n",
      "|    time_elapsed     | 301      |\n",
      "|    total_timesteps  | 840809   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.111    |\n",
      "|    n_updates        | 210177   |\n",
      "----------------------------------\n",
      "Episode reward: 84.690165\n",
      "Episode reward: 43.915661\n",
      "Episode reward: 91.087902\n",
      "Episode reward: 55.796983\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14516    |\n",
      "|    fps              | 2791     |\n",
      "|    time_elapsed     | 301      |\n",
      "|    total_timesteps  | 841086   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.147    |\n",
      "|    n_updates        | 210246   |\n",
      "----------------------------------\n",
      "Episode reward: 34.895864\n",
      "Episode reward: 55.78176\n",
      "Episode reward: 43.468274\n",
      "Episode reward: 103.854253\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14520    |\n",
      "|    fps              | 2791     |\n",
      "|    time_elapsed     | 301      |\n",
      "|    total_timesteps  | 841333   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0708   |\n",
      "|    n_updates        | 210308   |\n",
      "----------------------------------\n",
      "Episode reward: 91.595075\n",
      "Episode reward: 42.843846\n",
      "Episode reward: 41.90027\n",
      "Episode reward: 45.839189\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14524    |\n",
      "|    fps              | 2791     |\n",
      "|    time_elapsed     | 301      |\n",
      "|    total_timesteps  | 841556   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.714    |\n",
      "|    n_updates        | 210363   |\n",
      "----------------------------------\n",
      "Episode reward: 50.431933\n",
      "Episode reward: 70.677841\n",
      "Episode reward: 28.858251\n",
      "Episode reward: 56.138279\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14528    |\n",
      "|    fps              | 2791     |\n",
      "|    time_elapsed     | 301      |\n",
      "|    total_timesteps  | 841765   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0728   |\n",
      "|    n_updates        | 210416   |\n",
      "----------------------------------\n",
      "Episode reward: 40.51822\n",
      "Episode reward: 41.922632\n",
      "Episode reward: 46.896461\n",
      "Episode reward: 29.91163\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14532    |\n",
      "|    fps              | 2791     |\n",
      "|    time_elapsed     | 301      |\n",
      "|    total_timesteps  | 841925   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.048    |\n",
      "|    n_updates        | 210456   |\n",
      "----------------------------------\n",
      "Episode reward: 53.604589\n",
      "Episode reward: 69.905512\n",
      "Episode reward: 126.854233\n",
      "Episode reward: 42.742597\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14536    |\n",
      "|    fps              | 2791     |\n",
      "|    time_elapsed     | 301      |\n",
      "|    total_timesteps  | 842221   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0367   |\n",
      "|    n_updates        | 210530   |\n",
      "----------------------------------\n",
      "Episode reward: 37.92319\n",
      "Episode reward: 84.639621\n",
      "Episode reward: 70.712289\n",
      "Episode reward: 48.922241\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14540    |\n",
      "|    fps              | 2790     |\n",
      "|    time_elapsed     | 301      |\n",
      "|    total_timesteps  | 842464   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.462    |\n",
      "|    n_updates        | 210590   |\n",
      "----------------------------------\n",
      "Episode reward: 71.87798\n",
      "Episode reward: 37.949946\n",
      "Episode reward: 82.410055\n",
      "Episode reward: 51.43607\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14544    |\n",
      "|    fps              | 2790     |\n",
      "|    time_elapsed     | 301      |\n",
      "|    total_timesteps  | 842711   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.2      |\n",
      "|    n_updates        | 210652   |\n",
      "----------------------------------\n",
      "Episode reward: 130.851731\n",
      "Episode reward: 73.701389\n",
      "Episode reward: 39.884234\n",
      "Episode reward: 45.775283\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14548    |\n",
      "|    fps              | 2790     |\n",
      "|    time_elapsed     | 302      |\n",
      "|    total_timesteps  | 843004   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.11     |\n",
      "|    n_updates        | 210725   |\n",
      "----------------------------------\n",
      "Episode reward: 43.749074\n",
      "Episode reward: 58.060223\n",
      "Episode reward: 99.949995\n",
      "Episode reward: 103.498505\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14552    |\n",
      "|    fps              | 2790     |\n",
      "|    time_elapsed     | 302      |\n",
      "|    total_timesteps  | 843396   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0533   |\n",
      "|    n_updates        | 210823   |\n",
      "----------------------------------\n",
      "Episode reward: 43.830254\n",
      "Episode reward: 27.68647\n",
      "Episode reward: 82.25202\n",
      "Episode reward: 85.652795\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14556    |\n",
      "|    fps              | 2790     |\n",
      "|    time_elapsed     | 302      |\n",
      "|    total_timesteps  | 843637   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0782   |\n",
      "|    n_updates        | 210884   |\n",
      "----------------------------------\n",
      "Episode reward: 49.919342\n",
      "Episode reward: 56.77569\n",
      "Episode reward: 32.938005\n",
      "Episode reward: 29.780732\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14560    |\n",
      "|    fps              | 2790     |\n",
      "|    time_elapsed     | 302      |\n",
      "|    total_timesteps  | 843807   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.92     |\n",
      "|    n_updates        | 210926   |\n",
      "----------------------------------\n",
      "Episode reward: 55.912488\n",
      "Episode reward: 49.855253\n",
      "Episode reward: 34.516649\n",
      "Episode reward: 43.571596\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14564    |\n",
      "|    fps              | 2790     |\n",
      "|    time_elapsed     | 302      |\n",
      "|    total_timesteps  | 843993   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0708   |\n",
      "|    n_updates        | 210973   |\n",
      "----------------------------------\n",
      "Episode reward: 80.588916\n",
      "Episode reward: 89.364586\n",
      "Episode reward: 54.641378\n",
      "Episode reward: 40.90028\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14568    |\n",
      "|    fps              | 2790     |\n",
      "|    time_elapsed     | 302      |\n",
      "|    total_timesteps  | 844260   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0638   |\n",
      "|    n_updates        | 211039   |\n",
      "----------------------------------\n",
      "Episode reward: 64.625098\n",
      "Episode reward: 139.430225\n",
      "Episode reward: 54.891391\n",
      "Episode reward: 84.95065\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14572    |\n",
      "|    fps              | 2790     |\n",
      "|    time_elapsed     | 302      |\n",
      "|    total_timesteps  | 844614   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 211128   |\n",
      "----------------------------------\n",
      "Episode reward: 97.141651\n",
      "Episode reward: 36.713448\n",
      "Episode reward: 81.262824\n",
      "Episode reward: 70.680236\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14576    |\n",
      "|    fps              | 2789     |\n",
      "|    time_elapsed     | 302      |\n",
      "|    total_timesteps  | 844903   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.39     |\n",
      "|    n_updates        | 211200   |\n",
      "----------------------------------\n",
      "Episode reward: 69.661255\n",
      "Episode reward: 61.718545\n",
      "Episode reward: 33.885022\n",
      "Episode reward: 75.151629\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14580    |\n",
      "|    fps              | 2789     |\n",
      "|    time_elapsed     | 302      |\n",
      "|    total_timesteps  | 845145   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0516   |\n",
      "|    n_updates        | 211261   |\n",
      "----------------------------------\n",
      "Episode reward: 57.807719\n",
      "Episode reward: 86.671652\n",
      "Episode reward: 83.771692\n",
      "Episode reward: 37.826502\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14584    |\n",
      "|    fps              | 2789     |\n",
      "|    time_elapsed     | 303      |\n",
      "|    total_timesteps  | 845412   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0771   |\n",
      "|    n_updates        | 211327   |\n",
      "----------------------------------\n",
      "Episode reward: 101.917468\n",
      "Episode reward: 54.854137\n",
      "Episode reward: 47.843821\n",
      "Episode reward: 42.939113\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14588    |\n",
      "|    fps              | 2789     |\n",
      "|    time_elapsed     | 303      |\n",
      "|    total_timesteps  | 845661   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.51     |\n",
      "|    n_updates        | 211390   |\n",
      "----------------------------------\n",
      "Episode reward: 42.757891\n",
      "Episode reward: 61.697851\n",
      "Episode reward: 60.904137\n",
      "Episode reward: 65.793933\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14592    |\n",
      "|    fps              | 2789     |\n",
      "|    time_elapsed     | 303      |\n",
      "|    total_timesteps  | 845894   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0833   |\n",
      "|    n_updates        | 211448   |\n",
      "----------------------------------\n",
      "Episode reward: 50.824616\n",
      "Episode reward: 30.945125\n",
      "Episode reward: 31.914052\n",
      "Episode reward: 49.875544\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14596    |\n",
      "|    fps              | 2788     |\n",
      "|    time_elapsed     | 303      |\n",
      "|    total_timesteps  | 846058   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0488   |\n",
      "|    n_updates        | 211489   |\n",
      "----------------------------------\n",
      "Episode reward: 57.755901\n",
      "Episode reward: 85.952647\n",
      "Episode reward: 57.677129\n",
      "Episode reward: 85.633897\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14600    |\n",
      "|    fps              | 2788     |\n",
      "|    time_elapsed     | 303      |\n",
      "|    total_timesteps  | 846347   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0793   |\n",
      "|    n_updates        | 211561   |\n",
      "----------------------------------\n",
      "Episode reward: 40.905193\n",
      "Episode reward: 38.848605\n",
      "Episode reward: 65.306664\n",
      "Episode reward: 73.395087\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14604    |\n",
      "|    fps              | 2788     |\n",
      "|    time_elapsed     | 303      |\n",
      "|    total_timesteps  | 846567   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0647   |\n",
      "|    n_updates        | 211616   |\n",
      "----------------------------------\n",
      "Episode reward: 39.913993\n",
      "Episode reward: 67.694483\n",
      "Episode reward: 75.505783\n",
      "Episode reward: 56.873196\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14608    |\n",
      "|    fps              | 2788     |\n",
      "|    time_elapsed     | 303      |\n",
      "|    total_timesteps  | 846808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0932   |\n",
      "|    n_updates        | 211676   |\n",
      "----------------------------------\n",
      "Episode reward: 58.440118\n",
      "Episode reward: 62.596803\n",
      "Episode reward: 80.825316\n",
      "Episode reward: 41.661714\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14612    |\n",
      "|    fps              | 2787     |\n",
      "|    time_elapsed     | 303      |\n",
      "|    total_timesteps  | 847053   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0766   |\n",
      "|    n_updates        | 211738   |\n",
      "----------------------------------\n",
      "Episode reward: 101.196242\n",
      "Episode reward: 66.563309\n",
      "Episode reward: 102.675317\n",
      "Episode reward: 60.536794\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14616    |\n",
      "|    fps              | 2787     |\n",
      "|    time_elapsed     | 303      |\n",
      "|    total_timesteps  | 847395   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0467   |\n",
      "|    n_updates        | 211823   |\n",
      "----------------------------------\n",
      "Episode reward: 46.786922\n",
      "Episode reward: 92.047374\n",
      "Episode reward: 61.13365\n",
      "Episode reward: 49.882486\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14620    |\n",
      "|    fps              | 2787     |\n",
      "|    time_elapsed     | 304      |\n",
      "|    total_timesteps  | 847647   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 211886   |\n",
      "----------------------------------\n",
      "Episode reward: 84.27184\n",
      "Episode reward: 55.041089\n",
      "Episode reward: 88.131093\n",
      "Episode reward: 36.842341\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14624    |\n",
      "|    fps              | 2787     |\n",
      "|    time_elapsed     | 304      |\n",
      "|    total_timesteps  | 847919   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.049    |\n",
      "|    n_updates        | 211954   |\n",
      "----------------------------------\n",
      "Episode reward: 33.957334\n",
      "Episode reward: 45.813123\n",
      "Episode reward: 54.760606\n",
      "Episode reward: 95.834608\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14628    |\n",
      "|    fps              | 2787     |\n",
      "|    time_elapsed     | 304      |\n",
      "|    total_timesteps  | 848151   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.066    |\n",
      "|    n_updates        | 212012   |\n",
      "----------------------------------\n",
      "Episode reward: 36.937969\n",
      "Episode reward: 41.908476\n",
      "Episode reward: 64.062689\n",
      "Episode reward: 47.799988\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14632    |\n",
      "|    fps              | 2787     |\n",
      "|    time_elapsed     | 304      |\n",
      "|    total_timesteps  | 848343   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0856   |\n",
      "|    n_updates        | 212060   |\n",
      "----------------------------------\n",
      "Episode reward: 42.839031\n",
      "Episode reward: 43.478605\n",
      "Episode reward: 53.804934\n",
      "Episode reward: 42.907424\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14636    |\n",
      "|    fps              | 2787     |\n",
      "|    time_elapsed     | 304      |\n",
      "|    total_timesteps  | 848527   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.93     |\n",
      "|    n_updates        | 212106   |\n",
      "----------------------------------\n",
      "Episode reward: 65.780335\n",
      "Episode reward: 34.726425\n",
      "Episode reward: 48.924943\n",
      "Episode reward: 79.219677\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14640    |\n",
      "|    fps              | 2786     |\n",
      "|    time_elapsed     | 304      |\n",
      "|    total_timesteps  | 848757   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.88     |\n",
      "|    n_updates        | 212164   |\n",
      "----------------------------------\n",
      "Episode reward: 33.857398\n",
      "Episode reward: 36.954834\n",
      "Episode reward: 45.452386\n",
      "Episode reward: 39.807452\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14644    |\n",
      "|    fps              | 2786     |\n",
      "|    time_elapsed     | 304      |\n",
      "|    total_timesteps  | 848914   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.53     |\n",
      "|    n_updates        | 212203   |\n",
      "----------------------------------\n",
      "Episode reward: 106.256884\n",
      "Episode reward: 36.724965\n",
      "Episode reward: 93.836147\n",
      "Episode reward: 29.633242\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14648    |\n",
      "|    fps              | 2786     |\n",
      "|    time_elapsed     | 304      |\n",
      "|    total_timesteps  | 849184   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0749   |\n",
      "|    n_updates        | 212270   |\n",
      "----------------------------------\n",
      "Episode reward: 79.259786\n",
      "Episode reward: 98.090131\n",
      "Episode reward: 69.210335\n",
      "Episode reward: 27.951976\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14652    |\n",
      "|    fps              | 2786     |\n",
      "|    time_elapsed     | 304      |\n",
      "|    total_timesteps  | 849461   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.61     |\n",
      "|    n_updates        | 212340   |\n",
      "----------------------------------\n",
      "Episode reward: 128.308676\n",
      "Episode reward: 41.943039\n",
      "Episode reward: 47.846332\n",
      "Episode reward: 29.89961\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14656    |\n",
      "|    fps              | 2786     |\n",
      "|    time_elapsed     | 304      |\n",
      "|    total_timesteps  | 849712   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0338   |\n",
      "|    n_updates        | 212402   |\n",
      "----------------------------------\n",
      "Episode reward: 26.921336\n",
      "Episode reward: 68.283284\n",
      "Episode reward: 26.841218\n",
      "Episode reward: 52.8656\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14660    |\n",
      "|    fps              | 2786     |\n",
      "|    time_elapsed     | 305      |\n",
      "|    total_timesteps  | 849888   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0475   |\n",
      "|    n_updates        | 212446   |\n",
      "----------------------------------\n",
      "Episode reward: 35.862912\n",
      "Episode reward: 45.065025\n",
      "Episode reward: 46.898098\n",
      "Episode reward: 56.193651\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14664    |\n",
      "|    fps              | 2786     |\n",
      "|    time_elapsed     | 305      |\n",
      "|    total_timesteps  | 850074   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0839   |\n",
      "|    n_updates        | 212493   |\n",
      "----------------------------------\n",
      "Episode reward: 62.089544\n",
      "Episode reward: 56.63901\n",
      "Episode reward: 39.835541\n",
      "Episode reward: 48.722595\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14668    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 305      |\n",
      "|    total_timesteps  | 850283   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0729   |\n",
      "|    n_updates        | 212545   |\n",
      "----------------------------------\n",
      "Episode reward: 98.543493\n",
      "Episode reward: 42.742123\n",
      "Episode reward: 64.336743\n",
      "Episode reward: 107.083749\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14672    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 305      |\n",
      "|    total_timesteps  | 850606   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0552   |\n",
      "|    n_updates        | 212626   |\n",
      "----------------------------------\n",
      "Episode reward: 41.74422\n",
      "Episode reward: 136.400172\n",
      "Episode reward: 42.824334\n",
      "Episode reward: 61.74998\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14676    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 305      |\n",
      "|    total_timesteps  | 850890   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.889    |\n",
      "|    n_updates        | 212697   |\n",
      "----------------------------------\n",
      "Episode reward: 44.855897\n",
      "Episode reward: 65.726946\n",
      "Episode reward: 75.71861\n",
      "Episode reward: 51.762257\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14680    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 305      |\n",
      "|    total_timesteps  | 851130   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0662   |\n",
      "|    n_updates        | 212757   |\n",
      "----------------------------------\n",
      "Episode reward: 34.892326\n",
      "Episode reward: 58.744183\n",
      "Episode reward: 101.074882\n",
      "Episode reward: 105.238909\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14684    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 305      |\n",
      "|    total_timesteps  | 851433   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0603   |\n",
      "|    n_updates        | 212833   |\n",
      "----------------------------------\n",
      "Episode reward: 44.748998\n",
      "Episode reward: 89.516059\n",
      "Episode reward: 34.954605\n",
      "Episode reward: 64.889243\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14688    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 305      |\n",
      "|    total_timesteps  | 851668   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0988   |\n",
      "|    n_updates        | 212891   |\n",
      "----------------------------------\n",
      "Episode reward: 37.881917\n",
      "Episode reward: 39.903149\n",
      "Episode reward: 70.675665\n",
      "Episode reward: 107.366572\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14692    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 305      |\n",
      "|    total_timesteps  | 851928   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.384    |\n",
      "|    n_updates        | 212956   |\n",
      "----------------------------------\n",
      "Episode reward: 44.696344\n",
      "Episode reward: 32.956136\n",
      "Episode reward: 96.545792\n",
      "Episode reward: 41.752754\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14696    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 305      |\n",
      "|    total_timesteps  | 852152   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.043    |\n",
      "|    n_updates        | 213012   |\n",
      "----------------------------------\n",
      "Episode reward: 47.826496\n",
      "Episode reward: 40.918678\n",
      "Episode reward: 50.827543\n",
      "Episode reward: 77.168314\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14700    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total_timesteps  | 852370   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0699   |\n",
      "|    n_updates        | 213067   |\n",
      "----------------------------------\n",
      "Episode reward: 49.828106\n",
      "Episode reward: 92.146731\n",
      "Episode reward: 51.154467\n",
      "Episode reward: 37.509726\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14704    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total_timesteps  | 852604   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.263    |\n",
      "|    n_updates        | 213125   |\n",
      "----------------------------------\n",
      "Episode reward: 59.595639\n",
      "Episode reward: 32.908402\n",
      "Episode reward: 32.957041\n",
      "Episode reward: 77.724669\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14708    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total_timesteps  | 852808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0918   |\n",
      "|    n_updates        | 213176   |\n",
      "----------------------------------\n",
      "Episode reward: 31.901008\n",
      "Episode reward: 43.94307\n",
      "Episode reward: 38.905138\n",
      "Episode reward: 66.803544\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14712    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total_timesteps  | 852990   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.89     |\n",
      "|    n_updates        | 213222   |\n",
      "----------------------------------\n",
      "Episode reward: 69.646327\n",
      "Episode reward: 38.950087\n",
      "Episode reward: 62.871256\n",
      "Episode reward: 63.848872\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14716    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total_timesteps  | 853228   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0793   |\n",
      "|    n_updates        | 213281   |\n",
      "----------------------------------\n",
      "Episode reward: 55.859703\n",
      "Episode reward: 47.859318\n",
      "Episode reward: 33.796383\n",
      "Episode reward: 119.42033\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14720    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total_timesteps  | 853486   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0648   |\n",
      "|    n_updates        | 213346   |\n",
      "----------------------------------\n",
      "Episode reward: 63.610449\n",
      "Episode reward: 36.882486\n",
      "Episode reward: 31.926763\n",
      "Episode reward: 48.495837\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14724    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total_timesteps  | 853668   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.37     |\n",
      "|    n_updates        | 213391   |\n",
      "----------------------------------\n",
      "Episode reward: 69.696929\n",
      "Episode reward: 41.922975\n",
      "Episode reward: 40.892818\n",
      "Episode reward: 74.415693\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14728    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total_timesteps  | 853897   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0654   |\n",
      "|    n_updates        | 213449   |\n",
      "----------------------------------\n",
      "Episode reward: 78.745027\n",
      "Episode reward: 42.434033\n",
      "Episode reward: 42.473322\n",
      "Episode reward: 49.845046\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.7     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14732    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total_timesteps  | 854112   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.99     |\n",
      "|    n_updates        | 213502   |\n",
      "----------------------------------\n",
      "Episode reward: 56.578598\n",
      "Episode reward: 30.807815\n",
      "Episode reward: 36.928947\n",
      "Episode reward: 45.819031\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14736    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total_timesteps  | 854283   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.84     |\n",
      "|    n_updates        | 213545   |\n",
      "----------------------------------\n",
      "Episode reward: 43.934615\n",
      "Episode reward: 61.46176\n",
      "Episode reward: 49.74308\n",
      "Episode reward: 30.942816\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14740    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total_timesteps  | 854470   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0836   |\n",
      "|    n_updates        | 213592   |\n",
      "----------------------------------\n",
      "Episode reward: 61.879097\n",
      "Episode reward: 43.852386\n",
      "Episode reward: 53.700064\n",
      "Episode reward: 44.670358\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 57       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14744    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total_timesteps  | 854676   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.69     |\n",
      "|    n_updates        | 213643   |\n",
      "----------------------------------\n",
      "Episode reward: 58.982557\n",
      "Episode reward: 82.814828\n",
      "Episode reward: 28.908532\n",
      "Episode reward: 32.575969\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14748    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 306      |\n",
      "|    total_timesteps  | 854881   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0508   |\n",
      "|    n_updates        | 213695   |\n",
      "----------------------------------\n",
      "Episode reward: 41.921464\n",
      "Episode reward: 38.931639\n",
      "Episode reward: 85.556803\n",
      "Episode reward: 84.453621\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14752    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 307      |\n",
      "|    total_timesteps  | 855134   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0291   |\n",
      "|    n_updates        | 213758   |\n",
      "----------------------------------\n",
      "Episode reward: 43.879391\n",
      "Episode reward: 24.94543\n",
      "Episode reward: 69.426251\n",
      "Episode reward: 45.821572\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.1     |\n",
      "|    ep_rew_mean      | 55.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14756    |\n",
      "|    fps              | 2785     |\n",
      "|    time_elapsed     | 307      |\n",
      "|    total_timesteps  | 855319   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0676   |\n",
      "|    n_updates        | 213804   |\n",
      "----------------------------------\n",
      "Episode reward: 42.550822\n",
      "Episode reward: 52.910666\n",
      "Episode reward: 51.858723\n",
      "Episode reward: 94.781321\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14760    |\n",
      "|    fps              | 2784     |\n",
      "|    time_elapsed     | 307      |\n",
      "|    total_timesteps  | 855565   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 213866   |\n",
      "----------------------------------\n",
      "Episode reward: 62.845476\n",
      "Episode reward: 47.877197\n",
      "Episode reward: 80.635335\n",
      "Episode reward: 57.712218\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.4     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14764    |\n",
      "|    fps              | 2784     |\n",
      "|    time_elapsed     | 307      |\n",
      "|    total_timesteps  | 855815   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0522   |\n",
      "|    n_updates        | 213928   |\n",
      "----------------------------------\n",
      "Episode reward: 50.815798\n",
      "Episode reward: 41.934022\n",
      "Episode reward: 46.759962\n",
      "Episode reward: 25.88858\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14768    |\n",
      "|    fps              | 2784     |\n",
      "|    time_elapsed     | 307      |\n",
      "|    total_timesteps  | 855981   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0621   |\n",
      "|    n_updates        | 213970   |\n",
      "----------------------------------\n",
      "Episode reward: 38.90806\n",
      "Episode reward: 48.825179\n",
      "Episode reward: 43.80603\n",
      "Episode reward: 121.259911\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14772    |\n",
      "|    fps              | 2784     |\n",
      "|    time_elapsed     | 307      |\n",
      "|    total_timesteps  | 856235   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.038    |\n",
      "|    n_updates        | 214033   |\n",
      "----------------------------------\n",
      "Episode reward: 38.936167\n",
      "Episode reward: 69.737182\n",
      "Episode reward: 42.80813\n",
      "Episode reward: 43.902359\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.4     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14776    |\n",
      "|    fps              | 2784     |\n",
      "|    time_elapsed     | 307      |\n",
      "|    total_timesteps  | 856431   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.25     |\n",
      "|    n_updates        | 214082   |\n",
      "----------------------------------\n",
      "Episode reward: 100.297101\n",
      "Episode reward: 59.570667\n",
      "Episode reward: 125.762944\n",
      "Episode reward: 75.975661\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.7     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14780    |\n",
      "|    fps              | 2784     |\n",
      "|    time_elapsed     | 307      |\n",
      "|    total_timesteps  | 856796   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.039    |\n",
      "|    n_updates        | 214173   |\n",
      "----------------------------------\n",
      "Episode reward: 46.796364\n",
      "Episode reward: 59.300926\n",
      "Episode reward: 42.68444\n",
      "Episode reward: 62.712231\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.8     |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14784    |\n",
      "|    fps              | 2784     |\n",
      "|    time_elapsed     | 307      |\n",
      "|    total_timesteps  | 857009   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.127    |\n",
      "|    n_updates        | 214227   |\n",
      "----------------------------------\n",
      "Episode reward: 56.696692\n",
      "Episode reward: 45.908151\n",
      "Episode reward: 42.936475\n",
      "Episode reward: 85.234803\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.7     |\n",
      "|    ep_rew_mean      | 55.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14788    |\n",
      "|    fps              | 2784     |\n",
      "|    time_elapsed     | 307      |\n",
      "|    total_timesteps  | 857241   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0786   |\n",
      "|    n_updates        | 214285   |\n",
      "----------------------------------\n",
      "Episode reward: 61.659446\n",
      "Episode reward: 42.928934\n",
      "Episode reward: 73.130582\n",
      "Episode reward: 38.699417\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 55.3     |\n",
      "|    ep_rew_mean      | 54.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14792    |\n",
      "|    fps              | 2784     |\n",
      "|    time_elapsed     | 307      |\n",
      "|    total_timesteps  | 857459   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.08     |\n",
      "|    n_updates        | 214339   |\n",
      "----------------------------------\n",
      "Episode reward: 95.708574\n",
      "Episode reward: 53.752124\n",
      "Episode reward: 66.34603\n",
      "Episode reward: 89.457722\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14796    |\n",
      "|    fps              | 2783     |\n",
      "|    time_elapsed     | 308      |\n",
      "|    total_timesteps  | 857769   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0285   |\n",
      "|    n_updates        | 214417   |\n",
      "----------------------------------\n",
      "Episode reward: 36.880496\n",
      "Episode reward: 47.897061\n",
      "Episode reward: 100.96492\n",
      "Episode reward: 41.701179\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 55.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14800    |\n",
      "|    fps              | 2783     |\n",
      "|    time_elapsed     | 308      |\n",
      "|    total_timesteps  | 858000   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0618   |\n",
      "|    n_updates        | 214474   |\n",
      "----------------------------------\n",
      "Episode reward: 90.720648\n",
      "Episode reward: 34.928729\n",
      "Episode reward: 110.911591\n",
      "Episode reward: 73.630531\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.1     |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14804    |\n",
      "|    fps              | 2783     |\n",
      "|    time_elapsed     | 308      |\n",
      "|    total_timesteps  | 858315   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0766   |\n",
      "|    n_updates        | 214553   |\n",
      "----------------------------------\n",
      "Episode reward: 82.424747\n",
      "Episode reward: 55.426148\n",
      "Episode reward: 35.931199\n",
      "Episode reward: 43.699022\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14808    |\n",
      "|    fps              | 2783     |\n",
      "|    time_elapsed     | 308      |\n",
      "|    total_timesteps  | 858535   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 214608   |\n",
      "----------------------------------\n",
      "Episode reward: 43.744273\n",
      "Episode reward: 39.831683\n",
      "Episode reward: 68.728739\n",
      "Episode reward: 33.937182\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.3     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14812    |\n",
      "|    fps              | 2783     |\n",
      "|    time_elapsed     | 308      |\n",
      "|    total_timesteps  | 858722   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.121    |\n",
      "|    n_updates        | 214655   |\n",
      "----------------------------------\n",
      "Episode reward: 44.6956\n",
      "Episode reward: 116.768047\n",
      "Episode reward: 80.203535\n",
      "Episode reward: 106.601098\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14816    |\n",
      "|    fps              | 2783     |\n",
      "|    time_elapsed     | 308      |\n",
      "|    total_timesteps  | 859072   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.29     |\n",
      "|    n_updates        | 214742   |\n",
      "----------------------------------\n",
      "Episode reward: 61.758743\n",
      "Episode reward: 116.454073\n",
      "Episode reward: 53.825459\n",
      "Episode reward: 59.158414\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14820    |\n",
      "|    fps              | 2783     |\n",
      "|    time_elapsed     | 308      |\n",
      "|    total_timesteps  | 859367   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.33     |\n",
      "|    n_updates        | 214816   |\n",
      "----------------------------------\n",
      "Episode reward: 60.284841\n",
      "Episode reward: 64.631114\n",
      "Episode reward: 44.800385\n",
      "Episode reward: 76.167239\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14824    |\n",
      "|    fps              | 2783     |\n",
      "|    time_elapsed     | 308      |\n",
      "|    total_timesteps  | 859617   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 214879   |\n",
      "----------------------------------\n",
      "Episode reward: 40.515379\n",
      "Episode reward: 120.109612\n",
      "Episode reward: 34.896469\n",
      "Episode reward: 57.814306\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14828    |\n",
      "|    fps              | 2783     |\n",
      "|    time_elapsed     | 308      |\n",
      "|    total_timesteps  | 859872   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.397    |\n",
      "|    n_updates        | 214942   |\n",
      "----------------------------------\n",
      "Episode reward: 46.708197\n",
      "Episode reward: 106.187756\n",
      "Episode reward: 64.67368\n",
      "Episode reward: 33.478566\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14832    |\n",
      "|    fps              | 2783     |\n",
      "|    time_elapsed     | 308      |\n",
      "|    total_timesteps  | 860133   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.63     |\n",
      "|    n_updates        | 215008   |\n",
      "----------------------------------\n",
      "Episode reward: 31.777792\n",
      "Episode reward: 78.268234\n",
      "Episode reward: 35.825468\n",
      "Episode reward: 85.727929\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14836    |\n",
      "|    fps              | 2783     |\n",
      "|    time_elapsed     | 309      |\n",
      "|    total_timesteps  | 860367   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.166    |\n",
      "|    n_updates        | 215066   |\n",
      "----------------------------------\n",
      "Episode reward: 60.618551\n",
      "Episode reward: 32.921099\n",
      "Episode reward: 45.1385\n",
      "Episode reward: 41.925635\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14840    |\n",
      "|    fps              | 2783     |\n",
      "|    time_elapsed     | 309      |\n",
      "|    total_timesteps  | 860549   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.474    |\n",
      "|    n_updates        | 215112   |\n",
      "----------------------------------\n",
      "Episode reward: 85.785317\n",
      "Episode reward: 121.208633\n",
      "Episode reward: 62.229407\n",
      "Episode reward: 44.915484\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14844    |\n",
      "|    fps              | 2782     |\n",
      "|    time_elapsed     | 309      |\n",
      "|    total_timesteps  | 860869   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.27     |\n",
      "|    n_updates        | 215192   |\n",
      "----------------------------------\n",
      "Episode reward: 44.643657\n",
      "Episode reward: 88.700621\n",
      "Episode reward: 59.836294\n",
      "Episode reward: 60.796091\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14848    |\n",
      "|    fps              | 2782     |\n",
      "|    time_elapsed     | 309      |\n",
      "|    total_timesteps  | 861126   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.123    |\n",
      "|    n_updates        | 215256   |\n",
      "----------------------------------\n",
      "Episode reward: 61.876938\n",
      "Episode reward: 44.492833\n",
      "Episode reward: 30.931275\n",
      "Episode reward: 65.445777\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14852    |\n",
      "|    fps              | 2782     |\n",
      "|    time_elapsed     | 309      |\n",
      "|    total_timesteps  | 861330   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0862   |\n",
      "|    n_updates        | 215307   |\n",
      "----------------------------------\n",
      "Episode reward: 40.927593\n",
      "Episode reward: 55.813859\n",
      "Episode reward: 40.749602\n",
      "Episode reward: 45.904151\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14856    |\n",
      "|    fps              | 2782     |\n",
      "|    time_elapsed     | 309      |\n",
      "|    total_timesteps  | 861514   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 215353   |\n",
      "----------------------------------\n",
      "Episode reward: 56.797604\n",
      "Episode reward: 71.508727\n",
      "Episode reward: 39.95176\n",
      "Episode reward: 48.626823\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14860    |\n",
      "|    fps              | 2781     |\n",
      "|    time_elapsed     | 309      |\n",
      "|    total_timesteps  | 861732   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0749   |\n",
      "|    n_updates        | 215407   |\n",
      "----------------------------------\n",
      "Episode reward: 66.895381\n",
      "Episode reward: 123.756541\n",
      "Episode reward: 72.56831\n",
      "Episode reward: 74.671215\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.6     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14864    |\n",
      "|    fps              | 2781     |\n",
      "|    time_elapsed     | 309      |\n",
      "|    total_timesteps  | 862072   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0931   |\n",
      "|    n_updates        | 215492   |\n",
      "----------------------------------\n",
      "Episode reward: 91.542585\n",
      "Episode reward: 77.560033\n",
      "Episode reward: 31.936893\n",
      "Episode reward: 60.546334\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14868    |\n",
      "|    fps              | 2781     |\n",
      "|    time_elapsed     | 310      |\n",
      "|    total_timesteps  | 862336   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0602   |\n",
      "|    n_updates        | 215558   |\n",
      "----------------------------------\n",
      "Episode reward: 38.599602\n",
      "Episode reward: 61.39894\n",
      "Episode reward: 141.285372\n",
      "Episode reward: 29.916294\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14872    |\n",
      "|    fps              | 2780     |\n",
      "|    time_elapsed     | 310      |\n",
      "|    total_timesteps  | 862610   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.22     |\n",
      "|    n_updates        | 215627   |\n",
      "----------------------------------\n",
      "Episode reward: 39.545914\n",
      "Episode reward: 55.855193\n",
      "Episode reward: 82.4851\n",
      "Episode reward: 74.035652\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14876    |\n",
      "|    fps              | 2780     |\n",
      "|    time_elapsed     | 310      |\n",
      "|    total_timesteps  | 862864   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.693    |\n",
      "|    n_updates        | 215690   |\n",
      "----------------------------------\n",
      "Episode reward: 50.837308\n",
      "Episode reward: 36.860082\n",
      "Episode reward: 74.394258\n",
      "Episode reward: 58.179238\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14880    |\n",
      "|    fps              | 2780     |\n",
      "|    time_elapsed     | 310      |\n",
      "|    total_timesteps  | 863086   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.443    |\n",
      "|    n_updates        | 215746   |\n",
      "----------------------------------\n",
      "Episode reward: 66.077318\n",
      "Episode reward: 54.216984\n",
      "Episode reward: 45.889715\n",
      "Episode reward: 84.890522\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14884    |\n",
      "|    fps              | 2779     |\n",
      "|    time_elapsed     | 310      |\n",
      "|    total_timesteps  | 863340   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.304    |\n",
      "|    n_updates        | 215809   |\n",
      "----------------------------------\n",
      "Episode reward: 48.856907\n",
      "Episode reward: 53.84489\n",
      "Episode reward: 105.698235\n",
      "Episode reward: 43.929187\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14888    |\n",
      "|    fps              | 2779     |\n",
      "|    time_elapsed     | 310      |\n",
      "|    total_timesteps  | 863593   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0678   |\n",
      "|    n_updates        | 215873   |\n",
      "----------------------------------\n",
      "Episode reward: 53.908307\n",
      "Episode reward: 49.882351\n",
      "Episode reward: 70.644324\n",
      "Episode reward: 34.93865\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14892    |\n",
      "|    fps              | 2779     |\n",
      "|    time_elapsed     | 310      |\n",
      "|    total_timesteps  | 863804   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0585   |\n",
      "|    n_updates        | 215925   |\n",
      "----------------------------------\n",
      "Episode reward: 39.782949\n",
      "Episode reward: 65.471685\n",
      "Episode reward: 42.912822\n",
      "Episode reward: 62.631044\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14896    |\n",
      "|    fps              | 2779     |\n",
      "|    time_elapsed     | 310      |\n",
      "|    total_timesteps  | 864016   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0474   |\n",
      "|    n_updates        | 215978   |\n",
      "----------------------------------\n",
      "Episode reward: 44.758248\n",
      "Episode reward: 28.922393\n",
      "Episode reward: 54.845664\n",
      "Episode reward: 124.174907\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14900    |\n",
      "|    fps              | 2778     |\n",
      "|    time_elapsed     | 311      |\n",
      "|    total_timesteps  | 864271   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0632   |\n",
      "|    n_updates        | 216042   |\n",
      "----------------------------------\n",
      "Episode reward: 49.706684\n",
      "Episode reward: 34.938175\n",
      "Episode reward: 60.803763\n",
      "Episode reward: 44.705375\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14904    |\n",
      "|    fps              | 2778     |\n",
      "|    time_elapsed     | 311      |\n",
      "|    total_timesteps  | 864462   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0498   |\n",
      "|    n_updates        | 216090   |\n",
      "----------------------------------\n",
      "Episode reward: 50.560635\n",
      "Episode reward: 74.827729\n",
      "Episode reward: 52.814196\n",
      "Episode reward: 64.856867\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14908    |\n",
      "|    fps              | 2778     |\n",
      "|    time_elapsed     | 311      |\n",
      "|    total_timesteps  | 864706   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.071    |\n",
      "|    n_updates        | 216151   |\n",
      "----------------------------------\n",
      "Episode reward: 93.80932\n",
      "Episode reward: 51.68997\n",
      "Episode reward: 52.796601\n",
      "Episode reward: 37.658998\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14912    |\n",
      "|    fps              | 2778     |\n",
      "|    time_elapsed     | 311      |\n",
      "|    total_timesteps  | 864945   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0829   |\n",
      "|    n_updates        | 216211   |\n",
      "----------------------------------\n",
      "Episode reward: 67.642943\n",
      "Episode reward: 39.824758\n",
      "Episode reward: 52.762721\n",
      "Episode reward: 49.874112\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14916    |\n",
      "|    fps              | 2777     |\n",
      "|    time_elapsed     | 311      |\n",
      "|    total_timesteps  | 865156   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.88     |\n",
      "|    n_updates        | 216263   |\n",
      "----------------------------------\n",
      "Episode reward: 52.315706\n",
      "Episode reward: 60.203524\n",
      "Episode reward: 155.582742\n",
      "Episode reward: 66.570253\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14920    |\n",
      "|    fps              | 2777     |\n",
      "|    time_elapsed     | 311      |\n",
      "|    total_timesteps  | 865499   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0806   |\n",
      "|    n_updates        | 216349   |\n",
      "----------------------------------\n",
      "Episode reward: 26.697167\n",
      "Episode reward: 50.203802\n",
      "Episode reward: 108.380769\n",
      "Episode reward: 36.945704\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14924    |\n",
      "|    fps              | 2777     |\n",
      "|    time_elapsed     | 311      |\n",
      "|    total_timesteps  | 865723   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0809   |\n",
      "|    n_updates        | 216405   |\n",
      "----------------------------------\n",
      "Episode reward: 32.611169\n",
      "Episode reward: 84.713341\n",
      "Episode reward: 44.797956\n",
      "Episode reward: 83.583815\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14928    |\n",
      "|    fps              | 2777     |\n",
      "|    time_elapsed     | 311      |\n",
      "|    total_timesteps  | 865970   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0351   |\n",
      "|    n_updates        | 216467   |\n",
      "----------------------------------\n",
      "Episode reward: 101.055601\n",
      "Episode reward: 72.809497\n",
      "Episode reward: 51.9501\n",
      "Episode reward: 68.724265\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14932    |\n",
      "|    fps              | 2776     |\n",
      "|    time_elapsed     | 311      |\n",
      "|    total_timesteps  | 866270   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.97     |\n",
      "|    n_updates        | 216542   |\n",
      "----------------------------------\n",
      "Episode reward: 52.796427\n",
      "Episode reward: 62.837672\n",
      "Episode reward: 39.663467\n",
      "Episode reward: 32.963049\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14936    |\n",
      "|    fps              | 2776     |\n",
      "|    time_elapsed     | 312      |\n",
      "|    total_timesteps  | 866459   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.173    |\n",
      "|    n_updates        | 216589   |\n",
      "----------------------------------\n",
      "Episode reward: 35.944703\n",
      "Episode reward: 69.72446\n",
      "Episode reward: 36.763687\n",
      "Episode reward: 67.896556\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14940    |\n",
      "|    fps              | 2776     |\n",
      "|    time_elapsed     | 312      |\n",
      "|    total_timesteps  | 866670   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0517   |\n",
      "|    n_updates        | 216642   |\n",
      "----------------------------------\n",
      "Episode reward: 38.574814\n",
      "Episode reward: 71.779612\n",
      "Episode reward: 123.612623\n",
      "Episode reward: 47.909437\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14944    |\n",
      "|    fps              | 2775     |\n",
      "|    time_elapsed     | 312      |\n",
      "|    total_timesteps  | 866955   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 216713   |\n",
      "----------------------------------\n",
      "Episode reward: 51.870522\n",
      "Episode reward: 86.86051\n",
      "Episode reward: 73.453284\n",
      "Episode reward: 130.201135\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14948    |\n",
      "|    fps              | 2775     |\n",
      "|    time_elapsed     | 312      |\n",
      "|    total_timesteps  | 867314   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0988   |\n",
      "|    n_updates        | 216803   |\n",
      "----------------------------------\n",
      "Episode reward: 55.676857\n",
      "Episode reward: 59.36844\n",
      "Episode reward: 64.768842\n",
      "Episode reward: 90.603612\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.6     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14952    |\n",
      "|    fps              | 2774     |\n",
      "|    time_elapsed     | 312      |\n",
      "|    total_timesteps  | 867586   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.23     |\n",
      "|    n_updates        | 216871   |\n",
      "----------------------------------\n",
      "Episode reward: 83.859427\n",
      "Episode reward: 32.951367\n",
      "Episode reward: 96.696559\n",
      "Episode reward: 72.648028\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14956    |\n",
      "|    fps              | 2774     |\n",
      "|    time_elapsed     | 312      |\n",
      "|    total_timesteps  | 867873   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.522    |\n",
      "|    n_updates        | 216943   |\n",
      "----------------------------------\n",
      "Episode reward: 68.438752\n",
      "Episode reward: 41.405205\n",
      "Episode reward: 140.342703\n",
      "Episode reward: 46.831882\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 63.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14960    |\n",
      "|    fps              | 2774     |\n",
      "|    time_elapsed     | 312      |\n",
      "|    total_timesteps  | 868172   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0493   |\n",
      "|    n_updates        | 217017   |\n",
      "----------------------------------\n",
      "Episode reward: 31.878594\n",
      "Episode reward: 38.913543\n",
      "Episode reward: 38.859788\n",
      "Episode reward: 43.70527\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14964    |\n",
      "|    fps              | 2774     |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total_timesteps  | 868326   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0692   |\n",
      "|    n_updates        | 217056   |\n",
      "----------------------------------\n",
      "Episode reward: 47.851568\n",
      "Episode reward: 40.909482\n",
      "Episode reward: 85.621849\n",
      "Episode reward: 31.761295\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14968    |\n",
      "|    fps              | 2774     |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total_timesteps  | 868533   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0533   |\n",
      "|    n_updates        | 217108   |\n",
      "----------------------------------\n",
      "Episode reward: 45.601005\n",
      "Episode reward: 54.355869\n",
      "Episode reward: 51.893081\n",
      "Episode reward: 65.602878\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14972    |\n",
      "|    fps              | 2774     |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total_timesteps  | 868752   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.108    |\n",
      "|    n_updates        | 217162   |\n",
      "----------------------------------\n",
      "Episode reward: 32.957372\n",
      "Episode reward: 36.899737\n",
      "Episode reward: 55.758676\n",
      "Episode reward: 136.188932\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14976    |\n",
      "|    fps              | 2774     |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total_timesteps  | 869015   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.342    |\n",
      "|    n_updates        | 217228   |\n",
      "----------------------------------\n",
      "Episode reward: 56.553971\n",
      "Episode reward: 43.865677\n",
      "Episode reward: 47.657937\n",
      "Episode reward: 72.640871\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14980    |\n",
      "|    fps              | 2774     |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total_timesteps  | 869237   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.201    |\n",
      "|    n_updates        | 217284   |\n",
      "----------------------------------\n",
      "Episode reward: 63.271093\n",
      "Episode reward: 50.90592\n",
      "Episode reward: 42.927634\n",
      "Episode reward: 95.818138\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14984    |\n",
      "|    fps              | 2774     |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total_timesteps  | 869493   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 217348   |\n",
      "----------------------------------\n",
      "Episode reward: 52.914656\n",
      "Episode reward: 45.340404\n",
      "Episode reward: 38.914787\n",
      "Episode reward: 75.130292\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14988    |\n",
      "|    fps              | 2773     |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total_timesteps  | 869707   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.109    |\n",
      "|    n_updates        | 217401   |\n",
      "----------------------------------\n",
      "Episode reward: 39.454598\n",
      "Episode reward: 47.702647\n",
      "Episode reward: 151.706466\n",
      "Episode reward: 62.689738\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14992    |\n",
      "|    fps              | 2773     |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total_timesteps  | 870043   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.137    |\n",
      "|    n_updates        | 217485   |\n",
      "----------------------------------\n",
      "Episode reward: 114.152335\n",
      "Episode reward: 84.663064\n",
      "Episode reward: 51.040643\n",
      "Episode reward: 111.768455\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 14996    |\n",
      "|    fps              | 2773     |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total_timesteps  | 870409   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0823   |\n",
      "|    n_updates        | 217577   |\n",
      "----------------------------------\n",
      "Episode reward: 28.780758\n",
      "Episode reward: 49.872292\n",
      "Episode reward: 46.661885\n",
      "Episode reward: 149.031862\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15000    |\n",
      "|    fps              | 2773     |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total_timesteps  | 870686   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0544   |\n",
      "|    n_updates        | 217646   |\n",
      "----------------------------------\n",
      "Episode reward: 92.586066\n",
      "Episode reward: 36.376325\n",
      "Episode reward: 62.905319\n",
      "Episode reward: 38.924635\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15004    |\n",
      "|    fps              | 2773     |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 870921   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.136    |\n",
      "|    n_updates        | 217705   |\n",
      "----------------------------------\n",
      "Episode reward: 50.890426\n",
      "Episode reward: 48.76851\n",
      "Episode reward: 57.866419\n",
      "Episode reward: 75.620619\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15008    |\n",
      "|    fps              | 2773     |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 871155   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0752   |\n",
      "|    n_updates        | 217763   |\n",
      "----------------------------------\n",
      "Episode reward: 52.451138\n",
      "Episode reward: 59.774861\n",
      "Episode reward: 50.857005\n",
      "Episode reward: 50.836894\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15012    |\n",
      "|    fps              | 2773     |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 871370   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.31     |\n",
      "|    n_updates        | 217817   |\n",
      "----------------------------------\n",
      "Episode reward: 75.940445\n",
      "Episode reward: 101.558149\n",
      "Episode reward: 59.806192\n",
      "Episode reward: 32.888906\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.9     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15016    |\n",
      "|    fps              | 2773     |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 871642   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0933   |\n",
      "|    n_updates        | 217885   |\n",
      "----------------------------------\n",
      "Episode reward: 62.731897\n",
      "Episode reward: 64.26891\n",
      "Episode reward: 31.650113\n",
      "Episode reward: 45.835636\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15020    |\n",
      "|    fps              | 2773     |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 871849   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.25     |\n",
      "|    n_updates        | 217937   |\n",
      "----------------------------------\n",
      "Episode reward: 28.873026\n",
      "Episode reward: 38.683125\n",
      "Episode reward: 74.74727\n",
      "Episode reward: 39.718931\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15024    |\n",
      "|    fps              | 2772     |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 872032   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0666   |\n",
      "|    n_updates        | 217982   |\n",
      "----------------------------------\n",
      "Episode reward: 35.743129\n",
      "Episode reward: 50.922344\n",
      "Episode reward: 34.943544\n",
      "Episode reward: 59.835362\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15028    |\n",
      "|    fps              | 2773     |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 872214   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.468    |\n",
      "|    n_updates        | 218028   |\n",
      "----------------------------------\n",
      "Episode reward: 56.718196\n",
      "Episode reward: 69.241812\n",
      "Episode reward: 51.508766\n",
      "Episode reward: 35.818012\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15032    |\n",
      "|    fps              | 2772     |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 872430   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0549   |\n",
      "|    n_updates        | 218082   |\n",
      "----------------------------------\n",
      "Episode reward: 129.768401\n",
      "Episode reward: 68.398993\n",
      "Episode reward: 39.903849\n",
      "Episode reward: 57.607831\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 61.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15036    |\n",
      "|    fps              | 2772     |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 872728   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.924    |\n",
      "|    n_updates        | 218156   |\n",
      "----------------------------------\n",
      "Episode reward: 97.757527\n",
      "Episode reward: 50.706618\n",
      "Episode reward: 52.85248\n",
      "Episode reward: 46.917\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15040    |\n",
      "|    fps              | 2772     |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 872987   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0519   |\n",
      "|    n_updates        | 218221   |\n",
      "----------------------------------\n",
      "Episode reward: 43.806493\n",
      "Episode reward: 28.923196\n",
      "Episode reward: 72.155047\n",
      "Episode reward: 88.811478\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15044    |\n",
      "|    fps              | 2772     |\n",
      "|    time_elapsed     | 314      |\n",
      "|    total_timesteps  | 873222   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0593   |\n",
      "|    n_updates        | 218280   |\n",
      "----------------------------------\n",
      "Episode reward: 64.612017\n",
      "Episode reward: 94.479495\n",
      "Episode reward: 62.834813\n",
      "Episode reward: 53.899411\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15048    |\n",
      "|    fps              | 2772     |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total_timesteps  | 873499   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0664   |\n",
      "|    n_updates        | 218349   |\n",
      "----------------------------------\n",
      "Episode reward: 101.813839\n",
      "Episode reward: 40.874833\n",
      "Episode reward: 43.347191\n",
      "Episode reward: 45.928485\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15052    |\n",
      "|    fps              | 2772     |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total_timesteps  | 873734   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0861   |\n",
      "|    n_updates        | 218408   |\n",
      "----------------------------------\n",
      "Episode reward: 41.933398\n",
      "Episode reward: 73.862226\n",
      "Episode reward: 90.086873\n",
      "Episode reward: 52.759944\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15056    |\n",
      "|    fps              | 2772     |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total_timesteps  | 873996   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.266    |\n",
      "|    n_updates        | 218473   |\n",
      "----------------------------------\n",
      "Episode reward: 33.860784\n",
      "Episode reward: 60.850473\n",
      "Episode reward: 54.827733\n",
      "Episode reward: 42.626685\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15060    |\n",
      "|    fps              | 2772     |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total_timesteps  | 874189   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.336    |\n",
      "|    n_updates        | 218522   |\n",
      "----------------------------------\n",
      "Episode reward: 69.729587\n",
      "Episode reward: 37.425028\n",
      "Episode reward: 115.86847\n",
      "Episode reward: 30.911612\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15064    |\n",
      "|    fps              | 2772     |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total_timesteps  | 874445   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 218586   |\n",
      "----------------------------------\n",
      "Episode reward: 31.954264\n",
      "Episode reward: 28.831307\n",
      "Episode reward: 35.840092\n",
      "Episode reward: 35.824934\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15068    |\n",
      "|    fps              | 2772     |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total_timesteps  | 874578   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.05     |\n",
      "|    n_updates        | 218619   |\n",
      "----------------------------------\n",
      "Episode reward: 36.917811\n",
      "Episode reward: 132.084957\n",
      "Episode reward: 89.206336\n",
      "Episode reward: 34.875048\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15072    |\n",
      "|    fps              | 2772     |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total_timesteps  | 874876   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0762   |\n",
      "|    n_updates        | 218693   |\n",
      "----------------------------------\n",
      "Episode reward: 118.283848\n",
      "Episode reward: 166.616462\n",
      "Episode reward: 63.842737\n",
      "Episode reward: 31.91325\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15076    |\n",
      "|    fps              | 2772     |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total_timesteps  | 875258   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.631    |\n",
      "|    n_updates        | 218789   |\n",
      "----------------------------------\n",
      "Episode reward: 64.65833\n",
      "Episode reward: 56.470689\n",
      "Episode reward: 47.883249\n",
      "Episode reward: 32.769171\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15080    |\n",
      "|    fps              | 2772     |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total_timesteps  | 875461   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0812   |\n",
      "|    n_updates        | 218840   |\n",
      "----------------------------------\n",
      "Episode reward: 48.767068\n",
      "Episode reward: 54.877903\n",
      "Episode reward: 48.875899\n",
      "Episode reward: 27.82751\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15084    |\n",
      "|    fps              | 2772     |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total_timesteps  | 875642   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0419   |\n",
      "|    n_updates        | 218885   |\n",
      "----------------------------------\n",
      "Episode reward: 64.730363\n",
      "Episode reward: 29.951521\n",
      "Episode reward: 39.894132\n",
      "Episode reward: 62.729402\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15088    |\n",
      "|    fps              | 2771     |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total_timesteps  | 875840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.28     |\n",
      "|    n_updates        | 218934   |\n",
      "----------------------------------\n",
      "Episode reward: 116.022292\n",
      "Episode reward: 127.398555\n",
      "Episode reward: 75.774672\n",
      "Episode reward: 58.587195\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15092    |\n",
      "|    fps              | 2771     |\n",
      "|    time_elapsed     | 316      |\n",
      "|    total_timesteps  | 876227   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0275   |\n",
      "|    n_updates        | 219031   |\n",
      "----------------------------------\n",
      "Episode reward: 50.920725\n",
      "Episode reward: 68.874135\n",
      "Episode reward: 34.928368\n",
      "Episode reward: 37.923875\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15096    |\n",
      "|    fps              | 2771     |\n",
      "|    time_elapsed     | 316      |\n",
      "|    total_timesteps  | 876422   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.55     |\n",
      "|    n_updates        | 219080   |\n",
      "----------------------------------\n",
      "Episode reward: 99.241366\n",
      "Episode reward: 75.765224\n",
      "Episode reward: 91.429792\n",
      "Episode reward: 81.686944\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15100    |\n",
      "|    fps              | 2771     |\n",
      "|    time_elapsed     | 316      |\n",
      "|    total_timesteps  | 876772   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.263    |\n",
      "|    n_updates        | 219167   |\n",
      "----------------------------------\n",
      "Episode reward: 39.894278\n",
      "Episode reward: 31.844343\n",
      "Episode reward: 94.827458\n",
      "Episode reward: 32.873621\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15104    |\n",
      "|    fps              | 2771     |\n",
      "|    time_elapsed     | 316      |\n",
      "|    total_timesteps  | 876972   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.35     |\n",
      "|    n_updates        | 219217   |\n",
      "----------------------------------\n",
      "Episode reward: 43.8597\n",
      "Episode reward: 30.843326\n",
      "Episode reward: 47.865414\n",
      "Episode reward: 51.785098\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15108    |\n",
      "|    fps              | 2771     |\n",
      "|    time_elapsed     | 316      |\n",
      "|    total_timesteps  | 877147   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0374   |\n",
      "|    n_updates        | 219261   |\n",
      "----------------------------------\n",
      "Episode reward: 112.816938\n",
      "Episode reward: 45.729076\n",
      "Episode reward: 60.057803\n",
      "Episode reward: 94.982277\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15112    |\n",
      "|    fps              | 2771     |\n",
      "|    time_elapsed     | 316      |\n",
      "|    total_timesteps  | 877481   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 219345   |\n",
      "----------------------------------\n",
      "Episode reward: 93.56028\n",
      "Episode reward: 52.776272\n",
      "Episode reward: 99.836777\n",
      "Episode reward: 97.404727\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15116    |\n",
      "|    fps              | 2771     |\n",
      "|    time_elapsed     | 316      |\n",
      "|    total_timesteps  | 877828   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.27     |\n",
      "|    n_updates        | 219431   |\n",
      "----------------------------------\n",
      "Episode reward: 53.795696\n",
      "Episode reward: 42.935453\n",
      "Episode reward: 144.679067\n",
      "Episode reward: 105.531734\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15120    |\n",
      "|    fps              | 2771     |\n",
      "|    time_elapsed     | 316      |\n",
      "|    total_timesteps  | 878177   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.13     |\n",
      "|    n_updates        | 219519   |\n",
      "----------------------------------\n",
      "Episode reward: 43.878218\n",
      "Episode reward: 96.55037\n",
      "Episode reward: 60.839224\n",
      "Episode reward: 93.559628\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15124    |\n",
      "|    fps              | 2770     |\n",
      "|    time_elapsed     | 317      |\n",
      "|    total_timesteps  | 878474   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.77     |\n",
      "|    n_updates        | 219593   |\n",
      "----------------------------------\n",
      "Episode reward: 53.853033\n",
      "Episode reward: 54.796441\n",
      "Episode reward: 32.876183\n",
      "Episode reward: 53.910266\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15128    |\n",
      "|    fps              | 2770     |\n",
      "|    time_elapsed     | 317      |\n",
      "|    total_timesteps  | 878670   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 219642   |\n",
      "----------------------------------\n",
      "Episode reward: 70.251061\n",
      "Episode reward: 79.72576\n",
      "Episode reward: 63.764297\n",
      "Episode reward: 50.453894\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.1     |\n",
      "|    ep_rew_mean      | 64.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15132    |\n",
      "|    fps              | 2770     |\n",
      "|    time_elapsed     | 317      |\n",
      "|    total_timesteps  | 878937   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0648   |\n",
      "|    n_updates        | 219709   |\n",
      "----------------------------------\n",
      "Episode reward: 83.474317\n",
      "Episode reward: 45.68023\n",
      "Episode reward: 47.933848\n",
      "Episode reward: 43.682505\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15136    |\n",
      "|    fps              | 2770     |\n",
      "|    time_elapsed     | 317      |\n",
      "|    total_timesteps  | 879159   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.45     |\n",
      "|    n_updates        | 219764   |\n",
      "----------------------------------\n",
      "Episode reward: 45.71042\n",
      "Episode reward: 57.842503\n",
      "Episode reward: 54.86925\n",
      "Episode reward: 32.934416\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15140    |\n",
      "|    fps              | 2770     |\n",
      "|    time_elapsed     | 317      |\n",
      "|    total_timesteps  | 879351   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0794   |\n",
      "|    n_updates        | 219812   |\n",
      "----------------------------------\n",
      "Episode reward: 99.054642\n",
      "Episode reward: 62.846843\n",
      "Episode reward: 41.928923\n",
      "Episode reward: 73.798547\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.1     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15144    |\n",
      "|    fps              | 2770     |\n",
      "|    time_elapsed     | 317      |\n",
      "|    total_timesteps  | 879630   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0985   |\n",
      "|    n_updates        | 219882   |\n",
      "----------------------------------\n",
      "Episode reward: 45.766545\n",
      "Episode reward: 45.873758\n",
      "Episode reward: 57.743753\n",
      "Episode reward: 28.913482\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15148    |\n",
      "|    fps              | 2770     |\n",
      "|    time_elapsed     | 317      |\n",
      "|    total_timesteps  | 879809   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0812   |\n",
      "|    n_updates        | 219927   |\n",
      "----------------------------------\n",
      "Episode reward: 37.850428\n",
      "Episode reward: 80.505022\n",
      "Episode reward: 89.693113\n",
      "Episode reward: 47.893278\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15152    |\n",
      "|    fps              | 2770     |\n",
      "|    time_elapsed     | 317      |\n",
      "|    total_timesteps  | 880067   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.126    |\n",
      "|    n_updates        | 219991   |\n",
      "----------------------------------\n",
      "Episode reward: 68.488118\n",
      "Episode reward: 51.895746\n",
      "Episode reward: 74.823291\n",
      "Episode reward: 32.906176\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15156    |\n",
      "|    fps              | 2770     |\n",
      "|    time_elapsed     | 317      |\n",
      "|    total_timesteps  | 880296   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.434    |\n",
      "|    n_updates        | 220048   |\n",
      "----------------------------------\n",
      "Episode reward: 27.89548\n",
      "Episode reward: 48.593873\n",
      "Episode reward: 84.84232\n",
      "Episode reward: 54.607612\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15160    |\n",
      "|    fps              | 2770     |\n",
      "|    time_elapsed     | 317      |\n",
      "|    total_timesteps  | 880513   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 220103   |\n",
      "----------------------------------\n",
      "Episode reward: 26.951348\n",
      "Episode reward: 84.847376\n",
      "Episode reward: 113.809208\n",
      "Episode reward: 93.825656\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15164    |\n",
      "|    fps              | 2770     |\n",
      "|    time_elapsed     | 317      |\n",
      "|    total_timesteps  | 880839   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.16     |\n",
      "|    n_updates        | 220184   |\n",
      "----------------------------------\n",
      "Episode reward: 78.350614\n",
      "Episode reward: 58.766747\n",
      "Episode reward: 99.163989\n",
      "Episode reward: 46.885537\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.5     |\n",
      "|    ep_rew_mean      | 64.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15168    |\n",
      "|    fps              | 2770     |\n",
      "|    time_elapsed     | 318      |\n",
      "|    total_timesteps  | 881125   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.166    |\n",
      "|    n_updates        | 220256   |\n",
      "----------------------------------\n",
      "Episode reward: 53.622352\n",
      "Episode reward: 55.742492\n",
      "Episode reward: 31.539085\n",
      "Episode reward: 31.95085\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15172    |\n",
      "|    fps              | 2769     |\n",
      "|    time_elapsed     | 318      |\n",
      "|    total_timesteps  | 881300   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0897   |\n",
      "|    n_updates        | 220299   |\n",
      "----------------------------------\n",
      "Episode reward: 55.679415\n",
      "Episode reward: 135.763218\n",
      "Episode reward: 63.792611\n",
      "Episode reward: 61.599481\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15176    |\n",
      "|    fps              | 2769     |\n",
      "|    time_elapsed     | 318      |\n",
      "|    total_timesteps  | 881618   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0449   |\n",
      "|    n_updates        | 220379   |\n",
      "----------------------------------\n",
      "Episode reward: 34.869884\n",
      "Episode reward: 64.573117\n",
      "Episode reward: 74.69886\n",
      "Episode reward: 53.671859\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15180    |\n",
      "|    fps              | 2769     |\n",
      "|    time_elapsed     | 318      |\n",
      "|    total_timesteps  | 881848   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0927   |\n",
      "|    n_updates        | 220436   |\n",
      "----------------------------------\n",
      "Episode reward: 38.758522\n",
      "Episode reward: 28.707188\n",
      "Episode reward: 65.719422\n",
      "Episode reward: 50.894663\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15184    |\n",
      "|    fps              | 2769     |\n",
      "|    time_elapsed     | 318      |\n",
      "|    total_timesteps  | 882033   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.164    |\n",
      "|    n_updates        | 220483   |\n",
      "----------------------------------\n",
      "Episode reward: 61.808008\n",
      "Episode reward: 68.062269\n",
      "Episode reward: 45.934758\n",
      "Episode reward: 49.867197\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15188    |\n",
      "|    fps              | 2769     |\n",
      "|    time_elapsed     | 318      |\n",
      "|    total_timesteps  | 882260   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0912   |\n",
      "|    n_updates        | 220539   |\n",
      "----------------------------------\n",
      "Episode reward: 62.690398\n",
      "Episode reward: 43.777775\n",
      "Episode reward: 103.214449\n",
      "Episode reward: 47.880343\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15192    |\n",
      "|    fps              | 2769     |\n",
      "|    time_elapsed     | 318      |\n",
      "|    total_timesteps  | 882523   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.377    |\n",
      "|    n_updates        | 220605   |\n",
      "----------------------------------\n",
      "Episode reward: 31.932266\n",
      "Episode reward: 34.868069\n",
      "Episode reward: 84.201109\n",
      "Episode reward: 63.137248\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15196    |\n",
      "|    fps              | 2769     |\n",
      "|    time_elapsed     | 318      |\n",
      "|    total_timesteps  | 882739   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.17     |\n",
      "|    n_updates        | 220659   |\n",
      "----------------------------------\n",
      "Episode reward: 41.930383\n",
      "Episode reward: 39.894818\n",
      "Episode reward: 35.938637\n",
      "Episode reward: 46.306613\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15200    |\n",
      "|    fps              | 2769     |\n",
      "|    time_elapsed     | 318      |\n",
      "|    total_timesteps  | 882904   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0452   |\n",
      "|    n_updates        | 220700   |\n",
      "----------------------------------\n",
      "Episode reward: 27.721819\n",
      "Episode reward: 69.465039\n",
      "Episode reward: 65.53168\n",
      "Episode reward: 70.132526\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15204    |\n",
      "|    fps              | 2769     |\n",
      "|    time_elapsed     | 318      |\n",
      "|    total_timesteps  | 883139   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.111    |\n",
      "|    n_updates        | 220759   |\n",
      "----------------------------------\n",
      "Episode reward: 51.261926\n",
      "Episode reward: 96.323112\n",
      "Episode reward: 38.866454\n",
      "Episode reward: 74.303817\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.6     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15208    |\n",
      "|    fps              | 2769     |\n",
      "|    time_elapsed     | 319      |\n",
      "|    total_timesteps  | 883404   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.316    |\n",
      "|    n_updates        | 220825   |\n",
      "----------------------------------\n",
      "Episode reward: 95.659867\n",
      "Episode reward: 90.856102\n",
      "Episode reward: 71.314968\n",
      "Episode reward: 82.598984\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15212    |\n",
      "|    fps              | 2768     |\n",
      "|    time_elapsed     | 319      |\n",
      "|    total_timesteps  | 883750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.7      |\n",
      "|    n_updates        | 220912   |\n",
      "----------------------------------\n",
      "Episode reward: 104.29713\n",
      "Episode reward: 65.893352\n",
      "Episode reward: 42.910272\n",
      "Episode reward: 48.923353\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15216    |\n",
      "|    fps              | 2768     |\n",
      "|    time_elapsed     | 319      |\n",
      "|    total_timesteps  | 884013   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.035    |\n",
      "|    n_updates        | 220978   |\n",
      "----------------------------------\n",
      "Episode reward: 39.949278\n",
      "Episode reward: 50.660402\n",
      "Episode reward: 59.833453\n",
      "Episode reward: 52.82894\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15220    |\n",
      "|    fps              | 2768     |\n",
      "|    time_elapsed     | 319      |\n",
      "|    total_timesteps  | 884217   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0527   |\n",
      "|    n_updates        | 221029   |\n",
      "----------------------------------\n",
      "Episode reward: 50.775391\n",
      "Episode reward: 81.463642\n",
      "Episode reward: 47.846609\n",
      "Episode reward: 36.608968\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15224    |\n",
      "|    fps              | 2768     |\n",
      "|    time_elapsed     | 319      |\n",
      "|    total_timesteps  | 884435   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.418    |\n",
      "|    n_updates        | 221083   |\n",
      "----------------------------------\n",
      "Episode reward: 55.813875\n",
      "Episode reward: 50.848731\n",
      "Episode reward: 35.827988\n",
      "Episode reward: 100.357303\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15228    |\n",
      "|    fps              | 2768     |\n",
      "|    time_elapsed     | 319      |\n",
      "|    total_timesteps  | 884680   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.124    |\n",
      "|    n_updates        | 221144   |\n",
      "----------------------------------\n",
      "Episode reward: 50.820046\n",
      "Episode reward: 44.910164\n",
      "Episode reward: 34.69751\n",
      "Episode reward: 93.68461\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15232    |\n",
      "|    fps              | 2768     |\n",
      "|    time_elapsed     | 319      |\n",
      "|    total_timesteps  | 884905   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 221201   |\n",
      "----------------------------------\n",
      "Episode reward: 93.511183\n",
      "Episode reward: 90.53883\n",
      "Episode reward: 42.736834\n",
      "Episode reward: 144.517119\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15236    |\n",
      "|    fps              | 2768     |\n",
      "|    time_elapsed     | 319      |\n",
      "|    total_timesteps  | 885301   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.22     |\n",
      "|    n_updates        | 221300   |\n",
      "----------------------------------\n",
      "Episode reward: 85.133313\n",
      "Episode reward: 92.847285\n",
      "Episode reward: 59.818828\n",
      "Episode reward: 35.954161\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15240    |\n",
      "|    fps              | 2767     |\n",
      "|    time_elapsed     | 319      |\n",
      "|    total_timesteps  | 885577   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0681   |\n",
      "|    n_updates        | 221369   |\n",
      "----------------------------------\n",
      "Episode reward: 92.769089\n",
      "Episode reward: 33.950985\n",
      "Episode reward: 65.246906\n",
      "Episode reward: 69.738679\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15244    |\n",
      "|    fps              | 2767     |\n",
      "|    time_elapsed     | 320      |\n",
      "|    total_timesteps  | 885842   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.538    |\n",
      "|    n_updates        | 221435   |\n",
      "----------------------------------\n",
      "Episode reward: 47.794185\n",
      "Episode reward: 35.759181\n",
      "Episode reward: 69.830175\n",
      "Episode reward: 113.517382\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15248    |\n",
      "|    fps              | 2767     |\n",
      "|    time_elapsed     | 320      |\n",
      "|    total_timesteps  | 886110   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.108    |\n",
      "|    n_updates        | 221502   |\n",
      "----------------------------------\n",
      "Episode reward: 103.218814\n",
      "Episode reward: 45.667635\n",
      "Episode reward: 32.672008\n",
      "Episode reward: 91.788818\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15252    |\n",
      "|    fps              | 2767     |\n",
      "|    time_elapsed     | 320      |\n",
      "|    total_timesteps  | 886385   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.076    |\n",
      "|    n_updates        | 221571   |\n",
      "----------------------------------\n",
      "Episode reward: 29.850102\n",
      "Episode reward: 51.453812\n",
      "Episode reward: 89.971818\n",
      "Episode reward: 71.584901\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15256    |\n",
      "|    fps              | 2767     |\n",
      "|    time_elapsed     | 320      |\n",
      "|    total_timesteps  | 886631   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.138    |\n",
      "|    n_updates        | 221632   |\n",
      "----------------------------------\n",
      "Episode reward: 45.920011\n",
      "Episode reward: 33.941489\n",
      "Episode reward: 89.309874\n",
      "Episode reward: 51.762164\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15260    |\n",
      "|    fps              | 2767     |\n",
      "|    time_elapsed     | 320      |\n",
      "|    total_timesteps  | 886855   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0823   |\n",
      "|    n_updates        | 221688   |\n",
      "----------------------------------\n",
      "Episode reward: 35.891043\n",
      "Episode reward: 64.826071\n",
      "Episode reward: 33.947029\n",
      "Episode reward: 57.390054\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15264    |\n",
      "|    fps              | 2767     |\n",
      "|    time_elapsed     | 320      |\n",
      "|    total_timesteps  | 887048   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0636   |\n",
      "|    n_updates        | 221736   |\n",
      "----------------------------------\n",
      "Episode reward: 45.896423\n",
      "Episode reward: 84.483016\n",
      "Episode reward: 75.99382\n",
      "Episode reward: 43.867342\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15268    |\n",
      "|    fps              | 2767     |\n",
      "|    time_elapsed     | 320      |\n",
      "|    total_timesteps  | 887300   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0979   |\n",
      "|    n_updates        | 221799   |\n",
      "----------------------------------\n",
      "Episode reward: 43.935962\n",
      "Episode reward: 54.107924\n",
      "Episode reward: 54.683235\n",
      "Episode reward: 84.385355\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15272    |\n",
      "|    fps              | 2767     |\n",
      "|    time_elapsed     | 320      |\n",
      "|    total_timesteps  | 887539   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.188    |\n",
      "|    n_updates        | 221859   |\n",
      "----------------------------------\n",
      "Episode reward: 58.855056\n",
      "Episode reward: 49.685731\n",
      "Episode reward: 200.512138\n",
      "Episode reward: 50.780009\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15276    |\n",
      "|    fps              | 2767     |\n",
      "|    time_elapsed     | 320      |\n",
      "|    total_timesteps  | 887903   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0565   |\n",
      "|    n_updates        | 221950   |\n",
      "----------------------------------\n",
      "Episode reward: 60.758207\n",
      "Episode reward: 39.86412\n",
      "Episode reward: 43.901979\n",
      "Episode reward: 69.662561\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15280    |\n",
      "|    fps              | 2767     |\n",
      "|    time_elapsed     | 320      |\n",
      "|    total_timesteps  | 888118   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.245    |\n",
      "|    n_updates        | 222004   |\n",
      "----------------------------------\n",
      "Episode reward: 34.925356\n",
      "Episode reward: 110.054193\n",
      "Episode reward: 35.802539\n",
      "Episode reward: 60.891491\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15284    |\n",
      "|    fps              | 2767     |\n",
      "|    time_elapsed     | 321      |\n",
      "|    total_timesteps  | 888363   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0779   |\n",
      "|    n_updates        | 222065   |\n",
      "----------------------------------\n",
      "Episode reward: 52.905763\n",
      "Episode reward: 42.848687\n",
      "Episode reward: 52.833031\n",
      "Episode reward: 55.71075\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15288    |\n",
      "|    fps              | 2767     |\n",
      "|    time_elapsed     | 321      |\n",
      "|    total_timesteps  | 888568   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.198    |\n",
      "|    n_updates        | 222116   |\n",
      "----------------------------------\n",
      "Episode reward: 78.096185\n",
      "Episode reward: 98.492852\n",
      "Episode reward: 40.917885\n",
      "Episode reward: 64.765268\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15292    |\n",
      "|    fps              | 2767     |\n",
      "|    time_elapsed     | 321      |\n",
      "|    total_timesteps  | 888854   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0571   |\n",
      "|    n_updates        | 222188   |\n",
      "----------------------------------\n",
      "Episode reward: 139.963588\n",
      "Episode reward: 57.35251\n",
      "Episode reward: 34.853183\n",
      "Episode reward: 49.915551\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15296    |\n",
      "|    fps              | 2766     |\n",
      "|    time_elapsed     | 321      |\n",
      "|    total_timesteps  | 889138   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0848   |\n",
      "|    n_updates        | 222259   |\n",
      "----------------------------------\n",
      "Episode reward: 43.926415\n",
      "Episode reward: 52.838983\n",
      "Episode reward: 30.83487\n",
      "Episode reward: 59.469205\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15300    |\n",
      "|    fps              | 2766     |\n",
      "|    time_elapsed     | 321      |\n",
      "|    total_timesteps  | 889326   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.068    |\n",
      "|    n_updates        | 222306   |\n",
      "----------------------------------\n",
      "Episode reward: 62.77029\n",
      "Episode reward: 43.657084\n",
      "Episode reward: 109.762122\n",
      "Episode reward: 30.870856\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15304    |\n",
      "|    fps              | 2766     |\n",
      "|    time_elapsed     | 321      |\n",
      "|    total_timesteps  | 889574   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0652   |\n",
      "|    n_updates        | 222368   |\n",
      "----------------------------------\n",
      "Episode reward: 36.882139\n",
      "Episode reward: 65.69411\n",
      "Episode reward: 51.453169\n",
      "Episode reward: 47.870186\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15308    |\n",
      "|    fps              | 2766     |\n",
      "|    time_elapsed     | 321      |\n",
      "|    total_timesteps  | 889778   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0794   |\n",
      "|    n_updates        | 222419   |\n",
      "----------------------------------\n",
      "Episode reward: 29.94194\n",
      "Episode reward: 55.886617\n",
      "Episode reward: 73.695764\n",
      "Episode reward: 61.825479\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15312    |\n",
      "|    fps              | 2766     |\n",
      "|    time_elapsed     | 321      |\n",
      "|    total_timesteps  | 890001   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0877   |\n",
      "|    n_updates        | 222475   |\n",
      "----------------------------------\n",
      "Episode reward: 77.813004\n",
      "Episode reward: 93.454254\n",
      "Episode reward: 50.594685\n",
      "Episode reward: 46.923673\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.6     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15316    |\n",
      "|    fps              | 2766     |\n",
      "|    time_elapsed     | 321      |\n",
      "|    total_timesteps  | 890271   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0765   |\n",
      "|    n_updates        | 222542   |\n",
      "----------------------------------\n",
      "Episode reward: 43.812058\n",
      "Episode reward: 38.371135\n",
      "Episode reward: 49.856071\n",
      "Episode reward: 39.811602\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15320    |\n",
      "|    fps              | 2766     |\n",
      "|    time_elapsed     | 321      |\n",
      "|    total_timesteps  | 890444   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.18     |\n",
      "|    n_updates        | 222585   |\n",
      "----------------------------------\n",
      "Episode reward: 39.831353\n",
      "Episode reward: 56.644451\n",
      "Episode reward: 44.784464\n",
      "Episode reward: 71.453731\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15324    |\n",
      "|    fps              | 2766     |\n",
      "|    time_elapsed     | 321      |\n",
      "|    total_timesteps  | 890659   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.24     |\n",
      "|    n_updates        | 222639   |\n",
      "----------------------------------\n",
      "Episode reward: 45.848362\n",
      "Episode reward: 56.889317\n",
      "Episode reward: 46.881769\n",
      "Episode reward: 65.546325\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15328    |\n",
      "|    fps              | 2766     |\n",
      "|    time_elapsed     | 322      |\n",
      "|    total_timesteps  | 890875   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0849   |\n",
      "|    n_updates        | 222693   |\n",
      "----------------------------------\n",
      "Episode reward: 112.500299\n",
      "Episode reward: 49.885522\n",
      "Episode reward: 97.406831\n",
      "Episode reward: 65.690364\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15332    |\n",
      "|    fps              | 2765     |\n",
      "|    time_elapsed     | 322      |\n",
      "|    total_timesteps  | 891204   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0755   |\n",
      "|    n_updates        | 222775   |\n",
      "----------------------------------\n",
      "Episode reward: 28.928609\n",
      "Episode reward: 85.680913\n",
      "Episode reward: 75.552596\n",
      "Episode reward: 28.796761\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15336    |\n",
      "|    fps              | 2765     |\n",
      "|    time_elapsed     | 322      |\n",
      "|    total_timesteps  | 891429   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.03     |\n",
      "|    n_updates        | 222832   |\n",
      "----------------------------------\n",
      "Episode reward: 68.737474\n",
      "Episode reward: 37.889289\n",
      "Episode reward: 54.799498\n",
      "Episode reward: 52.844461\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15340    |\n",
      "|    fps              | 2765     |\n",
      "|    time_elapsed     | 322      |\n",
      "|    total_timesteps  | 891644   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 222885   |\n",
      "----------------------------------\n",
      "Episode reward: 39.853619\n",
      "Episode reward: 46.718953\n",
      "Episode reward: 70.554374\n",
      "Episode reward: 57.912892\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15344    |\n",
      "|    fps              | 2765     |\n",
      "|    time_elapsed     | 322      |\n",
      "|    total_timesteps  | 891860   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0664   |\n",
      "|    n_updates        | 222939   |\n",
      "----------------------------------\n",
      "Episode reward: 96.707692\n",
      "Episode reward: 70.767121\n",
      "Episode reward: 47.555249\n",
      "Episode reward: 195.151536\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15348    |\n",
      "|    fps              | 2765     |\n",
      "|    time_elapsed     | 322      |\n",
      "|    total_timesteps  | 892281   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.822    |\n",
      "|    n_updates        | 223045   |\n",
      "----------------------------------\n",
      "Episode reward: 40.820042\n",
      "Episode reward: 63.722777\n",
      "Episode reward: 78.67698\n",
      "Episode reward: 39.819931\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15352    |\n",
      "|    fps              | 2765     |\n",
      "|    time_elapsed     | 322      |\n",
      "|    total_timesteps  | 892505   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.242    |\n",
      "|    n_updates        | 223101   |\n",
      "----------------------------------\n",
      "Episode reward: 75.646168\n",
      "Episode reward: 74.619638\n",
      "Episode reward: 50.778194\n",
      "Episode reward: 53.834922\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15356    |\n",
      "|    fps              | 2765     |\n",
      "|    time_elapsed     | 322      |\n",
      "|    total_timesteps  | 892761   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.36     |\n",
      "|    n_updates        | 223165   |\n",
      "----------------------------------\n",
      "Episode reward: 33.681069\n",
      "Episode reward: 53.460235\n",
      "Episode reward: 43.881245\n",
      "Episode reward: 59.645312\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15360    |\n",
      "|    fps              | 2765     |\n",
      "|    time_elapsed     | 322      |\n",
      "|    total_timesteps  | 892953   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0419   |\n",
      "|    n_updates        | 223213   |\n",
      "----------------------------------\n",
      "Episode reward: 63.434325\n",
      "Episode reward: 51.888599\n",
      "Episode reward: 56.764032\n",
      "Episode reward: 87.94777\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15364    |\n",
      "|    fps              | 2764     |\n",
      "|    time_elapsed     | 323      |\n",
      "|    total_timesteps  | 893215   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.99     |\n",
      "|    n_updates        | 223278   |\n",
      "----------------------------------\n",
      "Episode reward: 85.059871\n",
      "Episode reward: 49.691667\n",
      "Episode reward: 48.8873\n",
      "Episode reward: 34.577234\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15368    |\n",
      "|    fps              | 2764     |\n",
      "|    time_elapsed     | 323      |\n",
      "|    total_timesteps  | 893438   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.271    |\n",
      "|    n_updates        | 223334   |\n",
      "----------------------------------\n",
      "Episode reward: 45.903952\n",
      "Episode reward: 43.825016\n",
      "Episode reward: 37.920573\n",
      "Episode reward: 81.830437\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15372    |\n",
      "|    fps              | 2764     |\n",
      "|    time_elapsed     | 323      |\n",
      "|    total_timesteps  | 893648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0873   |\n",
      "|    n_updates        | 223386   |\n",
      "----------------------------------\n",
      "Episode reward: 84.266292\n",
      "Episode reward: 57.779313\n",
      "Episode reward: 49.747352\n",
      "Episode reward: 73.308034\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15376    |\n",
      "|    fps              | 2765     |\n",
      "|    time_elapsed     | 323      |\n",
      "|    total_timesteps  | 893916   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0547   |\n",
      "|    n_updates        | 223453   |\n",
      "----------------------------------\n",
      "Episode reward: 68.741855\n",
      "Episode reward: 39.917868\n",
      "Episode reward: 51.21699\n",
      "Episode reward: 29.936243\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15380    |\n",
      "|    fps              | 2764     |\n",
      "|    time_elapsed     | 323      |\n",
      "|    total_timesteps  | 894107   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0464   |\n",
      "|    n_updates        | 223501   |\n",
      "----------------------------------\n",
      "Episode reward: 79.983176\n",
      "Episode reward: 67.666462\n",
      "Episode reward: 39.743774\n",
      "Episode reward: 50.896956\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15384    |\n",
      "|    fps              | 2765     |\n",
      "|    time_elapsed     | 323      |\n",
      "|    total_timesteps  | 894347   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0625   |\n",
      "|    n_updates        | 223561   |\n",
      "----------------------------------\n",
      "Episode reward: 50.572768\n",
      "Episode reward: 54.941244\n",
      "Episode reward: 28.828619\n",
      "Episode reward: 27.875302\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15388    |\n",
      "|    fps              | 2764     |\n",
      "|    time_elapsed     | 323      |\n",
      "|    total_timesteps  | 894511   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.74     |\n",
      "|    n_updates        | 223602   |\n",
      "----------------------------------\n",
      "Episode reward: 36.647826\n",
      "Episode reward: 129.487202\n",
      "Episode reward: 65.175625\n",
      "Episode reward: 63.820848\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15392    |\n",
      "|    fps              | 2764     |\n",
      "|    time_elapsed     | 323      |\n",
      "|    total_timesteps  | 894810   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.562    |\n",
      "|    n_updates        | 223677   |\n",
      "----------------------------------\n",
      "Episode reward: 66.876095\n",
      "Episode reward: 101.095163\n",
      "Episode reward: 36.664293\n",
      "Episode reward: 55.769282\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15396    |\n",
      "|    fps              | 2764     |\n",
      "|    time_elapsed     | 323      |\n",
      "|    total_timesteps  | 895075   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0774   |\n",
      "|    n_updates        | 223743   |\n",
      "----------------------------------\n",
      "Episode reward: 51.599517\n",
      "Episode reward: 56.906253\n",
      "Episode reward: 75.759742\n",
      "Episode reward: 111.768544\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15400    |\n",
      "|    fps              | 2764     |\n",
      "|    time_elapsed     | 323      |\n",
      "|    total_timesteps  | 895377   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0561   |\n",
      "|    n_updates        | 223819   |\n",
      "----------------------------------\n",
      "Episode reward: 54.705866\n",
      "Episode reward: 29.945503\n",
      "Episode reward: 110.64162\n",
      "Episode reward: 47.794512\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15404    |\n",
      "|    fps              | 2764     |\n",
      "|    time_elapsed     | 323      |\n",
      "|    total_timesteps  | 895622   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.21     |\n",
      "|    n_updates        | 223880   |\n",
      "----------------------------------\n",
      "Episode reward: 37.704548\n",
      "Episode reward: 45.937564\n",
      "Episode reward: 34.408106\n",
      "Episode reward: 44.825935\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15408    |\n",
      "|    fps              | 2764     |\n",
      "|    time_elapsed     | 324      |\n",
      "|    total_timesteps  | 895786   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.06     |\n",
      "|    n_updates        | 223921   |\n",
      "----------------------------------\n",
      "Episode reward: 64.817169\n",
      "Episode reward: 36.724822\n",
      "Episode reward: 42.902795\n",
      "Episode reward: 85.571859\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15412    |\n",
      "|    fps              | 2764     |\n",
      "|    time_elapsed     | 324      |\n",
      "|    total_timesteps  | 896017   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 223979   |\n",
      "----------------------------------\n",
      "Episode reward: 50.911898\n",
      "Episode reward: 27.878553\n",
      "Episode reward: 38.935222\n",
      "Episode reward: 91.066583\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15416    |\n",
      "|    fps              | 2764     |\n",
      "|    time_elapsed     | 324      |\n",
      "|    total_timesteps  | 896232   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0893   |\n",
      "|    n_updates        | 224032   |\n",
      "----------------------------------\n",
      "Episode reward: 76.849542\n",
      "Episode reward: 36.690161\n",
      "Episode reward: 53.919736\n",
      "Episode reward: 34.810286\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15420    |\n",
      "|    fps              | 2764     |\n",
      "|    time_elapsed     | 324      |\n",
      "|    total_timesteps  | 896435   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0692   |\n",
      "|    n_updates        | 224083   |\n",
      "----------------------------------\n",
      "Episode reward: 29.824835\n",
      "Episode reward: 53.861101\n",
      "Episode reward: 37.653141\n",
      "Episode reward: 114.674223\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15424    |\n",
      "|    fps              | 2764     |\n",
      "|    time_elapsed     | 324      |\n",
      "|    total_timesteps  | 896676   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0623   |\n",
      "|    n_updates        | 224143   |\n",
      "----------------------------------\n",
      "Episode reward: 49.904555\n",
      "Episode reward: 55.903669\n",
      "Episode reward: 35.657414\n",
      "Episode reward: 68.751929\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15428    |\n",
      "|    fps              | 2763     |\n",
      "|    time_elapsed     | 324      |\n",
      "|    total_timesteps  | 896887   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.295    |\n",
      "|    n_updates        | 224196   |\n",
      "----------------------------------\n",
      "Episode reward: 52.874656\n",
      "Episode reward: 30.810525\n",
      "Episode reward: 41.926599\n",
      "Episode reward: 54.607508\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15432    |\n",
      "|    fps              | 2763     |\n",
      "|    time_elapsed     | 324      |\n",
      "|    total_timesteps  | 897068   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0743   |\n",
      "|    n_updates        | 224241   |\n",
      "----------------------------------\n",
      "Episode reward: 44.925782\n",
      "Episode reward: 36.699052\n",
      "Episode reward: 107.519121\n",
      "Episode reward: 33.879391\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15436    |\n",
      "|    fps              | 2763     |\n",
      "|    time_elapsed     | 324      |\n",
      "|    total_timesteps  | 897301   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.143    |\n",
      "|    n_updates        | 224300   |\n",
      "----------------------------------\n",
      "Episode reward: 58.480056\n",
      "Episode reward: 46.89393\n",
      "Episode reward: 39.90757\n",
      "Episode reward: 64.831768\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15440    |\n",
      "|    fps              | 2763     |\n",
      "|    time_elapsed     | 324      |\n",
      "|    total_timesteps  | 897512   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0551   |\n",
      "|    n_updates        | 224352   |\n",
      "----------------------------------\n",
      "Episode reward: 65.716704\n",
      "Episode reward: 61.835437\n",
      "Episode reward: 57.200299\n",
      "Episode reward: 38.862015\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15444    |\n",
      "|    fps              | 2762     |\n",
      "|    time_elapsed     | 324      |\n",
      "|    total_timesteps  | 897737   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.115    |\n",
      "|    n_updates        | 224409   |\n",
      "----------------------------------\n",
      "Episode reward: 38.919182\n",
      "Episode reward: 86.476555\n",
      "Episode reward: 48.515886\n",
      "Episode reward: 48.699146\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15448    |\n",
      "|    fps              | 2762     |\n",
      "|    time_elapsed     | 325      |\n",
      "|    total_timesteps  | 897962   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.168    |\n",
      "|    n_updates        | 224465   |\n",
      "----------------------------------\n",
      "Episode reward: 62.831788\n",
      "Episode reward: 41.905575\n",
      "Episode reward: 57.843257\n",
      "Episode reward: 98.368778\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15452    |\n",
      "|    fps              | 2762     |\n",
      "|    time_elapsed     | 325      |\n",
      "|    total_timesteps  | 898224   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0561   |\n",
      "|    n_updates        | 224530   |\n",
      "----------------------------------\n",
      "Episode reward: 55.56885\n",
      "Episode reward: 36.932916\n",
      "Episode reward: 43.93079\n",
      "Episode reward: 41.942513\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 55.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15456    |\n",
      "|    fps              | 2762     |\n",
      "|    time_elapsed     | 325      |\n",
      "|    total_timesteps  | 898403   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0635   |\n",
      "|    n_updates        | 224575   |\n",
      "----------------------------------\n",
      "Episode reward: 39.809587\n",
      "Episode reward: 113.974954\n",
      "Episode reward: 97.618729\n",
      "Episode reward: 77.783171\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15460    |\n",
      "|    fps              | 2762     |\n",
      "|    time_elapsed     | 325      |\n",
      "|    total_timesteps  | 898752   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0875   |\n",
      "|    n_updates        | 224662   |\n",
      "----------------------------------\n",
      "Episode reward: 111.803828\n",
      "Episode reward: 72.681913\n",
      "Episode reward: 65.608418\n",
      "Episode reward: 39.542224\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15464    |\n",
      "|    fps              | 2762     |\n",
      "|    time_elapsed     | 325      |\n",
      "|    total_timesteps  | 899043   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0964   |\n",
      "|    n_updates        | 224735   |\n",
      "----------------------------------\n",
      "Episode reward: 39.749977\n",
      "Episode reward: 115.936477\n",
      "Episode reward: 49.888503\n",
      "Episode reward: 114.160537\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15468    |\n",
      "|    fps              | 2761     |\n",
      "|    time_elapsed     | 325      |\n",
      "|    total_timesteps  | 899385   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0983   |\n",
      "|    n_updates        | 224821   |\n",
      "----------------------------------\n",
      "Episode reward: 80.843911\n",
      "Episode reward: 49.907808\n",
      "Episode reward: 60.00829\n",
      "Episode reward: 43.634072\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15472    |\n",
      "|    fps              | 2761     |\n",
      "|    time_elapsed     | 325      |\n",
      "|    total_timesteps  | 899622   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0482   |\n",
      "|    n_updates        | 224880   |\n",
      "----------------------------------\n",
      "Episode reward: 110.173796\n",
      "Episode reward: 69.72434\n",
      "Episode reward: 35.896236\n",
      "Episode reward: 34.957077\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15476    |\n",
      "|    fps              | 2761     |\n",
      "|    time_elapsed     | 325      |\n",
      "|    total_timesteps  | 899876   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0504   |\n",
      "|    n_updates        | 224943   |\n",
      "----------------------------------\n",
      "Episode reward: 59.783137\n",
      "Episode reward: 37.885364\n",
      "Episode reward: 41.926204\n",
      "Episode reward: 47.637458\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15480    |\n",
      "|    fps              | 2761     |\n",
      "|    time_elapsed     | 325      |\n",
      "|    total_timesteps  | 900064   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.69     |\n",
      "|    n_updates        | 224990   |\n",
      "----------------------------------\n",
      "Episode reward: 38.929587\n",
      "Episode reward: 59.867263\n",
      "Episode reward: 46.764184\n",
      "Episode reward: 135.750702\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15484    |\n",
      "|    fps              | 2761     |\n",
      "|    time_elapsed     | 326      |\n",
      "|    total_timesteps  | 900347   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.45     |\n",
      "|    n_updates        | 225061   |\n",
      "----------------------------------\n",
      "Episode reward: 29.873595\n",
      "Episode reward: 75.638427\n",
      "Episode reward: 28.728424\n",
      "Episode reward: 39.651689\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15488    |\n",
      "|    fps              | 2761     |\n",
      "|    time_elapsed     | 326      |\n",
      "|    total_timesteps  | 900522   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0984   |\n",
      "|    n_updates        | 225105   |\n",
      "----------------------------------\n",
      "Episode reward: 44.905381\n",
      "Episode reward: 83.46814\n",
      "Episode reward: 95.455065\n",
      "Episode reward: 77.691326\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15492    |\n",
      "|    fps              | 2761     |\n",
      "|    time_elapsed     | 326      |\n",
      "|    total_timesteps  | 900825   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0679   |\n",
      "|    n_updates        | 225181   |\n",
      "----------------------------------\n",
      "Episode reward: 49.784399\n",
      "Episode reward: 110.194172\n",
      "Episode reward: 77.082078\n",
      "Episode reward: 92.322599\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15496    |\n",
      "|    fps              | 2761     |\n",
      "|    time_elapsed     | 326      |\n",
      "|    total_timesteps  | 901160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 225264   |\n",
      "----------------------------------\n",
      "Episode reward: 97.440146\n",
      "Episode reward: 31.771854\n",
      "Episode reward: 39.824296\n",
      "Episode reward: 33.928195\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15500    |\n",
      "|    fps              | 2761     |\n",
      "|    time_elapsed     | 326      |\n",
      "|    total_timesteps  | 901365   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.68     |\n",
      "|    n_updates        | 225316   |\n",
      "----------------------------------\n",
      "Episode reward: 111.388324\n",
      "Episode reward: 92.503431\n",
      "Episode reward: 106.908103\n",
      "Episode reward: 42.749381\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15504    |\n",
      "|    fps              | 2761     |\n",
      "|    time_elapsed     | 326      |\n",
      "|    total_timesteps  | 901736   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.25     |\n",
      "|    n_updates        | 225408   |\n",
      "----------------------------------\n",
      "Episode reward: 68.847152\n",
      "Episode reward: 45.772673\n",
      "Episode reward: 48.668758\n",
      "Episode reward: 58.871073\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15508    |\n",
      "|    fps              | 2761     |\n",
      "|    time_elapsed     | 326      |\n",
      "|    total_timesteps  | 901959   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0545   |\n",
      "|    n_updates        | 225464   |\n",
      "----------------------------------\n",
      "Episode reward: 77.601324\n",
      "Episode reward: 31.745875\n",
      "Episode reward: 70.616022\n",
      "Episode reward: 47.885612\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15512    |\n",
      "|    fps              | 2760     |\n",
      "|    time_elapsed     | 326      |\n",
      "|    total_timesteps  | 902189   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0425   |\n",
      "|    n_updates        | 225522   |\n",
      "----------------------------------\n",
      "Episode reward: 55.753652\n",
      "Episode reward: 32.943541\n",
      "Episode reward: 64.468019\n",
      "Episode reward: 71.547435\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15516    |\n",
      "|    fps              | 2760     |\n",
      "|    time_elapsed     | 326      |\n",
      "|    total_timesteps  | 902415   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.124    |\n",
      "|    n_updates        | 225578   |\n",
      "----------------------------------\n",
      "Episode reward: 39.902914\n",
      "Episode reward: 50.734624\n",
      "Episode reward: 64.354842\n",
      "Episode reward: 73.640977\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15520    |\n",
      "|    fps              | 2760     |\n",
      "|    time_elapsed     | 326      |\n",
      "|    total_timesteps  | 902647   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.337    |\n",
      "|    n_updates        | 225636   |\n",
      "----------------------------------\n",
      "Episode reward: 50.740211\n",
      "Episode reward: 78.995933\n",
      "Episode reward: 106.095843\n",
      "Episode reward: 38.835573\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15524    |\n",
      "|    fps              | 2760     |\n",
      "|    time_elapsed     | 327      |\n",
      "|    total_timesteps  | 902926   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.472    |\n",
      "|    n_updates        | 225706   |\n",
      "----------------------------------\n",
      "Episode reward: 33.873676\n",
      "Episode reward: 48.902395\n",
      "Episode reward: 64.973328\n",
      "Episode reward: 93.898464\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15528    |\n",
      "|    fps              | 2760     |\n",
      "|    time_elapsed     | 327      |\n",
      "|    total_timesteps  | 903170   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0452   |\n",
      "|    n_updates        | 225767   |\n",
      "----------------------------------\n",
      "Episode reward: 134.870794\n",
      "Episode reward: 63.857262\n",
      "Episode reward: 52.863903\n",
      "Episode reward: 55.879373\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.1     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15532    |\n",
      "|    fps              | 2760     |\n",
      "|    time_elapsed     | 327      |\n",
      "|    total_timesteps  | 903481   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0732   |\n",
      "|    n_updates        | 225845   |\n",
      "----------------------------------\n",
      "Episode reward: 38.944794\n",
      "Episode reward: 108.799045\n",
      "Episode reward: 67.492119\n",
      "Episode reward: 46.909547\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15536    |\n",
      "|    fps              | 2760     |\n",
      "|    time_elapsed     | 327      |\n",
      "|    total_timesteps  | 903744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 225910   |\n",
      "----------------------------------\n",
      "Episode reward: 92.83646\n",
      "Episode reward: 85.242756\n",
      "Episode reward: 35.790503\n",
      "Episode reward: 87.838763\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.4     |\n",
      "|    ep_rew_mean      | 64.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15540    |\n",
      "|    fps              | 2760     |\n",
      "|    time_elapsed     | 327      |\n",
      "|    total_timesteps  | 904048   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.9      |\n",
      "|    n_updates        | 225986   |\n",
      "----------------------------------\n",
      "Episode reward: 77.050501\n",
      "Episode reward: 61.878138\n",
      "Episode reward: 48.802409\n",
      "Episode reward: 68.715349\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.7     |\n",
      "|    ep_rew_mean      | 64.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15544    |\n",
      "|    fps              | 2760     |\n",
      "|    time_elapsed     | 327      |\n",
      "|    total_timesteps  | 904309   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0731   |\n",
      "|    n_updates        | 226052   |\n",
      "----------------------------------\n",
      "Episode reward: 49.47046\n",
      "Episode reward: 47.779603\n",
      "Episode reward: 41.906856\n",
      "Episode reward: 83.202231\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.7     |\n",
      "|    ep_rew_mean      | 64.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15548    |\n",
      "|    fps              | 2759     |\n",
      "|    time_elapsed     | 327      |\n",
      "|    total_timesteps  | 904533   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0695   |\n",
      "|    n_updates        | 226108   |\n",
      "----------------------------------\n",
      "Episode reward: 27.952512\n",
      "Episode reward: 68.049345\n",
      "Episode reward: 55.615034\n",
      "Episode reward: 30.740676\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.9     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15552    |\n",
      "|    fps              | 2759     |\n",
      "|    time_elapsed     | 327      |\n",
      "|    total_timesteps  | 904717   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0406   |\n",
      "|    n_updates        | 226154   |\n",
      "----------------------------------\n",
      "Episode reward: 33.917152\n",
      "Episode reward: 114.291828\n",
      "Episode reward: 127.70562\n",
      "Episode reward: 37.946912\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.3     |\n",
      "|    ep_rew_mean      | 65.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15556    |\n",
      "|    fps              | 2759     |\n",
      "|    time_elapsed     | 327      |\n",
      "|    total_timesteps  | 905037   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.351    |\n",
      "|    n_updates        | 226234   |\n",
      "----------------------------------\n",
      "Episode reward: 32.874067\n",
      "Episode reward: 50.110952\n",
      "Episode reward: 54.610579\n",
      "Episode reward: 74.584294\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65       |\n",
      "|    ep_rew_mean      | 64       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15560    |\n",
      "|    fps              | 2759     |\n",
      "|    time_elapsed     | 328      |\n",
      "|    total_timesteps  | 905251   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.136    |\n",
      "|    n_updates        | 226287   |\n",
      "----------------------------------\n",
      "Episode reward: 49.784829\n",
      "Episode reward: 78.182542\n",
      "Episode reward: 50.788803\n",
      "Episode reward: 44.928877\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.3     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15564    |\n",
      "|    fps              | 2759     |\n",
      "|    time_elapsed     | 328      |\n",
      "|    total_timesteps  | 905476   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0352   |\n",
      "|    n_updates        | 226343   |\n",
      "----------------------------------\n",
      "Episode reward: 113.41729\n",
      "Episode reward: 46.832525\n",
      "Episode reward: 90.784693\n",
      "Episode reward: 62.689339\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.1     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15568    |\n",
      "|    fps              | 2758     |\n",
      "|    time_elapsed     | 328      |\n",
      "|    total_timesteps  | 905799   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0705   |\n",
      "|    n_updates        | 226424   |\n",
      "----------------------------------\n",
      "Episode reward: 62.804333\n",
      "Episode reward: 124.126023\n",
      "Episode reward: 42.734616\n",
      "Episode reward: 50.885553\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15572    |\n",
      "|    fps              | 2758     |\n",
      "|    time_elapsed     | 328      |\n",
      "|    total_timesteps  | 906098   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0513   |\n",
      "|    n_updates        | 226499   |\n",
      "----------------------------------\n",
      "Episode reward: 30.824251\n",
      "Episode reward: 61.907748\n",
      "Episode reward: 54.785545\n",
      "Episode reward: 39.891962\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.1     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15576    |\n",
      "|    fps              | 2758     |\n",
      "|    time_elapsed     | 328      |\n",
      "|    total_timesteps  | 906287   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.106    |\n",
      "|    n_updates        | 226546   |\n",
      "----------------------------------\n",
      "Episode reward: 38.826807\n",
      "Episode reward: 31.943117\n",
      "Episode reward: 71.512809\n",
      "Episode reward: 77.832071\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15580    |\n",
      "|    fps              | 2758     |\n",
      "|    time_elapsed     | 328      |\n",
      "|    total_timesteps  | 906509   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0408   |\n",
      "|    n_updates        | 226602   |\n",
      "----------------------------------\n",
      "Episode reward: 114.383972\n",
      "Episode reward: 53.811743\n",
      "Episode reward: 94.299206\n",
      "Episode reward: 68.587036\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65       |\n",
      "|    ep_rew_mean      | 64       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15584    |\n",
      "|    fps              | 2758     |\n",
      "|    time_elapsed     | 328      |\n",
      "|    total_timesteps  | 906845   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0833   |\n",
      "|    n_updates        | 226686   |\n",
      "----------------------------------\n",
      "Episode reward: 54.855803\n",
      "Episode reward: 87.419615\n",
      "Episode reward: 61.883241\n",
      "Episode reward: 54.028402\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.8     |\n",
      "|    ep_rew_mean      | 64.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15588    |\n",
      "|    fps              | 2758     |\n",
      "|    time_elapsed     | 328      |\n",
      "|    total_timesteps  | 907106   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.92     |\n",
      "|    n_updates        | 226751   |\n",
      "----------------------------------\n",
      "Episode reward: 24.821728\n",
      "Episode reward: 64.116843\n",
      "Episode reward: 106.330164\n",
      "Episode reward: 32.926785\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.1     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15592    |\n",
      "|    fps              | 2758     |\n",
      "|    time_elapsed     | 328      |\n",
      "|    total_timesteps  | 907336   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.229    |\n",
      "|    n_updates        | 226808   |\n",
      "----------------------------------\n",
      "Episode reward: 56.856401\n",
      "Episode reward: 107.056734\n",
      "Episode reward: 70.696836\n",
      "Episode reward: 33.836413\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15596    |\n",
      "|    fps              | 2758     |\n",
      "|    time_elapsed     | 329      |\n",
      "|    total_timesteps  | 907616   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0308   |\n",
      "|    n_updates        | 226878   |\n",
      "----------------------------------\n",
      "Episode reward: 38.943238\n",
      "Episode reward: 62.81163\n",
      "Episode reward: 33.906727\n",
      "Episode reward: 89.526702\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 63.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15600    |\n",
      "|    fps              | 2757     |\n",
      "|    time_elapsed     | 329      |\n",
      "|    total_timesteps  | 907842   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.96     |\n",
      "|    n_updates        | 226935   |\n",
      "----------------------------------\n",
      "Episode reward: 42.896106\n",
      "Episode reward: 64.046232\n",
      "Episode reward: 33.579562\n",
      "Episode reward: 74.576849\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15604    |\n",
      "|    fps              | 2757     |\n",
      "|    time_elapsed     | 329      |\n",
      "|    total_timesteps  | 908060   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.346    |\n",
      "|    n_updates        | 226989   |\n",
      "----------------------------------\n",
      "Episode reward: 41.661096\n",
      "Episode reward: 51.843288\n",
      "Episode reward: 68.789197\n",
      "Episode reward: 93.917917\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15608    |\n",
      "|    fps              | 2756     |\n",
      "|    time_elapsed     | 329      |\n",
      "|    total_timesteps  | 908322   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.072    |\n",
      "|    n_updates        | 227055   |\n",
      "----------------------------------\n",
      "Episode reward: 61.714351\n",
      "Episode reward: 44.923235\n",
      "Episode reward: 70.845604\n",
      "Episode reward: 29.779507\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15612    |\n",
      "|    fps              | 2756     |\n",
      "|    time_elapsed     | 329      |\n",
      "|    total_timesteps  | 908530   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.104    |\n",
      "|    n_updates        | 227107   |\n",
      "----------------------------------\n",
      "Episode reward: 73.558443\n",
      "Episode reward: 36.78072\n",
      "Episode reward: 33.695383\n",
      "Episode reward: 72.64177\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15616    |\n",
      "|    fps              | 2756     |\n",
      "|    time_elapsed     | 329      |\n",
      "|    total_timesteps  | 908755   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0963   |\n",
      "|    n_updates        | 227163   |\n",
      "----------------------------------\n",
      "Episode reward: 60.095204\n",
      "Episode reward: 37.930311\n",
      "Episode reward: 30.868616\n",
      "Episode reward: 30.913833\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15620    |\n",
      "|    fps              | 2756     |\n",
      "|    time_elapsed     | 329      |\n",
      "|    total_timesteps  | 908917   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0702   |\n",
      "|    n_updates        | 227204   |\n",
      "----------------------------------\n",
      "Episode reward: 57.873974\n",
      "Episode reward: 79.988394\n",
      "Episode reward: 41.826792\n",
      "Episode reward: 57.896829\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15624    |\n",
      "|    fps              | 2755     |\n",
      "|    time_elapsed     | 329      |\n",
      "|    total_timesteps  | 909156   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0892   |\n",
      "|    n_updates        | 227263   |\n",
      "----------------------------------\n",
      "Episode reward: 61.860799\n",
      "Episode reward: 60.89188\n",
      "Episode reward: 54.784616\n",
      "Episode reward: 69.20454\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15628    |\n",
      "|    fps              | 2755     |\n",
      "|    time_elapsed     | 330      |\n",
      "|    total_timesteps  | 909405   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.158    |\n",
      "|    n_updates        | 227326   |\n",
      "----------------------------------\n",
      "Episode reward: 53.830339\n",
      "Episode reward: 39.892771\n",
      "Episode reward: 51.669695\n",
      "Episode reward: 73.223314\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15632    |\n",
      "|    fps              | 2755     |\n",
      "|    time_elapsed     | 330      |\n",
      "|    total_timesteps  | 909625   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0756   |\n",
      "|    n_updates        | 227381   |\n",
      "----------------------------------\n",
      "Episode reward: 43.625505\n",
      "Episode reward: 123.349927\n",
      "Episode reward: 52.868805\n",
      "Episode reward: 36.720165\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15636    |\n",
      "|    fps              | 2755     |\n",
      "|    time_elapsed     | 330      |\n",
      "|    total_timesteps  | 909885   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0542   |\n",
      "|    n_updates        | 227446   |\n",
      "----------------------------------\n",
      "Episode reward: 56.901089\n",
      "Episode reward: 37.949433\n",
      "Episode reward: 33.88212\n",
      "Episode reward: 62.569844\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15640    |\n",
      "|    fps              | 2755     |\n",
      "|    time_elapsed     | 330      |\n",
      "|    total_timesteps  | 910077   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0649   |\n",
      "|    n_updates        | 227494   |\n",
      "----------------------------------\n",
      "Episode reward: 109.586573\n",
      "Episode reward: 59.902504\n",
      "Episode reward: 59.651384\n",
      "Episode reward: 124.407812\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15644    |\n",
      "|    fps              | 2754     |\n",
      "|    time_elapsed     | 330      |\n",
      "|    total_timesteps  | 910447   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.059    |\n",
      "|    n_updates        | 227586   |\n",
      "----------------------------------\n",
      "Episode reward: 82.735409\n",
      "Episode reward: 52.85313\n",
      "Episode reward: 84.655767\n",
      "Episode reward: 78.457411\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15648    |\n",
      "|    fps              | 2754     |\n",
      "|    time_elapsed     | 330      |\n",
      "|    total_timesteps  | 910750   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0857   |\n",
      "|    n_updates        | 227662   |\n",
      "----------------------------------\n",
      "Episode reward: 46.744476\n",
      "Episode reward: 86.62785\n",
      "Episode reward: 35.950644\n",
      "Episode reward: 45.929266\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15652    |\n",
      "|    fps              | 2754     |\n",
      "|    time_elapsed     | 330      |\n",
      "|    total_timesteps  | 910967   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.137    |\n",
      "|    n_updates        | 227716   |\n",
      "----------------------------------\n",
      "Episode reward: 37.910298\n",
      "Episode reward: 31.861129\n",
      "Episode reward: 81.193181\n",
      "Episode reward: 139.839985\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15656    |\n",
      "|    fps              | 2754     |\n",
      "|    time_elapsed     | 330      |\n",
      "|    total_timesteps  | 911261   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.84     |\n",
      "|    n_updates        | 227790   |\n",
      "----------------------------------\n",
      "Episode reward: 56.796748\n",
      "Episode reward: 46.936738\n",
      "Episode reward: 36.770267\n",
      "Episode reward: 94.838196\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15660    |\n",
      "|    fps              | 2754     |\n",
      "|    time_elapsed     | 330      |\n",
      "|    total_timesteps  | 911497   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0507   |\n",
      "|    n_updates        | 227849   |\n",
      "----------------------------------\n",
      "Episode reward: 35.869211\n",
      "Episode reward: 61.826056\n",
      "Episode reward: 44.531911\n",
      "Episode reward: 34.934774\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15664    |\n",
      "|    fps              | 2753     |\n",
      "|    time_elapsed     | 331      |\n",
      "|    total_timesteps  | 911675   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0981   |\n",
      "|    n_updates        | 227893   |\n",
      "----------------------------------\n",
      "Episode reward: 73.057658\n",
      "Episode reward: 53.85173\n",
      "Episode reward: 41.436074\n",
      "Episode reward: 80.768488\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15668    |\n",
      "|    fps              | 2753     |\n",
      "|    time_elapsed     | 331      |\n",
      "|    total_timesteps  | 911931   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.127    |\n",
      "|    n_updates        | 227957   |\n",
      "----------------------------------\n",
      "Episode reward: 98.510507\n",
      "Episode reward: 32.946721\n",
      "Episode reward: 61.769061\n",
      "Episode reward: 68.215584\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15672    |\n",
      "|    fps              | 2753     |\n",
      "|    time_elapsed     | 331      |\n",
      "|    total_timesteps  | 912196   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.16     |\n",
      "|    n_updates        | 228023   |\n",
      "----------------------------------\n",
      "Episode reward: 33.948544\n",
      "Episode reward: 41.905852\n",
      "Episode reward: 52.822896\n",
      "Episode reward: 59.609888\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15676    |\n",
      "|    fps              | 2753     |\n",
      "|    time_elapsed     | 331      |\n",
      "|    total_timesteps  | 912385   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0409   |\n",
      "|    n_updates        | 228071   |\n",
      "----------------------------------\n",
      "Episode reward: 51.896029\n",
      "Episode reward: 57.676496\n",
      "Episode reward: 108.792497\n",
      "Episode reward: 53.151106\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15680    |\n",
      "|    fps              | 2753     |\n",
      "|    time_elapsed     | 331      |\n",
      "|    total_timesteps  | 912658   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0731   |\n",
      "|    n_updates        | 228139   |\n",
      "----------------------------------\n",
      "Episode reward: 54.385739\n",
      "Episode reward: 52.834629\n",
      "Episode reward: 69.380007\n",
      "Episode reward: 48.72255\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15684    |\n",
      "|    fps              | 2753     |\n",
      "|    time_elapsed     | 331      |\n",
      "|    total_timesteps  | 912885   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0332   |\n",
      "|    n_updates        | 228196   |\n",
      "----------------------------------\n",
      "Episode reward: 54.654226\n",
      "Episode reward: 53.756205\n",
      "Episode reward: 59.802973\n",
      "Episode reward: 54.892441\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15688    |\n",
      "|    fps              | 2753     |\n",
      "|    time_elapsed     | 331      |\n",
      "|    total_timesteps  | 913109   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0805   |\n",
      "|    n_updates        | 228252   |\n",
      "----------------------------------\n",
      "Episode reward: 33.918838\n",
      "Episode reward: 55.595248\n",
      "Episode reward: 39.880352\n",
      "Episode reward: 58.837949\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15692    |\n",
      "|    fps              | 2753     |\n",
      "|    time_elapsed     | 331      |\n",
      "|    total_timesteps  | 913298   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.186    |\n",
      "|    n_updates        | 228299   |\n",
      "----------------------------------\n",
      "Episode reward: 47.906287\n",
      "Episode reward: 76.328135\n",
      "Episode reward: 56.438549\n",
      "Episode reward: 40.951616\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15696    |\n",
      "|    fps              | 2752     |\n",
      "|    time_elapsed     | 331      |\n",
      "|    total_timesteps  | 913521   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.126    |\n",
      "|    n_updates        | 228355   |\n",
      "----------------------------------\n",
      "Episode reward: 43.652273\n",
      "Episode reward: 23.859446\n",
      "Episode reward: 73.402024\n",
      "Episode reward: 38.856109\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15700    |\n",
      "|    fps              | 2752     |\n",
      "|    time_elapsed     | 331      |\n",
      "|    total_timesteps  | 913702   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0621   |\n",
      "|    n_updates        | 228400   |\n",
      "----------------------------------\n",
      "Episode reward: 96.130284\n",
      "Episode reward: 59.869111\n",
      "Episode reward: 71.482085\n",
      "Episode reward: 34.590523\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15704    |\n",
      "|    fps              | 2752     |\n",
      "|    time_elapsed     | 332      |\n",
      "|    total_timesteps  | 913966   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.4      |\n",
      "|    n_updates        | 228466   |\n",
      "----------------------------------\n",
      "Episode reward: 61.640963\n",
      "Episode reward: 37.822946\n",
      "Episode reward: 95.417454\n",
      "Episode reward: 51.838095\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15708    |\n",
      "|    fps              | 2752     |\n",
      "|    time_elapsed     | 332      |\n",
      "|    total_timesteps  | 914214   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.133    |\n",
      "|    n_updates        | 228528   |\n",
      "----------------------------------\n",
      "Episode reward: 88.656837\n",
      "Episode reward: 45.789591\n",
      "Episode reward: 50.911264\n",
      "Episode reward: 90.918014\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15712    |\n",
      "|    fps              | 2752     |\n",
      "|    time_elapsed     | 332      |\n",
      "|    total_timesteps  | 914493   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0454   |\n",
      "|    n_updates        | 228598   |\n",
      "----------------------------------\n",
      "Episode reward: 45.816219\n",
      "Episode reward: 47.932998\n",
      "Episode reward: 70.077647\n",
      "Episode reward: 33.914962\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15716    |\n",
      "|    fps              | 2752     |\n",
      "|    time_elapsed     | 332      |\n",
      "|    total_timesteps  | 914693   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0623   |\n",
      "|    n_updates        | 228648   |\n",
      "----------------------------------\n",
      "Episode reward: 87.823094\n",
      "Episode reward: 62.691396\n",
      "Episode reward: 53.37492\n",
      "Episode reward: 24.947543\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15720    |\n",
      "|    fps              | 2751     |\n",
      "|    time_elapsed     | 332      |\n",
      "|    total_timesteps  | 914923   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.044    |\n",
      "|    n_updates        | 228705   |\n",
      "----------------------------------\n",
      "Episode reward: 45.927849\n",
      "Episode reward: 49.670111\n",
      "Episode reward: 72.835524\n",
      "Episode reward: 72.347058\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15724    |\n",
      "|    fps              | 2751     |\n",
      "|    time_elapsed     | 332      |\n",
      "|    total_timesteps  | 915167   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.661    |\n",
      "|    n_updates        | 228766   |\n",
      "----------------------------------\n",
      "Episode reward: 47.834719\n",
      "Episode reward: 57.809209\n",
      "Episode reward: 52.874266\n",
      "Episode reward: 36.892337\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15728    |\n",
      "|    fps              | 2751     |\n",
      "|    time_elapsed     | 332      |\n",
      "|    total_timesteps  | 915363   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.635    |\n",
      "|    n_updates        | 228815   |\n",
      "----------------------------------\n",
      "Episode reward: 161.658047\n",
      "Episode reward: 54.823067\n",
      "Episode reward: 31.576829\n",
      "Episode reward: 46.842831\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15732    |\n",
      "|    fps              | 2751     |\n",
      "|    time_elapsed     | 332      |\n",
      "|    total_timesteps  | 915660   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.918    |\n",
      "|    n_updates        | 228889   |\n",
      "----------------------------------\n",
      "Episode reward: 35.822574\n",
      "Episode reward: 91.870648\n",
      "Episode reward: 28.946842\n",
      "Episode reward: 57.735024\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15736    |\n",
      "|    fps              | 2751     |\n",
      "|    time_elapsed     | 332      |\n",
      "|    total_timesteps  | 915877   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.667    |\n",
      "|    n_updates        | 228944   |\n",
      "----------------------------------\n",
      "Episode reward: 109.811162\n",
      "Episode reward: 62.656028\n",
      "Episode reward: 71.772262\n",
      "Episode reward: 34.881461\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15740    |\n",
      "|    fps              | 2751     |\n",
      "|    time_elapsed     | 332      |\n",
      "|    total_timesteps  | 916157   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.66     |\n",
      "|    n_updates        | 229014   |\n",
      "----------------------------------\n",
      "Episode reward: 50.843576\n",
      "Episode reward: 41.921766\n",
      "Episode reward: 65.688344\n",
      "Episode reward: 77.851257\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15744    |\n",
      "|    fps              | 2751     |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total_timesteps  | 916395   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0357   |\n",
      "|    n_updates        | 229073   |\n",
      "----------------------------------\n",
      "Episode reward: 68.736073\n",
      "Episode reward: 71.517299\n",
      "Episode reward: 55.900716\n",
      "Episode reward: 62.575208\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15748    |\n",
      "|    fps              | 2751     |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total_timesteps  | 916656   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.33     |\n",
      "|    n_updates        | 229138   |\n",
      "----------------------------------\n",
      "Episode reward: 66.554928\n",
      "Episode reward: 80.224189\n",
      "Episode reward: 43.755585\n",
      "Episode reward: 36.830627\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15752    |\n",
      "|    fps              | 2751     |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total_timesteps  | 916885   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0487   |\n",
      "|    n_updates        | 229196   |\n",
      "----------------------------------\n",
      "Episode reward: 83.63697\n",
      "Episode reward: 64.882968\n",
      "Episode reward: 95.239151\n",
      "Episode reward: 57.300971\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15756    |\n",
      "|    fps              | 2751     |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total_timesteps  | 917189   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.21     |\n",
      "|    n_updates        | 229272   |\n",
      "----------------------------------\n",
      "Episode reward: 46.536265\n",
      "Episode reward: 38.921034\n",
      "Episode reward: 37.525222\n",
      "Episode reward: 106.451797\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15760    |\n",
      "|    fps              | 2751     |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total_timesteps  | 917421   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0476   |\n",
      "|    n_updates        | 229330   |\n",
      "----------------------------------\n",
      "Episode reward: 42.885178\n",
      "Episode reward: 47.881647\n",
      "Episode reward: 43.784406\n",
      "Episode reward: 67.694479\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.5     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15764    |\n",
      "|    fps              | 2751     |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total_timesteps  | 917624   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 229380   |\n",
      "----------------------------------\n",
      "Episode reward: 40.670384\n",
      "Episode reward: 47.628433\n",
      "Episode reward: 68.829533\n",
      "Episode reward: 30.936463\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15768    |\n",
      "|    fps              | 2751     |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total_timesteps  | 917813   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.033    |\n",
      "|    n_updates        | 229428   |\n",
      "----------------------------------\n",
      "Episode reward: 65.764802\n",
      "Episode reward: 46.601403\n",
      "Episode reward: 31.845649\n",
      "Episode reward: 44.7458\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15772    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total_timesteps  | 918003   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.43     |\n",
      "|    n_updates        | 229475   |\n",
      "----------------------------------\n",
      "Episode reward: 47.777953\n",
      "Episode reward: 48.881417\n",
      "Episode reward: 31.853235\n",
      "Episode reward: 39.946484\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15776    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total_timesteps  | 918172   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0686   |\n",
      "|    n_updates        | 229517   |\n",
      "----------------------------------\n",
      "Episode reward: 49.764168\n",
      "Episode reward: 42.75742\n",
      "Episode reward: 50.713698\n",
      "Episode reward: 43.599088\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57       |\n",
      "|    ep_rew_mean      | 56.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15780    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total_timesteps  | 918360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.85     |\n",
      "|    n_updates        | 229564   |\n",
      "----------------------------------\n",
      "Episode reward: 43.906511\n",
      "Episode reward: 59.844042\n",
      "Episode reward: 25.776734\n",
      "Episode reward: 38.90445\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.4     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15784    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total_timesteps  | 918529   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 229607   |\n",
      "----------------------------------\n",
      "Episode reward: 62.194953\n",
      "Episode reward: 79.545389\n",
      "Episode reward: 65.555169\n",
      "Episode reward: 54.654642\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.8     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15788    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 333      |\n",
      "|    total_timesteps  | 918793   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0615   |\n",
      "|    n_updates        | 229673   |\n",
      "----------------------------------\n",
      "Episode reward: 46.614447\n",
      "Episode reward: 41.936496\n",
      "Episode reward: 93.52877\n",
      "Episode reward: 43.923044\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.2     |\n",
      "|    ep_rew_mean      | 56.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15792    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 334      |\n",
      "|    total_timesteps  | 919021   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0786   |\n",
      "|    n_updates        | 229730   |\n",
      "----------------------------------\n",
      "Episode reward: 34.583063\n",
      "Episode reward: 145.671912\n",
      "Episode reward: 54.906028\n",
      "Episode reward: 67.151046\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58       |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15796    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 334      |\n",
      "|    total_timesteps  | 919325   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 229806   |\n",
      "----------------------------------\n",
      "Episode reward: 73.143345\n",
      "Episode reward: 60.495014\n",
      "Episode reward: 111.185051\n",
      "Episode reward: 29.764547\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15800    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 334      |\n",
      "|    total_timesteps  | 919610   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.112    |\n",
      "|    n_updates        | 229877   |\n",
      "----------------------------------\n",
      "Episode reward: 64.455922\n",
      "Episode reward: 73.088696\n",
      "Episode reward: 49.929483\n",
      "Episode reward: 73.026919\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15804    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 334      |\n",
      "|    total_timesteps  | 919873   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0653   |\n",
      "|    n_updates        | 229943   |\n",
      "----------------------------------\n",
      "Episode reward: 36.920847\n",
      "Episode reward: 52.768042\n",
      "Episode reward: 43.638111\n",
      "Episode reward: 79.559834\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15808    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 334      |\n",
      "|    total_timesteps  | 920087   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0833   |\n",
      "|    n_updates        | 229996   |\n",
      "----------------------------------\n",
      "Episode reward: 39.813909\n",
      "Episode reward: 99.59453\n",
      "Episode reward: 25.899823\n",
      "Episode reward: 53.74814\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15812    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 334      |\n",
      "|    total_timesteps  | 920307   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.173    |\n",
      "|    n_updates        | 230051   |\n",
      "----------------------------------\n",
      "Episode reward: 41.859885\n",
      "Episode reward: 46.928963\n",
      "Episode reward: 73.744035\n",
      "Episode reward: 37.893434\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.1     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15816    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 334      |\n",
      "|    total_timesteps  | 920508   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.53     |\n",
      "|    n_updates        | 230101   |\n",
      "----------------------------------\n",
      "Episode reward: 48.886445\n",
      "Episode reward: 67.383997\n",
      "Episode reward: 106.106978\n",
      "Episode reward: 79.353202\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15820    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 334      |\n",
      "|    total_timesteps  | 920820   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0829   |\n",
      "|    n_updates        | 230179   |\n",
      "----------------------------------\n",
      "Episode reward: 68.74196\n",
      "Episode reward: 59.315265\n",
      "Episode reward: 66.29375\n",
      "Episode reward: 54.876524\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15824    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 334      |\n",
      "|    total_timesteps  | 921072   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.97     |\n",
      "|    n_updates        | 230242   |\n",
      "----------------------------------\n",
      "Episode reward: 41.931221\n",
      "Episode reward: 42.931049\n",
      "Episode reward: 51.83096\n",
      "Episode reward: 43.737125\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15828    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 334      |\n",
      "|    total_timesteps  | 921253   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 230288   |\n",
      "----------------------------------\n",
      "Episode reward: 70.62931\n",
      "Episode reward: 51.876387\n",
      "Episode reward: 44.454222\n",
      "Episode reward: 30.940612\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15832    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 334      |\n",
      "|    total_timesteps  | 921453   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.635    |\n",
      "|    n_updates        | 230338   |\n",
      "----------------------------------\n",
      "Episode reward: 73.305342\n",
      "Episode reward: 61.286663\n",
      "Episode reward: 71.755415\n",
      "Episode reward: 72.763316\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.6     |\n",
      "|    ep_rew_mean      | 58       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15836    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 335      |\n",
      "|    total_timesteps  | 921734   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.166    |\n",
      "|    n_updates        | 230408   |\n",
      "----------------------------------\n",
      "Episode reward: 85.019949\n",
      "Episode reward: 78.682937\n",
      "Episode reward: 39.889723\n",
      "Episode reward: 55.145935\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15840    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 335      |\n",
      "|    total_timesteps  | 921996   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.2      |\n",
      "|    n_updates        | 230473   |\n",
      "----------------------------------\n",
      "Episode reward: 49.761086\n",
      "Episode reward: 97.055763\n",
      "Episode reward: 59.786221\n",
      "Episode reward: 95.611591\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.1     |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15844    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 335      |\n",
      "|    total_timesteps  | 922303   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.174    |\n",
      "|    n_updates        | 230550   |\n",
      "----------------------------------\n",
      "Episode reward: 32.923349\n",
      "Episode reward: 100.799306\n",
      "Episode reward: 73.722161\n",
      "Episode reward: 95.579145\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 58.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15848    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 335      |\n",
      "|    total_timesteps  | 922613   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0708   |\n",
      "|    n_updates        | 230628   |\n",
      "----------------------------------\n",
      "Episode reward: 36.813792\n",
      "Episode reward: 43.926712\n",
      "Episode reward: 63.286137\n",
      "Episode reward: 53.905967\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15852    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 335      |\n",
      "|    total_timesteps  | 922812   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.144    |\n",
      "|    n_updates        | 230677   |\n",
      "----------------------------------\n",
      "Episode reward: 35.645566\n",
      "Episode reward: 61.744645\n",
      "Episode reward: 54.777192\n",
      "Episode reward: 51.870796\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15856    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 335      |\n",
      "|    total_timesteps  | 923017   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.612    |\n",
      "|    n_updates        | 230729   |\n",
      "----------------------------------\n",
      "Episode reward: 95.560869\n",
      "Episode reward: 97.44718\n",
      "Episode reward: 91.317214\n",
      "Episode reward: 56.841783\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15860    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 335      |\n",
      "|    total_timesteps  | 923364   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0826   |\n",
      "|    n_updates        | 230815   |\n",
      "----------------------------------\n",
      "Episode reward: 41.614384\n",
      "Episode reward: 66.844359\n",
      "Episode reward: 81.750203\n",
      "Episode reward: 109.406199\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15864    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 335      |\n",
      "|    total_timesteps  | 923665   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.44     |\n",
      "|    n_updates        | 230891   |\n",
      "----------------------------------\n",
      "Episode reward: 45.845464\n",
      "Episode reward: 98.010542\n",
      "Episode reward: 53.776664\n",
      "Episode reward: 75.688825\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15868    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 335      |\n",
      "|    total_timesteps  | 923942   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.54     |\n",
      "|    n_updates        | 230960   |\n",
      "----------------------------------\n",
      "Episode reward: 102.790298\n",
      "Episode reward: 53.910219\n",
      "Episode reward: 71.774418\n",
      "Episode reward: 38.919413\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15872    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 336      |\n",
      "|    total_timesteps  | 924210   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.44     |\n",
      "|    n_updates        | 231027   |\n",
      "----------------------------------\n",
      "Episode reward: 114.617493\n",
      "Episode reward: 66.526567\n",
      "Episode reward: 56.89538\n",
      "Episode reward: 94.730886\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15876    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 336      |\n",
      "|    total_timesteps  | 924554   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.068    |\n",
      "|    n_updates        | 231113   |\n",
      "----------------------------------\n",
      "Episode reward: 44.678818\n",
      "Episode reward: 62.889282\n",
      "Episode reward: 31.844018\n",
      "Episode reward: 48.519174\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15880    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 336      |\n",
      "|    total_timesteps  | 924743   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0727   |\n",
      "|    n_updates        | 231160   |\n",
      "----------------------------------\n",
      "Episode reward: 130.479191\n",
      "Episode reward: 39.861758\n",
      "Episode reward: 37.784288\n",
      "Episode reward: 77.740468\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65       |\n",
      "|    ep_rew_mean      | 64.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15884    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 336      |\n",
      "|    total_timesteps  | 925033   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0746   |\n",
      "|    n_updates        | 231233   |\n",
      "----------------------------------\n",
      "Episode reward: 61.898852\n",
      "Episode reward: 40.827611\n",
      "Episode reward: 39.919738\n",
      "Episode reward: 90.88334\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 63.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15888    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 336      |\n",
      "|    total_timesteps  | 925268   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.133    |\n",
      "|    n_updates        | 231291   |\n",
      "----------------------------------\n",
      "Episode reward: 64.721672\n",
      "Episode reward: 44.748308\n",
      "Episode reward: 81.809527\n",
      "Episode reward: 55.723926\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65       |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15892    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 336      |\n",
      "|    total_timesteps  | 925517   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0611   |\n",
      "|    n_updates        | 231354   |\n",
      "----------------------------------\n",
      "Episode reward: 41.938552\n",
      "Episode reward: 91.573286\n",
      "Episode reward: 72.962944\n",
      "Episode reward: 38.758495\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15896    |\n",
      "|    fps              | 2750     |\n",
      "|    time_elapsed     | 336      |\n",
      "|    total_timesteps  | 925764   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.55     |\n",
      "|    n_updates        | 231415   |\n",
      "----------------------------------\n",
      "Episode reward: 47.872082\n",
      "Episode reward: 50.922723\n",
      "Episode reward: 49.901365\n",
      "Episode reward: 79.87381\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15900    |\n",
      "|    fps              | 2749     |\n",
      "|    time_elapsed     | 336      |\n",
      "|    total_timesteps  | 925993   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.465    |\n",
      "|    n_updates        | 231473   |\n",
      "----------------------------------\n",
      "Episode reward: 55.880015\n",
      "Episode reward: 98.383684\n",
      "Episode reward: 46.921532\n",
      "Episode reward: 35.928801\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15904    |\n",
      "|    fps              | 2749     |\n",
      "|    time_elapsed     | 336      |\n",
      "|    total_timesteps  | 926231   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 231532   |\n",
      "----------------------------------\n",
      "Episode reward: 36.82905\n",
      "Episode reward: 49.911406\n",
      "Episode reward: 100.638671\n",
      "Episode reward: 53.708664\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15908    |\n",
      "|    fps              | 2749     |\n",
      "|    time_elapsed     | 336      |\n",
      "|    total_timesteps  | 926473   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0731   |\n",
      "|    n_updates        | 231593   |\n",
      "----------------------------------\n",
      "Episode reward: 87.841942\n",
      "Episode reward: 55.888674\n",
      "Episode reward: 66.878884\n",
      "Episode reward: 61.491496\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 63.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15912    |\n",
      "|    fps              | 2749     |\n",
      "|    time_elapsed     | 337      |\n",
      "|    total_timesteps  | 926749   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0749   |\n",
      "|    n_updates        | 231662   |\n",
      "----------------------------------\n",
      "Episode reward: 111.113635\n",
      "Episode reward: 91.837394\n",
      "Episode reward: 59.801736\n",
      "Episode reward: 27.881655\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.4     |\n",
      "|    ep_rew_mean      | 64.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15916    |\n",
      "|    fps              | 2749     |\n",
      "|    time_elapsed     | 337      |\n",
      "|    total_timesteps  | 927044   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0752   |\n",
      "|    n_updates        | 231735   |\n",
      "----------------------------------\n",
      "Episode reward: 43.799188\n",
      "Episode reward: 67.863678\n",
      "Episode reward: 89.965186\n",
      "Episode reward: 50.987484\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15920    |\n",
      "|    fps              | 2749     |\n",
      "|    time_elapsed     | 337      |\n",
      "|    total_timesteps  | 927301   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0983   |\n",
      "|    n_updates        | 231800   |\n",
      "----------------------------------\n",
      "Episode reward: 68.00005\n",
      "Episode reward: 40.766377\n",
      "Episode reward: 71.648493\n",
      "Episode reward: 65.676581\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15924    |\n",
      "|    fps              | 2749     |\n",
      "|    time_elapsed     | 337      |\n",
      "|    total_timesteps  | 927549   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0614   |\n",
      "|    n_updates        | 231862   |\n",
      "----------------------------------\n",
      "Episode reward: 39.783381\n",
      "Episode reward: 36.842291\n",
      "Episode reward: 40.949963\n",
      "Episode reward: 74.787081\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.9     |\n",
      "|    ep_rew_mean      | 64.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15928    |\n",
      "|    fps              | 2749     |\n",
      "|    time_elapsed     | 337      |\n",
      "|    total_timesteps  | 927742   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0482   |\n",
      "|    n_updates        | 231910   |\n",
      "----------------------------------\n",
      "Episode reward: 74.026121\n",
      "Episode reward: 42.419888\n",
      "Episode reward: 52.8722\n",
      "Episode reward: 70.343289\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.3     |\n",
      "|    ep_rew_mean      | 64.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15932    |\n",
      "|    fps              | 2749     |\n",
      "|    time_elapsed     | 337      |\n",
      "|    total_timesteps  | 927985   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0631   |\n",
      "|    n_updates        | 231971   |\n",
      "----------------------------------\n",
      "Episode reward: 60.495548\n",
      "Episode reward: 54.906491\n",
      "Episode reward: 53.87175\n",
      "Episode reward: 41.779001\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 63.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15936    |\n",
      "|    fps              | 2749     |\n",
      "|    time_elapsed     | 337      |\n",
      "|    total_timesteps  | 928197   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0483   |\n",
      "|    n_updates        | 232024   |\n",
      "----------------------------------\n",
      "Episode reward: 30.911206\n",
      "Episode reward: 43.906532\n",
      "Episode reward: 92.495601\n",
      "Episode reward: 50.907676\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15940    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 337      |\n",
      "|    total_timesteps  | 928416   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.178    |\n",
      "|    n_updates        | 232078   |\n",
      "----------------------------------\n",
      "Episode reward: 58.139051\n",
      "Episode reward: 58.26697\n",
      "Episode reward: 34.870111\n",
      "Episode reward: 77.613649\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15944    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 337      |\n",
      "|    total_timesteps  | 928647   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.038    |\n",
      "|    n_updates        | 232136   |\n",
      "----------------------------------\n",
      "Episode reward: 54.31412\n",
      "Episode reward: 42.37392\n",
      "Episode reward: 91.826418\n",
      "Episode reward: 106.7827\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15948    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 337      |\n",
      "|    total_timesteps  | 928944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0621   |\n",
      "|    n_updates        | 232210   |\n",
      "----------------------------------\n",
      "Episode reward: 88.642531\n",
      "Episode reward: 101.653917\n",
      "Episode reward: 51.609648\n",
      "Episode reward: 84.595219\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.7     |\n",
      "|    ep_rew_mean      | 64       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15952    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 338      |\n",
      "|    total_timesteps  | 929280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0429   |\n",
      "|    n_updates        | 232294   |\n",
      "----------------------------------\n",
      "Episode reward: 70.613605\n",
      "Episode reward: 103.574726\n",
      "Episode reward: 67.503671\n",
      "Episode reward: 33.663239\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.4     |\n",
      "|    ep_rew_mean      | 64.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15956    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 338      |\n",
      "|    total_timesteps  | 929560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0544   |\n",
      "|    n_updates        | 232364   |\n",
      "----------------------------------\n",
      "Episode reward: 50.687466\n",
      "Episode reward: 73.514901\n",
      "Episode reward: 33.765422\n",
      "Episode reward: 44.916906\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15960    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 338      |\n",
      "|    total_timesteps  | 929764   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.246    |\n",
      "|    n_updates        | 232415   |\n",
      "----------------------------------\n",
      "Episode reward: 50.790219\n",
      "Episode reward: 145.717869\n",
      "Episode reward: 101.312612\n",
      "Episode reward: 52.659391\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.6     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15964    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 338      |\n",
      "|    total_timesteps  | 930122   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.45     |\n",
      "|    n_updates        | 232505   |\n",
      "----------------------------------\n",
      "Episode reward: 50.614533\n",
      "Episode reward: 76.346872\n",
      "Episode reward: 78.684911\n",
      "Episode reward: 32.817196\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15968    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 338      |\n",
      "|    total_timesteps  | 930363   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.13     |\n",
      "|    n_updates        | 232565   |\n",
      "----------------------------------\n",
      "Episode reward: 51.91346\n",
      "Episode reward: 48.930271\n",
      "Episode reward: 60.884935\n",
      "Episode reward: 57.869138\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15972    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 338      |\n",
      "|    total_timesteps  | 930583   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0382   |\n",
      "|    n_updates        | 232620   |\n",
      "----------------------------------\n",
      "Episode reward: 77.562814\n",
      "Episode reward: 100.802962\n",
      "Episode reward: 45.903521\n",
      "Episode reward: 45.886115\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15976    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 338      |\n",
      "|    total_timesteps  | 930854   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.82     |\n",
      "|    n_updates        | 232688   |\n",
      "----------------------------------\n",
      "Episode reward: 85.782588\n",
      "Episode reward: 48.905556\n",
      "Episode reward: 59.864458\n",
      "Episode reward: 71.483147\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15980    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 338      |\n",
      "|    total_timesteps  | 931122   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0635   |\n",
      "|    n_updates        | 232755   |\n",
      "----------------------------------\n",
      "Episode reward: 58.869976\n",
      "Episode reward: 71.809201\n",
      "Episode reward: 40.935542\n",
      "Episode reward: 82.494988\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15984    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 338      |\n",
      "|    total_timesteps  | 931380   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.74     |\n",
      "|    n_updates        | 232819   |\n",
      "----------------------------------\n",
      "Episode reward: 40.902381\n",
      "Episode reward: 40.897712\n",
      "Episode reward: 45.740135\n",
      "Episode reward: 50.875474\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15988    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 338      |\n",
      "|    total_timesteps  | 931559   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.973    |\n",
      "|    n_updates        | 232864   |\n",
      "----------------------------------\n",
      "Episode reward: 60.705689\n",
      "Episode reward: 59.891342\n",
      "Episode reward: 56.589751\n",
      "Episode reward: 95.548216\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15992    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 339      |\n",
      "|    total_timesteps  | 931837   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.07     |\n",
      "|    n_updates        | 232934   |\n",
      "----------------------------------\n",
      "Episode reward: 86.54573\n",
      "Episode reward: 59.710319\n",
      "Episode reward: 60.736046\n",
      "Episode reward: 104.704677\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 15996    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 339      |\n",
      "|    total_timesteps  | 932151   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.138    |\n",
      "|    n_updates        | 233012   |\n",
      "----------------------------------\n",
      "Episode reward: 51.747353\n",
      "Episode reward: 63.882265\n",
      "Episode reward: 56.855594\n",
      "Episode reward: 53.890078\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16000    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 339      |\n",
      "|    total_timesteps  | 932378   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0456   |\n",
      "|    n_updates        | 233069   |\n",
      "----------------------------------\n",
      "Episode reward: 146.228447\n",
      "Episode reward: 71.78866\n",
      "Episode reward: 87.737205\n",
      "Episode reward: 68.541698\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.3     |\n",
      "|    ep_rew_mean      | 64.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16004    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 339      |\n",
      "|    total_timesteps  | 932761   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0782   |\n",
      "|    n_updates        | 233165   |\n",
      "----------------------------------\n",
      "Episode reward: 64.536662\n",
      "Episode reward: 57.887905\n",
      "Episode reward: 63.419767\n",
      "Episode reward: 69.70067\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.5     |\n",
      "|    ep_rew_mean      | 64.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16008    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 339      |\n",
      "|    total_timesteps  | 933020   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0494   |\n",
      "|    n_updates        | 233229   |\n",
      "----------------------------------\n",
      "Episode reward: 43.726931\n",
      "Episode reward: 73.005226\n",
      "Episode reward: 42.586706\n",
      "Episode reward: 39.936107\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.7     |\n",
      "|    ep_rew_mean      | 64       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16012    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 339      |\n",
      "|    total_timesteps  | 933222   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0796   |\n",
      "|    n_updates        | 233280   |\n",
      "----------------------------------\n",
      "Episode reward: 79.46436\n",
      "Episode reward: 28.687672\n",
      "Episode reward: 111.59971\n",
      "Episode reward: 52.619387\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16016    |\n",
      "|    fps              | 2747     |\n",
      "|    time_elapsed     | 339      |\n",
      "|    total_timesteps  | 933497   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0921   |\n",
      "|    n_updates        | 233349   |\n",
      "----------------------------------\n",
      "Episode reward: 35.935449\n",
      "Episode reward: 41.688248\n",
      "Episode reward: 55.763198\n",
      "Episode reward: 89.602671\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16020    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 339      |\n",
      "|    total_timesteps  | 933721   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.61     |\n",
      "|    n_updates        | 233405   |\n",
      "----------------------------------\n",
      "Episode reward: 65.647022\n",
      "Episode reward: 83.763671\n",
      "Episode reward: 30.773537\n",
      "Episode reward: 63.722102\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.2     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16024    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 339      |\n",
      "|    total_timesteps  | 933966   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0937   |\n",
      "|    n_updates        | 233466   |\n",
      "----------------------------------\n",
      "Episode reward: 53.770318\n",
      "Episode reward: 94.425342\n",
      "Episode reward: 97.735708\n",
      "Episode reward: 37.562133\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.1     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16028    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 339      |\n",
      "|    total_timesteps  | 934252   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.48     |\n",
      "|    n_updates        | 233537   |\n",
      "----------------------------------\n",
      "Episode reward: 58.878691\n",
      "Episode reward: 43.904674\n",
      "Episode reward: 133.868768\n",
      "Episode reward: 49.604832\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.6     |\n",
      "|    ep_rew_mean      | 64.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16032    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 340      |\n",
      "|    total_timesteps  | 934547   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 233611   |\n",
      "----------------------------------\n",
      "Episode reward: 85.815753\n",
      "Episode reward: 72.224718\n",
      "Episode reward: 67.871285\n",
      "Episode reward: 36.913959\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.2     |\n",
      "|    ep_rew_mean      | 65.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16036    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 340      |\n",
      "|    total_timesteps  | 934812   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0573   |\n",
      "|    n_updates        | 233677   |\n",
      "----------------------------------\n",
      "Episode reward: 76.222407\n",
      "Episode reward: 48.799891\n",
      "Episode reward: 50.534264\n",
      "Episode reward: 95.854928\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.7     |\n",
      "|    ep_rew_mean      | 65.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16040    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 340      |\n",
      "|    total_timesteps  | 935087   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.16     |\n",
      "|    n_updates        | 233746   |\n",
      "----------------------------------\n",
      "Episode reward: 36.661366\n",
      "Episode reward: 32.822742\n",
      "Episode reward: 41.802591\n",
      "Episode reward: 40.85109\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.9     |\n",
      "|    ep_rew_mean      | 65.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16044    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 340      |\n",
      "|    total_timesteps  | 935240   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0795   |\n",
      "|    n_updates        | 233784   |\n",
      "----------------------------------\n",
      "Episode reward: 52.901475\n",
      "Episode reward: 68.090973\n",
      "Episode reward: 60.941412\n",
      "Episode reward: 78.415204\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.6     |\n",
      "|    ep_rew_mean      | 64.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16048    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 340      |\n",
      "|    total_timesteps  | 935506   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.08     |\n",
      "|    n_updates        | 233851   |\n",
      "----------------------------------\n",
      "Episode reward: 77.412559\n",
      "Episode reward: 38.551944\n",
      "Episode reward: 37.863281\n",
      "Episode reward: 54.890769\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16052    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 340      |\n",
      "|    total_timesteps  | 935717   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.99     |\n",
      "|    n_updates        | 233904   |\n",
      "----------------------------------\n",
      "Episode reward: 86.18852\n",
      "Episode reward: 171.591879\n",
      "Episode reward: 69.766676\n",
      "Episode reward: 99.142061\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.9     |\n",
      "|    ep_rew_mean      | 65.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16056    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 340      |\n",
      "|    total_timesteps  | 936153   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0866   |\n",
      "|    n_updates        | 234013   |\n",
      "----------------------------------\n",
      "Episode reward: 81.679448\n",
      "Episode reward: 35.902763\n",
      "Episode reward: 54.6689\n",
      "Episode reward: 55.866079\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.2     |\n",
      "|    ep_rew_mean      | 65.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16060    |\n",
      "|    fps              | 2747     |\n",
      "|    time_elapsed     | 340      |\n",
      "|    total_timesteps  | 936383   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.092    |\n",
      "|    n_updates        | 234070   |\n",
      "----------------------------------\n",
      "Episode reward: 29.650986\n",
      "Episode reward: 29.921764\n",
      "Episode reward: 35.953441\n",
      "Episode reward: 46.767372\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64       |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16064    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 340      |\n",
      "|    total_timesteps  | 936526   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0427   |\n",
      "|    n_updates        | 234106   |\n",
      "----------------------------------\n",
      "Episode reward: 30.94341\n",
      "Episode reward: 94.212226\n",
      "Episode reward: 55.569669\n",
      "Episode reward: 61.606566\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.1     |\n",
      "|    ep_rew_mean      | 63.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16068    |\n",
      "|    fps              | 2747     |\n",
      "|    time_elapsed     | 340      |\n",
      "|    total_timesteps  | 936771   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0197   |\n",
      "|    n_updates        | 234167   |\n",
      "----------------------------------\n",
      "Episode reward: 60.806164\n",
      "Episode reward: 58.632215\n",
      "Episode reward: 50.90993\n",
      "Episode reward: 82.887573\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 63.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16072    |\n",
      "|    fps              | 2747     |\n",
      "|    time_elapsed     | 341      |\n",
      "|    total_timesteps  | 937034   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0591   |\n",
      "|    n_updates        | 234233   |\n",
      "----------------------------------\n",
      "Episode reward: 55.519543\n",
      "Episode reward: 38.766834\n",
      "Episode reward: 44.744208\n",
      "Episode reward: 56.592253\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16076    |\n",
      "|    fps              | 2748     |\n",
      "|    time_elapsed     | 341      |\n",
      "|    total_timesteps  | 937231   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.04     |\n",
      "|    n_updates        | 234282   |\n",
      "----------------------------------\n",
      "Episode reward: 37.954072\n",
      "Episode reward: 35.955423\n",
      "Episode reward: 34.95098\n",
      "Episode reward: 57.728345\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16080    |\n",
      "|    fps              | 2747     |\n",
      "|    time_elapsed     | 341      |\n",
      "|    total_timesteps  | 937398   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.18     |\n",
      "|    n_updates        | 234324   |\n",
      "----------------------------------\n",
      "Episode reward: 65.595173\n",
      "Episode reward: 52.868461\n",
      "Episode reward: 63.84154\n",
      "Episode reward: 45.929482\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16084    |\n",
      "|    fps              | 2747     |\n",
      "|    time_elapsed     | 341      |\n",
      "|    total_timesteps  | 937627   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.939    |\n",
      "|    n_updates        | 234381   |\n",
      "----------------------------------\n",
      "Episode reward: 92.700476\n",
      "Episode reward: 81.671934\n",
      "Episode reward: 41.772927\n",
      "Episode reward: 33.942184\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16088    |\n",
      "|    fps              | 2747     |\n",
      "|    time_elapsed     | 341      |\n",
      "|    total_timesteps  | 937884   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.198    |\n",
      "|    n_updates        | 234445   |\n",
      "----------------------------------\n",
      "Episode reward: 87.954504\n",
      "Episode reward: 95.474791\n",
      "Episode reward: 68.860975\n",
      "Episode reward: 55.892207\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16092    |\n",
      "|    fps              | 2747     |\n",
      "|    time_elapsed     | 341      |\n",
      "|    total_timesteps  | 938197   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0455   |\n",
      "|    n_updates        | 234524   |\n",
      "----------------------------------\n",
      "Episode reward: 46.896439\n",
      "Episode reward: 38.870604\n",
      "Episode reward: 54.867796\n",
      "Episode reward: 44.891813\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16096    |\n",
      "|    fps              | 2747     |\n",
      "|    time_elapsed     | 341      |\n",
      "|    total_timesteps  | 938383   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.163    |\n",
      "|    n_updates        | 234570   |\n",
      "----------------------------------\n",
      "Episode reward: 45.833394\n",
      "Episode reward: 41.940107\n",
      "Episode reward: 55.691643\n",
      "Episode reward: 25.850059\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16100    |\n",
      "|    fps              | 2747     |\n",
      "|    time_elapsed     | 341      |\n",
      "|    total_timesteps  | 938553   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.37     |\n",
      "|    n_updates        | 234613   |\n",
      "----------------------------------\n",
      "Episode reward: 44.925116\n",
      "Episode reward: 44.833018\n",
      "Episode reward: 85.334289\n",
      "Episode reward: 54.347802\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16104    |\n",
      "|    fps              | 2747     |\n",
      "|    time_elapsed     | 341      |\n",
      "|    total_timesteps  | 938785   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0728   |\n",
      "|    n_updates        | 234671   |\n",
      "----------------------------------\n",
      "Episode reward: 41.616223\n",
      "Episode reward: 36.895367\n",
      "Episode reward: 58.76454\n",
      "Episode reward: 196.256578\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16108    |\n",
      "|    fps              | 2747     |\n",
      "|    time_elapsed     | 341      |\n",
      "|    total_timesteps  | 939124   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0449   |\n",
      "|    n_updates        | 234755   |\n",
      "----------------------------------\n",
      "Episode reward: 110.404748\n",
      "Episode reward: 86.816683\n",
      "Episode reward: 33.470962\n",
      "Episode reward: 42.796798\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16112    |\n",
      "|    fps              | 2747     |\n",
      "|    time_elapsed     | 341      |\n",
      "|    total_timesteps  | 939400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.54     |\n",
      "|    n_updates        | 234824   |\n",
      "----------------------------------\n",
      "Episode reward: 38.946626\n",
      "Episode reward: 58.6975\n",
      "Episode reward: 34.902097\n",
      "Episode reward: 51.893806\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16116    |\n",
      "|    fps              | 2747     |\n",
      "|    time_elapsed     | 342      |\n",
      "|    total_timesteps  | 939585   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.145    |\n",
      "|    n_updates        | 234871   |\n",
      "----------------------------------\n",
      "Episode reward: 38.842184\n",
      "Episode reward: 99.350752\n",
      "Episode reward: 32.922603\n",
      "Episode reward: 96.128138\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16120    |\n",
      "|    fps              | 2747     |\n",
      "|    time_elapsed     | 342      |\n",
      "|    total_timesteps  | 939856   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0433   |\n",
      "|    n_updates        | 234938   |\n",
      "----------------------------------\n",
      "Episode reward: 53.777013\n",
      "Episode reward: 41.724815\n",
      "Episode reward: 31.918872\n",
      "Episode reward: 46.433838\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16124    |\n",
      "|    fps              | 2746     |\n",
      "|    time_elapsed     | 342      |\n",
      "|    total_timesteps  | 940031   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.156    |\n",
      "|    n_updates        | 234982   |\n",
      "----------------------------------\n",
      "Episode reward: 68.2354\n",
      "Episode reward: 54.745719\n",
      "Episode reward: 63.416705\n",
      "Episode reward: 41.939965\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16128    |\n",
      "|    fps              | 2746     |\n",
      "|    time_elapsed     | 342      |\n",
      "|    total_timesteps  | 940262   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.46     |\n",
      "|    n_updates        | 235040   |\n",
      "----------------------------------\n",
      "Episode reward: 79.478914\n",
      "Episode reward: 49.427025\n",
      "Episode reward: 87.764726\n",
      "Episode reward: 66.183266\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16132    |\n",
      "|    fps              | 2746     |\n",
      "|    time_elapsed     | 342      |\n",
      "|    total_timesteps  | 940548   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.121    |\n",
      "|    n_updates        | 235111   |\n",
      "----------------------------------\n",
      "Episode reward: 93.701616\n",
      "Episode reward: 37.943138\n",
      "Episode reward: 84.820555\n",
      "Episode reward: 57.829909\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16136    |\n",
      "|    fps              | 2746     |\n",
      "|    time_elapsed     | 342      |\n",
      "|    total_timesteps  | 940823   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.48     |\n",
      "|    n_updates        | 235180   |\n",
      "----------------------------------\n",
      "Episode reward: 63.947586\n",
      "Episode reward: 58.827937\n",
      "Episode reward: 109.334381\n",
      "Episode reward: 36.60797\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16140    |\n",
      "|    fps              | 2746     |\n",
      "|    time_elapsed     | 342      |\n",
      "|    total_timesteps  | 941097   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.318    |\n",
      "|    n_updates        | 235249   |\n",
      "----------------------------------\n",
      "Episode reward: 37.953983\n",
      "Episode reward: 74.865548\n",
      "Episode reward: 89.904506\n",
      "Episode reward: 38.936976\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16144    |\n",
      "|    fps              | 2746     |\n",
      "|    time_elapsed     | 342      |\n",
      "|    total_timesteps  | 941341   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.1      |\n",
      "|    n_updates        | 235310   |\n",
      "----------------------------------\n",
      "Episode reward: 78.995783\n",
      "Episode reward: 64.792031\n",
      "Episode reward: 58.734267\n",
      "Episode reward: 95.325494\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16148    |\n",
      "|    fps              | 2745     |\n",
      "|    time_elapsed     | 342      |\n",
      "|    total_timesteps  | 941642   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.203    |\n",
      "|    n_updates        | 235385   |\n",
      "----------------------------------\n",
      "Episode reward: 39.790879\n",
      "Episode reward: 43.620309\n",
      "Episode reward: 82.087477\n",
      "Episode reward: 79.887306\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16152    |\n",
      "|    fps              | 2745     |\n",
      "|    time_elapsed     | 343      |\n",
      "|    total_timesteps  | 941890   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.16     |\n",
      "|    n_updates        | 235447   |\n",
      "----------------------------------\n",
      "Episode reward: 50.905056\n",
      "Episode reward: 93.111652\n",
      "Episode reward: 108.75991\n",
      "Episode reward: 30.893984\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16156    |\n",
      "|    fps              | 2745     |\n",
      "|    time_elapsed     | 343      |\n",
      "|    total_timesteps  | 942182   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.73     |\n",
      "|    n_updates        | 235520   |\n",
      "----------------------------------\n",
      "Episode reward: 31.951704\n",
      "Episode reward: 34.615274\n",
      "Episode reward: 43.910812\n",
      "Episode reward: 72.4711\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16160    |\n",
      "|    fps              | 2745     |\n",
      "|    time_elapsed     | 343      |\n",
      "|    total_timesteps  | 942368   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0495   |\n",
      "|    n_updates        | 235566   |\n",
      "----------------------------------\n",
      "Episode reward: 38.678032\n",
      "Episode reward: 60.831991\n",
      "Episode reward: 35.660427\n",
      "Episode reward: 47.777377\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16164    |\n",
      "|    fps              | 2745     |\n",
      "|    time_elapsed     | 343      |\n",
      "|    total_timesteps  | 942552   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.133    |\n",
      "|    n_updates        | 235612   |\n",
      "----------------------------------\n",
      "Episode reward: 65.881957\n",
      "Episode reward: 44.70492\n",
      "Episode reward: 61.975365\n",
      "Episode reward: 71.280133\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16168    |\n",
      "|    fps              | 2745     |\n",
      "|    time_elapsed     | 343      |\n",
      "|    total_timesteps  | 942798   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.516    |\n",
      "|    n_updates        | 235674   |\n",
      "----------------------------------\n",
      "Episode reward: 38.944151\n",
      "Episode reward: 112.952112\n",
      "Episode reward: 59.826431\n",
      "Episode reward: 42.41782\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16172    |\n",
      "|    fps              | 2745     |\n",
      "|    time_elapsed     | 343      |\n",
      "|    total_timesteps  | 943056   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.41     |\n",
      "|    n_updates        | 235738   |\n",
      "----------------------------------\n",
      "Episode reward: 83.746973\n",
      "Episode reward: 34.954619\n",
      "Episode reward: 49.929476\n",
      "Episode reward: 44.687092\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16176    |\n",
      "|    fps              | 2745     |\n",
      "|    time_elapsed     | 343      |\n",
      "|    total_timesteps  | 943270   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0741   |\n",
      "|    n_updates        | 235792   |\n",
      "----------------------------------\n",
      "Episode reward: 61.885012\n",
      "Episode reward: 34.873713\n",
      "Episode reward: 35.80377\n",
      "Episode reward: 69.872747\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16180    |\n",
      "|    fps              | 2745     |\n",
      "|    time_elapsed     | 343      |\n",
      "|    total_timesteps  | 943474   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 235843   |\n",
      "----------------------------------\n",
      "Episode reward: 80.533129\n",
      "Episode reward: 48.785419\n",
      "Episode reward: 60.739796\n",
      "Episode reward: 27.868033\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16184    |\n",
      "|    fps              | 2745     |\n",
      "|    time_elapsed     | 343      |\n",
      "|    total_timesteps  | 943693   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.61     |\n",
      "|    n_updates        | 235898   |\n",
      "----------------------------------\n",
      "Episode reward: 82.687211\n",
      "Episode reward: 67.655745\n",
      "Episode reward: 52.890526\n",
      "Episode reward: 63.749268\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16188    |\n",
      "|    fps              | 2745     |\n",
      "|    time_elapsed     | 343      |\n",
      "|    total_timesteps  | 943961   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0503   |\n",
      "|    n_updates        | 235965   |\n",
      "----------------------------------\n",
      "Episode reward: 51.450762\n",
      "Episode reward: 76.147532\n",
      "Episode reward: 59.824318\n",
      "Episode reward: 45.922965\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16192    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 343      |\n",
      "|    total_timesteps  | 944196   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.389    |\n",
      "|    n_updates        | 236023   |\n",
      "----------------------------------\n",
      "Episode reward: 118.981799\n",
      "Episode reward: 52.487861\n",
      "Episode reward: 34.910274\n",
      "Episode reward: 30.933464\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16196    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 344      |\n",
      "|    total_timesteps  | 944436   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0904   |\n",
      "|    n_updates        | 236083   |\n",
      "----------------------------------\n",
      "Episode reward: 65.825867\n",
      "Episode reward: 59.114905\n",
      "Episode reward: 29.860859\n",
      "Episode reward: 49.906924\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16200    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 344      |\n",
      "|    total_timesteps  | 944643   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.01     |\n",
      "|    n_updates        | 236135   |\n",
      "----------------------------------\n",
      "Episode reward: 71.852618\n",
      "Episode reward: 58.852744\n",
      "Episode reward: 35.953394\n",
      "Episode reward: 34.721341\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16204    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 344      |\n",
      "|    total_timesteps  | 944846   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.16     |\n",
      "|    n_updates        | 236186   |\n",
      "----------------------------------\n",
      "Episode reward: 57.416569\n",
      "Episode reward: 71.57981\n",
      "Episode reward: 56.632\n",
      "Episode reward: 66.119847\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16208    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 344      |\n",
      "|    total_timesteps  | 945101   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.224    |\n",
      "|    n_updates        | 236250   |\n",
      "----------------------------------\n",
      "Episode reward: 45.786766\n",
      "Episode reward: 79.705371\n",
      "Episode reward: 45.940418\n",
      "Episode reward: 132.712592\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16212    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 344      |\n",
      "|    total_timesteps  | 945407   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.03     |\n",
      "|    n_updates        | 236326   |\n",
      "----------------------------------\n",
      "Episode reward: 52.891668\n",
      "Episode reward: 38.903928\n",
      "Episode reward: 43.86519\n",
      "Episode reward: 40.925556\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16216    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 344      |\n",
      "|    total_timesteps  | 945584   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.147    |\n",
      "|    n_updates        | 236370   |\n",
      "----------------------------------\n",
      "Episode reward: 50.279955\n",
      "Episode reward: 54.927811\n",
      "Episode reward: 40.941367\n",
      "Episode reward: 25.929008\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16220    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 344      |\n",
      "|    total_timesteps  | 945757   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.161    |\n",
      "|    n_updates        | 236414   |\n",
      "----------------------------------\n",
      "Episode reward: 43.552798\n",
      "Episode reward: 66.151783\n",
      "Episode reward: 30.915587\n",
      "Episode reward: 50.604542\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16224    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 344      |\n",
      "|    total_timesteps  | 945951   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.39     |\n",
      "|    n_updates        | 236462   |\n",
      "----------------------------------\n",
      "Episode reward: 74.759552\n",
      "Episode reward: 95.104585\n",
      "Episode reward: 45.782502\n",
      "Episode reward: 36.954524\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16228    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 344      |\n",
      "|    total_timesteps  | 946205   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0629   |\n",
      "|    n_updates        | 236526   |\n",
      "----------------------------------\n",
      "Episode reward: 67.922176\n",
      "Episode reward: 44.640085\n",
      "Episode reward: 70.815405\n",
      "Episode reward: 88.004084\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.3     |\n",
      "|    ep_rew_mean      | 58.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16232    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 344      |\n",
      "|    total_timesteps  | 946481   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.55     |\n",
      "|    n_updates        | 236595   |\n",
      "----------------------------------\n",
      "Episode reward: 32.893218\n",
      "Episode reward: 28.675944\n",
      "Episode reward: 93.32259\n",
      "Episode reward: 34.933634\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.5     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16236    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 344      |\n",
      "|    total_timesteps  | 946673   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.95     |\n",
      "|    n_updates        | 236643   |\n",
      "----------------------------------\n",
      "Episode reward: 42.669857\n",
      "Episode reward: 78.80209\n",
      "Episode reward: 47.849305\n",
      "Episode reward: 39.923784\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16240    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 344      |\n",
      "|    total_timesteps  | 946883   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.4      |\n",
      "|    n_updates        | 236695   |\n",
      "----------------------------------\n",
      "Episode reward: 32.944091\n",
      "Episode reward: 60.435174\n",
      "Episode reward: 59.862905\n",
      "Episode reward: 52.688061\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.5     |\n",
      "|    ep_rew_mean      | 56.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16244    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 345      |\n",
      "|    total_timesteps  | 947090   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0799   |\n",
      "|    n_updates        | 236747   |\n",
      "----------------------------------\n",
      "Episode reward: 49.890705\n",
      "Episode reward: 36.89912\n",
      "Episode reward: 84.687462\n",
      "Episode reward: 30.944331\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.5     |\n",
      "|    ep_rew_mean      | 56       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16248    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 345      |\n",
      "|    total_timesteps  | 947293   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0595   |\n",
      "|    n_updates        | 236798   |\n",
      "----------------------------------\n",
      "Episode reward: 97.440085\n",
      "Episode reward: 33.913571\n",
      "Episode reward: 36.896875\n",
      "Episode reward: 54.504544\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.3     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16252    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 345      |\n",
      "|    total_timesteps  | 947517   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.68     |\n",
      "|    n_updates        | 236854   |\n",
      "----------------------------------\n",
      "Episode reward: 38.951089\n",
      "Episode reward: 79.794972\n",
      "Episode reward: 84.243867\n",
      "Episode reward: 76.012624\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.2     |\n",
      "|    ep_rew_mean      | 55.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16256    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 345      |\n",
      "|    total_timesteps  | 947801   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.124    |\n",
      "|    n_updates        | 236925   |\n",
      "----------------------------------\n",
      "Episode reward: 57.733987\n",
      "Episode reward: 58.637547\n",
      "Episode reward: 80.367382\n",
      "Episode reward: 53.819651\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 56.9     |\n",
      "|    ep_rew_mean      | 56.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16260    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 345      |\n",
      "|    total_timesteps  | 948055   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.077    |\n",
      "|    n_updates        | 236988   |\n",
      "----------------------------------\n",
      "Episode reward: 39.914039\n",
      "Episode reward: 42.55271\n",
      "Episode reward: 93.66928\n",
      "Episode reward: 75.761896\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.6     |\n",
      "|    ep_rew_mean      | 57.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16264    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 345      |\n",
      "|    total_timesteps  | 948311   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0984   |\n",
      "|    n_updates        | 237052   |\n",
      "----------------------------------\n",
      "Episode reward: 50.905828\n",
      "Episode reward: 83.058471\n",
      "Episode reward: 49.624003\n",
      "Episode reward: 92.601831\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16268    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 345      |\n",
      "|    total_timesteps  | 948590   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.166    |\n",
      "|    n_updates        | 237122   |\n",
      "----------------------------------\n",
      "Episode reward: 70.807251\n",
      "Episode reward: 118.753536\n",
      "Episode reward: 56.133973\n",
      "Episode reward: 36.86379\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.2     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16272    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 345      |\n",
      "|    total_timesteps  | 948875   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.5      |\n",
      "|    n_updates        | 237193   |\n",
      "----------------------------------\n",
      "Episode reward: 61.766486\n",
      "Episode reward: 29.966603\n",
      "Episode reward: 47.831945\n",
      "Episode reward: 39.845514\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 57.9     |\n",
      "|    ep_rew_mean      | 57.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16276    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 345      |\n",
      "|    total_timesteps  | 949055   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0617   |\n",
      "|    n_updates        | 237238   |\n",
      "----------------------------------\n",
      "Episode reward: 78.517089\n",
      "Episode reward: 101.610071\n",
      "Episode reward: 77.944313\n",
      "Episode reward: 43.567356\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16280    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 345      |\n",
      "|    total_timesteps  | 949362   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.83     |\n",
      "|    n_updates        | 237315   |\n",
      "----------------------------------\n",
      "Episode reward: 45.341659\n",
      "Episode reward: 59.814329\n",
      "Episode reward: 60.878847\n",
      "Episode reward: 64.841919\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16284    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 346      |\n",
      "|    total_timesteps  | 949595   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 237373   |\n",
      "----------------------------------\n",
      "Episode reward: 65.611753\n",
      "Episode reward: 49.597496\n",
      "Episode reward: 38.948464\n",
      "Episode reward: 74.663897\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16288    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 346      |\n",
      "|    total_timesteps  | 949827   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.36     |\n",
      "|    n_updates        | 237431   |\n",
      "----------------------------------\n",
      "Episode reward: 98.629677\n",
      "Episode reward: 35.771265\n",
      "Episode reward: 46.880454\n",
      "Episode reward: 74.591053\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.9     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16292    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 346      |\n",
      "|    total_timesteps  | 950084   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.347    |\n",
      "|    n_updates        | 237495   |\n",
      "----------------------------------\n",
      "Episode reward: 48.644592\n",
      "Episode reward: 32.96027\n",
      "Episode reward: 40.721558\n",
      "Episode reward: 54.864546\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.3     |\n",
      "|    ep_rew_mean      | 57.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16296    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 346      |\n",
      "|    total_timesteps  | 950262   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.147    |\n",
      "|    n_updates        | 237540   |\n",
      "----------------------------------\n",
      "Episode reward: 66.840392\n",
      "Episode reward: 38.943072\n",
      "Episode reward: 40.924513\n",
      "Episode reward: 77.490731\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16300    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 346      |\n",
      "|    total_timesteps  | 950487   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.51     |\n",
      "|    n_updates        | 237596   |\n",
      "----------------------------------\n",
      "Episode reward: 53.640902\n",
      "Episode reward: 53.861946\n",
      "Episode reward: 90.757006\n",
      "Episode reward: 59.030351\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59       |\n",
      "|    ep_rew_mean      | 58.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16304    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 346      |\n",
      "|    total_timesteps  | 950746   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.116    |\n",
      "|    n_updates        | 237661   |\n",
      "----------------------------------\n",
      "Episode reward: 50.279518\n",
      "Episode reward: 87.774091\n",
      "Episode reward: 65.826634\n",
      "Episode reward: 67.117671\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.2     |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16308    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 346      |\n",
      "|    total_timesteps  | 951020   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0569   |\n",
      "|    n_updates        | 237729   |\n",
      "----------------------------------\n",
      "Episode reward: 92.410657\n",
      "Episode reward: 67.476786\n",
      "Episode reward: 32.883531\n",
      "Episode reward: 32.934859\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.4     |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16312    |\n",
      "|    fps              | 2744     |\n",
      "|    time_elapsed     | 346      |\n",
      "|    total_timesteps  | 951247   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0423   |\n",
      "|    n_updates        | 237786   |\n",
      "----------------------------------\n",
      "Episode reward: 55.875312\n",
      "Episode reward: 58.456859\n",
      "Episode reward: 83.208205\n",
      "Episode reward: 72.84291\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.4     |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16316    |\n",
      "|    fps              | 2743     |\n",
      "|    time_elapsed     | 346      |\n",
      "|    total_timesteps  | 951520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0653   |\n",
      "|    n_updates        | 237854   |\n",
      "----------------------------------\n",
      "Episode reward: 103.275112\n",
      "Episode reward: 141.239861\n",
      "Episode reward: 127.760204\n",
      "Episode reward: 31.903702\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.8     |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16320    |\n",
      "|    fps              | 2743     |\n",
      "|    time_elapsed     | 346      |\n",
      "|    total_timesteps  | 951937   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0667   |\n",
      "|    n_updates        | 237959   |\n",
      "----------------------------------\n",
      "Episode reward: 89.076834\n",
      "Episode reward: 49.855168\n",
      "Episode reward: 81.517897\n",
      "Episode reward: 40.511545\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16324    |\n",
      "|    fps              | 2743     |\n",
      "|    time_elapsed     | 347      |\n",
      "|    total_timesteps  | 952200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0885   |\n",
      "|    n_updates        | 238024   |\n",
      "----------------------------------\n",
      "Episode reward: 63.503802\n",
      "Episode reward: 68.064631\n",
      "Episode reward: 32.685892\n",
      "Episode reward: 76.83831\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16328    |\n",
      "|    fps              | 2743     |\n",
      "|    time_elapsed     | 347      |\n",
      "|    total_timesteps  | 952444   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 238085   |\n",
      "----------------------------------\n",
      "Episode reward: 142.597343\n",
      "Episode reward: 36.816547\n",
      "Episode reward: 56.846772\n",
      "Episode reward: 58.734636\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16332    |\n",
      "|    fps              | 2743     |\n",
      "|    time_elapsed     | 347      |\n",
      "|    total_timesteps  | 952764   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0673   |\n",
      "|    n_updates        | 238165   |\n",
      "----------------------------------\n",
      "Episode reward: 92.632426\n",
      "Episode reward: 41.93591\n",
      "Episode reward: 74.735018\n",
      "Episode reward: 92.543282\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16336    |\n",
      "|    fps              | 2743     |\n",
      "|    time_elapsed     | 347      |\n",
      "|    total_timesteps  | 953067   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.708    |\n",
      "|    n_updates        | 238241   |\n",
      "----------------------------------\n",
      "Episode reward: 60.727023\n",
      "Episode reward: 32.665049\n",
      "Episode reward: 67.843342\n",
      "Episode reward: 36.926206\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 62.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16340    |\n",
      "|    fps              | 2743     |\n",
      "|    time_elapsed     | 347      |\n",
      "|    total_timesteps  | 953266   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0642   |\n",
      "|    n_updates        | 238291   |\n",
      "----------------------------------\n",
      "Episode reward: 50.748967\n",
      "Episode reward: 94.203381\n",
      "Episode reward: 85.771502\n",
      "Episode reward: 35.879014\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16344    |\n",
      "|    fps              | 2743     |\n",
      "|    time_elapsed     | 347      |\n",
      "|    total_timesteps  | 953534   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.104    |\n",
      "|    n_updates        | 238358   |\n",
      "----------------------------------\n",
      "Episode reward: 105.916409\n",
      "Episode reward: 58.860961\n",
      "Episode reward: 93.923142\n",
      "Episode reward: 57.252764\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.6     |\n",
      "|    ep_rew_mean      | 64.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16348    |\n",
      "|    fps              | 2743     |\n",
      "|    time_elapsed     | 347      |\n",
      "|    total_timesteps  | 953854   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.246    |\n",
      "|    n_updates        | 238438   |\n",
      "----------------------------------\n",
      "Episode reward: 53.879537\n",
      "Episode reward: 61.796043\n",
      "Episode reward: 85.860485\n",
      "Episode reward: 61.813718\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66       |\n",
      "|    ep_rew_mean      | 65.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16352    |\n",
      "|    fps              | 2742     |\n",
      "|    time_elapsed     | 347      |\n",
      "|    total_timesteps  | 954121   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.408    |\n",
      "|    n_updates        | 238505   |\n",
      "----------------------------------\n",
      "Episode reward: 28.94832\n",
      "Episode reward: 53.205485\n",
      "Episode reward: 122.568807\n",
      "Episode reward: 66.236957\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66       |\n",
      "|    ep_rew_mean      | 65       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16356    |\n",
      "|    fps              | 2742     |\n",
      "|    time_elapsed     | 347      |\n",
      "|    total_timesteps  | 954396   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0905   |\n",
      "|    n_updates        | 238573   |\n",
      "----------------------------------\n",
      "Episode reward: 35.803698\n",
      "Episode reward: 103.208144\n",
      "Episode reward: 69.940548\n",
      "Episode reward: 45.864445\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66       |\n",
      "|    ep_rew_mean      | 65.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16360    |\n",
      "|    fps              | 2742     |\n",
      "|    time_elapsed     | 348      |\n",
      "|    total_timesteps  | 954654   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0501   |\n",
      "|    n_updates        | 238638   |\n",
      "----------------------------------\n",
      "Episode reward: 32.81862\n",
      "Episode reward: 84.366397\n",
      "Episode reward: 58.905068\n",
      "Episode reward: 68.233415\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.9     |\n",
      "|    ep_rew_mean      | 65       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16364    |\n",
      "|    fps              | 2742     |\n",
      "|    time_elapsed     | 348      |\n",
      "|    total_timesteps  | 954901   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.177    |\n",
      "|    n_updates        | 238700   |\n",
      "----------------------------------\n",
      "Episode reward: 68.583864\n",
      "Episode reward: 44.822372\n",
      "Episode reward: 59.897186\n",
      "Episode reward: 96.110588\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.8     |\n",
      "|    ep_rew_mean      | 64.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16368    |\n",
      "|    fps              | 2742     |\n",
      "|    time_elapsed     | 348      |\n",
      "|    total_timesteps  | 955173   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.176    |\n",
      "|    n_updates        | 238768   |\n",
      "----------------------------------\n",
      "Episode reward: 57.830818\n",
      "Episode reward: 47.838558\n",
      "Episode reward: 85.486491\n",
      "Episode reward: 77.472508\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.7     |\n",
      "|    ep_rew_mean      | 64.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16372    |\n",
      "|    fps              | 2742     |\n",
      "|    time_elapsed     | 348      |\n",
      "|    total_timesteps  | 955444   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0918   |\n",
      "|    n_updates        | 238835   |\n",
      "----------------------------------\n",
      "Episode reward: 65.673248\n",
      "Episode reward: 51.768932\n",
      "Episode reward: 53.876508\n",
      "Episode reward: 49.922118\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.1     |\n",
      "|    ep_rew_mean      | 65.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16376    |\n",
      "|    fps              | 2741     |\n",
      "|    time_elapsed     | 348      |\n",
      "|    total_timesteps  | 955667   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 238891   |\n",
      "----------------------------------\n",
      "Episode reward: 55.896486\n",
      "Episode reward: 83.739745\n",
      "Episode reward: 56.35981\n",
      "Episode reward: 43.827459\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.5     |\n",
      "|    ep_rew_mean      | 64.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16380    |\n",
      "|    fps              | 2741     |\n",
      "|    time_elapsed     | 348      |\n",
      "|    total_timesteps  | 955908   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0813   |\n",
      "|    n_updates        | 238951   |\n",
      "----------------------------------\n",
      "Episode reward: 85.124192\n",
      "Episode reward: 43.940486\n",
      "Episode reward: 74.614791\n",
      "Episode reward: 64.637585\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.8     |\n",
      "|    ep_rew_mean      | 65       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16384    |\n",
      "|    fps              | 2741     |\n",
      "|    time_elapsed     | 348      |\n",
      "|    total_timesteps  | 956178   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.089    |\n",
      "|    n_updates        | 239019   |\n",
      "----------------------------------\n",
      "Episode reward: 135.19203\n",
      "Episode reward: 37.769023\n",
      "Episode reward: 52.890407\n",
      "Episode reward: 39.771157\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.2     |\n",
      "|    ep_rew_mean      | 65.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16388    |\n",
      "|    fps              | 2741     |\n",
      "|    time_elapsed     | 348      |\n",
      "|    total_timesteps  | 956449   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0679   |\n",
      "|    n_updates        | 239087   |\n",
      "----------------------------------\n",
      "Episode reward: 72.297363\n",
      "Episode reward: 80.739523\n",
      "Episode reward: 109.660417\n",
      "Episode reward: 96.303277\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.3     |\n",
      "|    ep_rew_mean      | 66.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16392    |\n",
      "|    fps              | 2741     |\n",
      "|    time_elapsed     | 348      |\n",
      "|    total_timesteps  | 956811   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0625   |\n",
      "|    n_updates        | 239177   |\n",
      "----------------------------------\n",
      "Episode reward: 56.724695\n",
      "Episode reward: 36.508072\n",
      "Episode reward: 61.649627\n",
      "Episode reward: 58.785376\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.6     |\n",
      "|    ep_rew_mean      | 66.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16396    |\n",
      "|    fps              | 2741     |\n",
      "|    time_elapsed     | 349      |\n",
      "|    total_timesteps  | 957026   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0394   |\n",
      "|    n_updates        | 239231   |\n",
      "----------------------------------\n",
      "Episode reward: 58.523941\n",
      "Episode reward: 33.918627\n",
      "Episode reward: 52.893991\n",
      "Episode reward: 48.899955\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.3     |\n",
      "|    ep_rew_mean      | 66.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16400    |\n",
      "|    fps              | 2741     |\n",
      "|    time_elapsed     | 349      |\n",
      "|    total_timesteps  | 957221   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.06     |\n",
      "|    n_updates        | 239280   |\n",
      "----------------------------------\n",
      "Episode reward: 35.894399\n",
      "Episode reward: 37.861974\n",
      "Episode reward: 53.877176\n",
      "Episode reward: 45.457209\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.5     |\n",
      "|    ep_rew_mean      | 65.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16404    |\n",
      "|    fps              | 2741     |\n",
      "|    time_elapsed     | 349      |\n",
      "|    total_timesteps  | 957395   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.108    |\n",
      "|    n_updates        | 239323   |\n",
      "----------------------------------\n",
      "Episode reward: 58.787539\n",
      "Episode reward: 70.816174\n",
      "Episode reward: 74.398304\n",
      "Episode reward: 53.841627\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.3     |\n",
      "|    ep_rew_mean      | 65.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16408    |\n",
      "|    fps              | 2741     |\n",
      "|    time_elapsed     | 349      |\n",
      "|    total_timesteps  | 957654   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.172    |\n",
      "|    n_updates        | 239388   |\n",
      "----------------------------------\n",
      "Episode reward: 75.788609\n",
      "Episode reward: 60.765097\n",
      "Episode reward: 48.900418\n",
      "Episode reward: 78.659062\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.7     |\n",
      "|    ep_rew_mean      | 65.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16412    |\n",
      "|    fps              | 2741     |\n",
      "|    time_elapsed     | 349      |\n",
      "|    total_timesteps  | 957919   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0599   |\n",
      "|    n_updates        | 239454   |\n",
      "----------------------------------\n",
      "Episode reward: 28.860143\n",
      "Episode reward: 95.305212\n",
      "Episode reward: 55.465085\n",
      "Episode reward: 57.889128\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.4     |\n",
      "|    ep_rew_mean      | 65.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16416    |\n",
      "|    fps              | 2741     |\n",
      "|    time_elapsed     | 349      |\n",
      "|    total_timesteps  | 958158   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.665    |\n",
      "|    n_updates        | 239514   |\n",
      "----------------------------------\n",
      "Episode reward: 66.856307\n",
      "Episode reward: 51.627982\n",
      "Episode reward: 31.942891\n",
      "Episode reward: 67.494978\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 63.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16420    |\n",
      "|    fps              | 2740     |\n",
      "|    time_elapsed     | 349      |\n",
      "|    total_timesteps  | 958377   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0736   |\n",
      "|    n_updates        | 239569   |\n",
      "----------------------------------\n",
      "Episode reward: 36.867929\n",
      "Episode reward: 89.389472\n",
      "Episode reward: 33.824048\n",
      "Episode reward: 51.782578\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16424    |\n",
      "|    fps              | 2740     |\n",
      "|    time_elapsed     | 349      |\n",
      "|    total_timesteps  | 958590   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0889   |\n",
      "|    n_updates        | 239622   |\n",
      "----------------------------------\n",
      "Episode reward: 49.786118\n",
      "Episode reward: 51.492274\n",
      "Episode reward: 54.89026\n",
      "Episode reward: 54.845918\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.6     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16428    |\n",
      "|    fps              | 2740     |\n",
      "|    time_elapsed     | 349      |\n",
      "|    total_timesteps  | 958802   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.915    |\n",
      "|    n_updates        | 239675   |\n",
      "----------------------------------\n",
      "Episode reward: 74.312195\n",
      "Episode reward: 40.937541\n",
      "Episode reward: 84.501926\n",
      "Episode reward: 59.72691\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16432    |\n",
      "|    fps              | 2740     |\n",
      "|    time_elapsed     | 349      |\n",
      "|    total_timesteps  | 959065   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0536   |\n",
      "|    n_updates        | 239741   |\n",
      "----------------------------------\n",
      "Episode reward: 102.736432\n",
      "Episode reward: 62.797588\n",
      "Episode reward: 44.746279\n",
      "Episode reward: 79.671237\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16436    |\n",
      "|    fps              | 2740     |\n",
      "|    time_elapsed     | 350      |\n",
      "|    total_timesteps  | 959356   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.332    |\n",
      "|    n_updates        | 239813   |\n",
      "----------------------------------\n",
      "Episode reward: 57.721367\n",
      "Episode reward: 82.661281\n",
      "Episode reward: 51.88344\n",
      "Episode reward: 46.835585\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16440    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 350      |\n",
      "|    total_timesteps  | 959596   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.93     |\n",
      "|    n_updates        | 239873   |\n",
      "----------------------------------\n",
      "Episode reward: 56.564979\n",
      "Episode reward: 72.514018\n",
      "Episode reward: 36.937181\n",
      "Episode reward: 48.685405\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16444    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 350      |\n",
      "|    total_timesteps  | 959813   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.339    |\n",
      "|    n_updates        | 239928   |\n",
      "----------------------------------\n",
      "Episode reward: 33.954896\n",
      "Episode reward: 58.770015\n",
      "Episode reward: 67.379242\n",
      "Episode reward: 51.879909\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16448    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 350      |\n",
      "|    total_timesteps  | 960026   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.07     |\n",
      "|    n_updates        | 239981   |\n",
      "----------------------------------\n",
      "Episode reward: 94.183913\n",
      "Episode reward: 45.865726\n",
      "Episode reward: 56.328471\n",
      "Episode reward: 63.470766\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16452    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 350      |\n",
      "|    total_timesteps  | 960288   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0822   |\n",
      "|    n_updates        | 240046   |\n",
      "----------------------------------\n",
      "Episode reward: 76.31993\n",
      "Episode reward: 43.928176\n",
      "Episode reward: 35.636241\n",
      "Episode reward: 82.026507\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16456    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 350      |\n",
      "|    total_timesteps  | 960530   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0517   |\n",
      "|    n_updates        | 240107   |\n",
      "----------------------------------\n",
      "Episode reward: 76.143176\n",
      "Episode reward: 74.488034\n",
      "Episode reward: 40.940422\n",
      "Episode reward: 74.780034\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16460    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 350      |\n",
      "|    total_timesteps  | 960800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.106    |\n",
      "|    n_updates        | 240174   |\n",
      "----------------------------------\n",
      "Episode reward: 59.789517\n",
      "Episode reward: 47.895673\n",
      "Episode reward: 49.869974\n",
      "Episode reward: 51.903724\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16464    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 350      |\n",
      "|    total_timesteps  | 961010   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0715   |\n",
      "|    n_updates        | 240227   |\n",
      "----------------------------------\n",
      "Episode reward: 92.588817\n",
      "Episode reward: 53.790901\n",
      "Episode reward: 55.762036\n",
      "Episode reward: 44.888308\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.9     |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16468    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 350      |\n",
      "|    total_timesteps  | 961259   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0938   |\n",
      "|    n_updates        | 240289   |\n",
      "----------------------------------\n",
      "Episode reward: 49.870015\n",
      "Episode reward: 30.844137\n",
      "Episode reward: 64.750107\n",
      "Episode reward: 37.79048\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16472    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 350      |\n",
      "|    total_timesteps  | 961443   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0515   |\n",
      "|    n_updates        | 240335   |\n",
      "----------------------------------\n",
      "Episode reward: 38.856243\n",
      "Episode reward: 92.339737\n",
      "Episode reward: 55.850124\n",
      "Episode reward: 44.872165\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16476    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 351      |\n",
      "|    total_timesteps  | 961676   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.161    |\n",
      "|    n_updates        | 240393   |\n",
      "----------------------------------\n",
      "Episode reward: 67.806133\n",
      "Episode reward: 31.946582\n",
      "Episode reward: 63.201778\n",
      "Episode reward: 29.940998\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.6     |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16480    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 351      |\n",
      "|    total_timesteps  | 961870   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0856   |\n",
      "|    n_updates        | 240442   |\n",
      "----------------------------------\n",
      "Episode reward: 47.870993\n",
      "Episode reward: 136.572514\n",
      "Episode reward: 58.298275\n",
      "Episode reward: 41.928025\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16484    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 351      |\n",
      "|    total_timesteps  | 962161   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0757   |\n",
      "|    n_updates        | 240515   |\n",
      "----------------------------------\n",
      "Episode reward: 77.563682\n",
      "Episode reward: 73.739284\n",
      "Episode reward: 78.438033\n",
      "Episode reward: 87.43261\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16488    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 351      |\n",
      "|    total_timesteps  | 962481   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0853   |\n",
      "|    n_updates        | 240595   |\n",
      "----------------------------------\n",
      "Episode reward: 51.890482\n",
      "Episode reward: 61.275648\n",
      "Episode reward: 60.663133\n",
      "Episode reward: 27.907918\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.7     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16492    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 351      |\n",
      "|    total_timesteps  | 962684   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.24     |\n",
      "|    n_updates        | 240645   |\n",
      "----------------------------------\n",
      "Episode reward: 129.113272\n",
      "Episode reward: 45.871676\n",
      "Episode reward: 30.921868\n",
      "Episode reward: 111.123468\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16496    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 351      |\n",
      "|    total_timesteps  | 963021   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0722   |\n",
      "|    n_updates        | 240730   |\n",
      "----------------------------------\n",
      "Episode reward: 41.841577\n",
      "Episode reward: 134.769648\n",
      "Episode reward: 37.929918\n",
      "Episode reward: 43.919437\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16500    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 351      |\n",
      "|    total_timesteps  | 963283   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.134    |\n",
      "|    n_updates        | 240795   |\n",
      "----------------------------------\n",
      "Episode reward: 49.852373\n",
      "Episode reward: 32.717928\n",
      "Episode reward: 28.925804\n",
      "Episode reward: 58.460911\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16504    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 351      |\n",
      "|    total_timesteps  | 963454   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.212    |\n",
      "|    n_updates        | 240838   |\n",
      "----------------------------------\n",
      "Episode reward: 48.809616\n",
      "Episode reward: 65.722\n",
      "Episode reward: 59.871538\n",
      "Episode reward: 47.839558\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16508    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 351      |\n",
      "|    total_timesteps  | 963677   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.924    |\n",
      "|    n_updates        | 240894   |\n",
      "----------------------------------\n",
      "Episode reward: 81.980043\n",
      "Episode reward: 96.38063\n",
      "Episode reward: 47.785216\n",
      "Episode reward: 45.869619\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16512    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 351      |\n",
      "|    total_timesteps  | 963951   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.198    |\n",
      "|    n_updates        | 240962   |\n",
      "----------------------------------\n",
      "Episode reward: 29.897\n",
      "Episode reward: 83.799994\n",
      "Episode reward: 77.544281\n",
      "Episode reward: 46.885877\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16516    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 352      |\n",
      "|    total_timesteps  | 964191   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0988   |\n",
      "|    n_updates        | 241022   |\n",
      "----------------------------------\n",
      "Episode reward: 55.657432\n",
      "Episode reward: 54.828702\n",
      "Episode reward: 62.733705\n",
      "Episode reward: 30.908689\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.2     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16520    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 352      |\n",
      "|    total_timesteps  | 964396   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.196    |\n",
      "|    n_updates        | 241073   |\n",
      "----------------------------------\n",
      "Episode reward: 86.805871\n",
      "Episode reward: 31.882827\n",
      "Episode reward: 38.669126\n",
      "Episode reward: 43.687646\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.1     |\n",
      "|    ep_rew_mean      | 59.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16524    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 352      |\n",
      "|    total_timesteps  | 964598   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0569   |\n",
      "|    n_updates        | 241124   |\n",
      "----------------------------------\n",
      "Episode reward: 71.039588\n",
      "Episode reward: 78.690602\n",
      "Episode reward: 62.348794\n",
      "Episode reward: 47.882624\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16528    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 352      |\n",
      "|    total_timesteps  | 964860   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0636   |\n",
      "|    n_updates        | 241189   |\n",
      "----------------------------------\n",
      "Episode reward: 57.750605\n",
      "Episode reward: 111.684473\n",
      "Episode reward: 67.59641\n",
      "Episode reward: 44.907432\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16532    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 352      |\n",
      "|    total_timesteps  | 965143   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0568   |\n",
      "|    n_updates        | 241260   |\n",
      "----------------------------------\n",
      "Episode reward: 58.689794\n",
      "Episode reward: 92.335861\n",
      "Episode reward: 28.892499\n",
      "Episode reward: 63.927075\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16536    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 352      |\n",
      "|    total_timesteps  | 965390   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0345   |\n",
      "|    n_updates        | 241322   |\n",
      "----------------------------------\n",
      "Episode reward: 45.527129\n",
      "Episode reward: 76.206034\n",
      "Episode reward: 80.037273\n",
      "Episode reward: 63.741\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16540    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 352      |\n",
      "|    total_timesteps  | 965660   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.194    |\n",
      "|    n_updates        | 241389   |\n",
      "----------------------------------\n",
      "Episode reward: 27.708838\n",
      "Episode reward: 61.814717\n",
      "Episode reward: 78.837568\n",
      "Episode reward: 61.855245\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16544    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 352      |\n",
      "|    total_timesteps  | 965895   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0547   |\n",
      "|    n_updates        | 241448   |\n",
      "----------------------------------\n",
      "Episode reward: 38.615216\n",
      "Episode reward: 67.894963\n",
      "Episode reward: 91.558452\n",
      "Episode reward: 61.807158\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16548    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 352      |\n",
      "|    total_timesteps  | 966156   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0831   |\n",
      "|    n_updates        | 241513   |\n",
      "----------------------------------\n",
      "Episode reward: 58.812473\n",
      "Episode reward: 78.018287\n",
      "Episode reward: 59.873114\n",
      "Episode reward: 94.951392\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16552    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 352      |\n",
      "|    total_timesteps  | 966455   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.29     |\n",
      "|    n_updates        | 241588   |\n",
      "----------------------------------\n",
      "Episode reward: 44.476849\n",
      "Episode reward: 38.751478\n",
      "Episode reward: 59.765559\n",
      "Episode reward: 36.895947\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.1     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16556    |\n",
      "|    fps              | 2739     |\n",
      "|    time_elapsed     | 352      |\n",
      "|    total_timesteps  | 966636   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.2      |\n",
      "|    n_updates        | 241633   |\n",
      "----------------------------------\n",
      "Episode reward: 57.506117\n",
      "Episode reward: 34.871861\n",
      "Episode reward: 65.868754\n",
      "Episode reward: 43.620258\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16560    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 353      |\n",
      "|    total_timesteps  | 966839   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.88     |\n",
      "|    n_updates        | 241684   |\n",
      "----------------------------------\n",
      "Episode reward: 60.839883\n",
      "Episode reward: 52.387931\n",
      "Episode reward: 37.953098\n",
      "Episode reward: 44.898272\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16564    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 353      |\n",
      "|    total_timesteps  | 967036   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0523   |\n",
      "|    n_updates        | 241733   |\n",
      "----------------------------------\n",
      "Episode reward: 38.879383\n",
      "Episode reward: 44.840368\n",
      "Episode reward: 62.696951\n",
      "Episode reward: 52.923503\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.8     |\n",
      "|    ep_rew_mean      | 59       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16568    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 353      |\n",
      "|    total_timesteps  | 967236   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0528   |\n",
      "|    n_updates        | 241783   |\n",
      "----------------------------------\n",
      "Episode reward: 53.882478\n",
      "Episode reward: 74.871329\n",
      "Episode reward: 121.318644\n",
      "Episode reward: 57.712869\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16572    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 353      |\n",
      "|    total_timesteps  | 967547   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.38     |\n",
      "|    n_updates        | 241861   |\n",
      "----------------------------------\n",
      "Episode reward: 87.596773\n",
      "Episode reward: 75.483128\n",
      "Episode reward: 48.923453\n",
      "Episode reward: 126.973717\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16576    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 353      |\n",
      "|    total_timesteps  | 967891   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.96     |\n",
      "|    n_updates        | 241947   |\n",
      "----------------------------------\n",
      "Episode reward: 47.836617\n",
      "Episode reward: 171.206751\n",
      "Episode reward: 42.685208\n",
      "Episode reward: 56.359092\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16580    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 353      |\n",
      "|    total_timesteps  | 968212   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.864    |\n",
      "|    n_updates        | 242027   |\n",
      "----------------------------------\n",
      "Episode reward: 39.678436\n",
      "Episode reward: 54.883301\n",
      "Episode reward: 49.74669\n",
      "Episode reward: 36.71135\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16584    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 353      |\n",
      "|    total_timesteps  | 968394   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0683   |\n",
      "|    n_updates        | 242073   |\n",
      "----------------------------------\n",
      "Episode reward: 49.851621\n",
      "Episode reward: 58.739301\n",
      "Episode reward: 68.873139\n",
      "Episode reward: 57.718206\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16588    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 353      |\n",
      "|    total_timesteps  | 968631   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0763   |\n",
      "|    n_updates        | 242132   |\n",
      "----------------------------------\n",
      "Episode reward: 36.852318\n",
      "Episode reward: 95.167062\n",
      "Episode reward: 51.497537\n",
      "Episode reward: 60.771342\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16592    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 353      |\n",
      "|    total_timesteps  | 968879   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.22     |\n",
      "|    n_updates        | 242194   |\n",
      "----------------------------------\n",
      "Episode reward: 147.859415\n",
      "Episode reward: 119.021838\n",
      "Episode reward: 84.175285\n",
      "Episode reward: 61.681033\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.7     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16596    |\n",
      "|    fps              | 2737     |\n",
      "|    time_elapsed     | 354      |\n",
      "|    total_timesteps  | 969295   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0607   |\n",
      "|    n_updates        | 242298   |\n",
      "----------------------------------\n",
      "Episode reward: 39.950523\n",
      "Episode reward: 77.806912\n",
      "Episode reward: 42.943573\n",
      "Episode reward: 90.4643\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.6     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16600    |\n",
      "|    fps              | 2737     |\n",
      "|    time_elapsed     | 354      |\n",
      "|    total_timesteps  | 969548   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.61     |\n",
      "|    n_updates        | 242361   |\n",
      "----------------------------------\n",
      "Episode reward: 76.561843\n",
      "Episode reward: 72.857911\n",
      "Episode reward: 69.777024\n",
      "Episode reward: 59.373822\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16604    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 354      |\n",
      "|    total_timesteps  | 969831   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.17     |\n",
      "|    n_updates        | 242432   |\n",
      "----------------------------------\n",
      "Episode reward: 120.062999\n",
      "Episode reward: 79.717806\n",
      "Episode reward: 38.913607\n",
      "Episode reward: 76.352035\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.7     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16608    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 354      |\n",
      "|    total_timesteps  | 970149   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.127    |\n",
      "|    n_updates        | 242512   |\n",
      "----------------------------------\n",
      "Episode reward: 49.888434\n",
      "Episode reward: 102.142931\n",
      "Episode reward: 56.3049\n",
      "Episode reward: 41.726447\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.3     |\n",
      "|    ep_rew_mean      | 63.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16612    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 354      |\n",
      "|    total_timesteps  | 970478   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.15     |\n",
      "|    n_updates        | 242594   |\n",
      "----------------------------------\n",
      "Episode reward: 45.654592\n",
      "Episode reward: 104.433814\n",
      "Episode reward: 46.887254\n",
      "Episode reward: 55.708353\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.4     |\n",
      "|    ep_rew_mean      | 64       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16616    |\n",
      "|    fps              | 2738     |\n",
      "|    time_elapsed     | 354      |\n",
      "|    total_timesteps  | 970732   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.25     |\n",
      "|    n_updates        | 242657   |\n",
      "----------------------------------\n",
      "Episode reward: 39.783655\n",
      "Episode reward: 50.889608\n",
      "Episode reward: 84.807198\n",
      "Episode reward: 84.576099\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66       |\n",
      "|    ep_rew_mean      | 64.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16620    |\n",
      "|    fps              | 2737     |\n",
      "|    time_elapsed     | 354      |\n",
      "|    total_timesteps  | 970993   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.6      |\n",
      "|    n_updates        | 242723   |\n",
      "----------------------------------\n",
      "Episode reward: 73.239847\n",
      "Episode reward: 53.423642\n",
      "Episode reward: 61.885714\n",
      "Episode reward: 60.635099\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.5     |\n",
      "|    ep_rew_mean      | 65.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16624    |\n",
      "|    fps              | 2737     |\n",
      "|    time_elapsed     | 354      |\n",
      "|    total_timesteps  | 971244   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.134    |\n",
      "|    n_updates        | 242785   |\n",
      "----------------------------------\n",
      "Episode reward: 38.251574\n",
      "Episode reward: 75.83742\n",
      "Episode reward: 106.277641\n",
      "Episode reward: 58.893625\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.7     |\n",
      "|    ep_rew_mean      | 65.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16628    |\n",
      "|    fps              | 2737     |\n",
      "|    time_elapsed     | 354      |\n",
      "|    total_timesteps  | 971526   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0384   |\n",
      "|    n_updates        | 242856   |\n",
      "----------------------------------\n",
      "Episode reward: 63.83424\n",
      "Episode reward: 42.931854\n",
      "Episode reward: 53.910874\n",
      "Episode reward: 40.659982\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.8     |\n",
      "|    ep_rew_mean      | 64.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16632    |\n",
      "|    fps              | 2737     |\n",
      "|    time_elapsed     | 354      |\n",
      "|    total_timesteps  | 971728   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.796    |\n",
      "|    n_updates        | 242906   |\n",
      "----------------------------------\n",
      "Episode reward: 39.409177\n",
      "Episode reward: 62.815466\n",
      "Episode reward: 56.831779\n",
      "Episode reward: 57.83901\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.6     |\n",
      "|    ep_rew_mean      | 64.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16636    |\n",
      "|    fps              | 2737     |\n",
      "|    time_elapsed     | 355      |\n",
      "|    total_timesteps  | 971946   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0508   |\n",
      "|    n_updates        | 242961   |\n",
      "----------------------------------\n",
      "Episode reward: 40.875938\n",
      "Episode reward: 94.081236\n",
      "Episode reward: 32.837019\n",
      "Episode reward: 94.829989\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.5     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16640    |\n",
      "|    fps              | 2737     |\n",
      "|    time_elapsed     | 355      |\n",
      "|    total_timesteps  | 972211   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0705   |\n",
      "|    n_updates        | 243027   |\n",
      "----------------------------------\n",
      "Episode reward: 61.58802\n",
      "Episode reward: 34.832879\n",
      "Episode reward: 72.900194\n",
      "Episode reward: 58.847038\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.5     |\n",
      "|    ep_rew_mean      | 64.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16644    |\n",
      "|    fps              | 2737     |\n",
      "|    time_elapsed     | 355      |\n",
      "|    total_timesteps  | 972443   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0988   |\n",
      "|    n_updates        | 243085   |\n",
      "----------------------------------\n",
      "Episode reward: 68.271891\n",
      "Episode reward: 59.467792\n",
      "Episode reward: 34.93328\n",
      "Episode reward: 31.818223\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.8     |\n",
      "|    ep_rew_mean      | 63.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16648    |\n",
      "|    fps              | 2737     |\n",
      "|    time_elapsed     | 355      |\n",
      "|    total_timesteps  | 972639   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.28     |\n",
      "|    n_updates        | 243134   |\n",
      "----------------------------------\n",
      "Episode reward: 38.458436\n",
      "Episode reward: 35.565884\n",
      "Episode reward: 53.875815\n",
      "Episode reward: 53.879181\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16652    |\n",
      "|    fps              | 2737     |\n",
      "|    time_elapsed     | 355      |\n",
      "|    total_timesteps  | 972822   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 243180   |\n",
      "----------------------------------\n",
      "Episode reward: 89.51947\n",
      "Episode reward: 91.099404\n",
      "Episode reward: 46.850016\n",
      "Episode reward: 30.831966\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.5     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16656    |\n",
      "|    fps              | 2737     |\n",
      "|    time_elapsed     | 355      |\n",
      "|    total_timesteps  | 973084   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.153    |\n",
      "|    n_updates        | 243245   |\n",
      "----------------------------------\n",
      "Episode reward: 86.480488\n",
      "Episode reward: 61.917459\n",
      "Episode reward: 79.231494\n",
      "Episode reward: 37.94468\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.1     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16660    |\n",
      "|    fps              | 2737     |\n",
      "|    time_elapsed     | 355      |\n",
      "|    total_timesteps  | 973353   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 243313   |\n",
      "----------------------------------\n",
      "Episode reward: 65.325775\n",
      "Episode reward: 56.774581\n",
      "Episode reward: 40.755624\n",
      "Episode reward: 48.820138\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.3     |\n",
      "|    ep_rew_mean      | 63.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16664    |\n",
      "|    fps              | 2737     |\n",
      "|    time_elapsed     | 355      |\n",
      "|    total_timesteps  | 973566   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0852   |\n",
      "|    n_updates        | 243366   |\n",
      "----------------------------------\n",
      "Episode reward: 35.936561\n",
      "Episode reward: 49.89377\n",
      "Episode reward: 64.743439\n",
      "Episode reward: 89.115436\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.7     |\n",
      "|    ep_rew_mean      | 64.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16668    |\n",
      "|    fps              | 2737     |\n",
      "|    time_elapsed     | 355      |\n",
      "|    total_timesteps  | 973807   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.77     |\n",
      "|    n_updates        | 243426   |\n",
      "----------------------------------\n",
      "Episode reward: 56.520509\n",
      "Episode reward: 43.938561\n",
      "Episode reward: 117.254234\n",
      "Episode reward: 36.916285\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.2     |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16672    |\n",
      "|    fps              | 2736     |\n",
      "|    time_elapsed     | 355      |\n",
      "|    total_timesteps  | 974063   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.14     |\n",
      "|    n_updates        | 243490   |\n",
      "----------------------------------\n",
      "Episode reward: 74.7788\n",
      "Episode reward: 57.315058\n",
      "Episode reward: 32.846664\n",
      "Episode reward: 47.83828\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.9     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16676    |\n",
      "|    fps              | 2736     |\n",
      "|    time_elapsed     | 355      |\n",
      "|    total_timesteps  | 974277   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.295    |\n",
      "|    n_updates        | 243544   |\n",
      "----------------------------------\n",
      "Episode reward: 48.905113\n",
      "Episode reward: 96.716752\n",
      "Episode reward: 43.827809\n",
      "Episode reward: 51.852726\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.1     |\n",
      "|    ep_rew_mean      | 61.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16680    |\n",
      "|    fps              | 2736     |\n",
      "|    time_elapsed     | 356      |\n",
      "|    total_timesteps  | 974519   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.04     |\n",
      "|    n_updates        | 243604   |\n",
      "----------------------------------\n",
      "Episode reward: 89.265936\n",
      "Episode reward: 50.85079\n",
      "Episode reward: 30.933095\n",
      "Episode reward: 70.415096\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16684    |\n",
      "|    fps              | 2736     |\n",
      "|    time_elapsed     | 356      |\n",
      "|    total_timesteps  | 974762   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0733   |\n",
      "|    n_updates        | 243665   |\n",
      "----------------------------------\n",
      "Episode reward: 42.90443\n",
      "Episode reward: 88.22287\n",
      "Episode reward: 32.830805\n",
      "Episode reward: 28.941697\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16688    |\n",
      "|    fps              | 2736     |\n",
      "|    time_elapsed     | 356      |\n",
      "|    total_timesteps  | 974956   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.456    |\n",
      "|    n_updates        | 243713   |\n",
      "----------------------------------\n",
      "Episode reward: 37.949015\n",
      "Episode reward: 109.589432\n",
      "Episode reward: 40.94383\n",
      "Episode reward: 75.008729\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16692    |\n",
      "|    fps              | 2735     |\n",
      "|    time_elapsed     | 356      |\n",
      "|    total_timesteps  | 975221   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.247    |\n",
      "|    n_updates        | 243780   |\n",
      "----------------------------------\n",
      "Episode reward: 41.866437\n",
      "Episode reward: 45.859423\n",
      "Episode reward: 87.759745\n",
      "Episode reward: 55.75443\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16696    |\n",
      "|    fps              | 2735     |\n",
      "|    time_elapsed     | 356      |\n",
      "|    total_timesteps  | 975454   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.24     |\n",
      "|    n_updates        | 243838   |\n",
      "----------------------------------\n",
      "Episode reward: 141.012123\n",
      "Episode reward: 33.952673\n",
      "Episode reward: 86.010716\n",
      "Episode reward: 30.787698\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16700    |\n",
      "|    fps              | 2735     |\n",
      "|    time_elapsed     | 356      |\n",
      "|    total_timesteps  | 975748   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.166    |\n",
      "|    n_updates        | 243911   |\n",
      "----------------------------------\n",
      "Episode reward: 30.912057\n",
      "Episode reward: 52.920081\n",
      "Episode reward: 84.02286\n",
      "Episode reward: 57.858233\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16704    |\n",
      "|    fps              | 2735     |\n",
      "|    time_elapsed     | 356      |\n",
      "|    total_timesteps  | 975975   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.552    |\n",
      "|    n_updates        | 243968   |\n",
      "----------------------------------\n",
      "Episode reward: 37.772397\n",
      "Episode reward: 45.94283\n",
      "Episode reward: 46.857325\n",
      "Episode reward: 47.255171\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 58.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16708    |\n",
      "|    fps              | 2735     |\n",
      "|    time_elapsed     | 356      |\n",
      "|    total_timesteps  | 976154   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0807   |\n",
      "|    n_updates        | 244013   |\n",
      "----------------------------------\n",
      "Episode reward: 78.613728\n",
      "Episode reward: 34.804337\n",
      "Episode reward: 57.800432\n",
      "Episode reward: 35.947927\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16712    |\n",
      "|    fps              | 2735     |\n",
      "|    time_elapsed     | 356      |\n",
      "|    total_timesteps  | 976362   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.211    |\n",
      "|    n_updates        | 244065   |\n",
      "----------------------------------\n",
      "Episode reward: 67.797948\n",
      "Episode reward: 120.93051\n",
      "Episode reward: 94.175829\n",
      "Episode reward: 80.10431\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16716    |\n",
      "|    fps              | 2734     |\n",
      "|    time_elapsed     | 357      |\n",
      "|    total_timesteps  | 976736   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.49     |\n",
      "|    n_updates        | 244158   |\n",
      "----------------------------------\n",
      "Episode reward: 73.917601\n",
      "Episode reward: 78.789137\n",
      "Episode reward: 70.785538\n",
      "Episode reward: 69.455646\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16720    |\n",
      "|    fps              | 2734     |\n",
      "|    time_elapsed     | 357      |\n",
      "|    total_timesteps  | 977033   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.151    |\n",
      "|    n_updates        | 244233   |\n",
      "----------------------------------\n",
      "Episode reward: 41.898253\n",
      "Episode reward: 66.88726\n",
      "Episode reward: 45.916961\n",
      "Episode reward: 41.759905\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.9     |\n",
      "|    ep_rew_mean      | 59.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16724    |\n",
      "|    fps              | 2734     |\n",
      "|    time_elapsed     | 357      |\n",
      "|    total_timesteps  | 977230   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 244282   |\n",
      "----------------------------------\n",
      "Episode reward: 44.857031\n",
      "Episode reward: 32.959428\n",
      "Episode reward: 54.384826\n",
      "Episode reward: 43.747728\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 58.8     |\n",
      "|    ep_rew_mean      | 58.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16728    |\n",
      "|    fps              | 2734     |\n",
      "|    time_elapsed     | 357      |\n",
      "|    total_timesteps  | 977407   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.146    |\n",
      "|    n_updates        | 244326   |\n",
      "----------------------------------\n",
      "Episode reward: 128.26723\n",
      "Episode reward: 54.433756\n",
      "Episode reward: 52.550927\n",
      "Episode reward: 45.888617\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16732    |\n",
      "|    fps              | 2734     |\n",
      "|    time_elapsed     | 357      |\n",
      "|    total_timesteps  | 977695   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0663   |\n",
      "|    n_updates        | 244398   |\n",
      "----------------------------------\n",
      "Episode reward: 65.859485\n",
      "Episode reward: 56.59948\n",
      "Episode reward: 33.959677\n",
      "Episode reward: 63.801131\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 59.7     |\n",
      "|    ep_rew_mean      | 59.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16736    |\n",
      "|    fps              | 2735     |\n",
      "|    time_elapsed     | 357      |\n",
      "|    total_timesteps  | 977917   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.157    |\n",
      "|    n_updates        | 244454   |\n",
      "----------------------------------\n",
      "Episode reward: 55.873998\n",
      "Episode reward: 29.946989\n",
      "Episode reward: 75.770641\n",
      "Episode reward: 161.87715\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16740    |\n",
      "|    fps              | 2735     |\n",
      "|    time_elapsed     | 357      |\n",
      "|    total_timesteps  | 978242   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.158    |\n",
      "|    n_updates        | 244535   |\n",
      "----------------------------------\n",
      "Episode reward: 59.447946\n",
      "Episode reward: 48.841212\n",
      "Episode reward: 76.653921\n",
      "Episode reward: 58.528774\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.4     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16744    |\n",
      "|    fps              | 2735     |\n",
      "|    time_elapsed     | 357      |\n",
      "|    total_timesteps  | 978487   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0504   |\n",
      "|    n_updates        | 244596   |\n",
      "----------------------------------\n",
      "Episode reward: 44.909166\n",
      "Episode reward: 76.603579\n",
      "Episode reward: 43.879014\n",
      "Episode reward: 48.709935\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.6     |\n",
      "|    ep_rew_mean      | 60.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16748    |\n",
      "|    fps              | 2734     |\n",
      "|    time_elapsed     | 357      |\n",
      "|    total_timesteps  | 978702   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0831   |\n",
      "|    n_updates        | 244650   |\n",
      "----------------------------------\n",
      "Episode reward: 56.197317\n",
      "Episode reward: 97.347433\n",
      "Episode reward: 98.532952\n",
      "Episode reward: 39.832273\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16752    |\n",
      "|    fps              | 2734     |\n",
      "|    time_elapsed     | 358      |\n",
      "|    total_timesteps  | 978996   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.956    |\n",
      "|    n_updates        | 244723   |\n",
      "----------------------------------\n",
      "Episode reward: 35.954754\n",
      "Episode reward: 34.848002\n",
      "Episode reward: 71.591751\n",
      "Episode reward: 79.821365\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16756    |\n",
      "|    fps              | 2734     |\n",
      "|    time_elapsed     | 358      |\n",
      "|    total_timesteps  | 979220   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0684   |\n",
      "|    n_updates        | 244779   |\n",
      "----------------------------------\n",
      "Episode reward: 79.733739\n",
      "Episode reward: 45.903227\n",
      "Episode reward: 35.69539\n",
      "Episode reward: 42.891991\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.7     |\n",
      "|    ep_rew_mean      | 60.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16760    |\n",
      "|    fps              | 2734     |\n",
      "|    time_elapsed     | 358      |\n",
      "|    total_timesteps  | 979425   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0363   |\n",
      "|    n_updates        | 244831   |\n",
      "----------------------------------\n",
      "Episode reward: 40.900097\n",
      "Episode reward: 50.756745\n",
      "Episode reward: 40.915484\n",
      "Episode reward: 40.939517\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.3     |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16764    |\n",
      "|    fps              | 2734     |\n",
      "|    time_elapsed     | 358      |\n",
      "|    total_timesteps  | 979599   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.095    |\n",
      "|    n_updates        | 244874   |\n",
      "----------------------------------\n",
      "Episode reward: 44.781911\n",
      "Episode reward: 33.700788\n",
      "Episode reward: 72.674156\n",
      "Episode reward: 59.481597\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16768    |\n",
      "|    fps              | 2734     |\n",
      "|    time_elapsed     | 358      |\n",
      "|    total_timesteps  | 979811   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0432   |\n",
      "|    n_updates        | 244927   |\n",
      "----------------------------------\n",
      "Episode reward: 74.813411\n",
      "Episode reward: 143.961892\n",
      "Episode reward: 43.932566\n",
      "Episode reward: 39.913932\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 60       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16772    |\n",
      "|    fps              | 2734     |\n",
      "|    time_elapsed     | 358      |\n",
      "|    total_timesteps  | 980115   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0515   |\n",
      "|    n_updates        | 245003   |\n",
      "----------------------------------\n",
      "Episode reward: 89.597568\n",
      "Episode reward: 76.12533\n",
      "Episode reward: 91.015644\n",
      "Episode reward: 43.836962\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16776    |\n",
      "|    fps              | 2733     |\n",
      "|    time_elapsed     | 358      |\n",
      "|    total_timesteps  | 980422   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0613   |\n",
      "|    n_updates        | 245080   |\n",
      "----------------------------------\n",
      "Episode reward: 33.893042\n",
      "Episode reward: 91.792505\n",
      "Episode reward: 63.876177\n",
      "Episode reward: 53.816663\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16780    |\n",
      "|    fps              | 2733     |\n",
      "|    time_elapsed     | 358      |\n",
      "|    total_timesteps  | 980666   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.89     |\n",
      "|    n_updates        | 245141   |\n",
      "----------------------------------\n",
      "Episode reward: 39.793962\n",
      "Episode reward: 33.494684\n",
      "Episode reward: 66.519104\n",
      "Episode reward: 93.776343\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16784    |\n",
      "|    fps              | 2733     |\n",
      "|    time_elapsed     | 358      |\n",
      "|    total_timesteps  | 980906   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.26     |\n",
      "|    n_updates        | 245201   |\n",
      "----------------------------------\n",
      "Episode reward: 60.847822\n",
      "Episode reward: 60.85742\n",
      "Episode reward: 72.601056\n",
      "Episode reward: 67.552682\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16788    |\n",
      "|    fps              | 2733     |\n",
      "|    time_elapsed     | 358      |\n",
      "|    total_timesteps  | 981172   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.074    |\n",
      "|    n_updates        | 245267   |\n",
      "----------------------------------\n",
      "Episode reward: 53.817446\n",
      "Episode reward: 87.56766\n",
      "Episode reward: 79.179484\n",
      "Episode reward: 23.920248\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16792    |\n",
      "|    fps              | 2733     |\n",
      "|    time_elapsed     | 359      |\n",
      "|    total_timesteps  | 981420   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0489   |\n",
      "|    n_updates        | 245329   |\n",
      "----------------------------------\n",
      "Episode reward: 45.942938\n",
      "Episode reward: 49.788119\n",
      "Episode reward: 38.832277\n",
      "Episode reward: 56.851571\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16796    |\n",
      "|    fps              | 2733     |\n",
      "|    time_elapsed     | 359      |\n",
      "|    total_timesteps  | 981612   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.7      |\n",
      "|    n_updates        | 245377   |\n",
      "----------------------------------\n",
      "Episode reward: 33.775302\n",
      "Episode reward: 29.633216\n",
      "Episode reward: 44.905848\n",
      "Episode reward: 124.004881\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61       |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16800    |\n",
      "|    fps              | 2733     |\n",
      "|    time_elapsed     | 359      |\n",
      "|    total_timesteps  | 981846   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 245436   |\n",
      "----------------------------------\n",
      "Episode reward: 65.805151\n",
      "Episode reward: 74.56546\n",
      "Episode reward: 43.71825\n",
      "Episode reward: 74.429354\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.3     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16804    |\n",
      "|    fps              | 2733     |\n",
      "|    time_elapsed     | 359      |\n",
      "|    total_timesteps  | 982106   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.113    |\n",
      "|    n_updates        | 245501   |\n",
      "----------------------------------\n",
      "Episode reward: 70.003518\n",
      "Episode reward: 43.892148\n",
      "Episode reward: 51.824216\n",
      "Episode reward: 28.889045\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16808    |\n",
      "|    fps              | 2733     |\n",
      "|    time_elapsed     | 359      |\n",
      "|    total_timesteps  | 982302   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.38     |\n",
      "|    n_updates        | 245550   |\n",
      "----------------------------------\n",
      "Episode reward: 48.836629\n",
      "Episode reward: 49.750051\n",
      "Episode reward: 65.855252\n",
      "Episode reward: 93.583681\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16812    |\n",
      "|    fps              | 2733     |\n",
      "|    time_elapsed     | 359      |\n",
      "|    total_timesteps  | 982561   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.071    |\n",
      "|    n_updates        | 245615   |\n",
      "----------------------------------\n",
      "Episode reward: 40.896179\n",
      "Episode reward: 44.920543\n",
      "Episode reward: 38.955464\n",
      "Episode reward: 49.872029\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60       |\n",
      "|    ep_rew_mean      | 59.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16816    |\n",
      "|    fps              | 2733     |\n",
      "|    time_elapsed     | 359      |\n",
      "|    total_timesteps  | 982736   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.148    |\n",
      "|    n_updates        | 245658   |\n",
      "----------------------------------\n",
      "Episode reward: 50.897363\n",
      "Episode reward: 98.410733\n",
      "Episode reward: 49.5074\n",
      "Episode reward: 111.04014\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.5     |\n",
      "|    ep_rew_mean      | 59.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16820    |\n",
      "|    fps              | 2733     |\n",
      "|    time_elapsed     | 359      |\n",
      "|    total_timesteps  | 983084   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0606   |\n",
      "|    n_updates        | 245745   |\n",
      "----------------------------------\n",
      "Episode reward: 65.711682\n",
      "Episode reward: 46.667699\n",
      "Episode reward: 72.280371\n",
      "Episode reward: 38.908868\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 60.8     |\n",
      "|    ep_rew_mean      | 59.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16824    |\n",
      "|    fps              | 2733     |\n",
      "|    time_elapsed     | 359      |\n",
      "|    total_timesteps  | 983309   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0452   |\n",
      "|    n_updates        | 245802   |\n",
      "----------------------------------\n",
      "Episode reward: 86.357038\n",
      "Episode reward: 96.214923\n",
      "Episode reward: 89.099667\n",
      "Episode reward: 51.900973\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16828    |\n",
      "|    fps              | 2733     |\n",
      "|    time_elapsed     | 359      |\n",
      "|    total_timesteps  | 983635   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.558    |\n",
      "|    n_updates        | 245883   |\n",
      "----------------------------------\n",
      "Episode reward: 52.892591\n",
      "Episode reward: 73.813454\n",
      "Episode reward: 92.368023\n",
      "Episode reward: 62.634254\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16832    |\n",
      "|    fps              | 2732     |\n",
      "|    time_elapsed     | 360      |\n",
      "|    total_timesteps  | 983919   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.603    |\n",
      "|    n_updates        | 245954   |\n",
      "----------------------------------\n",
      "Episode reward: 30.934784\n",
      "Episode reward: 57.849178\n",
      "Episode reward: 62.893959\n",
      "Episode reward: 32.787728\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16836    |\n",
      "|    fps              | 2732     |\n",
      "|    time_elapsed     | 360      |\n",
      "|    total_timesteps  | 984104   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.244    |\n",
      "|    n_updates        | 246000   |\n",
      "----------------------------------\n",
      "Episode reward: 62.473307\n",
      "Episode reward: 47.69791\n",
      "Episode reward: 71.221309\n",
      "Episode reward: 99.383285\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16840    |\n",
      "|    fps              | 2732     |\n",
      "|    time_elapsed     | 360      |\n",
      "|    total_timesteps  | 984390   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.295    |\n",
      "|    n_updates        | 246072   |\n",
      "----------------------------------\n",
      "Episode reward: 42.924635\n",
      "Episode reward: 68.645226\n",
      "Episode reward: 99.022819\n",
      "Episode reward: 50.84431\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16844    |\n",
      "|    fps              | 2731     |\n",
      "|    time_elapsed     | 360      |\n",
      "|    total_timesteps  | 984653   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.2      |\n",
      "|    n_updates        | 246138   |\n",
      "----------------------------------\n",
      "Episode reward: 37.932886\n",
      "Episode reward: 95.594817\n",
      "Episode reward: 108.292054\n",
      "Episode reward: 27.882261\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16848    |\n",
      "|    fps              | 2731     |\n",
      "|    time_elapsed     | 360      |\n",
      "|    total_timesteps  | 984926   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.259    |\n",
      "|    n_updates        | 246206   |\n",
      "----------------------------------\n",
      "Episode reward: 68.789266\n",
      "Episode reward: 40.874711\n",
      "Episode reward: 110.420721\n",
      "Episode reward: 52.892512\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16852    |\n",
      "|    fps              | 2731     |\n",
      "|    time_elapsed     | 360      |\n",
      "|    total_timesteps  | 985201   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0912   |\n",
      "|    n_updates        | 246275   |\n",
      "----------------------------------\n",
      "Episode reward: 89.145821\n",
      "Episode reward: 86.79876\n",
      "Episode reward: 50.890431\n",
      "Episode reward: 41.724728\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16856    |\n",
      "|    fps              | 2731     |\n",
      "|    time_elapsed     | 360      |\n",
      "|    total_timesteps  | 985472   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.2      |\n",
      "|    n_updates        | 246342   |\n",
      "----------------------------------\n",
      "Episode reward: 62.810782\n",
      "Episode reward: 82.356697\n",
      "Episode reward: 55.12949\n",
      "Episode reward: 44.929585\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16860    |\n",
      "|    fps              | 2731     |\n",
      "|    time_elapsed     | 360      |\n",
      "|    total_timesteps  | 985719   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.09     |\n",
      "|    n_updates        | 246404   |\n",
      "----------------------------------\n",
      "Episode reward: 73.043406\n",
      "Episode reward: 35.87885\n",
      "Episode reward: 31.839173\n",
      "Episode reward: 31.921079\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16864    |\n",
      "|    fps              | 2731     |\n",
      "|    time_elapsed     | 360      |\n",
      "|    total_timesteps  | 985894   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.072    |\n",
      "|    n_updates        | 246448   |\n",
      "----------------------------------\n",
      "Episode reward: 43.836121\n",
      "Episode reward: 82.721458\n",
      "Episode reward: 71.780796\n",
      "Episode reward: 57.847647\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16868    |\n",
      "|    fps              | 2731     |\n",
      "|    time_elapsed     | 361      |\n",
      "|    total_timesteps  | 986151   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.74     |\n",
      "|    n_updates        | 246512   |\n",
      "----------------------------------\n",
      "Episode reward: 31.819128\n",
      "Episode reward: 37.846745\n",
      "Episode reward: 68.50661\n",
      "Episode reward: 42.89756\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16872    |\n",
      "|    fps              | 2731     |\n",
      "|    time_elapsed     | 361      |\n",
      "|    total_timesteps  | 986333   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0554   |\n",
      "|    n_updates        | 246558   |\n",
      "----------------------------------\n",
      "Episode reward: 41.341656\n",
      "Episode reward: 69.548845\n",
      "Episode reward: 56.780902\n",
      "Episode reward: 34.723466\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16876    |\n",
      "|    fps              | 2731     |\n",
      "|    time_elapsed     | 361      |\n",
      "|    total_timesteps  | 986538   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.04     |\n",
      "|    n_updates        | 246609   |\n",
      "----------------------------------\n",
      "Episode reward: 46.848113\n",
      "Episode reward: 154.961307\n",
      "Episode reward: 44.861161\n",
      "Episode reward: 36.810955\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16880    |\n",
      "|    fps              | 2730     |\n",
      "|    time_elapsed     | 361      |\n",
      "|    total_timesteps  | 986824   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.135    |\n",
      "|    n_updates        | 246680   |\n",
      "----------------------------------\n",
      "Episode reward: 64.568842\n",
      "Episode reward: 68.065734\n",
      "Episode reward: 54.905791\n",
      "Episode reward: 86.950527\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16884    |\n",
      "|    fps              | 2730     |\n",
      "|    time_elapsed     | 361      |\n",
      "|    total_timesteps  | 987102   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.567    |\n",
      "|    n_updates        | 246750   |\n",
      "----------------------------------\n",
      "Episode reward: 43.935551\n",
      "Episode reward: 43.850986\n",
      "Episode reward: 87.327533\n",
      "Episode reward: 92.697543\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16888    |\n",
      "|    fps              | 2730     |\n",
      "|    time_elapsed     | 361      |\n",
      "|    total_timesteps  | 987372   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0543   |\n",
      "|    n_updates        | 246817   |\n",
      "----------------------------------\n",
      "Episode reward: 33.638721\n",
      "Episode reward: 95.07344\n",
      "Episode reward: 78.704393\n",
      "Episode reward: 66.722292\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16892    |\n",
      "|    fps              | 2730     |\n",
      "|    time_elapsed     | 361      |\n",
      "|    total_timesteps  | 987649   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0875   |\n",
      "|    n_updates        | 246887   |\n",
      "----------------------------------\n",
      "Episode reward: 102.754421\n",
      "Episode reward: 60.60776\n",
      "Episode reward: 49.889687\n",
      "Episode reward: 70.805014\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16896    |\n",
      "|    fps              | 2730     |\n",
      "|    time_elapsed     | 361      |\n",
      "|    total_timesteps  | 987938   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0613   |\n",
      "|    n_updates        | 246959   |\n",
      "----------------------------------\n",
      "Episode reward: 61.844268\n",
      "Episode reward: 69.863287\n",
      "Episode reward: 53.793072\n",
      "Episode reward: 87.686071\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16900    |\n",
      "|    fps              | 2730     |\n",
      "|    time_elapsed     | 361      |\n",
      "|    total_timesteps  | 988213   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0422   |\n",
      "|    n_updates        | 247028   |\n",
      "----------------------------------\n",
      "Episode reward: 64.718697\n",
      "Episode reward: 65.88601\n",
      "Episode reward: 67.434507\n",
      "Episode reward: 44.875929\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16904    |\n",
      "|    fps              | 2729     |\n",
      "|    time_elapsed     | 362      |\n",
      "|    total_timesteps  | 988458   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.041    |\n",
      "|    n_updates        | 247089   |\n",
      "----------------------------------\n",
      "Episode reward: 75.071233\n",
      "Episode reward: 37.843149\n",
      "Episode reward: 42.738498\n",
      "Episode reward: 53.218278\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.7     |\n",
      "|    ep_rew_mean      | 62.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16908    |\n",
      "|    fps              | 2729     |\n",
      "|    time_elapsed     | 362      |\n",
      "|    total_timesteps  | 988669   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.84     |\n",
      "|    n_updates        | 247142   |\n",
      "----------------------------------\n",
      "Episode reward: 47.917955\n",
      "Episode reward: 47.830892\n",
      "Episode reward: 62.880584\n",
      "Episode reward: 52.066894\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.2     |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16912    |\n",
      "|    fps              | 2729     |\n",
      "|    time_elapsed     | 362      |\n",
      "|    total_timesteps  | 988881   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0633   |\n",
      "|    n_updates        | 247195   |\n",
      "----------------------------------\n",
      "Episode reward: 45.737909\n",
      "Episode reward: 89.409218\n",
      "Episode reward: 30.835728\n",
      "Episode reward: 39.608547\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.5     |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16916    |\n",
      "|    fps              | 2729     |\n",
      "|    time_elapsed     | 362      |\n",
      "|    total_timesteps  | 989089   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0658   |\n",
      "|    n_updates        | 247247   |\n",
      "----------------------------------\n",
      "Episode reward: 39.822\n",
      "Episode reward: 45.834662\n",
      "Episode reward: 64.785596\n",
      "Episode reward: 39.941101\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16920    |\n",
      "|    fps              | 2729     |\n",
      "|    time_elapsed     | 362      |\n",
      "|    total_timesteps  | 989280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.64     |\n",
      "|    n_updates        | 247294   |\n",
      "----------------------------------\n",
      "Episode reward: 64.740916\n",
      "Episode reward: 96.753061\n",
      "Episode reward: 37.953989\n",
      "Episode reward: 57.708781\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.3     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16924    |\n",
      "|    fps              | 2729     |\n",
      "|    time_elapsed     | 362      |\n",
      "|    total_timesteps  | 989539   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.133    |\n",
      "|    n_updates        | 247359   |\n",
      "----------------------------------\n",
      "Episode reward: 77.718072\n",
      "Episode reward: 89.073841\n",
      "Episode reward: 59.731997\n",
      "Episode reward: 56.728228\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16928    |\n",
      "|    fps              | 2729     |\n",
      "|    time_elapsed     | 362      |\n",
      "|    total_timesteps  | 989824   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.258    |\n",
      "|    n_updates        | 247430   |\n",
      "----------------------------------\n",
      "Episode reward: 42.863464\n",
      "Episode reward: 150.699082\n",
      "Episode reward: 53.6136\n",
      "Episode reward: 34.815311\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.9     |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16932    |\n",
      "|    fps              | 2729     |\n",
      "|    time_elapsed     | 362      |\n",
      "|    total_timesteps  | 990108   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 247501   |\n",
      "----------------------------------\n",
      "Episode reward: 98.885671\n",
      "Episode reward: 84.485487\n",
      "Episode reward: 39.950083\n",
      "Episode reward: 56.553661\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16936    |\n",
      "|    fps              | 2729     |\n",
      "|    time_elapsed     | 362      |\n",
      "|    total_timesteps  | 990401   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0688   |\n",
      "|    n_updates        | 247575   |\n",
      "----------------------------------\n",
      "Episode reward: 32.871831\n",
      "Episode reward: 60.692303\n",
      "Episode reward: 53.337292\n",
      "Episode reward: 57.874518\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.2     |\n",
      "|    ep_rew_mean      | 61.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16940    |\n",
      "|    fps              | 2729     |\n",
      "|    time_elapsed     | 362      |\n",
      "|    total_timesteps  | 990607   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.27     |\n",
      "|    n_updates        | 247626   |\n",
      "----------------------------------\n",
      "Episode reward: 32.838985\n",
      "Episode reward: 42.654493\n",
      "Episode reward: 91.894303\n",
      "Episode reward: 45.753218\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16944    |\n",
      "|    fps              | 2729     |\n",
      "|    time_elapsed     | 363      |\n",
      "|    total_timesteps  | 990822   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.278    |\n",
      "|    n_updates        | 247680   |\n",
      "----------------------------------\n",
      "Episode reward: 77.107785\n",
      "Episode reward: 94.481934\n",
      "Episode reward: 39.740731\n",
      "Episode reward: 56.316956\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16948    |\n",
      "|    fps              | 2729     |\n",
      "|    time_elapsed     | 363      |\n",
      "|    total_timesteps  | 991094   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.209    |\n",
      "|    n_updates        | 247748   |\n",
      "----------------------------------\n",
      "Episode reward: 69.645613\n",
      "Episode reward: 77.300921\n",
      "Episode reward: 40.899949\n",
      "Episode reward: 57.858695\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16952    |\n",
      "|    fps              | 2729     |\n",
      "|    time_elapsed     | 363      |\n",
      "|    total_timesteps  | 991342   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.111    |\n",
      "|    n_updates        | 247810   |\n",
      "----------------------------------\n",
      "Episode reward: 102.36508\n",
      "Episode reward: 78.305878\n",
      "Episode reward: 40.883101\n",
      "Episode reward: 27.874776\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.2     |\n",
      "|    ep_rew_mean      | 60.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16956    |\n",
      "|    fps              | 2729     |\n",
      "|    time_elapsed     | 363      |\n",
      "|    total_timesteps  | 991596   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.153    |\n",
      "|    n_updates        | 247873   |\n",
      "----------------------------------\n",
      "Episode reward: 85.43605\n",
      "Episode reward: 72.388034\n",
      "Episode reward: 55.865654\n",
      "Episode reward: 46.89874\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.4     |\n",
      "|    ep_rew_mean      | 60.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16960    |\n",
      "|    fps              | 2729     |\n",
      "|    time_elapsed     | 363      |\n",
      "|    total_timesteps  | 991860   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.059    |\n",
      "|    n_updates        | 247939   |\n",
      "----------------------------------\n",
      "Episode reward: 37.858941\n",
      "Episode reward: 108.757559\n",
      "Episode reward: 75.513052\n",
      "Episode reward: 46.917572\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16964    |\n",
      "|    fps              | 2728     |\n",
      "|    time_elapsed     | 363      |\n",
      "|    total_timesteps  | 992132   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.251    |\n",
      "|    n_updates        | 248007   |\n",
      "----------------------------------\n",
      "Episode reward: 61.321978\n",
      "Episode reward: 44.73823\n",
      "Episode reward: 42.843345\n",
      "Episode reward: 37.53001\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.7     |\n",
      "|    ep_rew_mean      | 61       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16968    |\n",
      "|    fps              | 2728     |\n",
      "|    time_elapsed     | 363      |\n",
      "|    total_timesteps  | 992320   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.109    |\n",
      "|    n_updates        | 248054   |\n",
      "----------------------------------\n",
      "Episode reward: 54.923126\n",
      "Episode reward: 39.769204\n",
      "Episode reward: 102.521216\n",
      "Episode reward: 54.584786\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.4     |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16972    |\n",
      "|    fps              | 2728     |\n",
      "|    time_elapsed     | 363      |\n",
      "|    total_timesteps  | 992573   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.58     |\n",
      "|    n_updates        | 248118   |\n",
      "----------------------------------\n",
      "Episode reward: 51.599786\n",
      "Episode reward: 72.636998\n",
      "Episode reward: 29.787893\n",
      "Episode reward: 101.506327\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.9     |\n",
      "|    ep_rew_mean      | 62.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16976    |\n",
      "|    fps              | 2728     |\n",
      "|    time_elapsed     | 363      |\n",
      "|    total_timesteps  | 992831   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.296    |\n",
      "|    n_updates        | 248182   |\n",
      "----------------------------------\n",
      "Episode reward: 35.484757\n",
      "Episode reward: 55.576201\n",
      "Episode reward: 73.813942\n",
      "Episode reward: 25.741622\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16980    |\n",
      "|    fps              | 2728     |\n",
      "|    time_elapsed     | 363      |\n",
      "|    total_timesteps  | 993023   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.67     |\n",
      "|    n_updates        | 248230   |\n",
      "----------------------------------\n",
      "Episode reward: 32.89904\n",
      "Episode reward: 89.712996\n",
      "Episode reward: 73.748828\n",
      "Episode reward: 82.335576\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62       |\n",
      "|    ep_rew_mean      | 61.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16984    |\n",
      "|    fps              | 2728     |\n",
      "|    time_elapsed     | 364      |\n",
      "|    total_timesteps  | 993303   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.29     |\n",
      "|    n_updates        | 248300   |\n",
      "----------------------------------\n",
      "Episode reward: 71.468871\n",
      "Episode reward: 42.881156\n",
      "Episode reward: 47.892474\n",
      "Episode reward: 59.796632\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.5     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16988    |\n",
      "|    fps              | 2728     |\n",
      "|    time_elapsed     | 364      |\n",
      "|    total_timesteps  | 993526   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.72     |\n",
      "|    n_updates        | 248356   |\n",
      "----------------------------------\n",
      "Episode reward: 66.163761\n",
      "Episode reward: 54.756991\n",
      "Episode reward: 66.223799\n",
      "Episode reward: 90.527587\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 61.6     |\n",
      "|    ep_rew_mean      | 60.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16992    |\n",
      "|    fps              | 2728     |\n",
      "|    time_elapsed     | 364      |\n",
      "|    total_timesteps  | 993808   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.15     |\n",
      "|    n_updates        | 248426   |\n",
      "----------------------------------\n",
      "Episode reward: 77.224627\n",
      "Episode reward: 83.203766\n",
      "Episode reward: 78.030296\n",
      "Episode reward: 96.942204\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.1     |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 16996    |\n",
      "|    fps              | 2728     |\n",
      "|    time_elapsed     | 364      |\n",
      "|    total_timesteps  | 994151   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.112    |\n",
      "|    n_updates        | 248512   |\n",
      "----------------------------------\n",
      "Episode reward: 56.349184\n",
      "Episode reward: 76.624646\n",
      "Episode reward: 114.721595\n",
      "Episode reward: 96.458775\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17000    |\n",
      "|    fps              | 2727     |\n",
      "|    time_elapsed     | 364      |\n",
      "|    total_timesteps  | 994497   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.433    |\n",
      "|    n_updates        | 248599   |\n",
      "----------------------------------\n",
      "Episode reward: 45.935032\n",
      "Episode reward: 45.694721\n",
      "Episode reward: 50.726987\n",
      "Episode reward: 70.989287\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17004    |\n",
      "|    fps              | 2727     |\n",
      "|    time_elapsed     | 364      |\n",
      "|    total_timesteps  | 994712   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.6      |\n",
      "|    n_updates        | 248652   |\n",
      "----------------------------------\n",
      "Episode reward: 86.445071\n",
      "Episode reward: 27.871613\n",
      "Episode reward: 83.439571\n",
      "Episode reward: 33.896754\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.8     |\n",
      "|    ep_rew_mean      | 62.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17008    |\n",
      "|    fps              | 2727     |\n",
      "|    time_elapsed     | 364      |\n",
      "|    total_timesteps  | 994945   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.845    |\n",
      "|    n_updates        | 248711   |\n",
      "----------------------------------\n",
      "Episode reward: 34.903825\n",
      "Episode reward: 37.919295\n",
      "Episode reward: 34.950302\n",
      "Episode reward: 82.732815\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 62.5     |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17012    |\n",
      "|    fps              | 2727     |\n",
      "|    time_elapsed     | 364      |\n",
      "|    total_timesteps  | 995136   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0537   |\n",
      "|    n_updates        | 248758   |\n",
      "----------------------------------\n",
      "Episode reward: 46.891131\n",
      "Episode reward: 75.586488\n",
      "Episode reward: 115.684984\n",
      "Episode reward: 94.687231\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.8     |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17016    |\n",
      "|    fps              | 2727     |\n",
      "|    time_elapsed     | 364      |\n",
      "|    total_timesteps  | 995471   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0474   |\n",
      "|    n_updates        | 248842   |\n",
      "----------------------------------\n",
      "Episode reward: 52.720382\n",
      "Episode reward: 123.3807\n",
      "Episode reward: 23.92924\n",
      "Episode reward: 48.8911\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.4     |\n",
      "|    ep_rew_mean      | 63.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17020    |\n",
      "|    fps              | 2727     |\n",
      "|    time_elapsed     | 365      |\n",
      "|    total_timesteps  | 995721   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.231    |\n",
      "|    n_updates        | 248905   |\n",
      "----------------------------------\n",
      "Episode reward: 60.12604\n",
      "Episode reward: 47.598235\n",
      "Episode reward: 77.785188\n",
      "Episode reward: 36.749784\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 64.1     |\n",
      "|    ep_rew_mean      | 63.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17024    |\n",
      "|    fps              | 2727     |\n",
      "|    time_elapsed     | 365      |\n",
      "|    total_timesteps  | 995945   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.28     |\n",
      "|    n_updates        | 248961   |\n",
      "----------------------------------\n",
      "Episode reward: 52.889922\n",
      "Episode reward: 71.701198\n",
      "Episode reward: 30.920899\n",
      "Episode reward: 59.600654\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.4     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17028    |\n",
      "|    fps              | 2727     |\n",
      "|    time_elapsed     | 365      |\n",
      "|    total_timesteps  | 996163   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0688   |\n",
      "|    n_updates        | 249015   |\n",
      "----------------------------------\n",
      "Episode reward: 79.307851\n",
      "Episode reward: 65.832245\n",
      "Episode reward: 60.529026\n",
      "Episode reward: 42.913152\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63       |\n",
      "|    ep_rew_mean      | 62.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17032    |\n",
      "|    fps              | 2727     |\n",
      "|    time_elapsed     | 365      |\n",
      "|    total_timesteps  | 996413   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.106    |\n",
      "|    n_updates        | 249078   |\n",
      "----------------------------------\n",
      "Episode reward: 110.661629\n",
      "Episode reward: 74.144984\n",
      "Episode reward: 70.47951\n",
      "Episode reward: 56.636937\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 63.3     |\n",
      "|    ep_rew_mean      | 62.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17036    |\n",
      "|    fps              | 2727     |\n",
      "|    time_elapsed     | 365      |\n",
      "|    total_timesteps  | 996729   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 249157   |\n",
      "----------------------------------\n",
      "Episode reward: 57.812331\n",
      "Episode reward: 50.341188\n",
      "Episode reward: 85.322671\n",
      "Episode reward: 169.90064\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 65.1     |\n",
      "|    ep_rew_mean      | 64.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17040    |\n",
      "|    fps              | 2727     |\n",
      "|    time_elapsed     | 365      |\n",
      "|    total_timesteps  | 997118   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.536    |\n",
      "|    n_updates        | 249254   |\n",
      "----------------------------------\n",
      "Episode reward: 37.926191\n",
      "Episode reward: 130.988369\n",
      "Episode reward: 104.406188\n",
      "Episode reward: 83.995948\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 66.7     |\n",
      "|    ep_rew_mean      | 65.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17044    |\n",
      "|    fps              | 2727     |\n",
      "|    time_elapsed     | 365      |\n",
      "|    total_timesteps  | 997488   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.104    |\n",
      "|    n_updates        | 249346   |\n",
      "----------------------------------\n",
      "Episode reward: 86.63765\n",
      "Episode reward: 116.753247\n",
      "Episode reward: 85.392326\n",
      "Episode reward: 54.811292\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 67.4     |\n",
      "|    ep_rew_mean      | 66.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17048    |\n",
      "|    fps              | 2727     |\n",
      "|    time_elapsed     | 365      |\n",
      "|    total_timesteps  | 997838   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.164    |\n",
      "|    n_updates        | 249434   |\n",
      "----------------------------------\n",
      "Episode reward: 40.884865\n",
      "Episode reward: 36.626042\n",
      "Episode reward: 110.449026\n",
      "Episode reward: 119.060371\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.1     |\n",
      "|    ep_rew_mean      | 67.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17052    |\n",
      "|    fps              | 2726     |\n",
      "|    time_elapsed     | 366      |\n",
      "|    total_timesteps  | 998148   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.163    |\n",
      "|    n_updates        | 249511   |\n",
      "----------------------------------\n",
      "Episode reward: 40.941496\n",
      "Episode reward: 76.699049\n",
      "Episode reward: 49.793824\n",
      "Episode reward: 121.434688\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.5     |\n",
      "|    ep_rew_mean      | 67.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17056    |\n",
      "|    fps              | 2726     |\n",
      "|    time_elapsed     | 366      |\n",
      "|    total_timesteps  | 998447   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.135    |\n",
      "|    n_updates        | 249586   |\n",
      "----------------------------------\n",
      "Episode reward: 79.676399\n",
      "Episode reward: 35.663578\n",
      "Episode reward: 35.80173\n",
      "Episode reward: 112.586892\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.5     |\n",
      "|    ep_rew_mean      | 67.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17060    |\n",
      "|    fps              | 2726     |\n",
      "|    time_elapsed     | 366      |\n",
      "|    total_timesteps  | 998712   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.45     |\n",
      "|    n_updates        | 249652   |\n",
      "----------------------------------\n",
      "Episode reward: 46.86608\n",
      "Episode reward: 55.329501\n",
      "Episode reward: 93.539993\n",
      "Episode reward: 39.737753\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.2     |\n",
      "|    ep_rew_mean      | 67.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17064    |\n",
      "|    fps              | 2726     |\n",
      "|    time_elapsed     | 366      |\n",
      "|    total_timesteps  | 998949   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.361    |\n",
      "|    n_updates        | 249712   |\n",
      "----------------------------------\n",
      "Episode reward: 57.917267\n",
      "Episode reward: 57.915203\n",
      "Episode reward: 51.926989\n",
      "Episode reward: 92.38183\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.9     |\n",
      "|    ep_rew_mean      | 67.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17068    |\n",
      "|    fps              | 2726     |\n",
      "|    time_elapsed     | 366      |\n",
      "|    total_timesteps  | 999210   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.128    |\n",
      "|    n_updates        | 249777   |\n",
      "----------------------------------\n",
      "Episode reward: 77.510289\n",
      "Episode reward: 83.10889\n",
      "Episode reward: 63.768341\n",
      "Episode reward: 52.626464\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 69.2     |\n",
      "|    ep_rew_mean      | 68.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17072    |\n",
      "|    fps              | 2726     |\n",
      "|    time_elapsed     | 366      |\n",
      "|    total_timesteps  | 999490   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.153    |\n",
      "|    n_updates        | 249847   |\n",
      "----------------------------------\n",
      "Episode reward: 61.449708\n",
      "Episode reward: 62.734368\n",
      "Episode reward: 62.608527\n",
      "Episode reward: 31.899074\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 68.8     |\n",
      "|    ep_rew_mean      | 67.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 17076    |\n",
      "|    fps              | 2726     |\n",
      "|    time_elapsed     | 366      |\n",
      "|    total_timesteps  | 999710   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.547    |\n",
      "|    n_updates        | 249902   |\n",
      "----------------------------------\n",
      "Episode reward: 50.14623\n",
      "Episode reward: 127.642093\n",
      "Episode reward: 84.794193\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"DualCartPole-v4\", render_mode=\"rgb_array\")\n",
    "print(env.observation_space.shape)  # Should print (6,)\n",
    "\n",
    "# Play around with a custom reward function\n",
    "class CustomReward(gym.RewardWrapper):\n",
    "    \"\"\"\n",
    "    Custom reward function for the cart pole environment\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    \n",
    "    def reward(self, reward):\n",
    "        # Get the current state\n",
    "        state = self.unwrapped.state\n",
    "\n",
    "        # Unpack the state\n",
    "        x, x_dot, theta1, theta1_dot, theta2, theta2_dot = state\n",
    "\n",
    "        # Reward\n",
    "        reward = (\n",
    "            1.0 - (x) - 0.01 * (x_dot) - 0.001\n",
    "        )\n",
    "        return reward\n",
    "\n",
    "\n",
    "class RewardCallback(BaseCallback):\n",
    "    def _on_step(self) -> bool:\n",
    "        infos = self.locals.get(\"infos\", [])\n",
    "        for info in infos:\n",
    "            if \"episode\" in info:\n",
    "                print(f\"Episode reward: {info['episode']['r']}\")\n",
    "        return True\n",
    "\n",
    "\n",
    "# Set the wrapper\n",
    "env = CustomReward(env)\n",
    "env = Monitor(env)\n",
    "\n",
    "# Create and train the PPO model\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=2000000, callback=RewardCallback())\n",
    "model.save(\"dqn_cartpole\")\n",
    "\n",
    "# Delete and reload the model\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[0;32m---> 16\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     obs, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     18\u001b[0m     done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/AIEnvironment/lib/python3.12/site-packages/stable_baselines3/dqn/dqn.py:246\u001b[0m, in \u001b[0;36mDQN.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39mOverrides the base_class predict function to include epsilon-greedy exploration.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39m    (used in recurrent policies)\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m deterministic \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand() \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexploration_rate:\n\u001b[0;32m--> 246\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy\u001b[39m.\u001b[39;49mis_vectorized_observation(observation):\n\u001b[1;32m    247\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(observation, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    248\u001b[0m             n_batch \u001b[39m=\u001b[39m observation[\u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(observation\u001b[39m.\u001b[39mkeys()))]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/AIEnvironment/lib/python3.12/site-packages/stable_baselines3/common/policies.py:231\u001b[0m, in \u001b[0;36mBaseModel.is_vectorized_observation\u001b[0;34m(self, observation)\u001b[0m\n\u001b[1;32m    229\u001b[0m         vectorized_env \u001b[39m=\u001b[39m vectorized_env \u001b[39mor\u001b[39;00m is_vectorized_observation(maybe_transpose(obs, obs_space), obs_space)\n\u001b[1;32m    230\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     vectorized_env \u001b[39m=\u001b[39m is_vectorized_observation(\n\u001b[1;32m    232\u001b[0m         maybe_transpose(observation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobservation_space), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobservation_space\n\u001b[1;32m    233\u001b[0m     )\n\u001b[1;32m    234\u001b[0m \u001b[39mreturn\u001b[39;00m vectorized_env\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/AIEnvironment/lib/python3.12/site-packages/stable_baselines3/common/utils.py:404\u001b[0m, in \u001b[0;36mis_vectorized_observation\u001b[0;34m(observation, observation_space)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[39mfor\u001b[39;00m space_type, is_vec_obs_func \u001b[39min\u001b[39;00m is_vec_obs_func_dict\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(observation_space, space_type):\n\u001b[0;32m--> 404\u001b[0m         \u001b[39mreturn\u001b[39;00m is_vec_obs_func(observation, observation_space)  \u001b[39m# type: ignore[operator]\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    406\u001b[0m     \u001b[39m# for-else happens if no break is called\u001b[39;00m\n\u001b[1;32m    407\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError: Cannot determine if the observation is vectorized with the space type \u001b[39m\u001b[39m{\u001b[39;00mobservation_space\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/AIEnvironment/lib/python3.12/site-packages/stable_baselines3/common/utils.py:266\u001b[0m, in \u001b[0;36mis_vectorized_box_observation\u001b[0;34m(observation, observation_space)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_vectorized_box_observation\u001b[39m(observation: np\u001b[39m.\u001b[39mndarray, observation_space: spaces\u001b[39m.\u001b[39mBox) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m    258\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39m    For box observation type, detects and validates the shape,\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[39m    then returns whether or not the observation is vectorized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[39m    :return: whether the given observation is vectorized or not\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m     \u001b[39mif\u001b[39;00m observation\u001b[39m.\u001b[39;49mshape \u001b[39m==\u001b[39m observation_space\u001b[39m.\u001b[39mshape:\n\u001b[1;32m    267\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     \u001b[39melif\u001b[39;00m observation\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:] \u001b[39m==\u001b[39m observation_space\u001b[39m.\u001b[39mshape:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "env = gym.make(\"DualCartPole-v4\", render_mode=\"human\")  # \"human\" for real-time visualization\n",
    "model = DQN.load(\"dqn_cartpole\")\n",
    "\n",
    "episodes = 0\n",
    "while episodes < 10:\n",
    "    obs, _ = env.reset()\n",
    "\n",
    "    # Override internal state\n",
    "    env.unwrapped.state = [0.5, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "    # Also update observation if needed\n",
    "    obs = env.unwrapped.state\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "    episodes += 1\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.7 ('AIEnvironment')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "899f62d5093901655dee430c4b450c89a6dffaa1318f963d73f002151556cc67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
